[
  {
    "id": "6e46ece5-1997-4c6e-bae3-844f3f8e0ebd",
    "created_at": "2025-07-26T15:28:57.314863+00:00",
    "source_type": "local",
    "source_path": "templates/projects.html",
    "title": "Majid Khoshrou - Projects",
    "external_links": {
      "OpenSTEF": "https://github.com/OpenSTEF/openstef"
    },
    "text": "Majid Khoshrou - Projects Projects Below are selected projects demonstrating my work in machine learning, forecasting, and applied AI. Powering Smarter Market Forecasts ‚Äî Day-Ahead Allocation at Alliander Since June 2024, I've been part of the Short-Term Energy Forecasts (STEF) team at Alliander, where I focus on improving allocation forecasts for the day-ahead energy market. By refining core models, fixing legacy bugs, and introducing high-impact predictors, I helped boost forecast accuracy by 30% ‚Äî leading to over ‚Ç¨1.3 million in annual cost savings. The outcomes of this work were integrated into OpenSTEF, Alliander's open-source forecasting library, enhancing its robustness and usability. This project directly supported the Market Services (Marketdiensten) team, enabling more data-driven decision-making in grid operations and market planning. Data-Driven Risk Modeling for Medium Voltage Grid Reliability As a Data Consultant in the Power Flow Analysis Team at Alliander in 2023, I developed a framework to assess risk across medium voltage (MV) grid routes. We analyzed and ranked available data sources to create a scoring system that identified high-risk segments. I also built statistical models to quantify reliability threats and standardized model validation practices across teams. This work enabled consistent performance tracking and informed strategic decisions on grid maintenance and targeted sensor deployment. Your browser does not support the video tag. Carbon Impact Metrics Created tools to assess the carbon footprint of server clusters, influencing sustainability reporting.",
    "token_count": 305,
    "chunk_id": "6e46ece5-1997-4c6e-bae3-844f3f8e0ebd_1"
  },
  {
    "id": "0b6e683b-23d5-4241-bab0-e43de7e2d40d",
    "created_at": "2025-07-26T15:28:57.320462+00:00",
    "source_type": "local",
    "source_path": "templates/ask-mr-m.html",
    "title": "Majid Khoshrou - Ask Mr. M",
    "external_links": {},
    "text": "Majid Khoshrou - Ask Mr. M Talk to Mr. M ‚Äî Your AI Assistant Mr. M is Majid's custom-trained AI assistant. Curious about my research, background, or projects? Just ask! Example questions: ‚ÄúWhat are Majid‚Äôs latest publications?‚Äù, ‚ÄúTell me about his work at Alliander‚Äù, ‚ÄúWhat projects has he done in energy forecasting?‚Äù Hello! I'm Mr. M, Majid‚Äôs professional AI assistant. Ask me anything about his background, work, research, or publications. Send",
    "token_count": 110,
    "chunk_id": "0b6e683b-23d5-4241-bab0-e43de7e2d40d_1"
  },
  {
    "id": "cdb15be8-efa8-4222-940c-70e1fdc870f6",
    "created_at": "2025-07-26T15:28:57.323220+00:00",
    "source_type": "local",
    "source_path": "templates/contact.html",
    "title": "Majid Khoshrou - Contact",
    "external_links": {
      "linkedin.com/in/majid-khoshrou": "https://www.linkedin.com/in/majid-khoshrou-a2728349/",
      "github.com/majidkhoshrou": "https://github.com/majidkhoshrou"
    },
    "text": "Majid Khoshrou - Contact Contact Me If you‚Äôd like to connect, discuss collaboration opportunities, or have any questions, feel free to reach out: Email: majid.khoshrou@gmail.com LinkedIn: linkedin.com/in/majid-khoshrou GitHub: github.com/majidkhoshrou",
    "token_count": 65,
    "chunk_id": "cdb15be8-efa8-4222-940c-70e1fdc870f6_1"
  },
  {
    "id": "5ef6dc60-6b37-4b01-8731-8404af7dd126",
    "created_at": "2025-07-26T15:28:57.325697+00:00",
    "source_type": "local",
    "source_path": "templates/research.html",
    "title": "Majid Khoshrou - Research & Publications",
    "external_links": {},
    "text": "Majid Khoshrou - Research & Publications Research & Publications Below are selected publications, loaded dynamically from structured data.",
    "token_count": 24,
    "chunk_id": "5ef6dc60-6b37-4b01-8731-8404af7dd126_1"
  },
  {
    "id": "bd476ff7-c227-4ca0-bfe4-8eb1c238c40d",
    "created_at": "2025-07-26T15:28:57.327757+00:00",
    "source_type": "local",
    "source_path": "templates/about.html",
    "title": "Majid Khoshrou - About Me",
    "external_links": {
      "Ghaemshahr, Mazandaran": "https://en.wikipedia.org/wiki/Ghaemshahr",
      "‚Äôs-Hertogenbosch": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
      "Alliander": "https://www.alliander.com/en/",
      "Arnhem": "https://en.wikipedia.org/wiki/Arnhem",
      "OpenSTEF": "https://github.com/OpenSTEF/openstef",
      "energy forecasting paper": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf"
    },
    "text": "Majid Khoshrou - About Me About Me I am a Data Scientist with over a decade of combined experience in industry and academia. My work focuses on applying machine learning, forecasting, and real-time analytics to domains including energy systems, urban mobility, and sustainability. I am originally from Ghaemshahr, Mazandaran in northern Iran ‚Äî a lush region by the Caspian Sea, known for its rice fields, citrus orchards, and proximity to the Alborz mountains. It‚Äôs a place where nature meets tradition, and it continues to inspire my values and curiosity. I currently live in ‚Äôs-Hertogenbosch, Netherlands, and work as a Senior Data Scientist at Alliander in Arnhem. Professional Summary Throughout my career, I have delivered solutions in time series analysis, probabilistic modeling, and anomaly detection. I am passionate about building scalable AI systems and making impactful contributions to open-source initiatives like OpenSTEF. Skills & Technologies Python, SQL, MATLAB, PySpark Machine Learning: scikit-learn, TensorFlow, PyTorch, XGBoost Cloud Platforms: AWS, GCP, Azure Data Visualization: Power BI, Tableau, Matplotlib Time Series Forecasting & Anomaly Detection Education PhD in Artificial Intelligence ‚Äì CWI and Delft University of Technology (2015‚Äì2022) MSc in Information Engineering ‚Äì University of Porto (2012‚Äì2015) BSc in Electrical Power Engineering ‚Äì Babol Noshirvani University of Technology (2007‚Äì2011) link to a paper external source: energy forecasting paper Explore Research & Publications Peer-reviewed work in time series, forecasting, and smart energy systems. Learn More Projects Real-world applications and open-source contributions. View Projects Talks Invited talks, lectures, and recorded presentations. Watch Talks Where I'm From & Where I Live A global view connecting Ghaemshahr, Iran and ‚Äôs-Hertogenbosch, Netherlands.",
    "token_count": 395,
    "chunk_id": "bd476ff7-c227-4ca0-bfe4-8eb1c238c40d_1"
  },
  {
    "id": "70665305-6387-4273-86b4-fdd5085c2a2f",
    "created_at": "2025-07-26T15:28:57.332252+00:00",
    "source_type": "local",
    "source_path": "templates/talks.html",
    "title": "Majid Khoshrou - Talks",
    "external_links": {},
    "text": "Majid Khoshrou - Talks Talks & Presentations Here you can find selected talks and presentations I have delivered. PhD Defense ‚Äì Singular Value Decomposition for Time Series Analysis in Smart Energy Systems Your browser does not support the video tag. Defense date: December 19, 2022 Institution: Delft University of Technology & Centrum Wiskunde & Informatica Upcoming / Recent Talks Below is a placeholder for future talks and presentations. As more events occur, I will update this section with recordings, slides, and summaries. Biweekly stakeholder meetings (internal, not recorded). Future invited seminars and webinars.",
    "token_count": 126,
    "chunk_id": "70665305-6387-4273-86b4-fdd5085c2a2f_1"
  },
  {
    "id": "78000bb7-14c4-4de4-a1a1-cabedf3af8ee",
    "created_at": "2025-07-26T15:28:57.334497+00:00",
    "source_type": "local",
    "source_path": "templates/analytics.html",
    "title": "Majid Khoshrou - Analytics",
    "external_links": {},
    "text": "Majid Khoshrou - Analytics Visitor Analytics Total Visits: Loading... VPN Users: ... | Unknown Country: ... Visitor Locations Daily Visits Device Types",
    "token_count": 32,
    "chunk_id": "78000bb7-14c4-4de4-a1a1-cabedf3af8ee_1"
  },
  {
    "id": "f10c0c6b-8f93-4c0c-993f-5bbbbe6aacc2",
    "created_at": "2025-07-26T15:28:57.336804+00:00",
    "source_type": "local",
    "source_path": "templates/index.html",
    "title": "Majid Khoshrou - Home",
    "external_links": {},
    "text": "Majid Khoshrou - Home Hello & Welcome I'm Majid ‚Äî a Data Scientist passionate about leveraging machine learning, forecasting, and real-time analytics to create sustainable and intelligent systems. üîπ 10+ years in data science (industry + academia) üîπ Specializing in energy systems, urban mobility, and AI üîπ Open-source contributor to OpenSTEF üîπ PhD from TU Delft & CWI Download CV Contact Me Explore Research & Publications Peer-reviewed work in time series, forecasting, and smart energy systems. Learn More Projects Real-world applications and open-source contributions. View Projects Talks Invited talks, lectures, and recorded presentations. Watch Talks",
    "token_count": 133,
    "chunk_id": "f10c0c6b-8f93-4c0c-993f-5bbbbe6aacc2_1"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": "Propagating Uncertainty in Tree-Based Load Forecasts Abdolrahman Khoshrou, Eric J. Pauwels Centrum Wiskunde & Informatica, The Netherlands a.khoshrou@cwi.nl, eric.pauwels@cwi.nl Abstract This paper discusses the use of ensembles of regres- sion trees as a straightforward but versatile method- ology to generate short term (day-ahead) load fore- casts for real data from the Global Energy Forecast- ing Competition 2014. Since temperature is a strong predictor of load, we investigate how forecast uncer- tainty in temperature can affect the performance of the prediction model. To this end, a singular value decomposition (SVD) based approach is harnessed to simulate noisy but realistic temperature proÔ¨Åles. Our results show that as long as uncertainty is not exceedingly large, it is worthwhile to include tem- perature forecasts as predictors. 1. Introduction and Related Work Due to the increasing integration of intermittent re- newable energy sources and the lack of affordable large scale storage, balancing electricity supply and demand is becoming more challenging. Consequently, in to- day‚Äôs competitive and dynamic environment, an accu- rate load forecast is highly desirable both from a tech- nical and an economic point of view. Indeed, without accurate forecasts, issues like increasing rates, brown- outs or even black-outs are inevitable [1]. Depending on the time horizons, the prediction of the power (load) distribution is classiÔ¨Åed into short, medium and long term forecasting. The context of more than a couple of months to years in load predic- tion is studied in long term load forecasting (LTLF). It mainly assists in planning on setting up new power plants. Medium term load forecasting (MTLF) is asso- ciated with forecasts targeting few weeks to few months ahead, whereas short term load forecasting (STLF) deals with load estimations for the next few hours to few days. The former is usually done for balance sheet calculations, risk management, purchasing energy and pricing plans. The latter plays a key role in unit com- mitment and load dispatching. In this paper in addition to proposing a novel STLF method, the effect of un- certainty in the predictors on the performance of the proposed model is investigated. In the recent literature, there are numerous methods to forecast electricity load over different time horizons. This work was supported in part",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_1"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": " a novel STLF method, the effect of un- certainty in the predictors on the performance of the proposed model is investigated. In the recent literature, there are numerous methods to forecast electricity load over different time horizons. This work was supported in part by the Dutch STW un- der project grant Smart Energy Management and Services in Buildings and Grids (SES-BE). ArtiÔ¨Åcial intelligence (AI) based methods such as arti- Ô¨Åcial neural network [2], support vector machines [3] and fuzzy methods [4] are popular, mostly due to their robustness and ability to tackling the non-linearity be- tween predictors and the target variables. Statistical methods, on the other hand, are mostly popular in the econometric studies, due to the interpretability of their results. Members of this category include regression models, autoregressive models, heteroskedastic mod- els and so on. A bi-level prediction strategy for STLF of micro grids using evolutionary algorithm and neural networks is proposed in [5]. The reported work has the advantage of using an enhanced differential evolution algorithm in upper level to optimize the performance of the forecaster in lower level. In [6], a self organiz- ing map (SOM) approach is introduced to group the load proÔ¨Åles in an unsupervised manner. Each iden- tiÔ¨Åed cluster is then fed to individual support vector regression (SVR) models to predict the daily proÔ¨Åle. Recently, modeling and forecasting the trend-seasonal components and probabilistic (beyond point) forecasts have attracted a lot of attention [7]. Problem statement and contribution As brieÔ¨Çy ex- plained, numerous prediction techniques have been ap- plied to STLF problem. In the present work, we opt for a relatively simple yet versatile technique: ensem- bles of regression trees, as they are better suited to ad- dress the heterogeneity of the data (see e.g., [8]). Due to the characteristics of the available data, it is particularly advantageous to include temperature as a predictor. It is therefore of great interest to investigate how sensi- tive the results are to the noise level in this input vari- able. To model this uncertainty, we expand the avail- able temperature time series in data-driven orthogonal components for which the simulation becomes straight- forward. 2. Data To demonstrate the robustness of the proposed method and to make the results",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_2"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": " vari- able. To model this uncertainty, we expand the avail- able temperature time series in data-driven orthogonal components for which the simulation becomes straight- forward. 2. Data To demonstrate the robustness of the proposed method and to make the results reproducible, a case study was constructed based on publicly available data (average temperature and aggregated load) from the Global Energy Forecasting Competition 2014 (GEF- Com2014) [7]. The challenge in this competition was to construct a probabilistic forecast of the (aggregated) load. Our focus nonetheless is on developing a point 0 5 10 15 20 25 Hour-slot 100 110 120 130 140 150 160 170 180 190 Load (MW) Typical summer profile Typical winter profile Figure 1. Top: scatter plot of the load vs. temperature (in 2009). An ad-hoc customized polynomial (f(T) = 0.002T 3 ‚àí0.16T 2 ‚àí0.37T + 318.1) is superimposed on that. Bottom: comparison of the typical daily load proÔ¨Åles in winter and summer times. forecasting method. Obviously, to design a forecasting model, load history is needed. A large portion of the electricity is being used by the heating and cooling sys- tems in the winter and summer times. Consequently, load is considerably lower in spring and autumn as the temperature is more moderate. This aspect of the data is clearly visible in the top panel of Fig. 1. The depen- dence on temperature is also responsible for the sub- stantial change in the load proÔ¨Åles over the year as il- lustrated in the bottom panel of Fig. 1. Furthermore, the consumption patterns also change based on the work schedule, hours of the day, days of the week, and so on. Therefore, calendar information, holidays, and spe- cial event information are also of great value. Although temperature is an important (perhaps, the most impor- tant) predictor of load there are a number of reasons why, in and of itself, it is not sufÔ¨Åcient: 1. As can be seen from the data analysis, load pat- terns during week and weekend days are sub- stantially different. This reÔ¨Çection of human ac- tivity is of course absent in the weather",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_3"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": ": 1. As can be seen from the data analysis, load pat- terns during week and weekend days are sub- stantially different. This reÔ¨Çection of human ac- tivity is of course absent in the weather patterns. One can hence expect that the same temperature will result in different load patterns depending on whether we are looking at a week or week- end day. 2. Path dependence: Similar temperatures might also result in different behaviour depending on the immediately preceding situation. For in- stance, relatively high temperatures in early spring might not result in massive AC activa- tion since people might welcome the change in weather after a cold winter. This would be very different in the summer or autumn. As explained before, the overall relationship between Figure 2. Residuals of the Ô¨Åtted custom polynomial in the top panel of Fig. 1. load and temperature is clear: high and low tempera- tures require more cooling or heating respectively, and therefore result in higher loads (top panel of Fig. 1). However, it is plain to see that the polynomial Ô¨Åts do not sensibly capture the shape of the observed relationship (Fig. 2) and a more complex model is needed. Before explaining the methodology in Section 4, a brief intro- duction to singular value decomposition (SVD) tech- nique is brought in Section 3. Its importance lies in the fact that, SVD was used to generate new temperature proÔ¨Åles for uncertainty quantiÔ¨Åcation purposes (Sec- tion 4.3). We conclude our work in Section 5. 3. SVD-Based Representation of the Data Time series data in smart energy systems often show two (or more) distinct time scales. The data exhibit strong diurnal patterns reÔ¨Çecting the daily (or weekly) rhythms of human activities. Apart from that, these relatively fast diurnal patterns are superimposed on slower seasonal variations that have a signiÔ¨Åcant im- pact on the overall structure of the data. Recasting such a time series as a matrix, in which each column repre- sents the data for a single day, can be helpful in gaining more insight into the data. The advantage of this re- casting is two-fold. First, the resulting matrix can be displayed as an image, allowing one to scrutinize sub- tle or faint features. Second, one can",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_4"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": " be helpful in gaining more insight into the data. The advantage of this re- casting is two-fold. First, the resulting matrix can be displayed as an image, allowing one to scrutinize sub- tle or faint features. Second, one can draw on well- established matrix decomposition methods to elucidate underlying data structure. To illustrate the latter point using the data at hand, let‚Äôs take one year‚Äôs worth of ag- gregated hourly load values (L say). We can then recast L as a matrix in which each column represent the data for a single day (i.e. L ‚ààR24√ó365). As a consequence, the matrix L can be satisfactorily represented by a low-rank approximation. Singular value decomposition (SVD) provides us with an efÔ¨Åcient algorithm to com- pute such low-rank approximations [9]. More speciÔ¨Å- cally, given an arbitrary h √ó d matrix A ‚ààRh√ód, there exists orthogonal matrices U ‚ààRh√óh and V ‚ààRd√ód (both with orthonormal columns) such that: A = USV T = r X k=1 œÉkUkV T k (1) where S has the same size as A, and its non-zero ele- ments (singular values: œÉ1 ‚â•œÉ2 ‚â•. . . ‚â•œÉr ‚â•0) are 5 10 15 20 200 400 600 800 1000 1200 Temperature: singular values 5 10 15 20 500 1000 1500 2000 2500 3000 Load: singular values Figure 3. Singular values obtained for load and temper- ature daily proÔ¨Åles in 2009 (zero annual mean values). Temperature values (top) suggest that a reconstruction of rank-3 approximation would sufÔ¨Åce, indicating that temperature is quite regular. Load (bottom) on the other hand, requires a rank-4 or 5 approximation. uniquely positioned on the main diagonal, in descend- ing order. Furthermore, Uk and Vk denote the kth col- umn of U and V , respectively, and r = min{h, d} (see e.g. [9]). If there is only a small number of dominant singular values (as is the case for the load and temper- ature data in Fig. 3), then the expansion in (1",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_5"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": "{h, d} (see e.g. [9]). If there is only a small number of dominant singular values (as is the case for the load and temper- ature data in Fig. 3), then the expansion in (1) can be truncated after the Ô¨Årst few terms to yield an adequate approximation Ap of (lower) rank p: Ap = p X k=1 œÉkUkV T k where p < r. (2) To elaborate more, Fig. 4 illustrates a plot of the Ô¨Årst three columns of Uk (left) and Vk (right) for the 2009 hourly temperature data. The columns Uk can be in- terpreted as daily proÔ¨Åles and successive increments, while the coefÔ¨Åcients of Vk represent the correspond- ing scaling factors. Put differently, the original time se- ries is represented as a linear combination of the (data- driven) proÔ¨Åles speciÔ¨Åed by the columns of U while the V columns provide the corresponding coefÔ¨Åcients. For instance, looking at Ô¨Ågure, we clearly recognize in U1 (top left panel) an averaged daily temperature proÔ¨Åle, whereas the corresponding coefÔ¨Åcients in V1 outline daily temperature evolution over the year (top right panel). The middle panels display the most dom- inant corrective incremental proÔ¨Åle U2 (left) and the corresponding coefÔ¨Åcients V2 (right) which needs to be added to the Ô¨Årst proÔ¨Åle to get a better approximation. Similarly for the third proÔ¨Åle (bottom). Looking at the right column one gets the distinct impression that tem- peratures are less variable during the summer (middle parts). In Section 4.3 we will use this decomposition to investigate how uncertainty affects the forecasting re- sults. 5 10 15 20 0.2 0.22 U1 100 200 300 0.02 0.04 0.06 V 1 5 10 15 20 -0.2 0 0.2 U2 100 200 300 -0.1 0 0.1 V 2 5 10 15 20 -0.2 0 0.2 0.4 U3 100 200 300 -0.1 0",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_6"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": "300 -0.1 0 0.1 V 2 5 10 15 20 -0.2 0 0.2 0.4 U3 100 200 300 -0.1 0 0.1 0.2 V 3 Figure 4. SVD-based decomposition of hourly tem- perature data for 2009. Left column are the Ô¨Årst three columns Uk whereas the right column shows the corre- sponding Vk‚Äôs. 4. Prediction using Tree Ensembles After the data exploration above, this section fo- cuses on our approach to the point (single-valued) fore- casting problem. We have opted to use an ensemble of regression trees to predict the daily load prognoses given the daily temperature proÔ¨Åles, date and time. The rationale underpinning this choice is that trees are well suited to handle the heterogeneous input data which comprise both continuous and discrete variables. In ad- dition, tree models are modular in that new predictors can easily be added. Furthermore, it is well-known that ensemble models are less prone to overÔ¨Åtting. So, tree ensemble models promise to strike a good balance be- tween Ô¨Çexibility and generalizability. 4.1. Basic methodology The individual (weakly trained) regression trees in the ensemble are constructed using least-squares boost- ing method [10]. We have tried three different models (see below), which all have been trained on years 2005 through 2009, and tested on the data from 2010. In all of the following cases, the aim is to predict the 24 hourly load values for the next day d (L(d)). The com- mon inputs in all three models are discrete values such as month of the year (M ‚àà[1 : 12]), day of the week (W ‚àà[1 : 7]), and hour of the day (H ‚àà[1 : 24]). Furthermore, we assume that the load and temperature proÔ¨Åles for the previous day (d ‚àí1) are also available. Model 1: The Ô¨Årst case, we only use information which is available on day d ‚àí1. In particular, we do not use the predicted temperature proÔ¨Åle for day d. This provides us with a baseline performance gain which we will gauge the next models. Predictors: [M, W, H",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_7"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": " available on day d ‚àí1. In particular, we do not use the predicted temperature proÔ¨Åle for day d. This provides us with a baseline performance gain which we will gauge the next models. Predictors: [M, W, H, L(d ‚àí1), T(d ‚àí1)]. Model 2: In this and the next model we do use the actual(!) temperature proÔ¨Åle T(d) to predict the load on that day. The rationale for this is that fairly accurate temperature predictions for day d are available on day d ‚àí1. Furthermore, in Section 4.3 we will try and quantify the amount of additional uncertainty this assumption can introduce in the forecast. Predictors: [M, W, H, L(d ‚àí1), T(d ‚àí 1), T(d)]. Model 3: This model expands the previous one by adding Ô¨Årst and second derivatives of the temperature and load proÔ¨Åles. The thinking behind this ex- pansion of variables is that oftentimes the ac- tual values are not as important as the general underlying trend ((.)‚Ä≤: Ô¨Årst derivative) or trend changes ((.)‚Ä≤‚Ä≤: second derivative). Predictors: [M, W, H, L(d ‚àí1), L‚Ä≤(d ‚àí1), L‚Ä≤‚Ä≤(d ‚àí1), T(d ‚àí1), T ‚Ä≤(d ‚àí1), T ‚Ä≤‚Ä≤(d ‚àí1), T(d), T ‚Ä≤(d), T ‚Ä≤‚Ä≤(d)]. 4.2. Experimental Results The accuracy of the forecasts is evaluated using a conventional method, i.e., the mean average percentage error (MAPE): MAPE = 1 n n X t=1 ÀÜyt ‚àíyt yt (3) where yt is the hourly value of the load proÔ¨Åle from GEFComp2014 timeseries and ÀÜyt is the correspond- ing forecast value (using one of the models speciÔ¨Åed above). Table 1. MAPE (in %) results for the three models Train (2005-9) Test (2010) Model 1 (24 hrs) 9.57 10.35 Model 2 (24 hrs) 4.42 5.06 Model 3 (24 hrs) 3.95 4.81 4.3. Sensitivity to Uncertainty on Temperature Forecasts As pointed out above, we",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_8"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": " Model 2 (24 hrs) 4.42 5.06 Model 3 (24 hrs) 3.95 4.81 4.3. Sensitivity to Uncertainty on Temperature Forecasts As pointed out above, we have used the tempera- ture proÔ¨Åles for the next day as a proxy for the temper- ature forecasts. For that reason the error rates reported in Table 1 are over-optimistic and we need to attempt to quantify the extra amount of uncertainty that results from using forecasts rather than actual values. Unfortunately we do not have access to the historic forecast data, and it is therefore difÔ¨Åcult to quantify the corresponding amount of uncertainty directly. To inves- tigate how sensitive our results are to additional uncer- tainty, we therefore add noise to the input temperature proÔ¨Åles and feed these perturbed inputs into the tree en- semble, upon which we can compute the corresponding change in MAPE. However, simply adding independent Gaussian noise to the hourly values of individual tem- perature curves results in unrealistically jagged proÔ¨Åles. -0.2 -0.1 0 0.1 0.2 0 20 40 60 80 100 5 10 15 20 Hour-slot 72 74 76 78 80 82 Date: 2010-10-27 Figure 5. Top: Histogram of the V2 coefÔ¨Åcients for the 2009 temperature data (365 values). Note that the dis- tribution is approximately normal with zero mean and std(V2) ‚âà0.05. Bottom: Twenty examples of gen- erated noisy temperature proÔ¨Åles. The solid line is the actual proÔ¨Åle. Noise was generated by tweaking the V2, V3 and V4 coefÔ¨Åcients to which we added indepen- dent N(0, «´2) noise (with «´ = 0.01). We therefore propose to use the SVD decomposition results to create realistic noise. From the training set (covering 2005 through 2009) we know that the singu- lar values œÉk as well as the daily (incremental) proÔ¨Åles Uk show negligible change over the years. So we can reuse them for the test year 2010. The real variation is in the coefÔ¨Åc",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_9"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": "u- lar values œÉk as well as the daily (incremental) proÔ¨Åles Uk show negligible change over the years. So we can reuse them for the test year 2010. The real variation is in the coefÔ¨Åcients Vk which behave much more errat- ically from day to day (Fig. 4). So in order to create noisy temperature proÔ¨Åles we proceed as follows: 1. For each of the coefÔ¨Åcients V2 through V4 we estimate the corresponding standard deviation sk = std(Vk). The histogram for V2 is shown in the top panel of Fig. 5, which shows that s2 ‚âà0.05. In fact, from the data analysis it turns out that all three standard variations s2 through s4 have similar values of about 0.05. (Recall however that the contribution to the Ô¨Ånal proÔ¨Åle is scaled up or down by the corresponding sin- gular value for which we know: œÉ2 > œÉ3 > œÉ4). 2. Next, for any particular day d in the test year for which we want a forecast, we take the ac- tual temperature proÔ¨Åle for that day T = T(d), compute the corresponding SVD coefÔ¨Åcients v0 1, v0 2 . . . v0 4 and then perturb them by adding zero-mean Gaussian noise: vn k = v0 k+N(0, «´2). These perturbed SVD coefÔ¨Åcients are then used to reconstruct a noisy version of the temperature proÔ¨Åle. An example (for 20 different noise sam- ples) is shown in the lower panel of Fig. 5. 0 0.05 0.1 0.15 0.2 Sigma of Error 0 5 10 15 20 MAPE test MAPE: model 2 MAPE: model 3 Figure 6. Impact on MAPE (for models 2 and 3) of uncertainty on temperature proÔ¨Åle. The x-axis displays the standard deviation «´ of the Gaussian noise applied to the V2 : V4 coefÔ¨Åcients. Notice how model 3 is doing slightly worse than model 2 for large values of «´. 3. To quantify the effect of temperature uncertainty on the forecast results we generate for",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_10"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": " the V2 : V4 coefÔ¨Åcients. Notice how model 3 is doing slightly worse than model 2 for large values of «´. 3. To quantify the effect of temperature uncertainty on the forecast results we generate for each ac- tual day proÔ¨Åle T(d) one hundred perturbed pro- Ô¨Åles according to the scheme outlined above. All of these proÔ¨Åles are fed into the prediction model and the forecasts are duly compared to the actually observed values. This allows us to compute the corresponding MAPEs. 4. For completeness‚Äô sake, we point out that we did not perturb V1 as this is a proxy of the average temperature on a particular day, for which uncer- tainty is negligible. Similarly, there is little to be gained from perturbing higher order coefÔ¨Åcients (V5 etc) as their impact on the proÔ¨Åle is slight. The results of these experiments (for models 2 and 3) are shown in Fig. 6, where we plot MAPE as a function of the standard deviation «´ of the Gaussian noise imposed on the SVD coefÔ¨Åcients V2 through V4. When there is no uncertainty (i.e. «´ = 0) the results for both models are the ones reported in Table 1 (i.e. MAPE ‚âà5). Increasing «´ to about 0.05 (the standard deviation seen in the training data) inÔ¨Çates the MAPE of both models to about 7.5. Furthermore, the MAPEs attain a value of 10 for «´ ‚âà0.1 which means that for that amount of noise it is no longer advantageous to in- clude a temperature forecast as a predictor. Put differ- ently, models 2 and 3 are then doing worse than the baseline model 1. Finally, for even larger values of «´ model 3 does slightly worse than model 2. This is probably due to the inclusion of derivatives in model 3, which are well-known to be more sensitive to noise. 5. Conclusion and Future work In this paper we discussed the use of ensembles of regression trees as a straightforward but versatile methodology to generate short term (day-ahead) load forecast for real data from the Global Energy Forecast- ing Competition 2014 . Since load strongly depends on temperature",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_11"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": " In this paper we discussed the use of ensembles of regression trees as a straightforward but versatile methodology to generate short term (day-ahead) load forecast for real data from the Global Energy Forecast- ing Competition 2014 . Since load strongly depends on temperature (heating and cooling), performance of the prediction models is signiÔ¨Åcantly boosted if tempera- ture is included as a predictor. However, for real-time day-ahead prediction, actual temperatures are not avail- able, only forecasts. We therefore investigated how un- certainty on the temperature forecasts affects the per- formance of the prediction model. To this end, we in- troduced an SVD-based noise model and showed that as long as uncertainty is below a certain threshold, it is worthwhile to include temperature forecasts as predic- tors. We intend to extend this methodology towards a larger class of probabilistic load forecasting tasks. 6. References [1] T. Hong et al., ‚ÄúEnergy forecasting: Past, present, and future,‚Äù Foresight: The International Journal of Applied Forecasting, no. 32, pp. 43‚Äì48, 2014. [2] K. A. Keitsch and T. Bruckner, ‚ÄúModular electri- cal demand forecasting framework-a novel hybrid model approach,‚Äù in Systems, Signals & Devices (SSD), 2016 13th International Multi-Conference on. IEEE, 2016, pp. 454‚Äì458. [3] E. Ceperic, V. Ceperic, and A. Baric, ‚ÄúA strategy for short-term load forecasting by support vec- tor regression machines,‚Äù IEEE Transactions on Power Systems, vol. 28, no. 4, pp. 4356‚Äì4364, 2013. [4] A. Badri, Z. Ameli, and A. M. Birjandi, ‚ÄúApplica- tion of artiÔ¨Åcial neural networks and fuzzy logic methods for short term load forecasting,‚Äù Energy Procedia, vol. 14, pp. 1883‚Äì1888, 2012. [5] N. Amjady, F. Keynia, and H. Zareipour, ‚ÄúShort- term load forecast of microgrids by a new bilevel prediction strategy,‚Äù IEEE Transactions on smart grid, vol. 1, no. 3, pp. 286‚Äì294, 2010",
    "token_count": 500,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_12"
  },
  {
    "id": "cbe375cf-6f76-42e2-8e25-82113e394f76",
    "created_at": "2025-07-26T15:28:57.340437+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Propagating_Uncertainty_in_Tree_Based_Lo.pdf",
    "title": "Propagating_Uncertainty_in_Tree_Based_Lo",
    "text": ". Zareipour, ‚ÄúShort- term load forecast of microgrids by a new bilevel prediction strategy,‚Äù IEEE Transactions on smart grid, vol. 1, no. 3, pp. 286‚Äì294, 2010. [6] S. Fan and L. Chen, ‚ÄúShort-term load forecast- ing based on an adaptive hybrid method,‚Äù IEEE Transactions on Power Systems, vol. 21, no. 1, pp. 392‚Äì401, 2006. [7] T. Hong and S. Fan, ‚ÄúProbabilistic electric load forecasting: A tutorial review,‚Äù International Journal of Forecasting, vol. 32, no. 3, pp. 914‚Äì 938, 2016. [8] T. Mehenni and A. Moussaoui, ‚ÄúData mining from multiple heterogeneous relational databases using decision tree classiÔ¨Åcation,‚Äù Pattern Recog- nition Letters, vol. 33, no. 13, pp. 1768‚Äì1775, 2012. [9] G. Strang, Introduction to linear algebra. Wellesley-Cambridge Press Wellesley, MA, 1993, vol. 3. [10] J. H. Friedman, ‚ÄúStochastic gradient boost- ing,‚Äù Computational Statistics & Data Analysis, vol. 38, no. 4, pp. 367‚Äì378, 2002.",
    "token_count": 296,
    "chunk_id": "cbe375cf-6f76-42e2-8e25-82113e394f76_13"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": "The evolution of electricity price on the German day-ahead market before and after the energy switch Abdolrahman Khoshrou a, c, *, 1, Andr\u0001e B. Dorsman b, 2, Eric J. Pauwels a, 3 a Centrum Wiskunde & Informatica, Science Park 123, 1098 XG, Amsterdam, the Netherlands b VU University Amsterdam, 1081 HV, Amsterdam, the Netherlands c Department of Mathematics and Computer Science, Delft University of Technology, the Netherlands a r t i c l e i n f o Article history: Received 16 April 2018 Received in revised form 3 October 2018 Accepted 28 October 2018 Available online 5 November 2018 Keywords: electricity network Day-ahead price Renewable energy Volatility Energy switch Singular value decomposition a b s t r a c t Germany is a forerunner in developing renewable energies. It is therefore of considerable interest to investigate the impact of switch to renewables on the market during transition era. The aim of this study is in two parts: 1) Investigating the volatility; and 2) Conducting a descriptive study on the evolution of daily proÔ¨Åles and emergence of non-positive prices. In terms of volatility quantiÔ¨Åcation, the following characteristics of EPEX prices should be recognized: 1) Covering the whole year (24/7); 2) Taking non- positive values; 3) Depending on calendar information; and 4) Changing according to demand and supply availability. We, therefore, propose a robust and generic approach to account for diurnal or seasonal patterns of human activities in volatility analysis. An important distinction of our work is in introducing an alternative representation (as matrices) for quasi-periodic price data. We, herein, propose a new notion of volatility using a matrix decomposition technique, namely the singular value decom- position (SVD). Our observations indicate price volatility reduction, in the recent years. The second part of this article provides evidences of effect of renewables on daily price proÔ¨Åles e emergence of non- positive prices and also shifts of peak price values to hours where solar is less available. ¬© 2018 Elsevier Ltd. All rights reserved. 1. Introduction In Europe, Germany is taking the lead in switch from fossil and nuclear to renewable energy sources (RES). This creates new chal- lenges as wind and solar",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_1"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": ". ¬© 2018 Elsevier Ltd. All rights reserved. 1. Introduction In Europe, Germany is taking the lead in switch from fossil and nuclear to renewable energy sources (RES). This creates new chal- lenges as wind and solar energy are fundamentally intermittent, weather-dependent and unpredictable. This energy transition or as is called Energiewende, is a prominent example of an ambitious project spearheaded by the German government intended to replace the conventional energy sources by RES, to large extent, in the coming years [1]. To secure an economic and environmentally compatible supply, Germany has substantially expanded its RES- capacity, in particular wind and solar [2]. This creates new challenges as wind and solar energy are fundamentally intermit- tent, weather-dependent and unpredictable; it hence raises con- cerns over managing the Ô¨Çexibility in power demand and supply. It is therefore of considerable interest to investigate what effect Energiewende could have on the overall trend and volatility of the electricity price. This impact could be complex because there are two contradicting forces at play. The marginal cost of RES is rela- tively low and even negative (especially if subsidized), therefore, increased penetration of wind and solar would result in a down- ward trend in electricity prices. On the contrary, the associated uncertainty regarding the availability of wind and solar energy is expected to cause spikes in the market. In other words, the inte- gration of RES provokes assertion that the stability of power grid can (surely) be compromised due to inherent intermittency of such sources. Therefore, the increased price volatility will cause addi- tional market risks for suppliers and consumers on the market. While market coupling promises to reduce price volatility, depen- dence on RES might have the opposite effect. Because of the inte- gration of the European grids, the problems will not be conÔ¨Åned only to the German grid. Power quality issues and reduction of stability in Germany also means a higher instability in the neigh- boring grids. For example, the pros and cons of the Energiewende * Corresponding author. Centrum Wiskunde & Informatica, Science Park 123, 1098 XG, Amsterdam, the Netherlands. E-mail address: a.khoshrou@cwi.nl (A. Khoshrou). 1 Abdolrahman Khoshrou is with the Intelligent and Autonomous Systems Group at Centrum Wiskunde & Informatica; he is also",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_2"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": ". E-mail address: a.khoshrou@cwi.nl (A. Khoshrou). 1 Abdolrahman Khoshrou is with the Intelligent and Autonomous Systems Group at Centrum Wiskunde & Informatica; he is also a guest PhD student at TU Delft. 2 Andr\u0001e B. Dorsman is an associate professor at the School of Business and Economics, VU University Amsterdam. 3 Eric Pauwels is a senior researcher and the leader of the Intelligent and Autonomous Systems Group at Centrum Wiskunde & Informatica. Contents lists available at ScienceDirect Renewable Energy journal homepage: www.elsevier.com/locate/renene https://doi.org/10.1016/j.renene.2018.10.101 0960-1481/¬© 2018 Elsevier Ltd. All rights reserved. Renewable Energy 134 (2019) 1e13 for Norwegian grid is studied in Ref. [3]. Some researchers, how- ever, detract the latter, arguing that such assertions are irrelevant because intermittent energy sources, like wind, can and do contribute as a Ô¨Årm power source to the grid. Swift-Hook [4] con- tends that all the concerns regarding the availability of ‚Äúintermit- tent‚Äù energy sources are already well taken care of by back-up capacities that are in place for all plants, not just for wind and solar. Another evidence in rejecting such assertions is presented in Ref. [5]; it is argued that a fully-integrated power system which includes a component of intermittent renewable generation is reliable, at least as far as providing Ô¨Årm supply is concerned. Along with increase in utilization of intermittent renewable sources, short-term electricity market studies (including day- ahead, intraday and imbalance market) are becoming increasingly popular. The aim of this study is in two folds. First, to investigate the volatility of the market in transition era, and second, to explore the possible effect of RES on the overall price proÔ¨Åles (e.g., shifts in peak price hours, emergence of zero or negative prices). In the present work, we opt to focus on the day-ahead market as it represents an important and growing segment where market mechanisms are clearly visible. Inspired by the work in Ref. [6], we herein consider matrices as an alternative representation of the electricity market data where the time series demonstrates periodic patterns. We accordingly deÔ¨Åne a new, yet",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_3"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " growing segment where market mechanisms are clearly visible. Inspired by the work in Ref. [6], we herein consider matrices as an alternative representation of the electricity market data where the time series demonstrates periodic patterns. We accordingly deÔ¨Åne a new, yet easy-to-quantify, notion of volatility using a popular and numerically stable matrix decomposition technique, namely the singular value decomposition (SVD). It en- ables us to disentangle the matrix of daily price proÔ¨Åles (one year worth of hourly values) based on the most dominant daily proÔ¨Åles (left singular vectors as a notion of trend) and their corresponding variability (the right singular vectors), as it is fully explained in Section 3. The rest of this paper is organized as follows. Section 2 provides a brief about the German day-ahead market, along with the data description. The next consecutive sections are dedicated to our methodologies. Section 3 introduces the singular value decompo- sition, as the core means of the proposed methodology in this pa- per. The evolution of the volatility of the day-ahead price time series is investigated in Section 4. Section 5 provides an overview of the trend changes in the German day-ahead market, in the recent years. Section 6 discusses our Ô¨Åndings with respect to a number of similar studies. We conclude this work in Section 7. 2. EPEX day-ahead market To guarantee a single integrated and transparent market, the European Power Exchange (EPEX SPOT SE) acts as a neutral inter- mediary market operating service provider between the market members active in the central western European countries - viz. Switzerland, France, Germany and Austria. This market consist of non-Ô¨Ånal consumers and big players in the energy sector such as utilities, wind and solar farm owners, hydroelectric power stations, aggregators, the transmission system operators (TSOs), Ô¨Ånancial service providers and also energy trading entities that are working within the energy sector on a daily basis [7]. An exchange for short-term (one day before the power delivery) electricity contracts is the day-ahead market. It is a single inte- grated market where the participants themselves propel the trading. An electricity buyer, typically a utility or TSO, determines how much energy it will need to fulÔ¨Åll its customers requirements for the coming day. It also decides how much its purchase price on hourly basis is going to be. The seller, e",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_4"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " electricity buyer, typically a utility or TSO, determines how much energy it will need to fulÔ¨Åll its customers requirements for the coming day. It also decides how much its purchase price on hourly basis is going to be. The seller, e.g., the owner of a wind farm or hydroelectric power plant, also submits the quantity which they are prepared to deliver the next day, and the price level for each hour. The deadline for the market participants to submit the price (V/MWh) and the quantity (MWh) for which they seek to make a deal is 12h00 CET (MWh stands for megawatt-hour). These ‚Äúbids‚Äù are then fed into a complex algorithm to calculate the clearing price. This process, typically, takes no more than 42 min to clear the market and determine whether orders are accepted or rejected. In the end, the Ô¨Ånancial and physical transactions are being settled. The output of the algorithm is in fact a number of time series of prices (bounded between ¬Ω \u0002 500; 3000\u0003), and traded volumes which are going to be exchanged, per area and period of the day, for the next day [8,9]. The delivery of power begins by the sellers at the contract rate, from 00h00 CET the next day. As previously mentioned, in the course of Energiewende, be- sides technical challenges, energy market is also undergoing paramount changes. The state-aided priority of RES generation has led to a signiÔ¨Åcant decline in electricity prices. Moreover, a bi-product of that is a reduction in the proÔ¨Åt margin of co-generation units, and hence an increase in the necessity of Ô¨Çexible operations to avoid injection of power to the grid when spot prices drop below marginal costs [10]. Fig. 1 provides an overview of the evolution of the price values on the German day- ahead market from 2006 until 2016 (data source: [7]). It is plain to see that after triggering the energy transition in 2011, occur- rences of zero or negative price values is more frequent. Further- more, a cursory glance at this timeseries suggests an overall downward trend in price range as well as its volatility. Table 1 contains some statistics for the same data. Interestingly enough, despite a consistent reduction in the annual mean (m) and the standard deviation (std), the coef",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_5"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " timeseries suggests an overall downward trend in price range as well as its volatility. Table 1 contains some statistics for the same data. Interestingly enough, despite a consistent reduction in the annual mean (m) and the standard deviation (std), the coefÔ¨Åcient of variation (Cv ¬º std m \u0004 100) has increased from 2015 afterwards. In terms of analyzing day-ahead market, the following Fig. 1. Left: Evolution of the German day-ahead spot prices from 2006 through 2016 (daily averages). Right: The corresponding box-plots of the hourly price data (for the sake of visualization, only values between ¬Ω\u0002300; 300\u0003 are illustrated). It is evident to see that zero or negative prices started to appear in late 2008 afterwards. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 2 characteristics need to be considered: \u0005 EPEX prices cover the whole year, 24 h of the 7 days of the week. Accordingly, the underlying variability of the data could wrongly be conceived as volatility whereas it in fact simply reÔ¨Çects the diurnal patterns of human activities. In this work, we use SVD to account for such diurnal and seasonal patterns (Section 3). \u0005 More importantly, EPEX prices can be zero or even negative; therefore, the standard approach to switch to logarithmic measures can be done only after shifting up all values above zero by a certain threshold. On the other hand, price volatility has a dependence on the price level, which is even more pronounced when the spot prices are low [11] (also Table 1). Therefore, the generalizability of conventional approaches can be questioned, as the volatility measures can vary drastically, with respect to the magnitude of the aforementioned thresholds. Fig. 2 provides a comparison of annual standard deviation of the logarithmic returns of the EPEX data. First, we shift up all the hourly price values P ¬º fp1;p2;‚Ä¶;p8760} (p8784 for a leap year) by a positive a value (xt ¬º pt √æ a). We have considered three different cases: 1) a ¬º jmin√∞P√ûj √æ 1; 2) a ¬º jmax√∞P√ûj √æ 1; and 3) a ¬º 501",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_6"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " We have considered three different cases: 1) a ¬º jmin√∞P√ûj √æ 1; 2) a ¬º jmax√∞P√ûj √æ 1; and 3) a ¬º 501 (Recall that pt2¬Ω \u0002 500; 3000\u0003). The logarithmic returns are then calculated as follow: bt ¬º log√∞xt√û \u0002 log√∞xt\u00021√û (1) In the end, the standard deviation of the logarithmic return (bt) values are considered as a notion of annual volatility. It is plain to see that different a values can lead to contradictory results. The Ô¨Çowchart presented in Fig. 3 displays our proposed meth- odology. Our database contains hourly data 24/7; we compare the yearly datasets during our observed period, 2006e2016. In Section 3, we describe the SVD-method; further analysis of the volatility takes place in Section 4, followed by price analysis in terms of trend changes in Section 5. 3. Matrix decomposition using SVD The present work, considers matrices as an alternative repre- sentation for quasi-periodic time series price data. In other words, for each year, we reshape the time series data into matrix Ah\u0004d, where h ¬º 24 is the number of hours of the day, and d ¬º 365 (366 for a leap year) is the number of days of the year. Singular value decomposition (SVD) method is then used to decompose any given matrix A into a set of fundamental daily proÔ¨Åles and their corre- sponding weights during the observed time-span (it becomes apparent in the following section). This method is more robust, regarding the aforementioned issues with EPEX price data, as it enables us to explore trend and volatility of each year individually and in a data-driven manner, with no need to add offset values. Fig. 4 displays an overview of the German day-ahead market in Table 1 Annual mean, standard deviation and the coefÔ¨Åcient of variation Cv of EPEX price data, in the recent years. Year 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 m 50.79 37.98 65.76 38.85 ",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_7"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": "2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 m 50.79 37.98 65.76 38.85 44.48 51.12 42.59 37.78 32.76 31.63 28.98 std 49.42 30.35 28.65 19.40 13.98 13.60 18.69 16.45 12.77 12.67 12.48 Cv 97.31 79.91 43.58 49.94 31.42 26.60 43.87 43.53 38.99 40.05 43.08 Fig. 2. Comparison of annual standard deviation of logarithmic returns of EPEX data for different a values. Fig. 3. Illustration of the methodology proposed in this work. Fig. 4. An overview of the evolution of the hourly day-ahead price values in 2016. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 3 2016; looking closely at the data, some diurnal patterns super- imposed on relatively slower seasonal variations are visible. As mentioned earlier, as a Ô¨Årst step, we recast each year's worth of data into a matrix Ah\u0004d where each column contains 24 hourly values for a particular day e it can be seen as d points in h\u0002 dimensional space. In matrix A, if the daily price proÔ¨Åles for all d days were identical (or linearly dependent), the rank of the resulting matrix will be equal to one (rank√∞A√û ¬º 1), as all the columns would be the same (or linearly dependent). Put differently, the matrix Ah\u0004d can be factorized as the product of a h \u0004 1 column (a typical daily proÔ¨Åle) and a 1 \u0004 d row vector, containing their corresponding weights for each day. However, in practice, the daily price proÔ¨Åles for subse- quent days tend to differ, depending on the calendar information, supply availability and demand; accordingly, the rank of the matrix A exceeds one. In mathematical parlance, any given matrix Ah\u0004d can be factor- ized",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_8"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " for subse- quent days tend to differ, depending on the calendar information, supply availability and demand; accordingly, the rank of the matrix A exceeds one. In mathematical parlance, any given matrix Ah\u0004d can be factor- ized into the product of three matrices: A ¬º X r k¬º1 skUkVT k or more succinctly A ¬º USVT (2) where r ¬º min√∞h;d√û, and the columns of matrices U2O √∞h√û and V2 O √∞d√û are orthonormal, called the left and right singular vectors, respectively. More precisely, Uk and Vk correspondingly denote the kth column of U and V matrices. Here, S is an h \u0004 d diagonal matrix of singular values, for which only strictly positive real entries sk are situated on the main diagonal in a descending order (s1 \u0006 s2 \u0006 ‚Ä¶ \u0006 sr). The mathematical interpretation of (2) is that any given matrix A can be decomposed into the sum of r rank\u00021 matrices (i.e. a column times a row) where each next contribution in the sum is less important, based on the magnitude of their cor- responding singular value sk. Another important property of the SVD is that truncating the expansion in the right hand side of (2) after p \u0007 r terms yields the best approximation of the original matrix A by a matrix of (lower) rank \u0002 p; for the proof of formula see e.g., [12]. Ap ¬º arg min rank√∞R√û¬ºp \u0002\u0002\u0002\u0002 \u0002\u0002\u0002\u0002A \u0002 R \u0002\u0002\u0002\u0002 \u0002\u0002\u0002\u0002 (3) where the operator jj,jj can be either the spectral L2 or the Frobe- nius norm. Here, we exemplify the process of decomposing a matrix of the hourly price values, using the data for the year 2016 in Fig. 4. Recasting the time series data into daily segments yields a 24 \u0004 366 matrix A (2016 was a leap year). We then obtain its corresponding three factorization matrices using the SVD expansion. Fig. 5 illus- trates the Ô¨Årst two dominant Uk and Vk proÔ¨Åles, corresponding to the two largest singular values sk (k ¬º 1; 2). It is plain to see that",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_9"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": "VD expansion. Fig. 5 illus- trates the Ô¨Årst two dominant Uk and Vk proÔ¨Åles, corresponding to the two largest singular values sk (k ¬º 1; 2). It is plain to see that the most dominant U proÔ¨Åle (U1, top left), highly resembles an appropriately weighted average of daily pro- Ô¨Åles (averaged over the year). The morning and late afternoon price peaks are clearly discernible in this plot. The second column of U (U2 bottom left) acts as a correcting factor, which needs to appro- priately be added to the Ô¨Årst proÔ¨Åle to result in a better approxi- mation. The panels on the right display the corresponding Vk coefÔ¨Åcients that speciÔ¨Åes the magnitude of the corresponding Uk proÔ¨Åle for each day of the year. We, herein, propose to consider Vk proÔ¨Åles as a generic notion of volatility as they appropriately reÔ¨Çect the variability of the corresponding Uk proÔ¨Åles throughout the year. More details are presented in Section 4. Fig. 6 demonstrates the evolution of the singular values throughout the years. It is plain to see that by considering only a few singular values (and their cor- responding singular vectors) we are capable of reconstructing the price data with a good approximation. In Subsection 4.2, only the Fig. 5. SVD-based rank-2 approximation: the Ô¨Årst two most dominant Uk proÔ¨Åles are depicted on the left side. The panels on the right contain their corresponding Vk coefÔ¨Åcients. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 4 Ô¨Årst two Vk proÔ¨Åles are accordingly considered to measure the volatility of data for each year. 4. Measuring the volatility of daily proÔ¨Åles Volatility principally refers to random Ô¨Çuctuations of a time series about its mean or expected value. Generally speaking, in Ô¨Ånancial time series data analytics, volatility is measured by the standard deviation of the logarithmic return, or a derivation of that [13]. In the literature, numerous methods have been introduced to determine the volatility of the time series data. Diverse methods, from applied models such as Garman-Klass and Rogers-Satchell volatility estimators, to coefÔ¨Åcient",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_10"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " that [13]. In the literature, numerous methods have been introduced to determine the volatility of the time series data. Diverse methods, from applied models such as Garman-Klass and Rogers-Satchell volatility estimators, to coefÔ¨Åcient of variation based, and formal stochastic volatility models including GARCH, Heston models and so on [14]. Recently, however, new concepts and notions of vola- tility have been explored, especially in Ô¨Ånancial data analysis. In Ref. [15], the authors propose the permutation entropy, topological entropy and the modiÔ¨Åed permutation entropy as an alternative volatility measure. In the reported work, the degree of randomness or determinism of a time series is considered as the notion of volatility of data. Simonsen [11] studies different volatility features (including: volatility clustering, log-normal distribution, and long- range correlations) of the Nordic day ahead power spot market for the course of 12 years (1992 till May 2004). This work also reports the presence of a cyclic behavior of the time-dependent volatility for the quasi-periodic (with almost diurnal patterns) power market data. Additionally, the striking differences between the range of price data in different years is reported to be an obstacle in developing a generic approach to analyzing the market from different perspectives. The volatility has namely a dependence on price level, which is even more pronounced when spot prices are low. Therefore, as stated earlier in Section 2, in terms of analyzing EPEX data shifting up all the values for different years by a certain threshold in order to use the traditional Ô¨Ånancial data methodol- ogies, do not appear to be a viable approach, as the results may vary drastically for different thresholds. A frequency domain based method is deployed in Ref. [16] to systematically separate out the periodic components of the prices from random variations. After removing the deterministic part, the price volatility is determined by Ô¨Åtting a Wiener process to the remaining random stochastic (residual) part. With the growing contribution of RES, transmission grid ex- tensions along with increasing cross-border interconnections ca- pacities seem inevitable. In Ref. [17], a reduction in average price and its volatility in Ireland is concluded to be the outcome of two factors: 1) integration of wind-produced electricity into the power grid; and 2) the grid expansion between Great Britain and Ireland. On the contrary, in Ref",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_11"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " in average price and its volatility in Ireland is concluded to be the outcome of two factors: 1) integration of wind-produced electricity into the power grid; and 2) the grid expansion between Great Britain and Ireland. On the contrary, in Ref. [18], less predictability of price values and hence increasing the allocative inefÔ¨Åciencies in Nordic electricity market are concluded to be an outcome of high share of wind- produced energy in the grid. Schaber et al. [19] explore a number of market coupling and grid extension scenarios, using projected wind and solar data until 2020. It was done to examine the viability of such approaches in coping with the externalities associated with the growing penetration of RES in the grid. They conclude that expanding the grid is, indeed, helpful in coping with externalities which come with the deployment of renewable energies. A notable reduction in daytime peak price values in Germany and Italy is discussed to be the result of substantial expansion of the photo- voltaic (PV) produced energy in these countries, according to [20]. Adaduldah et al. [21] investigate the German market after trig- gering the energy switch in 2011, by taking into account the priority that the German policies assigns to renewables over fossil fuels in case of adequate supply. The authors report the existence of convincing evidence for the impact of RES on the emerging of negative prices on the German day-ahead market. The wavelet decomposition technique is used herein to quantify the volatility of the EPEX price data. 4.1. Wavelet decomposition In modern mathematics, wavelets are one of the most efÔ¨Åcient and widely used tools to analyse digital signals. As the name sug- gests, wavelet analysis is akin to Fourier analysis which de- composes the signal of interest as a linear combination of sine- waves of different frequency and phase. Wavelet analysis will not only tell us which frequencies are hidden in the signal, but can also pinpoint their location in the data stream. From this, it becomes clear that wavelets hand us a useful tool to probe the data for the occurrence and location of high- frequency Ô¨Çuctuations [22]. The Haar wavelet is arguably the simplest wavelet and lends itself to a straightforward interpretation. It basically takes any discrete signal x ¬º √∞x1; x2; x3; ‚Ä¶√û and creates an approximation a and detail d signal by running the following",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_12"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " is arguably the simplest wavelet and lends itself to a straightforward interpretation. It basically takes any discrete signal x ¬º √∞x1; x2; x3; ‚Ä¶√û and creates an approximation a and detail d signal by running the following simple recipe: 1. Take the Ô¨Årst two elements x1 and x2 and compute the approximation and detail coefÔ¨Åcients: a ¬º x1 √æ x2 2 and d ¬º x1 \u0002 x2 2 : Notice that this implies x1 ¬º a √æ d and x2 ¬º a \u0002 d, or more explicitly: the approximation coefÔ¨Åcient equals the mean of the two values, and the detail coefÔ¨Åcient the amount of deviation be- tween the actual value and the approximation. 2. Store the results in the approximation and detail vector, respectively: a√∞1√û ¬º a d√∞1√û ¬º d: Both vectors have a length equal to half the length of the original input x. Fig. 6. An overview of the evolution of the singular value of the price data in the recent years. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 5 3. Move on to the next pair √∞x3; x4√û and continue until all x-ele- ments have been processed. This way we get the level-one approximation (a1) and detail (d1) coefÔ¨Åcient (each vectors of half the length of the original x-sequence). 4. To compute the level-two approximation and detail coefÔ¨Åcients we repeat the whole procedure but use a1 as input (instead of x). 5. This can be continued until we have reached a pre-deÔ¨Åned level. Fig. 7 exempliÔ¨Åes the decomposition for a (short) discrete signal x ¬º √∞x1;x2;x3;x4√û. In the Ô¨Årst analysis step, the original values (the dots) are paired, and each pair is replaced by its mean or approxi- mation (ai, the dash-dotted lines) and the symmetric deviation di with respect to the corresponding mean. As a consequence, the original signal x can equally well be represented by the approxi- mation vector a ¬º √∞a1; a2√û and the vector of",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_13"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": ") and the symmetric deviation di with respect to the corresponding mean. As a consequence, the original signal x can equally well be represented by the approxi- mation vector a ¬º √∞a1; a2√û and the vector of detail coefÔ¨Åcients d ¬º √∞d1;d2√û. The next analysis step (not depicted here) would repeat the procedure, this time starting with the approximation a as input. As a concrete example, imagine that the time series is given by x ¬º √∞1 5 11 1‚Ä¶√û, then \u0005 Level 1 decomposition: x ¬º 0 B B B @1 5 |Ô¨Ñ{zÔ¨Ñ} 3¬±2 11 1 |Ô¨ÑÔ¨ÑÔ¨Ñ{zÔ¨ÑÔ¨ÑÔ¨Ñ} 6¬±√∞\u00025√û ‚Ä¶ 1 C C C A / a1 ¬º √∞3 6‚Ä¶√û and d1 ¬º √∞2 \u0002 5‚Ä¶√û \u0005 Level 2 decomposition: a1 ¬º √∞3 6 |Ô¨ÑÔ¨Ñ{zÔ¨ÑÔ¨Ñ} 4:5¬±√∞\u00021:5√û ‚Ä¶√û/ a2 ¬º √∞4:5 ‚Ä¶√û and d2 ¬º √∞ \u0002 1:5 ‚Ä¶√û 4.2. Volatility quantiÔ¨Åcation It is important to realize that the level-one detail coefÔ¨Åcients capture the highest frequency oscillations. Subsequent detail co- efÔ¨Åcients correlate with oscillations of successively lower fre- quencies. As mentioned before, in the present work, the right singular vectors Vk are considered to be an indicative for the volatility of the fundamental daily price proÔ¨Åles (Uk) throughout a year. We hence have applied the wavelet decomposition to the absolute value of the Ô¨Årst two Vk proÔ¨Åles. Fig. 6 conÔ¨Årms that there are only a few dominant singular values; we hence opt to consider only the Ô¨Årst two right singular vectors. Fig. 8 contains the standard deviation of the values of the Haar wavelet detail coefÔ¨Åcients, down to three level wavelength decomposition. The downward trend underscores a reduction in the volatility of the German day-ahead market",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_14"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " right singular vectors. Fig. 8 contains the standard deviation of the values of the Haar wavelet detail coefÔ¨Åcients, down to three level wavelength decomposition. The downward trend underscores a reduction in the volatility of the German day-ahead market in the recent years. Worth noting that V1 and V2 coefÔ¨Åcients have been magniÔ¨Åed using their corresponding singular values s1 and s2. The results here corroborate with [23], where the volatility of the German day-ahead market during the same period is studied. 5. Extracting the underlying trends This section is dedicated to a more a descriptive study on the evolution of the overall trend of the day-ahead market. 5.1. The evolution of the daily proÔ¨Åles As mentioned before, the left singular vectors (Uk proÔ¨Åles) represent the most dominant daily proÔ¨Åle (U1) and its additive corrective proÔ¨Åles (U2; U3; ‚Ä¶). Fig. 9 displays the evolution of the most dominant daily price proÔ¨Åles (U1 magniÔ¨Åed by s1) over the years. A continuous downward trend during the decade in the average value of the daily proÔ¨Åle is noticeable. More importantly, the change in the overall shape of the daily proÔ¨Åle is even more telling. Before 2011, the morning peak price values tended to be higher than the afternoon peak values. Whereas this trend has become reversed in the recent years. Another intriguing feature of the data is the shift of the time slot (during the day) for which more points to the effect of the low cost subsidized RES on the daily price proÔ¨Åle. Before 2011, the electricity price is most expensive at around 12h00. Evidently, the availability of solar after 2011 has pushed the prices lower and has led to a morning peak prices at around 9h00. In a similar way, the afternoon peak price time slot has a shift of an hour from around 19h00e20h00. Furthermore, it is plain to see that the ranges of the daily proÔ¨Åles (difference between the maximum and minimum values) shows a reduction, in the recent years. This also can be an indicative of less volatility in years. In other words, the change in timing and amplitude of daytime and evening time peak values after 2011 are striking. Before 201",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_15"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " values) shows a reduction, in the recent years. This also can be an indicative of less volatility in years. In other words, the change in timing and amplitude of daytime and evening time peak values after 2011 are striking. Before 2011, the midday peak price (around 12h00), was considerably higher than the early evening spike around 20h00. However after 2011, the Ô¨Årst spike is not just lower than the second one, but also shows a clear shift to earlier hours. This makes sense in light of higher contribution of renewables, in particular solar; it is reasonable to assume that the typically high supply of solar power around midday is the reason for drop in prices during these hours. The right panel of Fig. 9 displays an alternative representation of the same data in the left panel; it conÔ¨Årms the previous Ô¨Åndings by showing a downward trend in average daily prices from left to right. The diminishing contrast in each column indicates a smoother price proÔ¨Åle with lower daily spread over the years. Looking closely, the shift of the midday and afternoon peak hours is notable. 5.2. The extreme values In the next step, the extreme values of the hourly prices during the years has been probed. More speciÔ¨Åcally, collecting all the hour slot values for each year in the period 2006 through 2016 yields a price distribution for each year. Extreme prices (both high and low) are characterized as prices outside the extreme 5% percentiles. So we get a representative value for high (low) prices by focusing on the values of the 95% (5% respectively) percentile for the distribu- tion of each year's worth of hourly price values. The results are shown in Fig. 10 where we have plotted both values (high and low) for each year. There is a pronounced continuous downward trend for the high prices, with 2008 being an obvious outlier. The lowest prices show a slight decrease over the years, as there is obviously less room for manoeuvre. The overall spread of the prices is steadily decreasing and less volatile, indicative of a more mature market. Fig. 7. Schematic representation of the Haar wavelet decomposition. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 6 5.3. The distribution of high and low price values",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_16"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " 7. Schematic representation of the Haar wavelet decomposition. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 6 5.3. The distribution of high and low price values We herein explore the evolution in the distribution of occur- rences of the extreme prices over the course of the day. Recall that high (low) prices are deÔ¨Åned as values outside the 95th (5th) percentile of price distribution for that year. Fig. 11 (left panel) shows how the occurrence of low prices is distributed over the day (for the years 2006 through 2016). Whereas in the earlier years of the decade, there is a clear concentration of low price occurrences in the early morning (4h00-5h00), later years show a more uniform daily distribution. A similar distribution for the occurrence of high prices is shown in the right panel of Fig. 11. It indicates a distinct shift (occurring around 2011) in the time slot of high prices. More precisely, the day time peak is shifted from noon to the earlier hour of 9h00, while the evening is postponed, shifting from 19h00e20h00. In other words, before 2011, the daytime peak values were higher than the afternoon ones, and occurred around noon. After 2011, high prices occur predominantly at the beginning and end of the peak period. Each column represents 440 values, which is 5% of the total number of observations during one year. Also apparent is the fact that, starting in 2011, the afternoon spikes in the price proÔ¨Åle exceed the daytime ones. Fig. 8. Evolution of the annual standard deviation of the Haar wavelet detail coefÔ¨Åcients of the absolute values of v1, v2 proÔ¨Åles magniÔ¨Åed by their corresponding singular values, down to three level (starting from the top left). Fig. 9. Left: Averaged daily proÔ¨Åles of the day-head prices. Right: An alternative representation, for the sake of better visualization. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 7 5.4. Zero and negative prices Of special interest are zero or negative prices as they reÔ¨Çect the effect of subsidized RES. In Germany,",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_17"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " al. / Renewable Energy 134 (2019) 1e13 7 5.4. Zero and negative prices Of special interest are zero or negative prices as they reÔ¨Çect the effect of subsidized RES. In Germany, signiÔ¨Åcant amount of elec- tricity is still produced by conventional sources. In 2015, e.g., lignite, nuclear energy and hard coal were responsible for producing 24, 14.2 and 18.3% of gross electricity production, respectively [24]. The synchronization speed of these plants is slow and they can not be shut or ramped down very quickly. As a result, on some days when there is excess of electricity production by subsidized renewable energy sources, prices may become negative and consumers can actually make a proÔ¨Åt by consuming electricity. Fig.12 provides an overview of the frequency along with the magnitude of non-positive prices, in the recent years. More speciÔ¨Åcally, the width (on the x-axis) of the interval assigned to each year is proportional to the number of occurrences of negative (or zero) prices in that year. The y-axis depicts the corresponding magnitude of these negative prices. Starting in 2012, the number of occurrences (length of the interval) seems to in- crease steadily. This trend is strikingly consistent with the growing contribution of wind and solar energy in Appendix A. From this graph it transpires that there is a reduction in the magnitude of the negative prices in the recent years, although their number is mildly increasing. The distribution of the growing number of instances of zero as well as negative prices in the recent years, from a different perspective is illustrated in Fig. 13. The left panel highlights the frequency of occurrence of non-positive price values during different hours of the day, for each year. Although, before 2012, the majority of non-positive prices are happening in early hours of the day, a cluster of non-positive price values has appeared during the midday (11h00-18h00). Considering the fact that the electricity demand during these hours has not changed much (working hours), the most probable explanation for this change can be the oversupply by solar farms. As it is seen in appendix A.2, these are the hours with the highest solar energy availability; on average, at 13h00, solar production can become as high as 5 GW-hour (GWh), that is",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_18"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " solar farms. As it is seen in appendix A.2, these are the hours with the highest solar energy availability; on average, at 13h00, solar production can become as high as 5 GW-hour (GWh), that is almost 5 times more that solar feed-in at 10h00. This number can be even more during the summer. Appendix A.3 highlights the fact that wind and solar energy combined are responsible for almost 10 GWh feed-in at around 13h00, throughout the year. Another conspicuous observation in the left panel of Fig. 13, is the increased frequency of the occurrences of non-positive prices in the early hours of the day in the last two years. Interestingly enough, Appendix A.1 presents how the wind feed-in have notably increased in 2015 afterwards. The right panel of Fig. 13, conÔ¨Årms the fact the non-positive price values are most frequent during the weekends, when the consumption is low. However, we witness more instances of zero or negative prices during the week, from 2011 afterwards. 6. Discussion The following is a discussion on the Ô¨Åndings that were pre- sented in the previous sections. Fig. 10. The evolution of extreme prices shows a consistent downward trend in the data. Fig. 11. An overview of the distribution of low prices over the day (left), vs. high prices (right), throughout different years. Fig. 12. An overview of the occurrences of zero or negative prices. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 8 6.1. Volatility Our results suggest that the increasing integration of RES has not resulted in a more volatile day-ahead market. This implies that the counter measurements taken in Germany have been quite suc- cessful. Furthermore, our results is in line with [5] where it is argued that there are ways to tackle the issues related to the inherent variability of renewables. Possible explanations for the absence of an increase in the price volatility on the day-ahead market are that the TSOs assist each other (Subsection 6.4) or make use of the intraday market (Subsection 6.6). In this paper, we observe that in terms of the day-ahead electricity market, there is no sign of increase in the price volatility. 6.2. Impact on electricity price The energy switch",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_19"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " intraday market (Subsection 6.6). In this paper, we observe that in terms of the day-ahead electricity market, there is no sign of increase in the price volatility. 6.2. Impact on electricity price The energy switch from fossil fuels to renewables attracted authors to research the impact of this switch on for example the electricity prices. Zipp in Ref. [25] researches the ‚Äúmerit-order ef- fect‚Äù of the energy switch in Germany (and Austria) during the period 1 January 2011 to 31 December 2013.4 The merit-order is a way of ranking available sources of energy, especially electrical generation, based on ascending order of price with amount of en- ergy that will be generated. Due to the fact that producers of renewable energy comparing to the producers of fossil fuel have large Ô¨Åxed and small variable costs, renewable energy will be used before fossil fuel. Zipp shows that a systematic reduction of the average day ahead price on days where more variable renewable energy, such as wind and solar energy, are available. Zipp found for each year in the period 2011e2013 a negative inÔ¨Çuence of the wind and of the solar energy on the daily average electricity price. His results are in line with earlier studies of Cludius et al. [26] and Wrzburg et al. [27]. The results of Zipp are in line with our results. However, we did not only show a negative effect of energy switch on the electricity price, but also a change of the daily pattern of this price. We show in Fig. 9 that before and after triggering the energy switch in 2011, not only the electricity price was lowered by the increasing wind and solar energy, but also the morning peak at 12h00 (before 2011) has switched to 9h00, and similarly, the af- ternoon peak has shifted from 19h00e20h00. 6.3. Negative electricity prices Another striking issue is the emergence of non-positive price values during our observed period (2006e2016). The marginal costs of renewables is (nearly) zero. In Germany the production of wind and solar energy was subsidized, which means that even in the case of negative prices e as long as the subsidy covered the negative price e it was attractive to sell the energy and to pay for this selling possibility. Brijs et",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_20"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " Germany the production of wind and solar energy was subsidized, which means that even in the case of negative prices e as long as the subsidy covered the negative price e it was attractive to sell the energy and to pay for this selling possibility. Brijs et al. [28] investigate the emergence of negative prices in Belgium, France, Germany and The Netherlands for the period 1 December 2012 till 30 November 2013. They conclude that the negative imbalance prices are substantially induced by the expected generation of wind and solar during low energy demand periods. In our study, our observed period is longer, namely 2006e2016. After 2012, we observe also non-positive pri- ces during the hours 11h00-17h00. The cause of negative prices during peak hours is the increase in solar feed-in. Before 2012 the supply of solar energy was smaller and had apparently not much inÔ¨Çuence on the electricity price. 6.4. Interconnectors The transmission system operator (TSO) is responsible balancing the demand and supply of energy for any moment. The shift from fossil fuels to renewables, however, increases the vola- tility at the supply side of the grid. This shift complicates the task of the TSO. TSOs can help each other in balancing the grid. Conse- quently, in the recent years, the number of interconnectors be- tween countries has increased substantially. For an island like Ireland such assistance is very limited. Denny et al. [29] look into the inÔ¨Çuence of wind energy on the electricity price in 2009. In that year only one interconnector was operating, namely the inter- connector called Moyle (operator: Mutual Energy), it was opened in 2002 and has a capacity of 500 MW (MW). This capacity is nearly 5% of the installed capacity [29]. The second interconnector, East West Interconnector (EWIC), has been in commercial operation since December 2012 [30]. Greenlink is the third 500MW inter- connector, linking the electricity markets in Ireland and Great Britain, is planned for commissioning in 2023 [31]. Furthermore, it is easier for a larger country to manage an additional supply of (renewable) energy. Germany is a large country and located in the center of Europe. However, Dorsman et al. [32]",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_21"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": "3 [31]. Furthermore, it is easier for a larger country to manage an additional supply of (renewable) energy. Germany is a large country and located in the center of Europe. However, Dorsman et al. [32] show that the production of renewable energy is located in the north of Germany, whereas the demand for electricity is in the south part; but the tools for transport of the electricity from north to the south of Fig. 13. Left: The abundance of zero as well as negative prices during the period of absence of sunlight provokes the higher impact of wind than solar in this matter. Conversely, there are no negative prices in the evening hours 19 h - 23 h, as consumption is high, and solar input has vanished. Right: The percentage of the distribution of the zero or negative prices on the days of week. 4 Germany and Austria share a common grid. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 9 Germany is very limited. They also mention that the neighbors of Germany are not pleased when they receive the additional energy produced by wind and solar farms in the north. In other words, the imbalance on the German grid, due to the switch to renewables, on sunny and windy days are exported and are causing imbalances on the neighboring grids. The neighboring countries are not happy to pay the price (imbalance on their grid) for the energy switch (Energiewende) in Germany. 6.5. Access to the grid Access to the electricity and gas network is not the same for every country. In Germany and The Netherlands, the access for every household is (nearly) a hundred. Recently, the Dutch gov- ernment has decided to shut down a major gas production facility in Groningen (North Nederland) by 2020. The local population no longer accepts string of earthquakes caused by the extraction of gas. The gas Ô¨Åeld in the Netherlands is the largest producer in the EU. The gas is not only being used internally, it also being exported to other countries, for example Germany. Gas is among the cleanest (the smallest CO2 pollution) fossil fuels. Although Germany wants to switch from fossil fuel to renewables, they prefer to reduce the production of lignite, coal and oil above the reduction of gas and therefore support the North Stream 2, the second gas pipeline from Russia to Germany. In other countries the access to",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_22"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " to switch from fossil fuel to renewables, they prefer to reduce the production of lignite, coal and oil above the reduction of gas and therefore support the North Stream 2, the second gas pipeline from Russia to Germany. In other countries the access to the grid (elec- tricity and/or gas) is not so well distributed. Although low domestic gas prices in Russia is a huge hurdle for a switch from fossil fuel to renewables, Vasileva et al. [33] believe in line with Martitot [34] that renewables are a good alternative for remote areas. Kar- unnathilake et al. [35] look at the best scenarios for net-zero energy communities powered by renewable energy. They show that the optimal structure under a ‚Äúpro-environment scenario‚Äù, existence of small hydro, onshore wind and biomass combustion technologies, deviates from a ‚Äúpro-economic scenario‚Äù, where biomass com- bustion, small hydro, and landÔ¨Åll gas have the best rankings. 6.6. Intraday trade An alternative for the TSO to balance between demand and supply is to use the possibilities of the intraday market. Comparing to other European countries, the intraday market is well developed in Spain. Chaves et al. [36] show that the Spanish intraday market has effectively contributed to renewable generation balancing. Also other TSOs are more often using the intraday market to balance the grid due to the increased volatility of the supply caused by the relative higher supply of solar and wind energy. However, these intraday markets are mostly bilateral and data are missing to research the growing contribution of the intraday market in solving the uncertainty issues of the TSOs. 7. Conclusions The decision of the German government in 2011 to stimulate RES-generation has had a noticeable impact on the day-ahead electricity market. In this paper, we have traced such impact in two parts, in terms of volatility and overall trend changes, in the recent years. The price volatility is mostly originated by uncertainty in supply or demand. The focus of the present work is on the volatility of the daily price proÔ¨Åles prompted by renewable energy sources. Regarding the volatility quantiÔ¨Åcation, there are a number of peculiarities that make conducting the empirical methods onerous. EPEX price data have the following characteristics: 1) It covers the whole year, 24 h of 7 days of the week; 2) It can",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_23"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " a number of peculiarities that make conducting the empirical methods onerous. EPEX price data have the following characteristics: 1) It covers the whole year, 24 h of 7 days of the week; 2) It can have non-positive values; 3) It depends on the calendar information (working and non-working days); and 4) It shows daily upward and downward trends following the demand and also the supply availability. Therefore, there are a lot of underlying variability in data that simply reÔ¨Çects the diurnal patterns of human activities, and not reÔ¨Çecting the volatility. Furthermore, regarding the second point (non-positive values), the traditional approach in Ô¨Ånancial time series analysis to switch to logarithmic measures is imprac- tical, without shifting up all the values by a certain threshold. On the other hand, the price volatility has a dependence on the price level, which is even more pronounced when the spot prices are low. Therefore, with respect to the magnitude of the aforementioned threshold, results can vary drastically. We hence have explored an alternative approach by representing the market data as matrices rather as timeseries. A novel and generic notion of volatility was accordingly deÔ¨Åned using a well-known and numerically stable matrix decomposition technique, namely the singular value decomposition (SVD), combined with Haar wavelet transforms. The second part of this article was dedicated to a descriptive study on the trend changes of the day-ahead market. Our observations indicate a price volatility reduction and also prominent changes in the day-ahead price proÔ¨Åles, in the recent years. There is an overall downward trend in the average electricity price. This undoubtedly has a number of causes, but the increasing penetration of subsi- dized solar and wind power accounts for at least part of it. More- over, the traditional 12h00 peak before the Energiwende (Energy switch) are Ô¨Çattened out and shifted to earlier hours in the morning at 9h00. In a similar manner, the afternoon peak price hours has shifted 1 h, from 19h00e20h00. Indeed, it is possible to clearly trace the impact of solar on the change of the daily price proÔ¨Åle over the year (this effect is most pronounced in summer). Furthermore, the effect of the growth in wind power is most transparent in the shift in distribution of low and negative prices during the",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_24"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " of solar on the change of the daily price proÔ¨Åle over the year (this effect is most pronounced in summer). Furthermore, the effect of the growth in wind power is most transparent in the shift in distribution of low and negative prices during the day. Acknowledgment The authors gratefully acknowledge partial support by the Dutch NWO-TTW under project grant Smart Energy Management and Services in Buildings and Grids (SES-BE). The authors also would like to thank the anonymous reviewers for their fruitful comments. Appendix A. EPEX market and RES feed-in The following section contains some evidences of the impact of the day-ahead estimated wind and solar feed-in on the price changes (Section 5), in the recent years. Appendix A.1. Day-ahead wind energy feed-in (in GWh) Fig. A.14 provides an overview of the evolution of the wind feed- in (day-ahead forecasts) over the years. The left panel in Fig. A.14 indicates a smooth annual growth. In a similar way, the right panel highlights the fact that the production is relatively constant around the clock. The change in the annual average of the daily proÔ¨Åles from 2014 afterwards is noticeable. Peak production of the wind proÔ¨Åle is eventually moving from early afternoon to late night or early morning. This can become an issue for the stability of the grid, as there might not be enough demand during those particular hours. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 10 Appendix A.2. Day-ahead solar energy feed-in (GWh) The developments in energy storage technologies and also the falling costs of harvesting solar power have made it increasingly attractive for the private households [37]. Fig. A.15 shows the day- time (non-zero values) solar energy feed-in forecast from 2010 to 2016. After the rapid rise in 2010 through 2013, solar feed-in has leveled off in the last two years. The panel on the right in Fig. A.15 illustrates the annual averaged solar feed-in for each time slot for years 2010e2016. Peak of solar feed-in is around 13h00; that co- incides with the high demand during the day. Appendix A.3. Evolution of German day-ahead price during winter and summer To illustrate the impact of solar energy on the price, we scruti- nize the",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_25"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": "13h00; that co- incides with the high demand during the day. Appendix A.3. Evolution of German day-ahead price during winter and summer To illustrate the impact of solar energy on the price, we scruti- nize the data separately for the summer (June through August) and winter (December through February) periods. In winters, days are shorter and the sun, if it emerges at all, traces out a lower path in the sky; therefore, a signiÔ¨Åcantly smaller amount of solar energy is produced (Fig. A.16). Wind energy, on the other hand, is fairly constant throughout the day, but there are marked difference be- tween the seasons (Fig. A.17). Fig. A.14. Top: The consistent growth in wind energy feed-in over the years. Bottom: Annual average of the daily proÔ¨Åles. Fig. A.15. Left: Smooth growth in annual solar energy feed-in (only non-zero day-time values have been considered). Right: Annual daily average of the solar feed-in. Fig. A.16. Low production of solar and also shorter occurring hours in winters (left), vs. high amount and longer period of solar production during summer (right). A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 11 Fig. A.18 contrasts the evolution of the daily average of the price proÔ¨Åle during winter (December through February) and summer (June through August) season. During the observed period we see that for winter time the peak at 19h00 is reduced both in size and sharpness, most likely due to the increase in the wind energy. During the summer period, the morning peak at 12h00 disappears completely over the years, in all likelihood again due to the increasing supply of wind and especially solar energy. In other words, the increasing supply of wind and solar energy is not only reducing the electricity price, but it is also changing the daily proÔ¨Åle substantially. Comparing the solar energy feed-in in winters and summers in Fig. A.16 and also considering the evolution of the price proÔ¨Åles in Fig. A.18 allow us to conclude that solar energy, especially in summer, effectively Ô¨Çattens the daytime price proÔ¨Åle. Fig. A.18 highlights the evolution of the daily average of the price proÔ¨Åles during winter (",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_26"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": ".18 allow us to conclude that solar energy, especially in summer, effectively Ô¨Çattens the daytime price proÔ¨Åle. Fig. A.18 highlights the evolution of the daily average of the price proÔ¨Åles during winter (December through February) and summer (June through August) season. Every value is the average of the prices for that speciÔ¨Åc hour, with the average ranging over the speciÔ¨Åed period. The left panel shows that during winter period the maximum values occur from 18h00e20h00, with peak at 19h00. Also, there is a steep increase in the morning (around 7h00). On the other hand, during summer (right panel), the price increase in the morning (5h00-9h00) is considerably Ô¨Çatter. Also the price-spike observed during winter evenings (around 19h00) is completely absent in summers. Both observations underscore the impact of solar on the price. Appendix A.4. Day-ahead traded quantity (GWh) Fig. A.19 displays the evolution of the traded quantity values on the German day-ahead market, in the recent years. Two interesting features are readily apparent. In the left panel the occurrence of a considerable number of outliers (represented as individual points near the upper part of the boxplots) point to unusually high vol- umes being traded. This highly resembles the wind feed-in proÔ¨Åles in Fig. Appendix A.1. The panel on the right depicts the annual averages of a typical daily proÔ¨Åle. Again, the steady increase in the traded volume is evident. However, whereas in the Ô¨Årst half of the decade, the traded volume is essentially constant over the course of the day, the latter part of the decade shows an increasingly more prominent bump that mirrors the average supply of solar energy, and could therefore be an indicator of surpluses generated by the renewable energy sources (in particular solar). In 2016, however, we witness a minor reduction in the traded volume, as it may be a direct outcome of warm winter combined with less solar feed-in in that year. Fig. A.17. Almost smooth and steady harvest of constant wind breathe in winters (left), vs. low production of wind in summer (right). Fig. A.18. The evolution of the seasonal daily average of the price proÔ¨Åle during winter time (left) and",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_27"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " and steady harvest of constant wind breathe in winters (left), vs. low production of wind in summer (right). Fig. A.18. The evolution of the seasonal daily average of the price proÔ¨Åle during winter time (left) and summer time (right). A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 12 References [1] reportFourth ‚Äúenergy transition‚Äù monitoring report, https://www.bmwi.de/ BMWi/Redaktion/PDF/V/vierter-monitoring-bericht-energie-der-zukunft- englische- kurzfassung,property¬ºpdf,bereich¬ºbmwi2012,sprache¬ºde,rwb¬ºtrue.pdf. [2] Information portal renewable energy, http://www.erneuerbare-energien.de/ EE/Navigation/DE/Service/Erneuerbare_Energien_in_Zahlen/Zeitreihen/ zeitreihen.htm. [3] A.T. Gullberg, D. Ohlhorst, M. Schreurs, Towards a low carbon energy futureerenewable energy cooperation between Germany and Norway, Renew. Energy 68 (2014) 216e222. [4] D.T. Swift-Hook, Grid-connected intermittent renewables are the last to be stored, Renew. Energy 35 (9) (2010) 1967e1969. [5] D. Swift-Hook, A. Ter-Gazarian, et al., The value of storage on power systems with intermittent energy sources, Renew. Energy 5 (5) (1994) 1479e1482. [6] A. Khoshrou, A.B. Dorsman, E.J. Pauwels, Svd-based visualisation and approximation for time series data in smart energy systems, in: 2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-europe), 2017, pp. 1e6, https://doi.org/10.1109/ISGTEurope.2017.8260303. [7] Epexspot, day-ahead auction, https://www.epexspot.com/en/product-info/ auction/germany-austria. [8] B. Corn\u0001elusse, How the European Day-ahead Electricity Market Works, 2014. [9] Epexspot",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_28"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " auction, https://www.epexspot.com/en/product-info/ auction/germany-austria. [8] B. Corn\u0001elusse, How the European Day-ahead Electricity Market Works, 2014. [9] Epexspot, european power exchange, http://www.epexspot.com/en/market- coupling. [10] M. Angerer, M. Djukow, K. Riedl, S. Gleis, H. Spliethoff, Simulation of cogeneration-combined cycle plant Ô¨Çexibilization by thermochemical energy storage, J. Energy Resour. Technol. 140 (2) (2018), 020909. [11] I. Simonsen, Volatility of power markets, Phys. Stat. Mech. Appl. 355 (1) (2005) 10e20. [12] G.H. Golub, C. Reinsch, Singular value decomposition and least squares solu- tions, Numer. Math. 14 (5) (1970) 403e420. [13] Financial chaos theory, http://quantonline.co.za/Articles/article_volatility. htm. [14] R.T. Baillie, C.-F. Chung, M.A. Tieslau, Analysing inÔ¨Çation by the fractionally integrated arÔ¨Åmaegarch model, J. Appl. Econom. (1996) 23e40. [15] M. d. C. Ruiz, A. Guillam\u0001on, A. Gabald\u0001on, A new approach to measure volatility in energy markets, Entropy 14 (1) (2012) 74e91. [16] F.L. Alvarado, R. Rajaraman, Understanding price volatility in electricity markets, in: System Sciences, 2000. Proceedings of the 33rd Annual Hawaii International Conference on, IEEE, 2000, p. 5. [17] E. Denny, A. Tuohy, P. Meibom, A. Keane, D. Flynn, A. Mullane, M. Omalley, The impact of increased interconnection on electricity systems with large pene- trations of wind generation: a case study of Ireland and great britain, Energy Pol. 38 (11) (2010) 6946e695",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_29"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": "malley, The impact of increased interconnection on electricity systems with large pene- trations of wind generation: a case study of Ireland and great britain, Energy Pol. 38 (11) (2010) 6946e6954. [18] K. Gerasimova, et al., Electricity price volatility: its evolution and drivers. [19] K. Schaber, F. Steinke, T. Hamacher, Transmission grid extensions for the integration of variable renewable energies in europe: who beneÔ¨Åts where? Energy Pol. 43 (2012) 123e135. [20] K. Barnham, K. Knorr, M. Mazzer, BeneÔ¨Åts of photovoltaic power in supplying national electricity demand, Energy Pol. 54 (2013) 385e390. [21] N. Adaduldah, A. Dorsman, G.J. Franx, P. Pottuijt, The inÔ¨Çuence of renewables on the German day ahead electricity prices, in: Perspectives on Energy Risk, Springer, 2014, pp. 165e182. [22] I. Daubechies, The wavelet transform, time-frequency localization and signal analysis, IEEE Trans. Inf. Theor. 36 (5) (1990) 961e1005. [23] Quantifying Volatility Reduction in German Day-ahead Spot Market in the Period 2006 through, 2016. https://arxiv.org/abs/1807.07328v1. [24] Federal statistical ofÔ¨Åce of germany, https://www.destatis.de/EN/ FactsFigures/EconomicSectors/Energy/Production/Tables/ GrossElectricityProduction.html. [25] A. Zipp, The marketability of variable renewable energy in liberalized elec- tricity marketsean empirical analysis, Renew. Energy 113 (2017) 1111e1121. [26] J. Cludius, H. Hermann, F.C. Matthes, V. Graichen, The merit order effect of wind and photovoltaic electricity generation in Germany 2008e2016: esti- mation and distributional implications, Energy Econ. 44 (2014) 302e313. [27] K. W√ºrzburg, X. Labandeira, P. L",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_30"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": " Germany 2008e2016: esti- mation and distributional implications, Energy Econ. 44 (2014) 302e313. [27] K. W√ºrzburg, X. Labandeira, P. Linares, Renewable generation and electricity prices: taking stock and new evidence for Germany and Austria, Energy Econ. 40 (2013) S159eS171. [28] T. Brijs, K. De Vos, C. De Jonghe, R. Belmans, Statistical analysis of negative prices in european balancing markets, Renew. Energy 80 (2015) 53e60. [29] E. Denny, A. O'Mahoney, E. Lannoye, Modelling the impact of wind generation on electricity market prices in Ireland: an econometric versus unit commit- ment approach, Renew. Energy 104 (2017) 109e119. [30] Electricity interconnectors, http://www.ofgem.gov.uk/electricityU/ transmission-networks/electricity-inetrconnectors. [31] Greenlink interconnector, https://www.greenlinkinterconnector.eu/. [32] A.B. Dorsman, A. Nentjes, P. Polak, Geostrategy of the European Union in energy, in: Energy Economy, Finance and Geostrategy, Springer, 2018, pp. 199e220. [33] E. Vasileva, S. Viljainen, P. Sulamaa, D. Kuleshov, Res support in Russia: impact on capacity and electricity market prices, Renew. Energy 76 (2015) 82e90. [34] E. Martinot, Renewable energy in Russia: markets, development and tech- nology transfer, Renew. Sustain. Energy Rev. 3 (1) (1999) 49e75. [35] H. Karunathilake, K. Hewage, W. M\u0001erida, R. Sadiq, Renewable energy selection for net-zero energy communities: life cycle based decision making under uncertainty, Renew. Energy 130 (2019) 558e573. [36] J. Chaves-\u0001Avila, C. Fernandes, The Spanish intraday market design: a suc- cessful solution to balance renewable generation? Renew. Energy 74 (2015) 422",
    "token_count": 500,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_31"
  },
  {
    "id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac",
    "created_at": "2025-07-26T15:28:57.370912+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/301635002.pdf",
    "title": "301635002",
    "text": "558e573. [36] J. Chaves-\u0001Avila, C. Fernandes, The Spanish intraday market design: a suc- cessful solution to balance renewable generation? Renew. Energy 74 (2015) 422e432. [37] Duurzaam, http://www.duurzaambedrijfsleven.nl/industrie/15265/grootste- batterij-ter-wereld-wordt-game-changer-voor-energiesysteem. Fig. A.19. Left: Boxplots for the hourly values of traded volumes on the day-ahead market. Right: Daily evolution of the traded volume for each hour slot. A. Khoshrou et al. / Renewable Energy 134 (2019) 1e13 13",
    "token_count": 165,
    "chunk_id": "2b8ae2fc-00d3-47ed-b6ac-f8ce75f8bdac_32"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": "Computing Conference 2018 10-12 July 2018 | London, UK Data-driven pattern identiÔ¨Åcation and outlier detection in time series Abdolrahman Khoshrou Centrum Wiskunde & Informatica Science Park 123, 1098 XG Amsterdam, The Netherlands Email: a.khoshrou@cwi.nl Eric J. Pauwels Centrum Wiskunde & Informatica Science Park 123,1098 XG Amsterdam, The Netherlands Email: eric.pauwels@cwi.nl Abstract‚ÄîWe address the problem of data-driven pattern identiÔ¨Åcation and outlier detection in time series. To this end, we use singular value decomposition (SVD) which is a well-known technique to compute a low-rank approximation for an arbitrary matrix. By recasting the time series as a matrix it becomes possible to use SVD to highlight the underlying patterns and periodicities. This is done without the need for specifying user- deÔ¨Åned parameters. From a data mining perspective, this opens up new ways of analyzing time series in a data-driven, bottom-up fashion. However, in order to get correct results, it is important to understand how the SVD-spectrum of a time series is inÔ¨Çuenced by various characteristics of the underlying signal and noise. In this paper, we have extended the work in earlier papers by initiating a more systematic analysis of these effects. We then illustrate our Ô¨Åndings on some real-life data. Keywords‚ÄîData mining; time series; outliers; singular value decomposition (SVD); parameter-free approximation. I. INTRODUCTION A. Motivation Since the gathering of the sensor data has become relatively cheap and straightforward, nowadays it is common to collect detailed information about all sorts of processes and services that take place in factories, infrastructural networks and public spaces. In many of these applications (especially those related to human activities), there is a multitude of time series in which a pronounced but relatively short periodicity (e.g. daily pattern) is superimposed on a slower, more global trend. If this underlying trend is simple or regular, classic detrending algorithms (e.g. [1], [2]) can be applied to remove it. However, these techniques fall short if it is difÔ¨Åcult to identify clear underlying patterns. In this paper we propose to use singular value decomposition (SVD) as a way to extract regular periodic patterns in a data-driven fashion",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_1"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " to remove it. However, these techniques fall short if it is difÔ¨Åcult to identify clear underlying patterns. In this paper we propose to use singular value decomposition (SVD) as a way to extract regular periodic patterns in a data-driven fashion. The basic idea is fairly straightforward and was Ô¨Årst proposed in [3]. Let us suppose that one has a (1-dim) periodic time series x = (x1, x2, . . . , xn) that has a known period p. We can then reshape this time series into a matrix using the Ô¨Årst p observations (i.e. x1 through xp) to construct the Ô¨Årst column, the second set of p observations (xp+1 through x2p) as the second column, and so on. Assuming that the length n of the time series is an integer multiple (say q) of p (i.e. n = pq), this reshaping results in a p √ó q matrix A. If the time series is perfectly periodic and noiseless, this matrix A has rank 1, since all the columns are linearly dependent. This means that A can be expressed as the product of a single (p-dimensional) column u and (q-dimensional) row vT : A = œÉ1uvT (1) where œÉ1 > 0 is a scaling factor to ensure the normalization ||u|| = ||v|| = 1. In fact, in the case of identical columns, v = 1q (i.e. all v-entries are equal to 1), while u will be equal to the common column. Obviously, the above represents an extreme case where all the singular values beyond the Ô¨Årst one vanish. If we sprinkle a bit of noise onto the time series, the columns in A will no longer be identical, but still very similar. As a consequence, the expression in (1) will still hold to a very good approximation. This observation is the motivation for the introduction of singular value decomposition (SVD) which we will brieÔ¨Çy recapitulate below. B. SVD recapitulation and some notation The basic result that we will use throughout the paper is the following well-known theorem. Theorem: Singular Value Decomposition (SVD) Given an arbitrary p √ó q matrix A ‚ààRp√óq, then there exists matrices U and V (both with orthonormal columns), and positive numbers œÉ1 ‚â•œÉ",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_2"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " well-known theorem. Theorem: Singular Value Decomposition (SVD) Given an arbitrary p √ó q matrix A ‚ààRp√óq, then there exists matrices U and V (both with orthonormal columns), and positive numbers œÉ1 ‚â•œÉ2 ‚â•. . . ‚â•œÉr (where r = min(p, q)), such that: A = r X k=1 œÉkUkV T k = USV T (2) with Uk and Vk denoting the kth column of U and V , respectively, and S is an p √ó q matrix for which the numbers œÉk (the singular values) are placed on the main diagonal. For a proof, see e.g. [4]. In the remainder of this paper, we will assume that the singular values are arranged in descending order: œÉ1 ‚â•œÉ2 ‚â•. . . ‚â• œÉn ‚â•0. For a given matrix A we use the notation œÉi(A) or Œªi(A) to denote the i-th (ordered) singular or eigen-value, respectively. If there is no danger of confusion, the explicit reference to the matrix will be suppressed. Recall that there is a useful relationship between the singular values of a matrix A ‚ààRp√óq and the eigenvalues of the related matrices AAT and AT A: œÉi(A) = q Œªi(AAT ) = q Œªi(AT A). (3) where i = 1 : min(p, q). This connection will be used extensively in the analysis below. IEEE 1 | P a g e arXiv:1807.03386v1 [stat.ME] 25 Jun 2018 Computing Conference 2018 10-12 July 2018 | London, UK C. Applying SVD to time series In [5], the authors draw on SVD to address the following problems for time series: 1) Period extraction: Given a times series, x = (x1, x2, . . . xn), reshape it as a p√óq matrix A (where p ranges between some judiciously chosen lower and upper value, and q = floor(n/p), is the nearest integer less than n/p. The authors then introduce the singular value ratio SV R(p) = œÉ1/œÉ2 (4) to quantify the dominance of the Ô¨Årst singular value over the second. High values of the SVR are then considered as an indicator of existence of strong underlying periodic",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_3"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " the singular value ratio SV R(p) = œÉ1/œÉ2 (4) to quantify the dominance of the Ô¨Årst singular value over the second. High values of the SVR are then considered as an indicator of existence of strong underlying periodicities. Plotting SV R as a function of p allows one to spot peaks and identify underlying periodicities. It is not necessarily correct, however, and one must exercise caution when interpreting these graphs, as explained in Section II-B. 2) Data-driven times series approximation and de- composition: If in the expansion (2) all but the Ô¨Årst r singular values are negligible, then truncating the expansion after r terms will still result in an excellent approximation of the full matrix A (and cor- responding times series). Furthermore, the columns and rows that are retained, can often be interpreted as meaningful patterns (see Fig. 1). More precisely, for an arbitrary p √ó q matrix A (using the notation established above) we know that the (L2) optimal approximation of rank p < r is given by: Ap = p X k=1 œÉkUkV T k and the Frobenius norm of the residual is given by ||A ‚àíAp||2 F = œÉ2 p+1 The gist of these observations is clearly illustrated in Fig. 1. The top panel shows a noisy block signal of length n = 1000 with a pronounced period p = 100 and q = 10 full cycles. In addition to the noise, there are three irregularly occurring spikes. After rewriting this time series as a 100√ó10 matrix A, we apply the SVD algorithm to obtain A = USV T where S is 100√ó10 ‚Äúrectangular diagonal‚Äù matrix with the 10 singular values on its main diagonal. The middle panel shows those ten singular values, clearly illustrating that all except the Ô¨Årst two are negligible, which means that the matrix (and therefore the time series) can be accurately represented by truncating the expansion in (2) after the Ô¨Årst two terms, i.e. rank-2 approximation (see Fig. 2). Finally, the bottom panel of Fig. 1 displays the Ô¨Årst three columns of U (left) and V (right), respectively. As they correspond to the most signiÔ¨Åcant singular values, they are most important for the reconstruction of the signal. The U- columns cover one cycle and can be",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_4"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": "rst three columns of U (left) and V (right), respectively. As they correspond to the most signiÔ¨Åcant singular values, they are most important for the reconstruction of the signal. The U- columns cover one cycle and can be interpreted as successive proÔ¨Åles needed to reconstruct a generic cycle. In that sense, they are analogous to the various trigonometric basis functions in Fourier analysis. The V -columns, on the other hand, specify the amplitudes with which these basis functions need to be combined in order to reproduce the individual cycles observed Fig. 1. SVD application to pattern-extraction in noisy block signal. Top: Original data of noisy block signal with period 100. In addition to the noise there are three irregularly occurring spikes. Middle: The 10 singular values for SVD with period p = 100. Clearly, only the two Ô¨Årst are signiÔ¨Åcant and œÉ1 ‚â´œÉ2 conÔ¨Årming that p = 100 corresponds to a valid periodicity. Bottom: The Ô¨Årst three columns of U (left) and V (right). in the data. Not surprisingly, the main proÔ¨Åle (U1 top left) reÔ¨Çects the step-like behaviour seen during each cycle. As the amplitude of each of these steps is essentially constant, the 10 V1-entries displayed in the top-right panel show little variation. The U2 proÔ¨Åle (middle, left) captures the shape of the additional spikes that occur at irregular intervals. The positive values in the corresponding V2-coefÔ¨Åcients (middle, right) clearly indicate in which intervals these spikes occur. Finally, the erratic appearance of both U3 and V3 are a further indication (in line with œÉ3 ‚âà0) that all structural information has been extracted from the signal. Contribution of this paper and overview: The main contri- bution of this paper is to investigate more systematically the effects of noise (Section II-B) and signal levels (Section II-C) on the SVD spectrum of a time series with a known period. In Section III, we show how one can use this decomposition to detect and interpret outliers. IEEE 2 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK Fig. 2. Top: Original (blue) and rank-2 approximation (red) of",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_5"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " detect and interpret outliers. IEEE 2 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK Fig. 2. Top: Original (blue) and rank-2 approximation (red) of the block- signal. Bottom: Residuals with respect to the approximation. II. IMPACT OF SIGNAL- AND NOISE-LEVELS ON SINGULAR VALUES As mentioned before, (4) was used to identify underlying periods in [5]. However, what was apparently not realized is that the singular values are inÔ¨Çuenced by relative and absolute levels of noise. Failing to recognize this interplay can result in biased or misleading results. For this reason, we will review and complement some earlier results. A. Singular value spectrum of random matrices In the introductory sections, we assumed that the matrix A was the superposition of some underlying periodic signal and independent noise. However, to disentangle the impact of signal and noise, we Ô¨Årst focus on the effect of pure noise (i.e. random matrices). The spectral study of random matrices (i.e. matrices for which the entries are independent, identically distributed (i.i.d.) random variables) has been a very active research domain in recent years and uncovered a number of key insights (see e.g. [6], [7], [8]). One of the more striking results is the emergence of universality which basically says that as the size of the matrix grows, the distribution of the singular values becomes increasingly independent of the distribution of the individual entries. Put differently, as long as the mean and variance of the noise is kept constant, its actual distribution has very little inÔ¨Çuence on the distribution of the resulting singular values, assuming the size of the matrix is not too small. This surprising result is illustrated in Fig. 3 where we compare the singular values (averaged over 200 trials) of 50 √ó 50 random matrices for two different distributions of the individual matrix entries: standard normal and exponential (shifted to become zero-mean). The agreement of the singular values is striking. In addition to the above result, we also know that rescaling the variance of the entries in a zero-mean random matrix induces a corresponding rescaling of the singular values: œÉi(Œ±A) = Œ± œÉi(A). This follows immediately from the observation that Œ±A = U(Œ±S)V T . In other words, the",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_6"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " in a zero-mean random matrix induces a corresponding rescaling of the singular values: œÉi(Œ±A) = Œ± œÉi(A). This follows immediately from the observation that Œ±A = U(Œ±S)V T . In other words, the singular value ratio SV R = œÉ1/œÉ2 is not affected by a uniform increase in the noise variance. However, a shift in the mean of the noise does affect the SVR, as will be explained in the section below. Fig. 3. Singular values (averaged over 200 trials) for 50√ó50 random matrices generated by drawing i.i.d. entries from the standard normal (red) and (shifted to ensure zero mean and unit variance) exponential (blue) distributions. B. Impact of entries mean value In the original papers [5], [9], it was not sufÔ¨Åciently appre- ciated how a shift in the mean value of the time series (the DC component) impacts on the SVR. This is important as failure to understand this issue introduces a major bias in the test values and could therefore result in erroneous conclusions. To address this issue, we compare the singular values of zero-mean p √ó q random matrix A0 and its mean-shifted version: A = A0 + Œ± which is shorthand for A = A0 + Œ±1p√óq = A0 + Œ±1p1T q . Using the connection between singular values and eigenvalues expounded in (3), we can express any singular value œÉ(A) as: œÉ2(A) = Œª(AAT ) = Œª((A0 + Œ±1p1T q )(AT 0 + Œ±1q1T p )) = Œª \u0000A0AT 0 + Œ±(A01q1T p + 1p1T q AT 0 ) + Œ±21p1T q 1q1T p \u0001 = Œª \u0000A0AT 0 + Œ±q(R1T p + 1pRT ) + Œ±2q1p1T p \u0001 where R = (1/q)A01q is a p √ó 1 column matrix for which each element is the mean of the corresponding A0 row. However, recall that the entries of A0 are independent zero- mean stochastic variables. Hence, unless the matrix dimensions are very small, it follows that R ‚âà0 and can be neglected. We therefore derive the approximation:",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_7"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " corresponding A0 row. However, recall that the entries of A0 are independent zero- mean stochastic variables. Hence, unless the matrix dimensions are very small, it follows that R ‚âà0 and can be neglected. We therefore derive the approximation: œÉ2(A) ‚âàŒª \u0000A0AT 0 + Œ±2q1p1T p \u0001 (5) Next, we make use of the standard results on Rayleigh quo- tients for eigenvalues which states that the dominant eigenvalue of a symmetric, positive deÔ¨Ånite matrix M is the solution to the maximization problem: Œª1 = max xÃ∏=0 \u0012xT Mx xT x \u0013 = max ||u||=1 (uT Mu). Furthermore, if an unit vector u1 realizes the above maximum, then the second largest eigenvalue is obtained as the solution of the constrained optimization problem: Œª2 = max ||u||=1 (uT Mu) s.t. u ‚ä•u1. and so on for the successive eigenvalues. Combining this with the approximation derived in (5), we get the following approximation for the Ô¨Årst singular value of IEEE 3 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK A: œÉ2(A) ‚âà max ||u||=1 uT \u0000A0AT 0 + Œ±2q1p1T p \u0001 u = max ||u||=1 \u0000uT A0AT 0 u + Œ±2quT 1p1T p u \u0001 = max ||u||=1 uT A0AT 0 u + Œ±2q ( X i ui)2 ! (6) This derivation shows that œÉ2 1(A) ‚â§max ||u||=1 \u0000uT A0AT 0 u \u0001 + Œ±2pq = œÉ2 1(A0) + Œ±2pq, (7) since from the Cauchy-Schwartz inequality it follows: X i ui !2 ‚â§ p X i=1 u2 i ! p X i=1 1 ! = p since ||u|| = 1. However, in general the unit vector u that maximizes the Rayleigh quotient will not necessarily also maximize (P ui)2. In fact, for higher singular values, the number of orthogonal constraints on u increases proportion",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_8"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " ||u|| = 1. However, in general the unit vector u that maximizes the Rayleigh quotient will not necessarily also maximize (P ui)2. In fact, for higher singular values, the number of orthogonal constraints on u increases proportionally, suggesting that on average P ui ‚âà0, and therefore œÉ2 i (A) ‚âàœÉ2 i (A0). This is indeed exactly what is seen in numerical experiments (Fig. 4). Notice that the Ô¨Årst singular value is very close to the maximal value obtained in (7) which is derived if optimizing both terms in (6), independently and simultaneously was had been done. Fig. 4. Comparison of the singular values of a matrix (10 √ó 10) with zero- mean entries (red) and shifted mean (Œ± = 5). The dotted line indicates that (approximate) upper limit based on (7). Recall that the entries of the matrix A0 are random numbers, but by shifting the global mean the SV R = œÉ1/œÉ2 increases, erroneously suggesting that some underlying periodic structure is present. Clearly, failing to remove the mean from a noisy time series would inÔ¨Çate the Ô¨Årst singular value (and only the Ô¨Årst one!) resulting in a upwardly biased value for the singular value ratio (SVR). This would reduce the power of an SVD-method in data mining applications such a blind screening. In the next section we will investigate what the impact of genuine underlying periodic signal is. C. Impact of the underlying periodic signal Suppose that we have a noisy but perfectly stationary and periodic time series x = (x1, x2, . . . , xn) with period p. For the sake of simplicity, we assume that the data cover an integer number q = n/p of periods (cycles). As explained in Section I, we then use the Ô¨Årst p observations to create a Ô¨Årst column of the matrix A, and the observations xp+1, . . . , x2p to create the second column, and so on, until we end up with a p √ó q matrix A. If the noise is very small, each column is essentially a copy of the Ô¨Årst one and we can write: A ‚âàa1T q where the p √ó 1 column a represents the data for one period. In general, the data is noisy, however, and we model that by",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_9"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " a copy of the Ô¨Årst one and we can write: A ‚âàa1T q where the p √ó 1 column a represents the data for one period. In general, the data is noisy, however, and we model that by adding independent additive noise with variance Œµ2: A = a1T q + ŒµN. Here N is a p√óq matrix of independent, identically distributed (i.i.d.) noise variables with zero mean and unit variance. To investigate the behaviour of the singular values we use the fact that œÉ2(A) = Œª(AT A) = Œª((a1T q + ŒµN)T (a1T q + ŒµN)) = Œª(a21q1T q + Œµ(N T a1T q + 1qaT N) + Œµ2N T N) where a2 = aT a = ||a||2. Since the entries of the noise matrix N are independent, zero-mean and unit variance stochastic variables, we can make the following approximation for the q √ó q matrix N T N: (N T N)ij = p X k=1 NkiNkj ‚âà \u001a p if i = j 0 if i Ã∏= j The last approximation is obtained by taking the expected values and using the fact that E(NkiNkj) = 1 if i = j, and zero otherwise. From this, we conclude that approximately: N T N ‚âàpIq Similarly, because the expectation value of the cross-term vanishes, using the linearity of the expectation operator yields: E(N T a1T q + 1qaT N) = E(N T )a1T q + 1qaT E(N) = 0. As a consequence, to a good approximation, the singular values of A can be identiÔ¨Åed as the eigenvalues of the following matrix: œÉ2(A) ‚âàŒª(a21q1T q + Œµ2pIq). The structure of the matrix in the RHS allows us to arrive at some conclusions regarding the singular values. Since any vector is an eigenvector of the identity matrix, it sufÔ¨Åces to focus on the Ô¨Årst term which is a rank-1 matrix (as the product of a column and a row). This implies that all but one eigenvalue vanish, and since 1q is obviously an eigenvector \u0000(1q1",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_10"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " the Ô¨Årst term which is a rank-1 matrix (as the product of a column and a row). This implies that all but one eigenvalue vanish, and since 1q is obviously an eigenvector \u0000(1q1T q )1q = 1q(1T q 1q) = q1q \u0001 it follows that the maximal eigenvalue (and therefore, singular value) is approximately equal to œÉ1(A) ‚âà p a2q + Œµ2p The subsequent singular values correspond to the eigenvectors which are mapped to zero by the rank-1 matrix and therefore are not inÔ¨Çuenced by the a2 term: œÉi(A) ‚âà‚àöqŒµ (for i ‚â•2) IEEE 4 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK Fig. 5. The inÔ¨Çuence of the underlying signal strength on the Ô¨Årst singular value. The curve for k = 0 corresponds to pure noise (no underlying signal). Notice how increasing the signal strength results in the corresponding increments in the Ô¨Årst singular value. Put differently, these lower ranked singular values are not inÔ¨Çuenced by the signal a, just by the noise. Notice also that the difference between the Ô¨Årst and the subsequent singular values grows proportional to ‚àöq, as it means that the more cycles that are present in the data, the more pronounced the difference. Furthermore, in many cases the noise-level Œµ2 can be neglected with respect to the strength of the signal (a2), resulting in a further approximation: œÉ1(A) ‚âà‚àöqa. This is illustrated in Fig. 5 where we took a Ô¨Åxed noise-level œµ = 0.2 and a signal strength a which is a multiple of some basic level a0 = ‚àö 12.5 and a = ka0 with k = 0, 1, 2, 3. The number of full cycles in each case was equal to q = 10. We therefore expect the Ô¨Årst singular value for each of these signal levels to be roughly equal to ‚àöq a0k ‚âà11.2k. It is important to realize that this observation is different from the result in Section II-B where the Ô¨Årst singular value was affected by a shift in the mean noise",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_11"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " be roughly equal to ‚àöq a0k ‚âà11.2k. It is important to realize that this observation is different from the result in Section II-B where the Ô¨Årst singular value was affected by a shift in the mean noise level. In this case, the mean (1/p) P i ai of the periodic signal a can still be zero, but it is its L2 norm (a2 = ||a||2) that is seen to affect the Ô¨Årst singular value. III. APPLICATION: DATA-DRIVEN OUTLIER IDENTIFICATION In the preceding sections we have explored how the singular value spectrum can be used to identify a low-rank approximation of a time series and how to avoid misleading biases in the process. These low rank approximations provide us with a useful tool to identify and interpret outliers. As an illustration, consider the data in the top panel of Fig. 6 which represents the hourly averaged power consumption of an industrial cooler (installed in business ofÔ¨Åces) over roughly 6 months (January through early July, or n = 4368 data points). This cooler works in tandem with two other coolers which explains the burst-like character of the data. Since the activity of this cooler is linked to human activity, it shows a clear daily periodicity and we therefore performed an SVD with p = 24 and q = n/p = 182. The plots in the next two rows of Fig. 6 show (left) the Ô¨Årst two U-columns (24 entries each) and (right) the corresponding V -columns of length 182 each. The two U-proÔ¨Åles are plausible: the Ô¨Årst captures a (weighted) average of the daily activity and therefore shows some baseline-activity during the night which then ramps up around 8am and returns to the baseline at about 8pm. The additional contribution encoded in the second proÔ¨Åle results in a higher activity in the morning, but lower activity in the afternoon. The corresponding V -columns on the right specify the appropriate coefÔ¨Åcients with which these proÔ¨Åles should be weighted to obtain the approximation (red graph in top panel of Fig. 7). The V1 values roughly mirror the raw data, but the V2 shows a spike that corresponds to the high value in the 3rd burst, indicating that this high value is partly due to an unusually high value in the morning. However, notice",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_12"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " The V1 values roughly mirror the raw data, but the V2 shows a spike that corresponds to the high value in the 3rd burst, indicating that this high value is partly due to an unusually high value in the morning. However, notice that this spike is well modelled by the Ô¨Årst two coefÔ¨Åcients of the SVD: as a consequence this high value does not result in a corresponding high value for the residual (see bottom panel of Fig. 7 and the zoomed-in version in Fig. 8). In fact, the third burst shows a spike in the residuals but this corresponds to a relatively low value, which however is not adequately captured by a combination of the Ô¨Årst two U-proÔ¨Åles. So using this type of analysis we can easily make the distinction between high values that are the result of unusual but regular activity (encoded in U-proÔ¨Åles that correspond to large singular values, and possibly lower values that however cannot be adequately approximated by combining such promi- nent data-driven proÔ¨Åles (i.e. ‚Äùreal‚Äù outliers). IV. CONCLUSION In this paper we have argued that the well-known singu- lar value decomposition (SVD) (which is usually applied to matrix problems) can also be successfully applied to identify periodic patterns (proÔ¨Åles) in time series. Furthermore, these proÔ¨Åles are completely deÔ¨Åned by the data and do not require the speciÔ¨Åcation of user-deÔ¨Åned parameters, apart from the period (which itself can be estimated using this approach). As such, this methodology offers a purely data-driven approach to adaptive signal approximation, and based on that, outlier detection. Moreover, we have shown that a judicious comparison of the V -coefÔ¨Åcients and residuals allows one to distinguish between different ways in which data-points can be atypical or salient. From a data mining perspective, this opens up new ways of analyzing time series in a data-driven, bottom- up fashion. However, it then becomes essential to thoroughly understand how the spectrum of time series is inÔ¨Çuenced by various characteristics of the signal and noise. In this paper, we have extended the work in earlier papers by initiating a more systematic analysis of these effects. ACKNOWLEDGMENT The authors would like to acknowledge partial support by the Dutch TTW-project SES-BE. REFERENCES [1] Z. Wu, N.",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_13"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": " we have extended the work in earlier papers by initiating a more systematic analysis of these effects. ACKNOWLEDGMENT The authors would like to acknowledge partial support by the Dutch TTW-project SES-BE. REFERENCES [1] Z. Wu, N. E. Huang, S. R. Long, and C.-K. Peng, ‚ÄúOn the trend, detrending, and variability of nonlinear and nonstationary time series,‚Äù Proceedings of the National Academy of Sciences, vol. 104, no. 38, pp. 14 889‚Äì14 894, 2007. IEEE 5 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK [2] J. W. Kantelhardt, S. A. Zschiegner, E. Koscielny-Bunde, S. Havlin, A. Bunde, and H. E. Stanley, ‚ÄúMultifractal detrended Ô¨Çuctuation analysis of nonstationary time series,‚Äù Physica A: Statistical Mechanics and its Applications, vol. 316, no. 1, pp. 87‚Äì114, 2002. [3] P. P. Kanjilal and S. Palit, ‚ÄúThe singular value decompositionapplied in the modelling and prediction of quasiperiodic processes,‚Äù Signal processing, vol. 35, no. 3, pp. 257‚Äì267, 1994. [4] G. Strang, Introduction to linear algebra. Wellesley-Cambridge Press Wellesley, MA, 1993. [5] P. P. Kanjilal and S. Palit, ‚ÄúOn multiple pattern extraction using singular value decomposition,‚Äù IEEE transactions on signal processing, vol. 43, no. 6, pp. 1536‚Äì1540, 1995. [6] T. Tao and V. H. Vu, ‚ÄúRandom matrices: The distribution of the smallest singular values,‚Äù ArXiv: 0903:0614, 2009. [7] D. Paul and A. Aue, ‚ÄúRandom matrix theory in statistics: A review,‚Äù Journal of Statistical Planning and Inference, vol. 150, pp. 1‚Äì29, 2014. [8] H. H. Nguyen, V. Vu et al., ‚ÄúRandom matrices: Law of the determinant,‚Äù The",
    "token_count": 500,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_14"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": ",‚Äù Journal of Statistical Planning and Inference, vol. 150, pp. 1‚Äì29, 2014. [8] H. H. Nguyen, V. Vu et al., ‚ÄúRandom matrices: Law of the determinant,‚Äù The Annals of Probability, vol. 42, no. 1, pp. 146‚Äì167, 2014. [9] L. H. L. J. Z. Ying and Q. Liangsheng, ‚ÄúImproved singular value decomposition technique for detecting and extracting periodic impulse component in a vibration signal,‚Äù Chinese Journal of Mechanical Engi- neering, vol. 17, no. 3, p. 1, 2004. IEEE 6 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK Fig. 6. Top: Raw data: Hourly power consumption of cooler during Ô¨Årst 6 months of the year. Bursts of activity are interspersed with periods of non-activity. Simple thresholding of the data would suggest that there are a number of unusually high values in the data, viz. in the 3rd, 5th and (possibly) 6th burst. Bottom two rows: First two U-proÔ¨Åles (left) and corresponding V-proÔ¨Åles obtained by SVD. For more details, see main text. IEEE 7 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK Fig. 7. Top: Rank-2 approximation(red) of the original signal (blue). Bottom: Corresponding residuals. Notice that the high peak in the third burst does not yield a high residual because it is adequately modelled by the extracted proÔ¨Åles. IEEE 8 | P a g e Computing Conference 2018 10-12 July 2018 | London, UK Fig. 8. Detail of 3rd ‚Äùburst‚Äù in data of Fig. 7. Top: Original (blue) and rank-2 approximation (red). Bottom: Residuals corresponding to top panel. Notice that the most prominent residual corresponds to a relatively low data peak, which however is unusual in shape. IEEE 9 | P a g e",
    "token_count": 466,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_15"
  },
  {
    "id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7",
    "created_at": "2025-07-26T15:28:57.438747+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.03386v1.pdf",
    "title": "1807.03386v1",
    "text": ", which however is unusual in shape. IEEE 9 | P a g e",
    "token_count": 16,
    "chunk_id": "db4cc9f9-dac5-49db-9c9e-163a5f2fe5a7_16"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": "A novel VOC mixtures classification methods based on GBLinear and TabNet and informative feature selection from gas sensors (E-Nose) data Hamed Karami a,* , Abdolrahman Khoshrou b a Department of Petroleum Engineering, Knowledge University, Erbil, 44001, Iraq b System Operations department, Alliander, Arnhem, The Netherlands A R T I C L E I N F O Keywords: Advanced algorithms Classification methodology Feature selection Gas mixture analysis Electronic nose A B S T R A C T The GBLinear and TabNet algorithms have been incorporated with essential feature selection techniques to create a new method of classifying essential oils using e-nose systems. Essential oils, known for their complex chemical compositions and a wide variety of applications in industries such as food, cosmetics, and pharma¬≠ ceuticals, pose some challenges for e-nose systems due to the high variability and subtle differences in volatile compounds (VOCs). This novel approach, used for the first time for the analysis of electronic nose data, integrates efficient machine-learning models with advanced feature selection techniques and aims to increase the accuracy and interpretability of essential oil classification. This study highlights the potential of integrating interpretable machine learning models with deep learning-based architectures to address challenges in the analysis of complex gas mixtures. Not only was the classification accuracy increased by these methods, but these methods could be used in the future as promising models for analyzing complex mixtures. 1. Introduction The electronic nose, commonly known as e-nose, is a new and developing technology that can potentially impact the world of analyzing and identifying multi-mixed volatile compounds eg; VOCs [1]. These systems embed chemical gas sensors, signal processing, and ma¬≠ chine learning techniques and are used in different sectors such as medicine [2,3], environment [4,5], food safety and quality [6‚Äì8]. These devices use chemical sensors that capture odor profiles and translate them into measurable signals trying to replicate the biological olfactory system [9]. E-noses are now very helpful due to their nature of being able to analyze complex odors accurately in a short amount of time and not needing to be intrusive, especially when traditional means of anal¬≠ ysis are long, costly, and troublesome [4,10]. However, the recognition of odor using e-noses is challenging largely due to the methods used to process the signals from the sensors, therefore finding suitable pro¬≠ cessing methods is a key area in",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_1"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " long, costly, and troublesome [4,10]. However, the recognition of odor using e-noses is challenging largely due to the methods used to process the signals from the sensors, therefore finding suitable pro¬≠ cessing methods is a key area in research [11]. The primary step in electronic nose gas recognition is data analysis, which typically involves three stages: data preprocessing, feature extraction and selection, and pattern recognition [12]. Data pre¬≠ processing removes noise and sensor drift using filters like wavelet, Gaussian [13], Savitzky‚ÄìGolay [14] or, Kalman [15], ensuring standardized data. Gas sensing signals, often high-dimensional, are reduced using techniques such as Principal Component Analysis [16] or other feature extraction methods [17]. Feature selection follows to minimize computational complexity. Finally, machine learning algo¬≠ rithms such as genetic algorithms, K-nearest neighbor, support vector machines, and decision trees, are employed for gas classification, with studies comparing their performance across various tasks [18]. Researchers are always on the lookout for new and improved ways to classify e-nose systems, as they are becoming increasingly advanced [19, 20]. However, that presents the problem of accurately processing and understanding the vast amount of noisy data produced by the sensors [21]. This has triggered the growing need for more advanced algorithms that can better model the characteristics of e-nose data [22]. Despite the effectiveness of these methods in so many areas, they are often limited when the sensor data are high dimensional, non-linear, or have complicated interactions among features [11]. Moreover, the inherent noise and variability present in e-nose datasets further complicate these tasks and highlight the importance of exploring more advanced classi¬≠ fication frameworks that can withstand noise while being able to pre¬≠ serve more intricate patterns within the data [21]. In this regard, the introduction of new machine learning structures is one of the solutions that can be effective for analyzing electronic nose * Corresponding author. Department of Petroleum Engineering, Knowledge University, Erbil, 44001, Iraq. E-mail address: hamed.karami@knu.edu.iq (H. Karami). Contents lists available at ScienceDirect Talanta journal homepage: www.elsevier.com/locate/talanta https://doi.org/10.1016/j.talanta.2025.128554 Received 15 February 2025; Received in revised form 30 April 2025; Accepted ",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_2"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " www.elsevier.com/locate/talanta https://doi.org/10.1016/j.talanta.2025.128554 Received 15 February 2025; Received in revised form 30 April 2025; Accepted 4 July 2025 Talanta 297 (2026) 128554 Available online 8 July 2025 0039-9140/¬© 2025 Elsevier B.V. All rights are reserved, including those for text and data mining, AI training, and similar technologies. datasets. GBLinear and TabNet are two advanced models that seek to address the shortcomings of classical models in data analysis. GBLinear, for example, works extremely well in high dimensional datasets for applications that require linear interactions due to its ability to capture linear relationships. This approach is well suited to the balance of enhancing a model‚Äôs complexity while ensuring usability, thus making it a viable option for scenarios in which reasoning behind the decision is of value. Instead, GBLinear can still take complex relationships using linear models‚Äô simplicity and efficacy by sequentially applying linear regres¬≠ sion to the residuals of the last fitted models [23‚Äì25]. This feature is of great importance, especially for e-nose systems because the relationship between the sensor responses and the corresponding odor classes may be far from linear. However, in terms of completeness, I must mention TabNet, which is a latest deep neural network model tailored for tabular data. The combination of its capacity for modeling complex nonlinear relationships and other features such as attention and interpretability make it an appropriate candidate for increasing the performance of e-nose. Developed by Google researchers, TabNet applies attention and feature selection for automatically searching for the features that are most informative for each prediction. Understanding which parts of the data provide the most relevant information allows for more accurate predictions and better training of the model. Also, TabNet‚Äôs interpret¬≠ ability features can help scientists understand which particular re¬≠ sponses of the sensors are most helpful for discriminating some specific compounds, thus aiding the design of the sensor array in a more efficient manner [26‚Äì28]. The investigational method proposed here takes advantage of the simplicity and efficiency of GBLinear, but does not neglect the impor¬≠ tance of the deep learning aspects offered by TabNet, such as its multiple interactions between non-linear features. Together, these methods pre¬≠ sent a comprehensive framework that reconciles the often conflicting requirements of explainability and accuracy. The results of this",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_3"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": "¬≠ tance of the deep learning aspects offered by TabNet, such as its multiple interactions between non-linear features. Together, these methods pre¬≠ sent a comprehensive framework that reconciles the often conflicting requirements of explainability and accuracy. The results of this study have major ramifications for the development of the next generation e- nose systems. All the aforementioned factors make the GBLinear-TabNet fusion a step towards greater accuracy in e-nose classification. 2. Material and methods 2.1. Sample preparation Seven edible essential oils were prepared from various sources. These included three medicinal plant oils; mint, tarragon, and thyme, and four fruit-based oils; mango, lemon, orange, and strawberry. For each sam¬≠ ple, both pure and industrial-grade essential oils were prepared. A total of 14 groups of essential oils were considered for the experiments. 2.2. Electronic nose instrument A custom-built electronic nose system, developed by Karami [29], utilized a 9-sensor tin metal oxide semiconductor (MOS) array (Table 1) to analyze the aroma signature patterns of VOCs emitted by purified essential oils in this study. The system comprised five key components: an activated carbon filter, a sample headspace chamber, three one-way valves, a diaphragm pump, and a sensor array linked in series via 4.0 mm PTFE tubing. Sensor data were captured using a wireless data recorder, which transmitted the information to a personal computer (PC) for collation and statistical analysis. The data acquisition process from the e-nose system was divided into three phases: baseline establishment, sample odor injection, and puri¬≠ fication. In the baseline phase, clean air from the filter was introduced into the sensor chamber through a pump and one-way valves at a flow rate of 0.8 L per minute for 60 s to stabilize the sensor response. During the sample odor injection phase, the sample head was injected into the sensor chamber, maintaining the same flow rate for 150 s, until a stable voltage response was achieved. In the purification phase, clean air was reinjected into the sensor chamber by opening the solenoid valve for 60 s, allowing the sensors to return to their baseline values. To minimize instrument baseline drift, the analysis of sample headspace volatiles from purified essential oils was conducted daily during data acquisition. At least 15 replicates per sample were measured for each essential oil type, and",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_4"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " to return to their baseline values. To minimize instrument baseline drift, the analysis of sample headspace volatiles from purified essential oils was conducted daily during data acquisition. At least 15 replicates per sample were measured for each essential oil type, and all data recorded by a data card were transmitted wirelessly to a computer for further analysis. 2.3. Data analyze Data from the individual sensors of the e-nose sensor array were extracted for preprocessing and subsequent analysis. The purpose of signal preprocessing was to isolate relevant information from the sensor responses and prepare the data for multivariate pattern analysis. To achieve this, sensor responses were normalized against their baseline for thrust compensation, contrast enhancement, and scaling, using the fraction method outlined by Karami, Rasekh and Mirzaee-Ghaleh [30], as shown in equation (1): Ys(t) = Xs(t) ‚àíXs(0) Xs(0) (1) Where Ys(t), Xs(0), and Xs(t) represent the normalized sensor response, the baseline, and the raw unprocessed sensor response, respectively. 2.3.1. GBLinear model (gradient boosted linear) GBLinear is a variant of the gradient boosting algorithm [31] spe¬≠ cifically designed for linear models. Unlike its tree-based counterparts, GBLinear uses linear functions as weak learners, making it particularly effective for datasets where relationships among features are linear or nearly linear. By combining the power of gradient boosting with linear regression or logistic regression, GBLinear provides both simplicity and interpretability. Its straightforward implementation in frameworks like XGBoost makes it a practical choice for various domains that prioritize interpretable results. For multi-class classification with k classes, the model uses the softmax function to compute class probabilities and a cross-entropy loss function as follows: L (Œò) = ‚àí ‚àë n i=1 ‚àë k j=1 yi,j log ( ÃÇyi,j ) + Œ©(Œò) (2) Where: yi,j ‚àà{0, 1} is a one-hot encoding of the true label for sample i. y ‚å¢ i,j = exp(WT j xi+bj) ‚àëk l=1 exp(WT l xi+bl) is the predicted probability for class j, obtained using the softmax function. Œò = {W,b}, where W is the matrix of weights and b is the vector of biases for all",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_5"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": "ÔøΩk l=1 exp(WT l xi+bl) is the predicted probability for class j, obtained using the softmax function. Œò = {W,b}, where W is the matrix of weights and b is the vector of biases for all classes. Œ©(Œò) = 1 2 Œª‚ÄñW‚Äñ2 + Œ±‚ÄñW‚Äñ1 includes the regularization terms. 2.3.2. TabNet model (tabular neural networks) TabNet is a deep learning architecture that uniquely combines Table 1 The types of sensors, gas detection limits, and established chemical sensitivities of tin oxide MOS sensors incorporated within the electronic nose array. Sensor name Detection ranges (ppm) Main applications (gas detection) MQ9 10-1000 and 100-10000 CO, combustible gases MQ4 300‚Äì100 Urban gases and methane MQ135 10‚Äì10000 Steam ammonia, benzene, sulfides MQ8 100‚Äì1000 Hydrogen (H2) TGS2620 50‚Äì5000 Alcohols, steam organic solvents MQ136 1‚Äì200 Sulfur dioxide (SO2) TGS813 500‚Äì10000 CH4, C3H8, C4H10 (hydrocarbons) TGS822 50‚Äì5000 Steam organic solvents MQ3 10‚Äì300 Alcohols H. Karami and A. Khoshrou Talanta 297 (2026) 128554 2 feature selection and decision-making processes within a unified framework, leveraging sequential attention mechanisms. Unlike tradi¬≠ tional gradient-boosted models or neural networks, TabNet dynamically selects features at each decision step, allowing the model to focus on the most relevant features for classification. This feature selection is ach¬≠ ieved using sparse attention masks, promoting interpretability and ef¬≠ ficiency in high-dimensional datasets. TabNet‚Äôs ability to learn directly from raw tabular data without requiring extensive preprocessing makes it particularly suited for complex, heterogeneous data structures. In this study, TabNet was particularly valuable for capturing non-linear in¬≠ teractions and subtle patterns in the volatile organic compounds (VOCs) emitted by essential oils. L CE = ‚àí1 n ‚àë n i=1 ‚àë k j=1 yi,j log ( ÃÇyi,j ) (3) Where: similar to the previous case yi,j is a one-hot encoding of the true labels",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_6"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": ". L CE = ‚àí1 n ‚àë n i=1 ‚àë k j=1 yi,j log ( ÃÇyi,j ) (3) Where: similar to the previous case yi,j is a one-hot encoding of the true labels for sample i. y ‚å¢ i,j = exp(zi,j) ‚àëk c=1 exp(zi,c) is the predicted probability for class j for sample i. zi,j is the raw logit (output before applying softmax) for class j for sample i. For more details, see Ref. [26]. Fig. 1. Two-dimensional LDA plot. Fig. 2. Confusion matrix resulting from LDA model analysis. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 3 2.4. Evaluation criteria To evaluate the system‚Äôs performance, standard criteria such as Specificity, Recall, Precision, Accuracy, Area Under the Curve (AUC), and F-score were utilized. A confusion matrix, which incorporates true positive (TP), false positive (FP), true negative (TN), and false negative (FN) values, was used to calculate these metrics. The diagnostic criteria considered were outlined by Refs. [32,33]: Specificity = TN TN + FP (4) Precision = TP TP + FP (5) Recall = TP TP + FN (6) Accuracy = TP + TN TP + TN + FN + FP (7) AUC = Sensitivity + Precision 2 (8) F = 2 √ó PR P + R (9) In this study, 70 % of the data was used for training and 30 % for validation, and all analyses were performed using Python (version 3.9.12). 3. Result 3.1. LDA In this study, LDA was used to visually evaluate the grouping and overlap of different classes within the dataset, providing insights into the distinctiveness of each class based on their features. Additionally, LDA served as a benchmark classification method, offering a comparative baseline for evaluating the performance of more complex machine learning models used in subsequent analyses. As shown in Fig. 1, the natural essential oil samples from medicinal plants are clearly distin¬≠ guishable from their synthetic counterparts. However, for fruit-based samples, there is noticeable overlap between the natural and synthetic types. The confusion matrix for classifying different essential oil groups is shown",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_7"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " natural essential oil samples from medicinal plants are clearly distin¬≠ guishable from their synthetic counterparts. However, for fruit-based samples, there is noticeable overlap between the natural and synthetic types. The confusion matrix for classifying different essential oil groups is shown in Fig. 2. For each class, the main diagonal values represent true positives (TP), while the sum of the remaining diagonal values corre¬≠ sponds to true negatives (TN). Additionally, the sum of the values in the respective column indicates false positives (FP), and the sum of the values in the respective row represents false negatives (FN). According to the figure, within the natural fruit essential oil group, 17 out of 24 samples were correctly classified, while 7 samples were misclassified. In the second group, representing synthetic essential oils, 22 samples were accurately identified, and 2 samples were misclassified. Finally, for the third and fourth groups, comprising pure medicinal essential oils and synthetic medicinal essential oils, all 8 samples in each group were correctly classified. Based on equations (2)‚Äì(7), the performance parameters of the LDA method for classifying essential oils are summarized in Table 2. The confusion matrix was employed to compute the performance parameters of the detection models. As shown in Table 2, the LDA method achieved an impressive 100 % accuracy in classifying the data, highlighting its effectiveness in distinguishing between different essential oil groups. As shown in Table 2, the average precision of the LDA method achieved 90.6 % in data classification, and the values of accuracy, recall, AUC, Table 2 Performance parameters obtained from the LDA model. Group Accuracy Precision Recall Specificity AUC F Fruit Natural 0.893 0.708 0.895 0.892 0.800 0.791 Fruit Synthetic 0.893 0.917 0.759 0.964 0.940 0.830 Medicine Natural 1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average per class 0.946 0.906 0.913 0.964 0.935 0.905 Fig. 3. Confusion matrix resulting from GBLinear model analysis. H. Karami and A",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_8"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": "000 Average per class 0.946 0.906 0.913 0.964 0.935 0.905 Fig. 3. Confusion matrix resulting from GBLinear model analysis. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 4 and F-score were equal to 94.6, 91.3, 96.4, 93.5, and 90.5 %, respectively. 3.2. GBLinear The results of the LDA method revealed its limitations in accurately classifying fruit-based essential oils, emphasizing the importance of achieving reliable differentiation within these groups. To address this challenge, GBLinear was utilized as a more robust approach for classi¬≠ fying and analyzing the dataset. This method provided valuable insights into the predictive capabilities of the features and served as a benchmark for comparing its performance with other models. As illustrated in Fig. 3, GBLinear demonstrated exceptional accuracy in distinguishing between natural and synthetic essential oils derived from medicinal plants. For fruit-based samples, while some overlap was observed, only 3 sample were misclassified, showcasing a significant improvement over tradi¬≠ tional methods commonly applied to electronic nose data. Also, ac¬≠ cording to Table 3, the values of precision, recall, and F-score were 96.9 % for the performance parameters. 3.3. TabNet TabNet was employed to further analyze the dataset and classify essential oil groups, leveraging its advanced deep learning architecture designed for tabular data. This method combines attention mechanisms with feature selection, enabling it to capture complex patterns and re¬≠ lationships within the data. As shown in Fig. 4, TabNet achieved excellent results in distinguishing between natural and synthetic essential oils from both medicinal plants and fruits. Unlike other models, TabNet effectively minimized misclassification, correctly classifying all medicinal plant samples and achieving near-perfect accuracy for fruit- based samples, with only 2 minor overlaps observed. As presented in Table 4, TabNet demonstrated exceptional performance across various classification metrics. The model achieved an average precision of 97.9 %, reflecting its strong ability to correctly identify relevant samples. In terms of other performance metrics, accuracy reached 98.8 %, recall was 97.9 %, AUC scored 98.5 %, and the F-score was 97.9 %. These results highlight TabNet‚Äôs superior capability in",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_9"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " terms of other performance metrics, accuracy reached 98.8 %, recall was 97.9 %, AUC scored 98.5 %, and the F-score was 97.9 %. These results highlight TabNet‚Äôs superior capability in effectively handling complex datasets and ensuring high reliability in the classification of essential oil samples. According to the results obtained, the models classified 100 % of the medicinal essential oil samples and only failed to classify fruit essential oils completely. Therefore, it is very important to focus on the sensors that are important for this sector in this section. Some sensors in the analysis may exhibit high sensitivity toward specific target analytes, making them crucial for the detection of trace compounds in food samples. Fig. 5a and b illustrate how each sensor contributes positively or negatively to the overall sensor system performance. According to Fig. 5a, the positive effect of the sensors on the classes is observed. As it is clear, the MQ136 sensor is the only sensor that has a 100 % role on the Table 3 Performance parameters obtained from the GBLinear model. Group Accuracy Precision Recall Specificity AUC F Fruit Natural 0.964 0.917 0.957 0.967 0.942 0.936 Fruit Synthetic 0.964 0.958 0.920 0.983 0.971 0.939 Medicine Natural 1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average per class 0.982 0.969 0.969 0.988 0.978 0.969 Fig. 4. Confusion matrix resulting from TabNet model analysis. Table 4 Performance parameters obtained from the TabNet model. Group Accuracy Precision Recall Specificity AUC F Fruit Natural 0.976 0.958 0.958 0.983 0.971 0.958 Fruit Synthetic 0.976 0.958 0.958 0.983 0.971 0.958 Medicine Natural 1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_10"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": "1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average per class 0.988 0.979 0.979 0.992 0.985 0.979 H. Karami and A. Khoshrou Talanta 297 (2026) 128554 5 chemical fruit essential oil group. The MQ3 sensor also played the most role in the natural fruit essential oil. Therefore, these two sensors are key sensors for increasing the classification accuracy in these groups. The two sensors MQ135 and TGS813 also have a positive role in detecting natural fruit essential oil. On the other hand, the two sensors MQ9 and MQ4 also played the most role in classifying the essential oil of aromatic plants. Also, according to Fig. 5b, it can be seen that the TGS822 sensor has the most negative effect on the natural fruit essential oil group and the MQ8 sensor has the most positive effect on the chemical fruit essential oil group. Perhaps by removing these two sensors, better ac¬≠ curacy can be achieved in these groups. And similarly, the TGS 2620 sensor has a large negative impact on the natural medicinal essential oil group. These three sensors in Fig. 5a are sensors that have had an effect on at least three groups of essential oils. Perhaps by removing these sensors, higher accuracy can be achieved, especially in the fruit group. This study‚Äôs results reveal that the GBLinear and TabNet approach has outperformed the traditional classification methods like LDA. While employing an electronic nose for essential oil analysis, it is important to make use of models that can capture complicated non-linear relation¬≠ ships between the sensor responses and the volatile organic compounds (VOCs). Our research clearly illustrates how the use of these algorithms, especially in the classification of fruit-based essential oils, has had significantly better results than before.To this point, the work done on e- nose classification techniques has primarily focused on the use of the traditional machine learning methods like Principal Component Anal¬≠ ysis (PCA), Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and Random Forest (RF). For example, Rasekh and Karami [34] tried to detection of juices fraud and achieved a success rate of nearly ",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_11"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": "PCA), Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and Random Forest (RF). For example, Rasekh and Karami [34] tried to detection of juices fraud and achieved a success rate of nearly 94 %, an outcome that was bettered with our method. Others, like. This study shows that the GBLinear model alone is superior to this method by achieving 96.9 % accuracy. Furthermore, TabNet further enhances classification performance, achieving an overall accuracy of 98.8 %. The complexity and variations of e-nose sensor response is one of the main challenges that data analyzers must deal with. Linear approaches are implemented mainly using LDA, however, fruits-based essential oils suffer from classification errors during LDA. The reason for this is the overlap between VOC profiles. As was shown in our analysis, several fruit-based samples were assigned LDA class marks in error due to composition of volatile organic compounds. That is, LDA assumptions were satisfied only to an accuracy level of 94.6 %. On the other hand, GBLinear showed improvement but only through attaining the most essential linear relationships present in the data set. While GBLinear also showed improvements counting 96,9 % in recall, the real improvement was in TabNet with 97.9 % accuracy and 99.2 % specificance. This model uses attention-based feature selection techniques deep learning classification models to overcome classification blockades. With TabNet setting, the model was able to successfully tell apart natural and syn¬≠ thetic fruit essential oils. In this case the model also greatly improved recall and specificity. Another important factor is the contribution of a specific sensor element within a classification category. During the conducted analysis of sensor importance, it was found that specific sensors like, MQ136 and MQ3, are much more critical than MQ9 and Fig. 5. a) positive and b) negative effect. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 6 MQ4 for classifying fruit essential oils and medicinal plant essential oils. Research has shown that gas sensors can often respond to multiple volatile organic compounds (VOCs), making them prone to misidenti¬≠ fication, especially when analyzing complex mixtures [35]. This insight aligns with findings from previous research, such as Di Natale, Capuano, Quercia, Catini, Biasioli, Khomen",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_12"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " misidenti¬≠ fication, especially when analyzing complex mixtures [35]. This insight aligns with findings from previous research, such as Di Natale, Capuano, Quercia, Catini, Biasioli, Khomenko and Paolesse [35], which empha¬≠ sized the need for selective sensor optimization to improve e-nose classification accuracy. Moreover, our results indicate that certain sen¬≠ sors, including TGS822 and MQ8, contributed negatively to classifica¬≠ tion performance in specific groups, suggesting that their exclusion or recalibration could further enhance model accuracy. 4. Conclusion The combination of GBLinear and TabNet algorithms along with the selection of informative features has improved the classification of oils with the use of e-nose. TabNet with an accuracy of 98.8 %, was able to classify samples of essential oils more accurately. The accuracy of Tab¬≠ Net was considerably higher than that of LDA and GBLinear which was 94.6 % and 96.9 %. While all models worked well for the classification of the essential oils from the medicinal plants, it was found that TabNet algorithm did the best with incorporating essential oils derived from fruits. These results also emphasize the superiority of combining elec¬≠ tronic noses with advanced machine learning algorithms by demon¬≠ strating their ability to fathom complex odors. The combination of GBLinear and TabNet improves accuracy and interpretability, then this method can enhance e-nose technology in the food, cosmetics, and pharmaceutical industries. As a result, this methodology contributes to algorithms combination for enhance model robustness, complete. Future research could explore the application of this methodology to a broader range of volatile compounds and investigate its potential in real-time analysis scenarios. CRediT authorship contribution statement Hamed Karami: Supervision, Visualization, Data curation, Re¬≠ sources, Writing ‚Äì original draft, Validation, Software, Methodology, Conceptualization, Investigation, Formal analysis. Abdolrahman Kho¬≠ shrou: Writing ‚Äì original draft, Data curation, Software, Formal analysis. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability Data will be made available on request. References [1] J.A. Covington, S. Marco, K.C. Persaud, S.S. Schiffman, H.T. Nagle, Artificial",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_13"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " the work reported in this paper. Data availability Data will be made available on request. References [1] J.A. Covington, S. Marco, K.C. Persaud, S.S. Schiffman, H.T. Nagle, Artificial olfaction in the 21 st century, IEEE Sens. J. 21 (11) (2021) 12969‚Äì12990. [2] D. Karakaya, O. Ulucan, M. Turkan, Electronic nose and its applications: a survey, Int. J. Autom. Comput. 17 (2) (2020) 179‚Äì209. [3] A.D. Wilson, M. Baietto, Advances in electronic-nose technologies developed for biomedical applications, Sensors 11 (1) (2011) 1105‚Äì1176. [4] A. Khorramifar, H. Karami, L. Lvova, A. Kolouri, E. ≈Åazuka, M. Pi≈Çat-RoÀôzek, G. ≈Åag¬¥od, J. Ramos, J. Lozano, M. Kaveh, Y. Darvishi, Environmental engineering applications of electronic nose systems based on MOX gas sensors, Sensors 23 (12) (2023) 5716. [5] J.P. S¬¥a, M.C.M. Alvim-Ferraz, F.G. Martins, S.I.V. Sousa, Application of the low-cost sensing technology for indoor air quality monitoring: a review, Environ. Technol. Innovat. 28 (2022) 102551. [6] J.B.B. Rayappan, A.J. Kulandaisamy, M. Ezhilan, P. Srinivasan, G.K. Mani, Developments in electronic noses for quality and safety control, Advances in Food Diagnostics2017, pp. 63-96. [7] H. Karami, M. Kamruzzaman, J.A. Covington, M.¬¥e. Hassouna, Y. Darvishi, M. Ueland, S. Fuentes, M. Gancarz, Advanced evaluation techniques: gas sensor networks, machine learning, and chemometrics for fraud detection in plant and animal products, Sensor Actuator Phys. 370 (2024) 115192. [8] P",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_14"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": ", M. Gancarz, Advanced evaluation techniques: gas sensor networks, machine learning, and chemometrics for fraud detection in plant and animal products, Sensor Actuator Phys. 370 (2024) 115192. [8] P. Darvishi, E. Mirzaee-Ghaleh, Z. Ramedani, H. Karami, A.D. Wilson, Detecting whey adulteration of powdered milk by analysis of volatile emissions using a MOS electronic nose, Int. Dairy J. 157 (2024) 106012. [9] A.D. Wilson, M. Baietto, Applications and advances in electronic-nose technologies, Sensors 9 (7) (2009) 5099‚Äì5148. [10] S. Zorpeykar, E. Mirzaee-Ghaleh, H. Karami, Z. Ramedani, A.D. Wilson, Electronic nose analysis and statistical methods for investigating volatile organic compounds and yield of mint essential oils obtained by hydrodistillation, Chemosensors 10 (11) (2022) 486. [11] F. Wu, R. Ma, Y. Li, F. Li, S. Duan, X. Peng, A novel electronic nose classification prediction method based on TETCN, Sensor. Actuator. B Chem. 405 (2024) 135272. [12] J.A. Covington, S. Marco, K.C. Persaud, S.S. Schiffman, H.T. Nagle, Artificial olfaction in the 21st century, IEEE Sens. J. 21 (11) (2021) 12969‚Äì12990. [13] H.H. Afshari, S.A. Gadsden, S. Habibi, Gaussian filters for parameter and state estimation: a general review of theory and recent trends, Signal Process. 135 (2017) 218‚Äì238. [14] X. Wang, C. Qian, Z. Zhao, J. Li, M. Jiao, A novel gas recognition algorithm for gas sensor array combining savitzky‚Äìgolay smooth and image conversion route, Chemosensors 11 (2) (2023) 96. [15] F. Auger, M. Hilairet, J.M. Guerrero, E. Monmasson, T. Orl",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_15"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": " and image conversion route, Chemosensors 11 (2) (2023) 96. [15] F. Auger, M. Hilairet, J.M. Guerrero, E. Monmasson, T. Orlowska-Kowalska, S. Katsura, Industrial applications of the Kalman filter: a review, IEEE Trans. Ind. Electron. 60 (12) (2013) 5458‚Äì5471. [16] H. Karami, B. Thurn, N.K. de Boer, J. Ramos, J.A. Covington, J. Lozano, T. Liu, W. Zhang, S. Su, M. Ueland, Application of gas sensor technology to locate victims in mass disasters ‚Äì a review, Nat. Hazards (2024). [17] N.S. Aghili, M. Rasekh, H. Karami, O. Edriss, A.D. Wilson, J. Ramos, Aromatic fingerprints: VOC analysis with E-Nose and GC-MS for rapid detection of adulteration in sesame oil, Sensors 23 (14) (2023) 6294. [18] X. Wang, Y. Zhou, Z. Zhao, X. Feng, Z. Wang, M. Jiao, Advanced algorithms for low dimensional metal oxides-based electronic nose application: a review, Crystals 13 (4) (2023) 615. [19] M. Rasekh, H. Karami, S. Fuentes, M. Kaveh, R. Rusinek, M. Gancarz, Preliminary study non-destructive sorting techniques for pepper (Capsicum annuum L.) using odor parameter, LWT 164 (2022) 113667. [20] N. Mohammadian, A.M. Ziaiifar, E. Mirzaee-Ghaleh, M. Kashaninejad, H. Karami, Gas sensor technology and AI: forecasting lemon juice quality dynamics during the storage period, J. Stored Prod. Res. 109 (2024) 102449. [21] T. Liu, L. Guo, M. Wang, C. Su, D. Wang, H. Dong, J. Chen, W. Wu, Review on algorithm design in electronic noses: challenges, status, and",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_16"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": ". [21] T. Liu, L. Guo, M. Wang, C. Su, D. Wang, H. Dong, J. Chen, W. Wu, Review on algorithm design in electronic noses: challenges, status, and trends, Intelligent Computing 2 (2023) 12. [22] H.-J. He, d.S.F.M. Vinicius, W. Qianyi, K. Hamed, M. Kamruzzaman, Portable and miniature sensors in supply chain for food authentication: a review, Crit. Rev. Food Sci. Nutr. 1-21. [23] C. Wade, K. Glynn, Hands-On Gradient Boosting with Xgboost and scikit-learn: Perform Accessible Machine Learning and Extreme Gradient Boosting with Python, Packt Publishing Ltd2020. [24] S. Karimi, M. Asghari, R. Rabie, M. Emami Niri, Machine learning-based white-box prediction and correlation analysis of air pollutants in proximity to industrial zones, Process Saf. Environ. Prot. 178 (2023) 1009‚Äì1025. [25] S. Dhiman, A. Thukral, P. Bedi, Impact of clinical features on disease diagnosis using knowledge graph embedding and machine learning: a detailed analysis, in: A. Verma, P. Verma, K.K. Pattanaik, S.K. Dhurandher, I. Woungang (Eds.), Advanced Network Technologies and Intelligent Computing, Springer Nature Switzerland, Cham, 2024, pp. 340‚Äì352. [26] S.¬®O. Arik, T. Pfister, Tabnet: attentive interpretable tabular learning, Proc. AAAI Conf. Artif. Intell. (2021) 6679‚Äì6687. [27] C. Shah, Q. Du, Y. Xu, Enhanced TabNet: attentive interpretable tabular learning for hyperspectral image classification, Remote Sens. 14 (3) (2022) 716. [28] K. McDonnell, F. Murphy, B. Sheehan, L. Masello, G. Castignani, Deep learning in insurance: accuracy and model interpretability using TabNet, Expert Syst. Appl. 217 (2023) 119543. [29] M. Rase",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_17"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": "an, L. Masello, G. Castignani, Deep learning in insurance: accuracy and model interpretability using TabNet, Expert Syst. Appl. 217 (2023) 119543. [29] M. Rasekh, H. Karami, A.D. Wilson, M. Gancarz, Performance analysis of MAU-9 electronic-nose MOS sensor array components and ANN classification methods for discrimination of herb and fruit essential oils, Chemosensors 9 (9) (2021) 243. [30] H. Karami, M. Rasekh, E. Mirzaee-Ghaleh, Application of the E-nose machine system to detect adulterations in mixed edible oils using chemometrics methods, J. Food Process. Preserv. 44 (9) (2020) e14696. [31] T. Chen, C. Guestrin, Xgboost: a scalable tree boosting system, Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining (2016) 785‚Äì794. [32] H. Karami, M. Rasekh, E. Mirzaee ‚Äì Ghaleh, Comparison of chemometrics and AOCS official methods for predicting the shelf life of edible oil, Chemometr. Intell. Lab. Syst. 206 (2020) 104165. [33] H. Karami, S. Karami Chemeh, V. Azizi, H. Sharifnasab, J. Ramos, M. Kamruzzaman, Gas sensor-based machine learning approaches for characterizing tarragon aroma and essential oil under various drying conditions, Sensor Actuator Phys. 365 (2024) 114827. [34] M. Rasekh, H. Karami, Application of electronic nose with chemometrics methods to the detection of juices fraud, J. Food Process. Preserv. 45 (5) (2021) e15432. [35] C. Di Natale, R. Capuano, L. Quercia, A. Catini, F. Biasioli, I. Khomenko, R. Paolesse, AR1. 3-Real time proton transfer reaction and electronic nose H. Karami and A. Khoshrou Talanta 297 (",
    "token_count": 500,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_18"
  },
  {
    "id": "eb2ab534-8788-467e-a6cc-1216b675f247",
    "created_at": "2025-07-26T15:28:57.463178+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/VOC_paper.pdf",
    "title": "VOC_paper",
    "text": ", F. Biasioli, I. Khomenko, R. Paolesse, AR1. 3-Real time proton transfer reaction and electronic nose H. Karami and A. Khoshrou Talanta 297 (2026) 128554 7 simultaneous measurements on same samples, Proceedings IMCS 2018 (2018) 229‚Äì230. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 8",
    "token_count": 103,
    "chunk_id": "eb2ab534-8788-467e-a6cc-1216b675f247_19"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": "Quantifying Volatility Reduction in German Day-ahead Spot Market in the Period 2006 through 2016 Abdolrahman Khoshrou Intelligent and Autonomous Systems Group Centrum Wiskunde & Informatica The Netherlands Email: a.khoshrou@cwi.nl Eric J. Pauwels Intelligent and Autonomous Systems Group Centrum Wiskunde & Informatica The Netherlands Email: Eric.Pauwels@cwi.nl Abstract‚ÄîIn Europe, Germany is taking the lead in the switch from the conventional to renewable energy. This poses new challenges as wind and solar energy are fundamentally inter- mittent, weather-dependent and less predictable. It is therefore of considerable interest to investigate the evolution of price volatility in this post-transition era. There are a number of reasons, however, that makes the practical studies difÔ¨Åcult. For instance, EPEX prices can be zero or negative. Consequently, the standard approach in Ô¨Ånancial time series analysis to switch to logarithmic measures is inapplicable. Furthermore, in contrast to the stock market prices which are only available for trading days, EPEX prices cover the whole year, including weekends and holidays. Accordingly, there is a lot of underlying variability in the data which has nothing to do with volatility, but simply reÔ¨Çects diurnal activity patterns. An important distinction of the present work is the application of matrix decomposition techniques, namely the singular value decomposition (SVD), for deÔ¨Åning an alternative notion of volatility. This approach is systematically more robust toward outliers and also the diurnal patterns. Our observations show that the day-ahead market is becoming less volatile in recent years. Keywords‚ÄîDay-ahead price, Electricity market, Energy switch, Singular value decomposition, Time-series analysis, Renewable energy sources. I. INTRODUCTION Renewable Energy Sources (RES) are assuming an increas- ingly pre-eminent role in the German electricity production. SigniÔ¨Åcant cost reductions, on the one hand, and tremendous technology advances and reliability improvements, on the other hand, have primed a growing interest in green electricity. Germany is pursuing an ambitious goal, a switch from fossil fuel to renewables, ‚ÄúEnergiewende‚Äù (energy transition). By 2050, the emission of greenhouse gases is planned to reduce by 80-95% (see [1]). To achieve this, energy consumption is to be reduced by 50% and at least 80% of electricity is to come from renewables. In line",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_1"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": " the emission of greenhouse gases is planned to reduce by 80-95% (see [1]). To achieve this, energy consumption is to be reduced by 50% and at least 80% of electricity is to come from renewables. In line with that, Germany has substantially expanded its RES-capacity, in particular wind and solar [2]. Consequently, the need for accurate predictions for the quantity of green electricity which is going to be fed into the grid at any given moment is becoming increasingly important. Moreover, energy transition could put pressure on the energy sector in This work was supported in part by the Dutch STW under project grant Smart Energy Management and Services in Buildings and Grids (SES-BE). terms of Ô¨Çexibility in managing power demand and supply. It is therefore to be expected that this evolution will have a signiÔ¨Åcant impact on German electricity prices. This paper provides an overview of the price volatility of the German day-ahead EPEX market. If price volatility increases, it can cause additional risks for suppliers and consumers on the electricity market. Negatively impact the reli- ability of the power grid is also possible. Due to the integration of the European grids the problems will not be limited to the German grid. Increasing instability in the German grid means also a higher instability in the neighboring grids. In the present work, we have opted to focus on this market as it represents an important and growing segment where market mechanisms are clearly visible. In particular, we focus on the following question: How can the evolution of the price volatility of the day-ahead market over the past eleven years (i.e., 2006-2016) be quantiÔ¨Åed? The rest of this paper is organized as follows: Section II contains background studies and literature review. Section III focuses on the data description for day-ahead market; also explains the source and a brief summary of the day-ahead market mechanism. The evolution of a new type of volatility measure for time series data is discussed in Section IV. The general reduction in the volatility of price data is argued in Section V. II. BACKGROUND AND LITERATURE REVIEW Recently, the impact of variable generation on the electric- ity market has attracted a lot of attention. We brieÔ¨Çy highlight a number of important contributions which are related to the topics discussed in this paper. Denny et al. [3] study the functionality of the increased interconnection between Great Britain and Ireland to facilitate the integration of",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_2"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": " We brieÔ¨Çy highlight a number of important contributions which are related to the topics discussed in this paper. Denny et al. [3] study the functionality of the increased interconnection between Great Britain and Ireland to facilitate the integration of the wind farms into the power system. This work suggests a reduction in average price and its volatility in Ireland to be an outcome of the increased interconnection. With the growing contribution of intermittent energy sources, transmission grid extensions and increasing the cross-border interconnection capacities seem inevitable. Schaber et al. [4] examine the viability of this approach and its effects, based on projected wind and solar data until 2020; they also conclude that expanding the grid is, indeed, helpful in coping with externalities which come with arXiv:1807.07328v1 [q-fin.ST] 19 Jul 2018 the deployment of RES. The relation of substantial expansion of photovoltaic (PV) installations in Germany and Italy with daytime peak price fall in these countries is discussed in [5]. In [6] the inÔ¨Çuence of the RES on the German day-ahead market is studied; the authors also have considered priority that the German government assigns to the green electricity over fossil fuels in case of adequate supply. This paper also argues that the emergence of negative prices in the German day-ahead market is the result of the integration of RES. In the present paper, our main focus is the evolution of the price volatility. Therefore, a novel approach to quantify the volatility of the German day-ahead market is proposed. III. DATA The European Power Exchange (EPEX SPOT SE) operates on the Central Western European (CWE) spot market, i.e. Swiss, French, German and Austrian short-term electricity markets. Striving for the creation of a single integrated electric- ity market, EPEX SPOT functions as an organized wholesale market place for trading large quantities of electricity between the market members. These members are mostly non-Ô¨Ånal consumers and big players in the energy sector such as utilities and aggregators, industrial producers, the Transmission System Operators (TSOs), banks, Ô¨Ånancial service providers and energy trading entities that are working within the energy sector on a daily basis. In fact, this company offers its clients the technologies, electronic trading systems and platform to operate their orders based on reference prices. a) Day-ahead Auction Spot Market: The day-ahead market is an exchange for short",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_3"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": " the energy sector on a daily basis. In fact, this company offers its clients the technologies, electronic trading systems and platform to operate their orders based on reference prices. a) Day-ahead Auction Spot Market: The day-ahead market is an exchange for short-term electricity contracts. The trading in this market is driven by its participants. A buyer, typically a utility, needs to assess how much energy (MWh) it will need to fulÔ¨Åll its customers requirements for the following day, and how much its purchase price is going to be (Euro/MWh) hour by hour. The seller, for example the owner of a wind farm, also submits the quantity he is prepared to deliver the next day and the price level on hourly basis. The deadline for the members to submit the price and the quantity for which they seek to make an agreement is 12:00 CET. These ‚Äúbids‚Äù are fed into a complex algorithm to calculate the clearing price. From 00:00 CET the next day, the sellers deliver the power at the contracted rate. b) Day-Ahead Spot Prices (in Euro/MWh): This is the price (for each time-slot of the next day) as set by the spot market. As previously mentioned, on the day-ahead market the hourly price of the traded quantity (in Euro/MWh) is set a day earlier. Fig. 1 illustrates an overview of the hourly values of the price on the day-ahead market in Germany and Austria from 2006 until 2016 (data source: [7]). IV. VOLATILITY OF THE DAY-AHEAD PRICE A. Introduction It is reasonable to question whether the intermittency of renewables would render the price more erratic. This can happen due to technical problems in the grid, e.g., conges- tion; or simply due to poor performance of the day-ahead energy forecasting models. For that, we are interested in the volatility of the day-ahead price. Loosely speaking, volatility Fig. 1. German day-ahead spot prices from 2006 through 2016 (daily averages); an overall downward trend in the day-ahead price is notable. refers to the random Ô¨Çuctuations of a time series about its expected value. There are various methods to deÔ¨Åne and quantify volatility, from applied models like Garman/Klass to coefÔ¨Åcient of variation and formal Stochastic Volatility models such as GARCH, Heston models and the like, see",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_4"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": ". There are various methods to deÔ¨Åne and quantify volatility, from applied models like Garman/Klass to coefÔ¨Åcient of variation and formal Stochastic Volatility models such as GARCH, Heston models and the like, see, e.g., [8], [9]. However, there are at least two reasons why it is problematic to blindly transfer standard Ô¨Åntech methodology to the current setting: ‚Ä¢ Since EPEX prices can be zero or negative, the standard approach to switch to logarithmic measures is not applicable. ‚Ä¢ More importantly, while the stock market prices are only available on trading days; EPEX prices cover the whole year, including weekends and holidays. As a consequence, there is a lot of underlying variability in the data which has nothing to do with volatility, but simply reÔ¨Çects the diurnal activity patterns. For these reasons, we will Ô¨Årst pre-proccess the raw data to eliminate the underlying patterns; and subsequently focus on quantifying the volatility of the resulting residuals. The nature of this pre-processing is discussed in the following subsection. B. Extracting underlying trends Singular value decomposition (SVD) is a popular matrix decomposition technique; which we use to extract the under- lying daily and seasonal patterns. SVD is applied extensively in matrix computations, but can also be put to good use in the study of time series which have exogenously induced periods. This is often the case in economics time series, where the variables of interest show daily or annual periods. In the case at hand, it is clear that prices would show daily patterns that might change relatively slowly over the year. To apply SVD, we rewrite the time series as a matrix where each column records the 24 hourly values for a particular day [10]. In this way, a time series representing a typical year is recast as a matrix A of size 24 √ó 365. If the results for every day were identical, then all the columns would be identical and the matrix would have a rank equal to one (rank(A) = 1). Put differently, the matrix could be written as the product of a 24 √ó 1 column and a 1 √ó 365 row. In practice, however, the values for subsequent days will tend to be slightly different Fig. 2. Raw price data for 2016 Fig. 3. SVD-based rank-2 approximation: Left column: Ô¨Årst two columns",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_5"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": ". In practice, however, the values for subsequent days will tend to be slightly different Fig. 2. Raw price data for 2016 Fig. 3. SVD-based rank-2 approximation: Left column: Ô¨Årst two columns of U-matrix representing a weighted averaged proÔ¨Åle for each day (top) and a Ô¨Årst order correction (again one value for each hour over a 24 hour period). Right column: corresponding amplitudes (V columns). and therefore A has a rank that exceeds one. Nevertheless, SVD assures us that A can still be expanded as a sum of rank 1 matrices (i.e. a column times a row) where each next contribution in the sum is less important. In mathematical parlance, any given matrix Ah√ód can be written as: A = r X k=1 œÉkUkV T k or more succinctly A = USV T (1) where U ‚ààO(h) and V ‚ààO(d) are matrices with orthonormal columns, with Uk and Vk denoting the kth column of U and V , respectively; and S is an h√ód matrix for which the only strictly positive elements œÉk (so-called singular values) are situated on the main diagonal [11]. The importance of this decomposition lies in the fact that truncating the expansion in the right hand side of (1) after the pth term yields the best approximation of the original matrix A by a matrix of (lower) rank p ‚â§r [12]. Ap = arg min rank(R)=p ||A ‚àíR|| (2) where the norm || ¬∑ || can be either the Frobenius or spectral L2 norm. We illustrate the process for the price data of the year 2016. The raw hourly values are shown in Fig. 2. After recasting this time series into a 24 √ó 366 matrix (2016 was a leap year!), we can compute the Ô¨Årst two terms in the SVD expansion. The results are illustrated in Fig. 3. The left panels depict the Ô¨Årst two columns of the U matrix. The top left panel resembles an appropriately weighted daily average‚Äì averaged over the year. The price peaks in the morning and Fig. 4. Detail of rank-2 approximation (red) superimposed on original data (blue). Fig. 5. Top: Original and rank-2 approximation of the price data",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_6"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": " the year. The price peaks in the morning and Fig. 4. Detail of rank-2 approximation (red) superimposed on original data (blue). Fig. 5. Top: Original and rank-2 approximation of the price data for 2016. Bottom: Absolute values of the residuals after rank-2 approximation. Residuals as a means to measure volatility. late afternoon are clearly visible. The second column of U is depicted on the bottom left panel; it provides a correction which needs to be added to the average in order to get a better approximation. The panels on the right-hand side represent the Ô¨Årst two columns of the V matrix and specify an amplitude coefÔ¨Åcient for every day. To obtain an approximation for the actual data on day d, one must multiply each proÔ¨Åle on the left by the d-th amplitude coefÔ¨Åcient on the right and of course the corresponding singular value; then add them all up. To get some idea of what a rank-2 approximation looks like, Fig. 4 shows a detail of the approximation (in red) superimposed on the actual data (blue). Fig. 5 contains a more general case of the reconstruction of price data in 2016, along with the absolute value of the corresponding residuals. C. Quantifying volatility In the current section, we focus on the residuals of the price after compensating for daily patterns using a rank-2 approximation; it is done to quantify the volatility of the data over the years. The choice to focus on rank-2 approximation is relatively arbitrary and unimportant. Fig. 6 illustrates that the singular values of the price data throughout different years follow the same pattern. Furthermore, as can be seen in the top panel of Fig. 7, the absolute value of the residuals adhere remarkably well to an exponential distribution (with mean 2.97). It is almost only the top 1% that is substantially higher in value than expected. Moreover, the lower panel of Fig. 7 highlights the fact that the higher rank approximations yield Fig. 6. An overview of the evolution of the singular value of the price data in each year. Fig. 7. Top: The residuals of the rank-2 approximation of the day-ahead market prices for year 2016: almost 99% of residuals adhere to exponential distribution. Bottom: Higher rank approximations yield similar results. similar results. Fig. 8 conÔøΩ",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_7"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": " The residuals of the rank-2 approximation of the day-ahead market prices for year 2016: almost 99% of residuals adhere to exponential distribution. Bottom: Higher rank approximations yield similar results. similar results. Fig. 8 conÔ¨Årms that this pattern is also seen throughout the period (2006-2016) ‚Äì we focus on in this paper. Based on this observation, we propose the following approach to quantify the evolution in (annual) volatility in the years 2006 through 2016: 1) The inÔ¨Çuence of the daily and seasonal variations is removed by Ô¨Åtting a rank-2 approximation, and extracting the residual of the actual data with respect to this approximation. As volatility is inÔ¨Çuenced by both positive and negative Ô¨Çuctuations, we focus on the absolute values of these residuals. 2) For every year, we Ô¨Åt the lowest 99% of the residual values with an exponential and compute the corre- sponding parameter (i.e. mean of the exponential). This value corresponds to the size of the residuals. Fig. 8. Exponential distribution of the residuals of the rank-2 approximations for different years. Fig. 9. Evolution of the price volatility on the German day-ahead market in the period 2006 through 2016 . The individual data points record the estimated exponential parameter (mean) based on all but the 1% highest values of the residuals. The regression line has a slope equal to -0.58 which is highly signiÔ¨Åcant (95% conÔ¨Ådence interval: -0.89 : -0:26). See main text for more details. 3) Typically, the top 1% of the observed distribution is much larger than expected (based on the bulk of the distribution). We characterize these values by computing the median value this top 1% segment separately. The results are shown in Figs. 9 and 10. The former Ô¨Ågure shows a robust estimate for the mean of exponential distribu- tion for each year. The estimate is based on the lowest 99% of the residual (absolute) values and is therefore robust with respect to the 1% extremely large values. The 99% vs. 1% is dictated by the exponential prob-plot in Figs. 7 and 8 which show a clear divergence at the ",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_8"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": " values and is therefore robust with respect to the 1% extremely large values. The 99% vs. 1% is dictated by the exponential prob-plot in Figs. 7 and 8 which show a clear divergence at the 99% mark. To quantify this decreasing trend, we have also computed the regression line, which yields a statistically signiÔ¨Åcant downward slope equal to -0.58 (with 95% conÔ¨Ådence interval: -0.89:-0.26). The quality of this regression can be further improved by Ô¨Åtting a power law, but at this point we simply want to illustrate the signiÔ¨Åcant downward trend. The evolution of the top 1% is shown in Fig. 10 where these data are represented by their median value. The picture we get from this indicates that whereas extreme residuals were not uncommon prior to 2010, these values fell signiÔ¨Åcantly and have been roughly constant during the last Ô¨Åve years. The message from both Ô¨Ågures combined is that volatility has decreased signiÔ¨Åcantly over the past decade. Fig. 10. Evolution of top 1% residuals over the years 2006-2016. Each data point represents the median value of the top one percent residuals (in absolute value). As such, these values characterize the extreme deviations in day ahead prices. The plot clearly shows that these extreme values decreased signiÔ¨Åcantly before 2010, and then stayed approximately constant. a) Volatility tends to be higher in winter: Fig. 5 sug- gests that volatility tends to be lower in summer (middle part of graph) than winter (extremal parts of the graph). To demon- strate that this is indeed the case, we use a measure based on the angular momentum. More precisely, if the residual for hour slot h is given by R(h) and the distance between the hour slot h and the central hour slot hm = n/2 = 4392 equals |h‚àíhm| the observed angular momentum is deÔ¨Åned a: Lobs = n X h=1 R(h)(h ‚àíhm)2 (3) where n is equal to the total number of hour slots. If we re-scale the values of the hour slot in such a way that hm = 0 and ‚àí1 ‚â§h ‚â§1 (divided by 1000,",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_9"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": "2 (3) where n is equal to the total number of hour slots. If we re-scale the values of the hour slot in such a way that hm = 0 and ‚àí1 ‚â§h ‚â§1 (divided by 1000, for ease of comparison), we obtain Lobs = 10.676. A high value for Lobs refutes the assumption that the residuals are uniformly distributed throughout the year, and favours an interpretation in which residuals (and hence volatility) is higher in the winter season. To judge the signiÔ¨Åcance of this result, we use a permutation test. The rationale is straightforward: if the residuals are uniformly distributed over the hour slots, then a random permutation of the values should not result in a signiÔ¨Åcantly different value for Lobs. The results for 2016 are depicted in Fig. 11. It can be shown that all the other years produced similar results. V. CONCLUSIONS The growing share of renewables (especially wind and solar) in the German energy mix appears to result in a higher degree of volatility of the electricity prices; as RES are intermittent and less predictable. Any errors in day-ahead projections for these sources can lead to higher variability in the market. In this paper, we looked at the electricity prices on the German day-ahead market in the period 2006 through 2016. The occurrence of zero or even negative prices makes it difÔ¨Å- cult to simply use the standard volatility measures which are common in Ô¨Åntech and stock markets. Therefore, we focused on residuals obtained after removing the underlying diurnal or seasonal patterns. This was accomplished by applying singular value decomposition (SVD) to the time series to get a low rank approximation of the raw data. Our results show that price Fig. 11. Price data for 2016: Results of the permutation test. The histogram of the L-values for 1000 random permutations of the actual data. Obviously, the actually observed value (indicated in red) is signiÔ¨Åcantly larger than values we would expect for data sets without structure (with a p-value < 10‚àí3). This conÔ¨Årms our observation that volatility shows a seasonal pattern. volatility has signiÔ¨Åcantly decreased during the past eleven years. The most likely cause for this is the improved accuracy of the forecasting tools for renewables in recent years. REFERENCES [1] ‚ÄúFourth energy transition monitoring report,‚Äù https://",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_10"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": " pattern. volatility has signiÔ¨Åcantly decreased during the past eleven years. The most likely cause for this is the improved accuracy of the forecasting tools for renewables in recent years. REFERENCES [1] ‚ÄúFourth energy transition monitoring report,‚Äù https://www.bmwi.de/BMWi/Redaktion/PDF/V/ vierter-monitoring-bericht-energie-der-zukunft-englische-kurzfassung, property=pdf,bereich=bmwi2012,sprache=de,rwb=true.pdf. [2] ‚ÄúInformation portal renewable energy,‚Äù http://www. erneuerbare-energien.de/EE/Navigation/DE/Service/. [3] E. Denny, A. Tuohy, P. Meibom, A. Keane, D. Flynn, A. Mullane, and M. Omalley, ‚ÄúThe impact of increased interconnection on electricity systems with large penetrations of wind generation: A case study of ireland and great britain,‚Äù Energy Policy, vol. 38, no. 11, pp. 6946‚Äì 6954, 2010. [4] K. Schaber, F. Steinke, and T. Hamacher, ‚ÄúTransmission grid extensions for the integration of variable renewable energies in europe: Who beneÔ¨Åts where?‚Äù Energy Policy, vol. 43, pp. 123‚Äì135, 2012. [5] K. Barnham, K. Knorr, and M. Mazzer, ‚ÄúBeneÔ¨Åts of photovoltaic power in supplying national electricity demand,‚Äù Energy Policy, vol. 54, pp. 385‚Äì390, 2013. [6] N. Adaduldah, A. Dorsman, G. J. Franx, and P. Pottuijt, ‚ÄúThe inÔ¨Çuence of renewables on the german day ahead electricity prices,‚Äù in Perspec- tives on Energy Risk. Springer, 2014, pp. 165‚Äì182. [7] ‚ÄúEpexspot, day-ahead auction,‚Äù https://www.epexspot.com/en/ product-info/auction/germany-austria. [8] L. C. G. Rogers and S. E. Satchell, ‚ÄúEstimating variance from high, low and closing prices,‚Äù The Annals of Applied Probability, pp. 504‚Äì512, ",
    "token_count": 500,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_11"
  },
  {
    "id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89",
    "created_at": "2025-07-26T15:28:57.500194+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.07328v1.pdf",
    "title": "1807.07328v1",
    "text": "many-austria. [8] L. C. G. Rogers and S. E. Satchell, ‚ÄúEstimating variance from high, low and closing prices,‚Äù The Annals of Applied Probability, pp. 504‚Äì512, 1991. [9] R. T. Baillie, C.-F. Chung, and M. A. Tieslau, ‚ÄúAnalysing inÔ¨Çation by the fractionally integrated arÔ¨Åma‚Äìgarch model,‚Äù Journal of applied econometrics, pp. 23‚Äì40, 1996. [10] A. Khoshrou, A. B. Dorsman, and E. J. Pauwels, ‚ÄúSvd-based visualisa- tion and approximation for time series data in smart energy systems,‚Äù in 2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), Sept 2017, pp. 1‚Äì6. [11] K. Baker, ‚ÄúSingular value decomposition tutorial,‚Äù The Ohio State University, vol. 24, 2005. [12] G. H. Golub and C. Reinsch, ‚ÄúSingular value decomposition and least squares solutions,‚Äù Numerische mathematik, vol. 14, no. 5, pp. 403‚Äì420, 1970.",
    "token_count": 278,
    "chunk_id": "37c7ec4f-c3f2-4a24-9227-3beba66a2c89_12"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "REAL-TIME UNSUPERVISED MOTION LEARNING FOR AUTONOMOUS UNDERWATER VEHICLES USING GAUSSIAN MIXTURE MODELS ABDOLRAHMAN KHOSHROU DISSERTA√á√ÉO DE MESTRADO APRESENTADA √Ä FACULDADE DE ENGENHARIA DA UNIVERSIDADE DO PORTO EM √ÅREA CIENT√çFICA M 2015 FACULDADE DE ENGENHARIA DA UNIVERSIDADE DO PORTO Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles using Gaussian Mixture Models Abdolrahman Khoshrou WORKING VERSION Master in Information Engineering Supervisor: Professor Ant√≥nio Pedro Aguiar July 27, 2015 Abstract Over the last decade, there has been a Ô¨Çurry of activity in the development of autonomous marine robotic vehicles to improve the means available for ocean exploration and exploitation. A partic- ular scenario where Autonomous Underwater Vehicles (AUVs) can play an important role is in the automatic acquisition of marine environmental data. In this case, one or more AUVs acting in cooperation are programmed to survey a given region. To this end, an important problem that has to be addressed is the sampling motion control strategy, that is, the high-level software algorithm that is implemented on a computer system at the AUV, that decides based on the on-board sensors where (and in some cases when) to acquire environmental data. Motivated by the above, this thesis proposes a solution to solve the problem of real-time adaptive sampling using a coordinated Ô¨Çeet of AUVs. In the Ô¨Årst part of the thesis, we address the on-line unsupervised learning problem of Gaussian mixture models (GMMs) in the presence of uncer- tain dynamic environments. In particular, we assume that the number of Gaussian components (clusters) is unknown and can change over time. We propose a multi-hypothesis adaptive algo- rithm that continuously updates the number of components and estimates the model parameters as the measurements (sample data) are being acquired. This is done by incrementally maximizing the likelihood probability associated to the estimated parameters and keeping/creating/removing in parallel a number of hypothesis models that are ranked according to the minimum description length (MDL), a well-known concept in information theory. The proposed algorithm has the ad- ditional feature that it relaxes ‚Äúthe sufÔ¨Åciently large data set‚Äù",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_1"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " number of hypothesis models that are ranked according to the minimum description length (MDL), a well-known concept in information theory. The proposed algorithm has the ad- ditional feature that it relaxes ‚Äúthe sufÔ¨Åciently large data set‚Äù restriction by not requiring an initial batch of data. Simulation results illustrate the performance of the proposed algorithm. In the second part of the thesis, we use the proposed unsupervised algorithm to develop an adaptive sampling strategy to obtain relevant conductivity, temperature and depth (CTD) information of a given area using a coordinated Ô¨Çeet of AUVs. In the proposed setup, a leader AUV is tasked to acquire CTD data by running a set of user-deÔ¨Åned mission instructions like for example following a desired path proÔ¨Åle. The rest of the Ô¨Çeet (the followers AUVs) will follow the leader closely with a desired formation that will adaptively change according to the CTD data that they are acquiring. More precisely, each AUV is in charge of running in real-time the proposed unsupervised learning algorithm for GMMs that is fed by the CTD data. At each time that the vehicles resurface (and this is done in a coordinated fashion), the leader AUV broadcast its currently estimated parameters of the GMM, and the followers based on this and their estimated GMM compute the variational distance error between these GMMs. This error, which provides a notion of how different is, from the leader, the CTD measurements that each follower is acquiring, is then used to update the next formation conÔ¨Åguration, which typically scales the distance between the AUVs in the formation (making a zoom-in and zoom-out), in order to improve the efÔ¨Åciency of data acquisition in a given region. The simulation results show the feasibility and accuracy of the motion learning strategies in many uniform and complex environments. i ii Acknowledgments My deepest gratitude goes to my supervisor Professor Ant√≥nio Pedro Aguiar. I am extremely thankful and indebted to him for sharing his expertise, and sincere and valuable guidance and encouragement extended to me. He has set an example of excellence as a researcher, mentor, instructor and role model. Next, I need to thank all the people who created such a good atmosphere in the lab; Silvia, Andr√©, Lu√≠s, Hugo and Behzad. I would also like to thank the secretarial and academic staff",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_2"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " instructor and role model. Next, I need to thank all the people who created such a good atmosphere in the lab; Silvia, Andr√©, Lu√≠s, Hugo and Behzad. I would also like to thank the secretarial and academic staff for putting up with me and answering all my questions. A special thanks goes to M√≥nica Oliveira, Catarina Morais, Paulo Lopes and Jos√© Ant√≥nio Nogueira who all deserve early retirement after I leave. I am also very thankful to all friends I met in Portugal. I had a great time with you. A lot of thanks goes to Michael Silva, Lu√≠s Mendes, Carlos Almeida and Mario Alejandro Salgado. I hope to see you again as soon as possible. And last but not least, my heartfelt thanks goes to my family. My mother Mina, my sisters Hannaneh and Samaneh and my brother Hamid. You are a constant source of understanding and support. iii iv ‚ÄúHe who says he can and he who says he can‚Äôt are both usually right‚Äù Confucius v vi Contents 1 Introduction 1 1.1 Technologies for ocean sampling . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.1.1 Research Vessels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.1.2 Moored Instrumentation and Ocean Observatories . . . . . . . . . . . . 3 1.1.3 Towed Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.1.4 Remotely Operated Vehicles . . . . . . . . . . . . . . . . . . . . . . . . 5 1.1.5 Autonomous Underwater Gliders . . . . . . . . . . . . . . . . . . . . . 6 1.1.6 Unmanned Surface Vessels: Wave Gliders . . . . . . . . . . . . . . . . . 7 1.1.7 Autonomous Underwater Vehicles . . . . . . .",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_3"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "1.6 Unmanned Surface Vessels: Wave Gliders . . . . . . . . . . . . . . . . . 7 1.1.7 Autonomous Underwater Vehicles . . . . . . . . . . . . . . . . . . . . . 7 1.1.8 The AOSN Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.2 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.3 Contributions and Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.4 Dissertation Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2 Unsupervised Learning of Gaussian Mixture Models 13 2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.2 Previous Works/Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.3 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.4 Preliminaries and basic results . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.4.1 The Basic Expectation-Maximization (Off-line) Algorithm . . . . . . . . 17 2.4.2 Titterington‚Äôs On-line Algorithm for a Multivariate Normal Mixture . . . 23 2.4.3 The Minimum Description Length (MDL) Principle . . . . . . . . . . . 25 2.4.4 Gaussian Mixture Reduction . .",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_4"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " Multivariate Normal Mixture . . . 23 2.4.3 The Minimum Description Length (MDL) Principle . . . . . . . . . . . 25 2.4.4 Gaussian Mixture Reduction . . . . . . . . . . . . . . . . . . . . . . . . 28 2.5 The Proposed On-line Unsupervised Learning Algorithm . . . . . . . . . . . . . 33 2.6 Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.6.1 A 2-d Gaussian Mixture . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.6.2 The Iris Data Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.6.3 A 1-d Gaussian Mixture . . . . . . . . . . . . . . . . . . . . . . . . . . 37 2.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 3 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles 41 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3.2 Literature Review on Adaptive Sampling using AUVs . . . . . . . . . . . . . . . 42 3.3 Problem Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.4 Preliminaries and Background . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.4.1 Coordinate Frames . . . . . . . . . . . .",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_5"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " Background . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.4.1 Coordinate Frames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 3.4.2 SimpliÔ¨Åed Kinematic Equations . . . . . . . . . . . . . . . . . . . . . . 47 3.4.3 CTD Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 vii viii CONTENTS 3.4.4 Navigation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 3.5 CTD adaptive sampling strategy . . . . . . . . . . . . . . . . . . . . . . . . . . 55 3.5.1 Path Following . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 3.5.2 Coordinated Formation . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 3.5.3 Variational distance between GMMs . . . . . . . . . . . . . . . . . . . . 57 3.6 Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 3.6.1 The Leader AUV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 3.6.2 The follower AUV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 3.6.3 Uniform Environment Simulation . . . . . . . . . . . . . . . . .",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_6"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " . . . . . . . . . . . . . . . . . . . . . . 59 3.6.3 Uniform Environment Simulation . . . . . . . . . . . . . . . . . . . . . 61 3.6.4 Complex Environment Simulation . . . . . . . . . . . . . . . . . . . . . 63 3.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 4 Conclusions and FutureWork 65 4.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 4.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 References 67 List of Figures 1.1 Underwater exploration (image sources: [3]). . . . . . . . . . . . . . . . . . . . 1 1.2 A Lesson In Complexity (image source: [4]) . . . . . . . . . . . . . . . . . . . . 2 1.3 Ocean expedition (image sources: Left [4], Right [2]). . . . . . . . . . . . . . . 3 1.4 Endurance array and slope base mooring (image source: [4]) . . . . . . . . . . . 4 1.5 Tethered Underwater Vehicles (image sources: Left [2], Right [4]). . . . . . . . 5 1.6 Free-Swimming Autonomous Sampling Vehicles (image sources: Left [2], Right [12]). 6 1.7 Light Autonomous Underwater Vehicles (image source: [17]) . . . . . . . . . . . 8 1.8 The Autonomous Ocean Sampling Network (image source: [1]) . . . . . . . . . 9 2.1 An example of good initialization . . . .",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_7"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " . . . . . . . . 8 1.8 The Autonomous Ocean Sampling Network (image source: [1]) . . . . . . . . . 9 2.1 An example of good initialization . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.2 EM drawbacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.3 An example of the execution behaviour of the proposed algorithm. . . . . . . . . 35 2.4 Iris Data Set Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 2.5 Linearly separable mixture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 2.6 Fairly overlapped mixture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 2.7 Highly overlapped mixture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 3.1 The earth-Ô¨Åxed inertial frame {U} and the body-Ô¨Åxed frame {B} with position, orientation and linear and angular velocities . . . . . . . . . . . . . . . . . . . . 46 3.2 SimpliÔ¨Åed kinematic model of an underwater vehicle that maintains in a horizontal plane. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 3.3 A close up of the CTD sensor of the AUV (image source: [1]) . . . . . . . . . . 48 3.4 Temperature ProÔ¨Åles (images source: [17]). . . . . . . . . . . . . . . . . . . . . 49 3",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_8"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " . . . . . . . . 48 3.4 Temperature ProÔ¨Åles (images source: [17]). . . . . . . . . . . . . . . . . . . . . 49 3.5 A two-dimensional kinematic model of an AUV. The angle Œ∏ of the resulting ve- locity V does not necessarily correspond with the heading angle œà . . . . . . . . 51 3.6 A typical DVL device (image source: [1]) . . . . . . . . . . . . . . . . . . . . . 52 3.7 Two categories of INSs (image sources: Left [4], Right [7]). . . . . . . . . . . . 53 3.8 Overall visual servoing control scheme.(image source: [117]) . . . . . . . . . . . 54 3.9 Schematic representation of the setup . . . . . . . . . . . . . . . . . . . . . . . 56 3.10 Schematic representation of the leader . . . . . . . . . . . . . . . . . . . . . . . 58 3.11 Schematic representation of the follower . . . . . . . . . . . . . . . . . . . . . . 59 3.12 Real CTD data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 3.13 Uniform environment. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 3.14 Uneven environment. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 ix x LIST OF FIGURES List of Tables 3.1 Simulation parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 xi xii LIST OF TABLES Abbreviations and Symbols GMM Gaussian Mixture Model EM Expectation Maximization",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_9"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " . . . . . . . . . . . . . . . . . . . . . . . . . 57 xi xii LIST OF TABLES Abbreviations and Symbols GMM Gaussian Mixture Model EM Expectation Maximization ML Maximum Likelihood MAP Maximum A posteriori Probability CTD Conductivity, Temperature, Depth AIC Akaike‚Äôs Information Criterion BIC Bayesian Inference Criterion FIM Fisher Information Matrix MHT Multi-Hypothesis Tracker JPDAF Joint Probabilistic Data Association Filter KL Kullback-Leibler MDL Minimum Description Length MML Minimum Message Length SC Stochastic Complexity RCA Robust Competitive clustering Algorithm ART Adaptive Resonance Theory AUV Autonomous Underwater Vehicle ACM Acoustic Current Meter DSL Digital Subscriber Line USV Unmanned Surface Vessel ASC Autonomous Surface Craft AOSN Autonomous Ocean Sampling Network IMU Inertial Measurement Unit INS Inertial Navigation System GPS Global Positioning System ITRF2000 International Terrestrial Reference Frame 2000 ROV Remotely Operated Vehicle DVL Doppler Velocity Log RPM Round Per Minute UUV Unmanned Underwater Vehicle ROMS Regional Ocean Model System COLREGs International Regulations for Prevention of Collision SONAR Sound Navigation And Ranging LBL Long-Base-Line USBL Ultra-Short-Base-Line xiii Chapter 1 Introduction The ocean is a crucial feature of Earth, but due to extreme conditions in deep beneath the sur- face, it still remains a nearly unexplored territory. Ocean expedition, methodical observations and documentation of different outlooks of the ocean, e.g., in biology, geochemistry, physics and ar- chaeology can help us to reveal the mysteries of the deep ocean ecosystems. Recent discoveries reveal that largest mass of living things on earth are living near the ocean Ô¨Çoor. Figure 1.1(a) shows expanding of molten rock in the form of bubbles, under the pressure of mag- matic gas. This magmatic gas is presumed to be mostly water because when the water is under the magmas and the magmatic temperature is a thousand degrees and when it is suddenly cooled by coming contact with the sea water, the bubble bursts. The ocean Ô¨Çoors are formed exclusively by these volcanic activities. Hydrothermal vents, which are chimney like structures with several stories high, spewing hot wa- ter geysers black with minerals and nutrients. The temperature around these deep sea events can scorch up to ",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_10"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " are formed exclusively by these volcanic activities. Hydrothermal vents, which are chimney like structures with several stories high, spewing hot wa- ter geysers black with minerals and nutrients. The temperature around these deep sea events can scorch up to 760‚ó¶F. Figure 1.1(b) shows an astonishing sight of an exotic garden of giant tube worms, that thriving without sunlight and feed on sulfur compounds erupting from the vents in this toxic water [1, 2]. Deep understanding of the ocean, demands novel research approaches to (a) Hydrothermal vents (b) An exotic marine garden Figure 1.1: Underwater exploration (image sources: [3]). study interactive ocean processes thoroughly and simultaneously to determine the linkage among 1 2 Introduction Figure 1.2: A Lesson In Complexity (image source: [4]) and between chemical, physical, biological and geological factors in a coherent temporal and spa- tial framework, see Figure 1.2. For example, the chemistry of water in different geographic areas, affect the organisms that live there and those in turn inÔ¨Çuence the geology of the ocean Ô¨Çoor. With the recent advances in technology, ocean observatories are gaining the capacity to fulÔ¨Ål the expec- tations in expedition of vast, unstructured and dynamic environments of the ocean by analysing the dependency and correlation between ocean dynamics, climate and ecosystem responses at the lo- cal to basin scales in real-time. These powerful new approaches are named as the grand challenges in environmental and ocean sciences [4]. 1.1 Technologies for ocean sampling Our climate and weather, the water we drink and the food we eat, even the air we breathe, all of these are closely connected to the ocean that covers almost three quarters of our planet. Today, much of the ocean and how it works still remains a mystery, but in the way that the doctors con- stantly monitor the health of critical patients, scientists from around the world are now using the sate-of-the-art technology to constantly take the pulse of our dynamic marine and coastal environ- ments. In the early days, exploring the ocean started by sending divers down into the water. Divers had to deal with a number of hazards such as decompression, dragging to the ship holes or pounding into the infrastructures, due to the currents. During the years, researchers use observatories wherever they can so they don‚Äôt have to",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_11"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ". Divers had to deal with a number of hazards such as decompression, dragging to the ship holes or pounding into the infrastructures, due to the currents. During the years, researchers use observatories wherever they can so they don‚Äôt have to put themselves in those kind of situations. Ocean observatories are collections of high-tech instruments above and below the waves that pro- vide around-the-clock information about what is happening in the ocean in an systematic non- invasive way. 1.1 Technologies for ocean sampling 3 (a) A Research Vessel (b) A surface mooring in deep water Figure 1.3: Ocean expedition (image sources: Left [4], Right [2]). Sensors on satellites miles above the earth, look at both large and small areas of the ocean surface providing key data about the temperature, color and tide of the water. Radar towers on land, col- lect information about the movement of the water at the surface of the motion, including the speed and the direction of the surface currents. Sensors and instruments attached to the stationary buoys collect the information at the same location over long periods of time. Autonomous underwater vehicles travel independently below the ocean surface collecting infor- mation about the water conditions. This data then sent back to the scientists on land or board ships. Instruments connected to the network of underwater hops called nodes continuously collect data and send it back to the land through cables. The same cables also provide electrical power to the nodes and other equipments. Using data collected through ocean observatories, scientists are now beginning to forecast ocean conditions, much like meteorologists do for the weather. 1.1.1 Research Vessels A typical way to get ocean measurements is called shipboard hydrographic programme, which is the employment of in-situ sensors on cargo ships or ferry-boats. The ships are equipped with special tools and technology that allow scientists to collect samples and taking measurements in a different levels of the ocean. Annual cruises are launched to measure the water properties by lowering down the instruments all the way to the bottom of the ocean, step by step in different levels, to measure the water properties and the Ô¨Çow. This enables the scientists to get a snapshot of the ocean circulation yearly. In early design vessels, typical instruments such as temperature and conductivity recorders, current proÔ¨Ålers and so on, capture the data and store them internally. It is only retrieved when the ship reaches the Ô¨Ånal destination [",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_12"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " ocean circulation yearly. In early design vessels, typical instruments such as temperature and conductivity recorders, current proÔ¨Ålers and so on, capture the data and store them internally. It is only retrieved when the ship reaches the Ô¨Ånal destination [5]. Late research vessels, equipped with state-of-the-art technological gadgetry, provide stable platforms for the scientists to deploy divers and submersibles, Figure 1.3(a). 1.1.2 Moored Instrumentation and Ocean Observatories Ocean processes are around-the-clock, so, the use of annual research vessel cruises is not practical to observe the ocean throughout the year. Scientists and engineers have come up with ways to 4 Introduction Figure 1.4: Endurance array and slope base mooring (image source: [4]) leave instruments out in the ocean for long-term monitoring. A cost-effective solution could be implementing an array of moored proÔ¨Ålers which are anchored to the bottom of the ocean. Moored observatories are platforms which can occupy a spot in the ocean and allow the researchers to observe a column of water years. They are important tools for monitoring the oceanic processes in large temporal scale and, due to advances in sensor tech- nologies, the of them increasing in the last decade [6]. This technology can help the researchers to develop ocean-atmosphere models, and learn about air-sea interactions in seasonal and yearly scales. The basic suite of instruments of a typical buoy is depicted in Figure 1.3(b). Above the water, moored buoys equipped with meteorological sensors and solar panes are able to measure the hu- midity and temperature of the air and solar and/or infra red radiation. Beneath the surface, buoys hold various instruments, such as: current meters, temperature and pressure sensors, sediment traps, chemical sensors, power supplies, data recorders, and an ACM (acoustic current meter). The captured data can be sent to a central repository in almost real-time through satellite or radio communication systems. Researchers are looking ahead to the prospect of sending data home in real-time via satellite [7]. It is quite challenging to get these instruments to operate for years in sea in very harsh environments, and only a very small portion of the ocean can be covered in this approach. As a result, the spatial resolution is typically poor due to the high cost. Furthermore, sea water generally does not get along well with electronic devices and, on",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_13"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " environments, and only a very small portion of the ocean can be covered in this approach. As a result, the spatial resolution is typically poor due to the high cost. Furthermore, sea water generally does not get along well with electronic devices and, on the other hand, the surface waves can physically damage the instruments and the moorings. With recent developments, the instrumentation and performance of the moored arrays can be im- proved by combining a proÔ¨Åling mechanism to a moored based system, see [8]. Nowadays, Ô¨Å- bre cables are capable of supplying electric power for the mooring proÔ¨Ålers and platforms and transferring the data from deep in the ocean to the land, see Figure 1.4. Also, battery-powered 1.1 Technologies for ocean sampling 5 (a) The CAMera samPlER, or ‚ÄúCamper\" (b) ROPOS on a mission Figure 1.5: Tethered Underwater Vehicles (image sources: Left [2], Right [4]). traction motor can help the proÔ¨Ålers to climb up and down the mooring and provide unparalleled spatial-temporal resolution on biological and geochemical features, ocean acidiÔ¨Åcation, and other oceanographic processes. 1.1.3 Towed Systems To expand the spatial scale of the area under study, scientists and engineers have devised large sampling sledges that are tethered to research vessels. Towed systems lowered down to the sea Ô¨Çoor to collect samples from the ocean bottom. With respect to the objective of the mission, towed sled can be equipped with different instruments to collect samples or take measurements. Chemical sensors, CTD sensor devices, lights and optical instrumentation, a navigation system, a video camera, and claws to quickly grab samples, can be mounted on these sledges, Figure 1.5(a). Recent towed systems, by using impeller-forced wings, are able to rotate and undulate to the upper level of water. A multi-conductor tow cable, or in sonar type a long Ô¨Åbre, is used to send the control signals from on-board ship control unit to a hydraulic unit inside the vehicle to modify the wings. Towed systems have limited maneuverability, are slow, costly and controlled from a ship via a cable or Ô¨Åbre, that provides electrical and data transfer possibility. Some undulating versions allow for complex vertical yo-yo paths, even so, during the last",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_14"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " systems have limited maneuverability, are slow, costly and controlled from a ship via a cable or Ô¨Åbre, that provides electrical and data transfer possibility. Some undulating versions allow for complex vertical yo-yo paths, even so, during the last decade towed systems are being widely replaced by untethered submersibles. See [2, 9] for more details. 1.1.4 Remotely Operated Vehicles Remotely Operated Vehicles (ROVs), see Figure 1.5(b), are tremendous powerful platforms teth- ered by the ships and typically known as underwater helicopters, because they can hover over a sea Ô¨Çoor target and surf a vast area to explore unblemished ocean parts. ROVs are tethered to the research vessel by a Ô¨Åber-optic cable to be able to send high band-width data to a control console and receive electrical power and mission plan. 6 Introduction (a) (b) Figure 1.6: Free-Swimming Autonomous Sampling Vehicles (image sources: Left [2], Right [12]). Unlike the towed vehicles in Section 1.1.3, here, a pilot can have a direct control over the vehi- cle‚Äôs mission using a hand-controller to send the control commands and adjust the sensors. This, allows the researchers to carry out detailed experiments, take measurements, collect samples and observe the deep sea Ô¨Çoor while controlling the vehicle from the surface. Another advantage is that, ROVs are less affected by the position and relative motion of the vessel and the current, so they get perfect sensor data, perfect video. ROVs, typically, are equipped with video cameras, lights, acoustic imaging sonars, which are used to ‚Äúsee\" in zero visibility, velocity meters and CTD sensor devices. Using tracking and navigation systems, the exact location f them are known in real-time which increases the maneuverability of these vehicles. Recent ROVs are called smart Ô¨Çights which are semi-autonomy package that allow return to the target by pushing a button doing way-points navigation. High cost, constrained mobility by the umbilical, relatively low speed the drag associated to the frame and the tether are the major challenges in using these vehicles [9]. 1.1.5 Autonomous Underwater Gliders An Autonomous Underwater Glider (AUG) is a buoyancy-propelled, Ô¨Åxed-wing vehicle that en- ables robotic",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_15"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " are the major challenges in using these vehicles [9]. 1.1.5 Autonomous Underwater Gliders An Autonomous Underwater Glider (AUG) is a buoyancy-propelled, Ô¨Åxed-wing vehicle that en- ables robotic exploration in large bodies of water, Figure 1.6(a). with the help of its wings and by means of internal mass redistribution, the vehicle goes up and down through the ocean in a pattern called a saw-tooth [10]. The wings actually take the vertical motion of the vehicle and translate that into forward motion. In oceanographic studies, these robots are being used to take scientiÔ¨Åc measurements of salinity, temperature, volcanic matters, oxygen contents in the water and so on. They sink and rise, on command, to send the high-resolution data back to the researchers. AUGs, while on the surface, can communicate with the operators via RF modems or Iridium satellite phones. As mentioned earlier, gliders sink and rise on command, i.e., during the mission the op- erators are able to program and change the current task or waypoints of the vehicle and send the commands via Iridium satellite links. Portability and scalability in infrastructure of the Ô¨Çeet are the main advantages of these small, inexpensive platforms to cover a vast area. On the other hand, the waves can cause a lot of damage to the robots or they may get hit by other vehicles during 1.1 Technologies for ocean sampling 7 resurfacing. The surface currents can become a serious issue, because it is not necessarily clear what the trajectories of the glider are. Therefore, the researchers may have to trace the AUG down using its last known location as well as the prediction of water currents to localize and recover the vehicle. Nevertheless, Ô¨Çeet of AUGs are one of the best at hand approaches to obtain subsurface spatial resolution necessary in oceanography [11]. 1.1.6 Unmanned Surface Vessels: Wave Gliders Unmanned surface vessels (USVs) are robotic Ô¨Çoat boats that typically use solar panels to power their electric systems for propulsion and operate without any tether link with an operator. USVs have a variety of applications in oceanography science, ocean acidiÔ¨Åcation, national secu- rity, phytoplankton studies and general robotics research, e.g. [2]. Figure 1.6(b",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_16"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " operator. USVs have a variety of applications in oceanography science, ocean acidiÔ¨Åcation, national secu- rity, phytoplankton studies and general robotics research, e.g. [2]. Figure 1.6(b) shows an Un- manned Wave Glider (UWG), which is a simple, cost effective platform for collecting ocean data that does not rely on expensive ships or buoys. These wave gliders are propelled through the water by underwater Ô¨Åns or wings that convert the wave energy into forward thrust. UWGs have revo- lutionized the cost of data gathering in oceanographic studies. They are the generation of marine vehicles that are persistent and wave-propelled systems, without any need to fuel or crew. A wave glider is a two-part system, the Ô¨Çoat which stays on the surface the entire time and a set of wings or Ô¨Åns that are connected to the Ô¨Çoat by a cable. When the vehicle is deployed the set of wings are a few meter below the Ô¨Çoat. Whatever direction the Ô¨Çoat is get to move by the ocean waves, the glider wings goes up and down with the motion of the ocean surface and consequently the vehicle propelled itself. Affordable, long range and higher bandwidth satellite system, pow- ered by solar panels, is used for communication and navigation in real-time. These systems, along with accurate and compact global positioning systems, have also increased the reliability and ap- plicability of the UWGs. While the technology potential of USVs is bright, looming policies in shipping and surface trafÔ¨Åc rules restrict their applicability [13]. 1.1.7 Autonomous Underwater Vehicles Some of the most recent technological advances, particularly in the last decade, have fostered the development of Autonomous Underwater Vehicles [14]. An Autonomous Underwater Vehi- cle (AUV) is a robot designed to operate underwater, see Figure 1.7. It is typically a free body swimming and is not attached to the support vessel to which is launched. Equipped with a set of relevant sophisticated in-situ sensors, AUVs characterize the underwater environment without real-time control by human operators. This characteristic increases the maneuverability of AUVs in temporal and spatial scales in oceanography applications. AUVs have brought together speciÔ¨Åc complementary knowledge in computer science, electrical and mechanical engineering",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_17"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " environment without real-time control by human operators. This characteristic increases the maneuverability of AUVs in temporal and spatial scales in oceanography applications. AUVs have brought together speciÔ¨Åc complementary knowledge in computer science, electrical and mechanical engineering. These vehicles, are a vital tool in gathering detailed ocean data at reasonable cost in order to targeting speciÔ¨Åc set of oceanography questions. The vehicle is programmed to complete a partic- ular mission and uses its on-board sensors to estimate its state in order to complete those mission 8 Introduction Figure 1.7: Light Autonomous Underwater Vehicles (image source: [17]) objectives. AUVs are generally used in scientiÔ¨Åc expeditions to map new environments using a variety of sensors including sonar and/or vision. ScientiÔ¨Åc applications include geoscience to map particular features such as hydrothermal events or submarine volcanoes [4]. In oceanography for mapping the physical structure of the ocean [2]. In archeology for documenting shipwrecks and submerged cities [7]. In ecological applications for surveying the marine habitants and document their states to understand the changes through time [4]. In industry they are extensively used for conducting surveys for minerals and in oil and gas exploration. AUVs are also used in defence applications to fulÔ¨Ål dangerous roles such as mine counter measures and rapid environmental assessments. Conventional deployment of the AUVs generally involves following a predeÔ¨Åned mission path in terms of a series of way points, [15]. Because of unstructured and harsh envi- ronments underwater, navigation and localization of the vehicle is an uneasy task. Thus, various control techniques needed to intelligently correct the position errors and also update the mission plan e.g. [16]. In Section 3.4, AUVs are presented in more detail. 1.1.8 The AOSN Concept In the last couple of decades, with the advances in technology, the introduction of robotic systems are starting to play an important role. Robotic systems show up in several different ways. Nu- merous remotely operated vehicles as tele-operated systems, tethered by the ships and operated by the human operators are being used in oceanographic studies. But, another class of platforms are AUVs which usually are smaller than tethered platforms but can carry quite sophisticated pay- loads. Equipped with sonar scan and sub-bottom proÔ¨Ålers",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_18"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " human operators are being used in oceanographic studies. But, another class of platforms are AUVs which usually are smaller than tethered platforms but can carry quite sophisticated pay- loads. Equipped with sonar scan and sub-bottom proÔ¨Ålers, AUVs can look for ship wrecks or make map of the bottom of the ocean, probably with highest resolution maps of any other vehicles. AUV is a preferred platform, for doing certain classes of ocean observing but its endurance and battery power is tight comparing to the ship. Energy is a fundamental constraint in designing underwater systems. We can divide the energy used in an AUV in two general categories. One that depends on the velocity of the vehicle raised to the power of three, the other called a hotel load which in fact 1.2 Objectives 9 Figure 1.8: The Autonomous Ocean Sampling Network (image source: [1]) depends on everything else in the vehicle such as control, navigation systems and sensor devices. So, the trade off in designing AUVs is between endurance and the energy consumption. There are vehicles designed with low power sensors, very long endurance and comparatively low speeds. The other types have much higher power sensor systems, fairly short endurance and signiÔ¨Åcantly higher speeds. It can be mathematically proved that, using a couple of vehicles instead of one to do the same survey can increase the endurance of the vehicles and decrease the power consumption dramati- cally. For example, to do a survey in a given path in a certain area, consider the fact of using two vehicles instead of one. What happens then is that the path way that each vehicle goes drops by a factor of two, but if the time of experiment stays the same, then the speed drops by a factor of two and the power consumption of each vehicle drops by eight. As a result, the total energy consumed by the observation system is a factor of four lower. This realization can make the sensor systems very efÔ¨Åcient. The concept of Autonomous Ocean Sampling Networks (AOSN) is introduced in [18], which is a multi-platform approach to provide a framework to encompass a set of cooperative efforts to observe an area of the ocean. Figure 1.8 shows a Ô¨Åeld experiment involved numerous ships and dozens of Ô¨Çoating, proÔ¨Ålers, and autonomous oceanographic instruments operating simulta- neously. AOSNs have enabled the observatories to cover larger",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_19"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " 1.8 shows a Ô¨Åeld experiment involved numerous ships and dozens of Ô¨Çoating, proÔ¨Ålers, and autonomous oceanographic instruments operating simulta- neously. AOSNs have enabled the observatories to cover larger areas and be able to persist for large amounts of time. 1.2 Objectives The main motivation behind this thesis is to develop an adaptive sampling strategy to obtain rel- evant conductivity, temperature and depth (CTD) information of a given area using a coordinated 10 Introduction Ô¨Çeet of Autonomous Underwater Vehicles (AUVs), where one AUV plays the role of leader and the other(s) as follower(s). To this end, a real-time motion learning algorithm will be developed that allows to survey the ocean in close proximity, and provide suitable viewpoints for different ap- plications. We assume that the mission plan of the leader is predeÔ¨Åned, while as for the follower(s), they will be deÔ¨Åned in real-time according to the motion algorithm that will be developed. In this work, we take into account the communication constraints and in particular we consider that the vehicles can not exchange data underwater at all. The follower(s), only on the surface can talk to the leader. The main objectives of the thesis are: ‚Ä¢ Propose a new algorithm to solve the problem of real-time unsupervised learning of Gaus- sian Mixture Models (GMMs) in the presence of uncertain dynamic environments, i.e., we assume that the number of Gaussian components (clusters) is not only unknown but it can also change over time. ‚Ä¢ Carry out a thorough review of prior work in adaptive sampling and real-time motion learn- ing literature and identify requirements in this domain that have not been addressed in the literature. ‚Ä¢ Use the algorithm developed in 1. and propose a novel real-time adaptive sampling motion learning for Autonomous Underwater Vehicles (AUVs) using Gaussian mixture models. The objective is to Ô¨Ånd strategies that are suitable for noisy environment and extremely restricted communication. We assumed that the communication constraints underwater are extreme, i.e., the vehicles can only communicate on the surface. ‚Ä¢ Implement and evaluate the performance of the algorithm proposed through extensive com- puter simulations. 1.3 Contributions and Scope A novel on-line unsupervised learning of GMMs in the presence of uncertain dynamic environ- ments is proposed to be used in motion learning for AUVs",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_20"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " proposed through extensive com- puter simulations. 1.3 Contributions and Scope A novel on-line unsupervised learning of GMMs in the presence of uncertain dynamic environ- ments is proposed to be used in motion learning for AUVs. We assume that the complexity of the model not only is unknown, but it can also change over time. In other words, the number of Gaus- sian components is unknown and not Ô¨Åxed. Inspired by the work in [19], namely the use of the minimum description length (MDL) principle, we propose a multi-hypothesis adaptive algorithm that continuously updates the number of components and estimates the model parameters as the measurements (sample data) are being acquired. The proposed algorithm has the additional feature that it relaxes ‚Äúthe sufÔ¨Åciently large data set‚Äù restriction by not requiring in fact any initial batch of data. Simulation results illustrate the performance of the proposed algorithm where it shows that indeed it is able to continuously adapt to the dynamic changes of the number of clusters and estimate the parameters of the mixture model. A second key contribution is the following: we address the problem of adaptive sampling using a coordinated Ô¨Çeet of AUVs. The system setup consist of one leader AUV and two or more follower 1.4 Dissertation Outline 11 AUVs, where all the vehicles are equipped with a conductivity, temperature and depth (CTD) sensor devices. The CTD data that is being acquired by each AUV is modelled in real-time as a GMM by running locally the proposed unsupervised learning algorithm developed in the Ô¨Årst part of the thesis. The task of the leader vehicle is to follow some desired, predeÔ¨Åned path proÔ¨Åle while acquiring CTD data. The aim of the follower AUVs is to follow the leader motion by keeping a desired formation that is a function of a particular error. This error is the variational distance be- tween two GMMs, [20], that gives a notion of how different is the environment that each follower is travelling within from the leader. In other words, every follower has to explore the environments where in terms of CTD data are desirably, given by a distance value between two GMMs, different from the leader. The experimental results show the feasibility and accuracy of the motion learning strategies in many uniform and complex environments. 1.4 Dissertation Outline The remainder of this dissertation",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_21"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "irably, given by a distance value between two GMMs, different from the leader. The experimental results show the feasibility and accuracy of the motion learning strategies in many uniform and complex environments. 1.4 Dissertation Outline The remainder of this dissertation is organized as follow. Chapter 2 is dedicated to the problem of Unsupervised Learning of Gaussian Mixture Models. First, we present an overview of the state of the art of the algorithms and methods for unsupervised learning of Gaussian mixture models. Some background knowledge of unsupervised learning of GMMs is also described. A particular point is the Titterington‚Äôs on-line algorithm to update the GMM in time, which is highlighted in Section 2.4.2. Section 2.4.3 explains the minimum description length principle, which is used to determine the complexity of the GMM in our proposed algorithm. Gaussian mixture reduction methods, as another important feature of our algorithm, is presented in Section 2.4.4. Our pro- posed algorithm is fully described in detail in Section 2.5. The applicability of the algorithm over synthetic and real datasets are examined in Section 2.6. Chapter 3 is devoted to the second contribution of the thesis, which is the development of an adap- tive ocean sampling scheme for a formation of AUVs. This chapter starts with the motivation and an overview of strategies for ocean sampling. A brief introduction to coordination frames of AUVs is then brought in Section 3.4.1. Section 3.4.2 presents a simpliÔ¨Åed kinematic dynamic motion equation for an AUV. The CTD sensor devices are explained in Section 3.4.3. Section 3.6 contains our contribution for real-time motion learning for a Ô¨Çeet of autonomous underwater vehicles. In the proposed setup, the AUVs are required to keep a deÔ¨Åned formation pattern while individually solving path following problems. As mentioned before, the objective is to Ô¨Ånd strategies that are suitable for noisy environment and restricted communication. Therefore data exchange within the vehicles are only carried out on the surface. Each AUV system contains a path generator, inter vehicle coordination, communication, path following control, inner low-level dynamic con- trol (inner loop) and a position estimator. Computer simulations of complete closed loop motion control system for each AUV as well the overall proposed adaptive ocean sampling scheme were implemented in",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_22"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " coordination, communication, path following control, inner low-level dynamic con- trol (inner loop) and a position estimator. Computer simulations of complete closed loop motion control system for each AUV as well the overall proposed adaptive ocean sampling scheme were implemented in Matlab/Simulink R‚Éùto evaluate the performance in uniform and more complex en- vironments. The simulations presented show that the results are sufÔ¨Åciently promising to be tested in real scenarios. The conclusion and future works are presented in Chapter 4. 12 Introduction Chapter 2 Unsupervised Learning of Gaussian Mixture Models This chapter addresses the problem of unsupervised learning of Gaussian mixture models. We start with a brief introduction to the problem and present an overview of the state of the art of Gaussian mixture models. Section 2.3 contains the problem statement that we propose to solve. Some basic and background knowledge is then provided in Section 2.4. Our proposed algorithm is fully described in detail in Section 2.5. In Section 2.6, the viability of the proposed unsupervised learning of the GMMs algorithm is investigated over synthetic and real data. Section 2.7 wraps up this chapter. 2.1 Introduction Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. In order to learn a new object or understand a new phenomenon, people always try to seek the feature that can describe it, and further compare it with other known objects or phenomena. The comparison is based on some similarity or dissimilarity, generalized as proximity, according to some certain standards or rules. The goal of clustering is to distinguish and characterize a Ô¨Ånite and discrete set of intrinsically similar or natural in a Ô¨Ånite unlabelled dataset. Generally speaking, in clustering which also called exploratory data analysis, we are more interested in Ô¨Ånding the hidden data structures, rather than provide an accurate characterization of unobserved samples generated from the same probability distribution [21, 22]. This can make the task of clustering fall outside of the framework of unsupervised predictive learning problems, such as probability density function estimation [23] and entropy maximization [24]. Over the years, research on Ô¨Ånding the best complex model, identifying and classifying un- known number of components, to describe a random process has been an important topic in",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_23"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " density function estimation [23] and entropy maximization [24]. Over the years, research on Ô¨Ånding the best complex model, identifying and classifying un- known number of components, to describe a random process has been an important topic in com- puter vision and pattern recognition communities. In particular, for data clustering, mixture mod- els, where each component density of the mixture represents a given set of individuals in the total 13 14 Unsupervised Learning of Gaussian Mixture Models community, has been applied in a widespread of applications. For example, the deployment of generic recognition or tracking systems with minimal prior knowledge to set-up the initializa- tion and the ability to train the model over time. Generally speaking we can name some desired characteristics of clustering methods as below ‚Ä¢ being Ô¨Çexible and capable of generating arbitrary shapes of clusters rather than be limited to some particular shape; ‚Ä¢ handle big data as well as high-dimensional features with acceptable model complexity and in reasonable time; ‚Ä¢ be able to Ô¨Ånd an automated solution with minimum reliance on the user-deÔ¨Åned parameters; ‚Ä¢ capable of detecting and excluding the outliers and noises in the data; ‚Ä¢ have the capability in real-time applications without relearning from the scratch; ‚Ä¢ be immune to the effects of order of incoming points; ‚Ä¢ provide some insight to estimate the complexity of the model without prior knowledge; The normal mixture is perhaps the most popular and widely studied type of the mixture fami- lies. The main reason could be its natural characteristics and Ô¨Çexibility to modelling the complex and non-linear pattern variations [25], which makes them an excellent choice for representing complex class-conditional pdfs (e.g. likelihood functions) in Bayesian supervised learning sce- narios or prior probabilities for Bayesian parameter estimation [23]. It is simple and efÔ¨Åcient in terms of memory, a principled model complexity selection is possible and importantly, there are theoretically guaranteed to converge algorithms for model parameter estimation [26]. In this work we propose a new unsupervised learning of Gaussian mixture models algorithm, that is Ô¨Çexible in terms of shape of the components, can deal with high dimensional data, is robust toward outliers and noises and with minimum dependency on initialization or prior knowledge. 2.2 Previous Works/Literature Review In the probabilistic view, samples are assumed to be generated according to several probability distributions. Data points in different components are extracted from different probability distri- butions",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_24"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " dependency on initialization or prior knowledge. 2.2 Previous Works/Literature Review In the probabilistic view, samples are assumed to be generated according to several probability distributions. Data points in different components are extracted from different probability distri- butions. They can be derived from different types of density functions, e.g., multivariate Gaussian or t-distribution, or the same families, but different parameters [27]. If the distributions are known, Ô¨Ånding the clusters of a given dataset is equivalent to estimating the parameters of several under- lying models. For off-line clustering, and more precisely to compute the parameters that deÔ¨Åne the mixture model given a Ô¨Ånite data set, a widely used procedure is to apply the expectation- maximization (EM) algorithm that incrementally converges to a maximum likelihood estimate of the mixture model [26]. However in the basic EM algorithm, the complexity of the model has to be known a-priori and the whole dataset should be available. Therefore, the basic EM algorithm is 2.2 Previous Works/Literature Review 15 unable to deal with on-line data since it is an iterative algorithm that requires all the batch of data in each iteration. Another important restriction is the number of components of the mixture which can change under different circumstances. Greggio et al. [28], presents a method to Ô¨Ånd the best Ô¨Åt in a batch of data. Starting from a Ô¨Åxed number of components, a split-and-merge approach together with a dissimilarity index concept is presented that adaptively updates the complexity of the mixture models. In [29], authors present an unsupervised algorithm for learning a Ô¨Ånite mixture model from multivariate data based on the Dirichlet distribution. The proposed approach for estimating the parameters of a Dirichlet mixture is based on the maximum likelihood (ML) and Fisher scoring methods. BrieÔ¨Çy, Zwolinski and Yang [30], and Figueiredo and Jain [19] overestimate the complexity of the model and reduce it by discarding ‚Äúweak\" components. Vlassis and Likas [31] use a weighted sample kurtoses of Gaussian kernels, while Verbeek et al. [32], introduces a heuristic greedy approach in which mixture components are added one at the time. A. Declercq and J. H. Piater et al. [26] presents a method to incrementally learning Gaussian mixture",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_25"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "ek et al. [32], introduces a heuristic greedy approach in which mixture components are added one at the time. A. Declercq and J. H. Piater et al. [26] presents a method to incrementally learning Gaussian mixture models (GMMs) based on a new Ô¨Ådelity criterion for splitting and merging mixture components. Ueda et al. proposes a split-and-merge EM algorithm to alleviate the problem of local convergence of the EM method [33]. Subsequently, Zhang et al. introduced another split-and-merge technique [34]. The split-and-merge equations show that the merge operation is a well-posed problem, whereas the split operation is ill-posed. Two methods for solving this problem are developed through singular value decomposition and Cholesky decomposition and then a new modiÔ¨Åed EM algorithm is constructed. Thrun et al. [35] presents a modiÔ¨Åed version of the EM capable of generating online 3D maps. Essentially all previous works with GMM concentrated on non time critical applications, typ- ically in which, historical data or some part of it, is available. Model Ô¨Åtting and determining the complexity of the model is performed in a full batch of data or using a relatively small training corpus. However, latest direction in robotics and computer vision is towards real-time applica- tions (for example for human-computer interaction and on-the-Ô¨Çy model building) and modelling of dynamic, uncertain complex patterns which inherently involves large amounts of data. In both cases, the usual batch Ô¨Åtting becomes impractical and an having a dynamic model is necessary. Incremental Ô¨Åtting of GMMs has already been addressed in the machine learning literature. Most of the existing methods assume that novel data arrives in blocks as opposed to a single datum at a time. Z. Zivkovic et al. [36] inspired by [19] proposed an on-line (recursive) algorithm that estimates the parameters of the mixture and simultaneously selects the number of components by starting with overestimating the complexity of the model in a small batch and searching for the maximum a posteriori (MAP) solution, and discarding the irrelevant components. Hall et al. [37] use a pair-wise merging of Gaussian components approach by considering volumes of the corre- sponding hyper-ellipsoids. Song and Wang et al. [38] propose a more principled",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_26"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " the irrelevant components. Hall et al. [37] use a pair-wise merging of Gaussian components approach by considering volumes of the corre- sponding hyper-ellipsoids. Song and Wang et al. [38] propose a more principled method by using W statistic for covariance and Hottelling‚Äôs T 2 statistic for mean equivalence. However, they do not fully exploit the available probabilistic information by not considering the weights of the Gaussian components. In other words, they fail to take into account the evidence for each component at the time of merging, as is suggested in, for example [19]. Hall, Marshal and Martin et al. [37] fail to 16 Unsupervised Learning of Gaussian Mixture Models to make use of the existing model when the GMM corresponding to new data is Ô¨Åtted. This means that even if some of the new data is already explained well by the current model, the complexity of the model unnecessarily will change, in the context of the other novel data, affecting the accuracy of the Ô¨Åt as well as the subsequent component merging. Similar to that,in [38] the EM Ô¨Åtting fails to use the current model properly. The method of Hicks et al. [39] does not suffer from the same drawback. The authors propose to Ô¨Årst ‚Äúconcatenate\" two GMMs and then determine the complexity of the model by taking into account all low complexities and choosing the one that gives the largest penalized log-likelihood. A similar approach of combining Gaussian components was also described in [40, 41]. Arandjelovic et al. [42], addresses the problem of unsupervised learning of Gaussian Mixture Models (GMMs). Similar to our approach, his method works for the case when novel data points arrive one-by-one. This assumption is in contrary to many previous approaches which universally assume that new data comes in blocks representable by GMMs which and then merged with the current model estimate. In his method, two hypotheses are kept at each time and no historical data. The current Ô¨Åt is updated with the assumption that the number of components is Ô¨Åxed, which is increased or reduced when enough evidence for a new component is seen. This is deduced from the change from the oldest Ô¨Åt of the same complexity. This approach can be quite vulnerable to the order of arriving data. Our proposed method has tackled this problem by in fact keping more than",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_27"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " new component is seen. This is deduced from the change from the oldest Ô¨Åt of the same complexity. This approach can be quite vulnerable to the order of arriving data. Our proposed method has tackled this problem by in fact keping more than two hypotheses, no historical data likewise, and checking the Gaussian mixture reduction by receiving a new sample. In this chapter, we address the on-line unsupervised learning problem of GMMs in the pres- ence of uncertain dynamic environments, i.e., we assume that the number of Gaussian components (clusters) is not only unknown but it also can change over time. Inspired by the work in [19], namely the use of the minimum description length (MDL) concept, we propose a multi-hypothesis adaptive algorithm that continuously updates the number of components and estimates the model parameters as the measurements (sample data) are being acquired. The proposed algorithm has the additional feature that it relaxes ‚Äúthe sufÔ¨Åciently large data set‚Äù restriction by not requiring in fact any initial batch of data. Simulation results illustrate the performance of the proposed algorithm where it shows that indeed it is able to continuously adapt to the dynamic changes of the number of clusters and estimate the parameters of the mixture model. 2.3 Problem Statement We consider the problem of determining the structure of clustered data, without prior knowledge of the number of clusters or any other information about their composition. Data are represented by a mixture model in which each component corresponds to a different cluster. Models with varying geometric properties are obtained through Gaussian components with different parametrizations and cross-cluster constraints. Unsupervised learning of Gaussian mixture models is a surprisingly difÔ¨Åcult task. The main challenges of this problem is the model complexity selection which is required to be dynamic by the nature of the framework, without having access to historical data. 2.4 Preliminaries and basic results 17 Intuitively, if the present GMM hypothesis at time t, can fully explain all the available and/or observed information up to time t, a single novel point never carries enough information to cause an increase in the number of Gaussian components. Another closely related difÔ¨Åculty lies in the order in which new data arrives [43]. If successive data points are always badly correlated, a considerably large number of samples needs to be seen to obtain a highly accurate model. We now formulate the above ideas mathematically. Let {Yn, n = 0,1,2,...",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_28"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " If successive data points are always badly correlated, a considerably large number of samples needs to be seen to obtain a highly accurate model. We now formulate the above ideas mathematically. Let {Yn, n = 0,1,2,...} be a discrete- time random process where for each particular time n, Yn follows a K-component mixture of d-dimensional Gaussian with probability density function (pdf) given by p(y|Œ∏) = K ‚àë k=1 w[k] p[k](y|Œ∏ [k]), (2.1) where y represents one particular outcome of Yn and w = {w[1],...,w[K]} is the mixing weight set that satisÔ¨Åes K ‚àë k=1 w[k] = 1, w[k] > 0, (2.2) K denotes the number of components of the mixture, Œ∏ [k] = {¬µ[k], Œ£[k]} is the mean and covariance matrix of the kth component, with Œ∏ = {Œ∏ [1],...,Œ∏ [K]}, and p[k](y|Œ∏ [k]) = 1 (2œÄ)d/2|Œ£[k]|1/2 exp \u0010 ‚àí1 2(y‚àí¬µ[k])T(Œ£[k])‚àí1(y‚àí¬µ[k]) \u0011 . (2.3) Note that for simplicity of notation we have omitted in the parameters K, w, Œ∏ their explicit de- pendence on the time n. As long as the parameter vector Œ∏ is decided, the posterior probability for assigning a data point to a cluster can be easily calculated with Bayes‚Äôs theorem. Here, the mix- ture can be constructed with any types of components, but more commonly, multivariate Gaussian densities are used due to its complete theory and analytical tractability [44, 45]. We can now formulate the problem addressed in the paper: Given a sequence of observations Y0,Y1,..., Ô¨Ånd on-line, as the samples are arriving, a sequence of estimates for the parameters K, w, Œ∏ that is most likely to be in some sense close to the correct characterization of the random process {Yn, n = 0,1,2,...}. 2.4 Preliminaries and basic results This section presents several background results, starting with the EM algorithm, that are needed to understand the proposed on-line unsupervised learning algorithm.",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_29"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "n, n = 0,1,2,...}. 2.4 Preliminaries and basic results This section presents several background results, starting with the EM algorithm, that are needed to understand the proposed on-line unsupervised learning algorithm. 2.4.1 The Basic Expectation-Maximization (Off-line) Algorithm Finite mixtures presume that each observation is generated from one of a set of alternative ran- dom sources, and infer these sources and identify which source is most likely to have produced each observation. Finite mixtures are fundamental models in pattern recognition, classiÔ¨Åcation 18 Unsupervised Learning of Gaussian Mixture Models and clustering analysis applications, where the mixture model uses assumed component densi- ties to represent individuals that have the same characteristics in the total population. Among the mixture families, the normal mixture is perhaps the most studied type, due to its naturalness and some interesting properties of the exponential family to which it belongs [25, 46]. The unsu- pervised learning of Ô¨Ånite mixtures is usually realized via a maximum likelihood estimator. The Expectation Maximization (EM) algorithm, which was named by Dempster et al. in [26], is con- veniently suitable for obtaining the Maximum Likelihood Estimation (MLE) of a Ô¨Ånite mixture problem. Thus, it has found application in almost all statistical contexts and in almost all Ô¨Åelds in which statistical techniques may be applied, such as economics, bioinformatics, medical imaging, etc [23]. The original EM algorithm works in a batch manner, that is, the parameters of mixtures are not updated until a thorough scan of available data samples is completed. In real-time learning systems, a stable dataset for off-line estimation does not exist. On-line algorithms are hence devised to deal with real-time applications. In contrast to the traditional version of EM, on-line EM variants can Ô¨Çexibly update the parameters of a Ô¨Ånite mixture as soon as a new sample is observed, and meanwhile does not need to store the large number of data samples that is indispensable for batch learning algorithms. An important on-line EM variant elaborated in our work is proposed by Titterington in [47]. It is said to be closely related to Stochastic Approximation Theory [48]. A theoretical proof for utilizing this EM variant is provided in [46]. The EM algorithm is extremely suitable for deriving Maximum Likelihood Estimation (MLE) or Maximum",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_30"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "47]. It is said to be closely related to Stochastic Approximation Theory [48]. A theoretical proof for utilizing this EM variant is provided in [46]. The EM algorithm is extremely suitable for deriving Maximum Likelihood Estimation (MLE) or Maximum A Posteriori (MAP) estimations. Moreover, it has long been recognized to be useful at dealing with incomplete data problems and mixtures of densities. Although the EM algorithm is reported to have only Ô¨Årst- order convergence (slower than the methods of scoring or Newton-Raphson), it has some desirable features that can compensate for this drawback. For one thing, the EM algorithm automatically satisÔ¨Åes the probabilistic constraints of mixture problems [49]. For another, the EM algorithm has exhibited reliable global convergence behaviour under proper conditions [50]. Finally, EM is easy to realize and the computation per iteration is relatively low. For Ô¨Ånite mixture models, given a set of n independent and identically distributed samples Y = {Y1,...,Yn}, the log-likelihood corresponding to a K-component mixture where all the components are d-dimensional Gaussian is [23] ‚Ñì= log p(Y|Œ∏) = log n ‚àè i=1 p(Yi|Œ∏) = n ‚àë i=1 log K ‚àë k=1 w[k]p(Yi|Œ∏ [k]) (2.4) Maximum likelihood (ML) estimation is an important statistical approach for parameter estima- tion [51] and it considers the best estimate as one that maximizes the probability of generating all the observations, which is given by the joint density function, Equation (2.4). The best esti- mate can be achieved by solving the log-likelihood equations (‚àÇ‚Ñì(Œ∏))/‚àÇŒ∏ [k] = 0. Unfortunately, since the solutions of the likelihood equations can not be obtained analytically in most circum- stances [19, 52], iteratively suboptimal approaches are required to approximate the ML estimates. Among these methods, the expectation-maximization (EM) algorithm is the most popular [53]. 2.4 Preliminaries and basic results 19 EM regards the dataset as incomplete and divides each data point into two parts, observable fea- tures and missing data. It is well-known that the maximum likelihood (ML) or maximum a posteriori (MAP) estimates can not be found analytically [23, Ch.",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_31"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " divides each data point into two parts, observable fea- tures and missing data. It is well-known that the maximum likelihood (ML) or maximum a posteriori (MAP) estimates can not be found analytically [23, Ch. 9]. An elegant and powerful method for Ô¨Ånding ML or MAP solutions for models with latent variables is called the expectation-maximization or EM algorithm [26], [23, Ch. 9]. The EM is an easily implementable algorithm that iteratively increases the posterior density or likelihood function. In order to describe the EM, we need to introduce for each observation Yi, a discrete unobserved indicator vector Zi = [Z[1] i ,...,Z[K] i ]. This vector speciÔ¨Åes from which component the observation Yi was drawn, i.e., if Z[k] i = 1 and Z[p] i = 0 for k Ã∏= p, then this means that the sample Yi was produced by the kth component. Hence, the complete log-likelihood function (i.e. the one from which we could estimate Œ∏,w if the complete data X = {Y,Z} was observed [26, 54]) can be written as a product log p(Y,Z|Œ∏) = n ‚àë i=1 K ‚àë k=1 Z[k] i log h w[k]p(Yi|Œ∏ [k]) i (2.5) The basic EM algorithm works with an incomplete batch sample set to estimate the missing or potential parameters. It runs over the whole data set Y and until some convergence criterion is met, iteratively produces a sequence of estimates ÀÜŒ∏m, ÀÜwm,m = 0,1,2,... by alternatively applying two steps: E-Step: Computes the expected value of conditional probability of unobserved or under- lying parameters given the observed data at the present parameter setting. Given Y and the current estimates ÀÜŒ∏m, ÀÜwm and by considering the fact that log p(Y,Z|Œ∏) is linear with re- spect to the missing Z, the so-called Q-function computes the conditional expectation of the complete log-likelihood function as Q(Œ∏, ÀÜŒ∏m)=E \u0002 log p(Y,Z|Œ∏) Y, ÀÜŒ∏m \u0003 = log p(Y,Œì|Œ∏), (2.6) where Œì ‚â°E[Z",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_32"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " Q(Œ∏, ÀÜŒ∏m)=E \u0002 log p(Y,Z|Œ∏) Y, ÀÜŒ∏m \u0003 = log p(Y,Œì|Œ∏), (2.6) where Œì ‚â°E[Z|Y, ÀÜŒ∏m, ÀÜwm] is the a conditional expectation that each observation is gener- ated by which component. Since the elements of Z are binary, as mentioned in [19], their conditional expectations are given by Œì[k] i = E h Z[k] i |Y, ÀÜŒ∏m i = Pr[Z[k] i = 1|Yi, ÀÜŒ∏m] = ÀÜw[k] m p(Yi| ÀÜŒ∏ [k] m ) K ‚àë k=1 ÀÜw[k] m p(Yi| ÀÜŒ∏ [k] m ) , (2.7) where ÀÜw[k] m corresponds to the a priori probability that Z[k] i = 1 in the m-th iteration of the basic EM algorithm over Y, while Œì[k] i is the a posteriori probability that Z[k] i = 1, after ob- serving Yi. M-Step: Maximizes the log-likelihood of the observed data on the basis of the result from 20 Unsupervised Learning of Gaussian Mixture Models ‚àí6 ‚àí4 ‚àí2 0 2 4 ‚àí3 ‚àí2 ‚àí1 0 1 2 3 4 5 6 Figure 2.1: An example of good initialization the former stage. Maximizing Q by constructing a Lagrangian function to update the pa- rameter estimation for Œ∏. ÀÜŒ∏m+1 = argmax Œ∏ Q(Œ∏, ÀÜŒ∏m), (2.8) for the ML estimation. In the case of MAP criterion, instead of Q(Œ∏, ÀÜŒ∏m), we need to maximize {Q(Œ∏, ÀÜŒ∏m)+log p(Œ∏)}. It is evident that each sample Yi inÔ¨Çuences the parameter estimation by directly taking part in computation of the a posteriori probability in Equation (2.7), with all the samples doing the same thing simultaneously. Figure 2.1 shows a successful implementation of the standard EM algorithm over a synthetic dataset composed of three components. 2.4.",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_33"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " the a posteriori probability in Equation (2.7), with all the samples doing the same thing simultaneously. Figure 2.1 shows a successful implementation of the standard EM algorithm over a synthetic dataset composed of three components. 2.4.1.1 Drawbacks of the EM Basically, all deterministic algorithms for Ô¨Åtting mixtures, especially when the true number of components is unknown [19], which use the EM algorithm have two major drawbacks: ‚Ä¢ EM is highly dependent on initialization. It is a local method that is, it tends to converge to a local optimum and not necessarily the global one, thus it is sensitive to the initialization because the likelihood function of a mixture model is not uni-modal. Figure 2.2(a) shows a fail in Ô¨Ånding the true component due to ‚Äúbad\" initialization. ‚Ä¢ It may converge to the boundary of the parameter space (where the likelihood is unbounded) leading to meaningless estimates, Figure 2.2(b). For example, when Ô¨Åtting a Gaussian mix- ture with unconstrained covariance matrices, one of the w[k] th may approach zero and the corresponding covariance matrix may become arbitrary close to singular. When the number of components assumed is larger than the optimal/true one, this tends to happen frequently, thus being a serious problem for methods that require mixture estimates for various values of K. 2.4 Preliminaries and basic results 21 ‚àí6 ‚àí4 ‚àí2 0 2 4 ‚àí3 ‚àí2 ‚àí1 0 1 2 3 4 5 6 (a) Local but not optimal solution ‚àí6 ‚àí4 ‚àí2 0 2 4 ‚àí3 ‚àí2 ‚àí1 0 1 2 3 4 5 6 (b) Convergence to the boundary Figure 2.2: EM drawbacks To tackle these problems a couple of time-consuming strategies can be done. Using multiple random starts and choosing the Ô¨Ånal model with the highest likelihood, or using the clustering algorithms such as K-means and feed the output of them as the initialization step in the EM algo- rithm. Since in many real world applications, the complexity of the model is unknown and it may change over time, and also due to memory and time constraints, for these types of applications, a modiÔ¨Åed version of the EM algorithm should be used to accommodate those issues and also to be applicable in an",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_34"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " model is unknown and it may change over time, and also due to memory and time constraints, for these types of applications, a modiÔ¨Åed version of the EM algorithm should be used to accommodate those issues and also to be applicable in an on-line context. 2.4.1.2 How Many Clusters? The clustering process partitions data into an appropriate number of subsets. Although for some applications, users can determine the number of clusters, K, in terms of their expertise, under more circumstances, the value of K is unknown and needs to be estimated exclusively from the data themselves. Many clustering algorithms ask K to be provided as an input parameter, and it is obvious that the the estimation of K can directly affect the likelihood value and the quality of the Ô¨Åtting model. Overestimating the complexity of the model can make it hard to interpret and analyse the results, while a division with too few components, also known as underestimating the model, may cause the loss of information and misleads the Ô¨Ånal decision. Dubes called the prob- lem of determining the best K as ‚Äúthe fundamental problem of cluster validity\" [55]. A large number of attempts have been made to estimate the appropriate K and some of represen- tative examples are illustrated in the following ‚Ä¢ Visualization of the dataset For the data points that can be effectively projected onto two-dimensional Euclidean space, direct observation can give intuition to estimate the complexity of the model. A histogram or 22 Unsupervised Learning of Gaussian Mixture Models scatter plot can be insightful in these cases. Although in many real world complex datasets, this method fails to give us enough evidence to determine the optimal K. As a result, the effectiveness of the strategy is only restricted to a small scope applications. ‚Ä¢ Construction of certain indices or stopping rules These indices usually emphasize the compactness of intra-cluster and isolation of inter- cluster. Mathematically it is easy to show that the minimizing of the intra-class covariance is the same as maximizing the inter-class covariance. Consider the comprehensive effects of several factors, including the deÔ¨Åned squared error, the geometric or statistical properties of the data, the number of patterns, the dissimilarity (or similarity) and the number of clusters. Milligan and Cooper compared and ranked 30 indices according to their performance over a series of artiÔ¨Åcial datasets [56]. Among these indices, the Cali√±ski and Harabasz index, CH",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_35"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ") and the number of clusters. Milligan and Cooper compared and ranked 30 indices according to their performance over a series of artiÔ¨Åcial datasets [56]. Among these indices, the Cali√±ski and Harabasz index, CH(K), achieved the best performance [55]. The K ‚àà[1,...,M], that maximizes the value of CH(K) is selected as the optimal. The drawback of this method is the dependency of CH(K) to the data. Therefore, the good performance of this criterion for a certain data does not guarantee the same behaviour with different data. As pointed out by Everitt, Landau and Leese, ‚Äúit is advisable not to depend on a single rule for selecting the number of groups, but to synthesize the results of several techniques\" [57]. ‚Ä¢ Optimization of some criterion functions under probabilistic mixture-model framework In a statistical framework, Ô¨Ånding the correct complexity for a model, is equivalent to Ô¨Åtting a model with observed data and optimizing some criterion [52]. As mentioned before, the EM algorithm is a widely used tool to estimate the model parameters for a given K, which goes through a predeÔ¨Åned range of values. The optimal value of K is the one that maximizes (or minimizes) some deÔ¨Åned criterion. Smyth et al. [58] proposes a Monte-Carlo cross validation method, which randomly separates the data into training and test sets M times according to a certain function Œ≤ (Œ≤ = 0.5 works well from the empirical results). The K is selected either directly based on the criterion function or some prior knowledge. In literature, a large number of criteria with combination with information theory concepts have been proposed. Typical examples are as follow: ‚Äì Akaike‚Äôs information criterion (AIC) where K is selected with the minimum value of AIC(K) [59, 60]. ‚Äì Bayesian inference criterion (BIC) The optimal K is one that maximizes the value of BIC(K) [61, 62]. The BIC can be used to select an optimal model for the covariance matrices [63]. ‚Äì Minimum description length criterion (MDL) Is a widely used criterion, e.g. [42, 19, 64], and we focus on this in Section 2.4.3 ‚Ä¢ Other heuristic approaches based on a variety of techniques and theories Girolami et al. [65], propose an eigen",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_36"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ", e.g. [42, 19, 64], and we focus on this in Section 2.4.3 ‚Ä¢ Other heuristic approaches based on a variety of techniques and theories Girolami et al. [65], propose an eigenvalue decomposition on the kernel matrix in the high- dimensional feature space. The dominant K components were used in the decomposition 2.4 Preliminaries and basic results 23 summation as an indication of the possible existence of K clusters. A scale-based method, in which the distance from a cluster centroid to other neighbouring clusters is considered in [66]. The idea behind these, is that we penalize the models according to the number of parameters that they have. Therefore, a model with more parameters, is a more complex model, thus it is penalized more. AIC, BIC and MDL share a lot in common with maximum likelihood Bayesian approach, where we want to maximize the probability of a model given the data, e.g. [19]. Besides the previous methods, there are some adaptive methods, such as constructive clustering algorithms, that are capable of changing the complexity of a model in time. Adaptive Resonance Theory (ART) network is capable of continuous training in real time. ARTs increase the com- plexity of the model, only when the conÔ¨Ådence level of the match between the input pattern and the expectation drops below some certain threshold [67]. The Robust Competitive Agglomeration (RCA) starts by overestimating the complexity of the model to reduce the sensitivity to initializa- tion, and determines the actual number of clusters by a process of competitive agglomeration. It processes all the components in stages, and components that become ‚Äúweak\", lose in the competi- tion discarded and the weights of the others renormalized [68]. The generalization of this method is in [69], which the trade-off is between the complexity of the model and some Ô¨Ådelity index. Another example of this process is in [19], which attains the number of components by balancing the effect between the complexity and the minimum description length criterion. To review further methods, interested readers are referred to [27, 70]. 2.4.2 Titterington‚Äôs On-line Algorithm for a Multivariate Normal Mixture Nowadays, huge datasets are routinely encountered in real applications, rendering a thorough scan of all the data costly and impractical. Moreover, real-time",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_37"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "70]. 2.4.2 Titterington‚Äôs On-line Algorithm for a Multivariate Normal Mixture Nowadays, huge datasets are routinely encountered in real applications, rendering a thorough scan of all the data costly and impractical. Moreover, real-time systems receive data streams from sen- sors and store them in such a manner that the oldest data are discarded to free up capacity for the newest one. Therefore, searching for an on-line version of EM has aroused considerable interest in both statistical and pattern recognition communities. Neal and Hinton [71] proposed an incre- mental EM algorithm by updating some sufÔ¨Åcient statistics in the ‚ÄúE\" step and then estimating parameters from those statistics in the ‚ÄúM\" step. Although the method is still conÔ¨Åned to batch dataset, the convergence is claimed to be faster than traditional EM. A step-wise on-line EM algo- rithm was proposed in [72] for normalized Gaussian networks with a discussion of the conditional equivalence of the on-line and batch EM. It has been long recognized that recursive EM shares much in common with stochastic approximation theory, both working favourably with Ô¨Ånite mix- ture densities. The most important work in this respect is Titterington‚Äôs on-line algorithm [47] on which we are going to concentrate. Since the on-line algorithm is closely related to the basic EM algorithm, the notations of incomplete and complete data functions are considered carefully in the descriptions of their respective frameworks. We will Ô¨Årst present some background about incomplete and complete data functions in the light of [26], before introducing the algorithm. 24 Unsupervised Learning of Gaussian Mixture Models This section is mostly based on [46], where the application of an on-line EM variants for multi- variate normal mixture model in background learning and moving foreground detection was in- vestigated. DeÔ¨Ånition 1 Consider two sample spaces X and Y and a many-to-one mapping from X to Y. All the observed data samples Y are from Y, while the actual data vector x ‚ààX is invisible and is only reached indirectly from y. In the mapping of y = y(x), we refer to x as the complete data and y as the incomplete data. By postulating a mathematical representation of the complete data density f(x|Œ∏) dependent on Œ∏, a connection between f(x|Œ∏) and the incomplete date density p(y|Œ∏) is formed as p(y|Œ∏) = Z f(x",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_38"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " postulating a mathematical representation of the complete data density f(x|Œ∏) dependent on Œ∏, a connection between f(x|Œ∏) and the incomplete date density p(y|Œ∏) is formed as p(y|Œ∏) = Z f(x|Œ∏)dx (2.9) The choice of f(x|Œ∏) is generally not unique. Since in this work p(y|Œ∏) is a family of multivariate normal models deÔ¨Åned by Equation (2.1), the complete data vector x is considered as a concatena- tion of y and a Kronecker Delta vector Œ¥ = [Œ¥ [1] ...Œ¥ [K]]T in which exactly one element is 1 while others are all zeros. We specify f(x|Œ∏) as f(x|Œ∏) = K ‚àè k=1 [w[k]p[k](y|Œ∏ [k])]Œ¥ [k] (2.10) As mentioned earlier, the original EM algorithm works in a batch manner. In contrast to the traditional version of the EM, on-line EM variants can Ô¨Çexibly update the parameters of Yn as soon as a new sample is observed. The on-line recursive parameter estimation proposed by Titterington [47] is a popular method for solving mixture estimation problems. The recursive procedure proposed takes the form Œ∏n+1 = Œ∏n +n‚àí1I‚àí1 c (Œ∏n)vp(yn+1,Œ∏n), (2.11) where vp(Yn+1,Œ∏n) is the score function of p(y|Œ∏) given the newest observed value and the current parameter estimation, and it is deÔ¨Åned as vp = ‚àáŒ∏ log p(Y|Œ∏) (2.12) where ‚àáŒ∏ denotes the gradient of Œ∏. In Equation (2.11), n is the time of the last received obser- vation, and can be interpreted as the sequence of estimation m in the basic EM algorithm, since during the on-line task, parameter estimations are being updated by every new-comer point. Ic(Œ∏) is the Fisher Information Matrix (FIM) for the complete likelihood: Ic(Œ∏) = EŒ∏[vcvT c ]. (2.13) where, vc is the score function of the complete-data likelihood f(x|Œ∏) deÔ¨Åned as vc = ‚àáŒ∏ log f(x|Œ∏)",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_39"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "(Œ∏) = EŒ∏[vcvT c ]. (2.13) where, vc is the score function of the complete-data likelihood f(x|Œ∏) deÔ¨Åned as vc = ‚àáŒ∏ log f(x|Œ∏) (2.14) 2.4 Preliminaries and basic results 25 under the constraint that all derivatives and expected values exist. For further details the reader is referred to [46]. Titterington‚Äôs On-line Algorithm: The Titterington-type on-line recursive parameter estima- tion for multivariate normal mixtures are given by ¬µ[k] n+1 = ¬µ[k] n + 1 n Œì[k] n+1 w[k] n (Yn+1 ‚àí¬µ[k] n ) (2.15) Œ£[k] n+1 = Œ£[k] n + 1 n Œì[k] n+1 w[k] n \u0014 (Yn+1 ‚àí¬µ[k] n )(Yn+1 ‚àí¬µ[k] n ) T ‚àíŒ£[k] n \u0015 (2.16) w[k] n+1 = w[k] n + 1 n(Œì[k] n+1 ‚àíw[k] n ) (2.17) where Yn+1 is the new observation, Œì[k] n+1 is the a posteriori probability described by Equation (2.7), n is the time, w[k] n+1 is the mixing weight of kth component at time n+1, ¬µ[k] n+1 is the updated mean of kth component and Œ£[k] n+1 is the updated covariance of kth component. For more details and the derivation of the formulas see [46]. Before we introduce the proposed algorithm, in the next section, Ô¨Årst we brieÔ¨Çy describe the criterion that is used in [19] in order to Ô¨Ånd the number of components in a batch of data. Later, we explain how to use this criterion in real time applications. 2.4.3 The Minimum Description Length (MDL) Principle Two powerful method of inductive inference, the basis of statistical modelling, pattern recogni- tion, and machine learning are the Minimum Description Length (MDL) and Minimum Message Length (MML) approaches. The main difference between these two is the interpretation of prior probabilities. Used as a proxy for the complexity of the model,",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_40"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "i- tion, and machine learning are the Minimum Description Length (MDL) and Minimum Message Length (MML) approaches. The main difference between these two is the interpretation of prior probabilities. Used as a proxy for the complexity of the model, the MDL principle is a two-part code that maximizes the probabil- ity of a model given the data. On the other hand, the MML principle is a one-part code that do not determine the complexity of a model but instead provide a predictive model for the data [73, 74]. The task of inductive inference is to Ô¨Ånd patterns or regularities underlying some given set of data. These patterns are then used to understand the inner nature of the data or to classify or predict future data. The MDL principle is rooted in the fact that any regularity in a given set of data can be used to compress it, i.e., using less symbols than the number of symbols required to describe the data lit- erally. The more regularities the data have, the more it can be compressed. Formalizing this idea, which is just a version of famous Ockham‚Äôs razor1, leads to a theory that is relevant to all kinds of high entropy reasoning under uncertainty, including inductive inference. In contrast to most other approaches in this Ô¨Åeld, MDL has its roots in theoretical computer science rather than statistics. The MDL principle has mainly been developed by Risannen [75], having important precursors in the works of Solomonoff and Wallace and Boulton [74]. 1Ockham‚Äôs razor says among equally valid alternatives, the best explanation is the simplest one 26 Unsupervised Learning of Gaussian Mixture Models Here, we are concentrated on the application of MDL to model selection, the task of deciding which of several hypotheses best describes the data at hand [76, 77]. In the proposed method, dynamic model complexity estimation is based on the MDL criterion. BrieÔ¨Çy, MDL assigns to a model a cost related to the amount of information necessary to encode the model and the data given the model (Equation (2.18)). The rationale behind minimum encoding length criteria (like MDL and MML) is: if you can build a short code for your data, this means that you have a good data generation model. To formalize this idea, consider some dataset Y, known to have been generated according to p(Y|",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_41"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "L and MML) is: if you can build a short code for your data, this means that you have a good data generation model. To formalize this idea, consider some dataset Y, known to have been generated according to p(Y|Œ∏), which is to be encoded and transmitted. Following Shannon theory [78, 79], the shortest code length (measured in bits, if base-2 logarithm is used, or in nats, if natural logarithm is adapted [80]) for Y is ‚åà‚àílog p(Y|Œ∏)‚åâ, where ‚åàa‚åâdenotes ‚Äúthe smallest integer no less than a\". Since for even moderately large datasets ‚àílog p(Y|Œ∏) ‚â´1, the ‚åà.‚åâoperator is usually dropped. If p(Y|Œ∏) is fully known to both the transmitter and receiver, they can both build the same code and communication can proceed. However, if Œ∏ is a priori unknown, the transmitter has to start by estimating and transmitting Œ∏. This leads to a two-part message, whose total length is given by Length(Œ∏|Y) = Length(Œ∏)+Length(Y|Œ∏) (2.18) All minimum encoding length criteria (like MDL and MML) state that the parameter estimate is the one that minimizes Length(Œ∏,Y). A key issue of this approach, which the several Ô¨Çavours of the minimum encoding length principle (e.g., MDL and MML) address differently, is that since Œ∏ is a vector of real parameters, a Ô¨Ånite code-length can only be obtained by quantizing Œ∏ to Ô¨Ånite precision. The central idea involves the following trade off. Let ÀúŒ∏ be a quantized version of Œ∏. If a Ô¨Åne preci- sion is used, Length( ÀúŒ∏) is large, but Length(Y| ÀúŒ∏) can be made small because ÀúŒ∏ can be very close to the optimal value. Conversely, with a coarse precision, Length( ÀúŒ∏) is small but Length(Y| ÀúŒ∏) can be very far from the optimality. There are several ways to formalize and solve this trade off; see [81, 78] for a comprehensive review and pointers to the literature. The fact that the data itself may also be real-valued does",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_42"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " very far from the optimality. There are several ways to formalize and solve this trade off; see [81, 78] for a comprehensive review and pointers to the literature. The fact that the data itself may also be real-valued does not cause any difÔ¨Åculty; simply truncate Y to some arbitrary Ô¨Åne precision Œ¥ and replace the density p(Y|Œ∏) by the probability p(Y|Œ∏)Œ¥ d (d is the dimensionality of Y). The resulting code-length is ‚àílog p(Y|Œ∏)‚àíd logŒ¥, but ‚àíd logŒ¥ is an irrelevant additive constant. The particular form of MML approach herein adopted is derived in [19] and leads to the following criterion (where the minimization with respect to Œ∏ is to be understood as simultaneously in Œ∏ and c, the dimension of Œ∏): ÀÜŒ∏ = argmin Œ∏ \u001a ‚àílog p(Œ∏)‚àílog p(Y|Œ∏)+ 1 2log|I(Œ∏)|+ c 2(1+log 1 12) \u001b (2.19) where2 I(Œ∏) = ‚àíE[D2 Œ∏ log p(Y|Œ∏)] is the expected Fisher information matrix, and |I(Œ∏)| denotes its determinant. The MDL criterion (which formally, though not conceptually, coincides with 2Here, D2 Œ∏ denotes the matrix of second derivatives, or also known as the Hessian matrix 2.4 Preliminaries and basic results 27 BIC) can be obtained as an approximation to Equation (2.19). Start by assuming a Ô¨Çat prior p(Œ∏) and drop it. Then, since I(Œ∏) = nI(1)(Œ∏) (where I(1)(Œ∏) is the Fisher information corresponding to a single observation), log|I(Œ∏)| = clogn + log|I(1)(Œ∏)|. For large n, drop the order 1 terms log|I(1)(Œ∏)| and c 2(1+log 1 12). Finally, for a given c, take ‚àílog p(Y|Œ∏) ‚âÉ‚àílog p(Y| ÀÜŒ∏(c)), where ÀÜŒ∏(c) is the corresponding ML estimate. The result is the well-known MDL criterion, ÀÜcMDL = argmin c n ‚àílog p(Y|",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_43"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "‚àílog p(Y| ÀÜŒ∏(c)), where ÀÜŒ∏(c) is the corresponding ML estimate. The result is the well-known MDL criterion, ÀÜcMDL = argmin c n ‚àílog p(Y| ÀÜŒ∏(c))+ c 2 logn o (2.20) whose two-part code interpretation is clear: the data code-length is ‚àílog p(Y| ÀÜŒ∏(c)), while each of the c components of ÀÜŒ∏(c) requires a code-length proportional to (1/2)logn. Intuitively, this means that the encoding precision of the parameter estimates is made inversely proportional to the estimation error standard deviation, which, under regularity conditions, decreases with ‚àön, leading to the (1/2)logn term [82]. 2.4.3.1 The Proposed Criterion for Mixtures For mixtures, I(Œ∏) cannot, in general, be obtained analytically [52, 83, 84]. To side-step this difÔ¨Å- culty, we replace I(Œ∏) by the complete-data Fisher information matrix Ic(Œ∏) = E[D2 Œ∏ log p(Y,Z|Œ∏)], which upper-bound I(Œ∏), see [52]. Ic(Œ∏) has block-diagonal structure Ic(Œ∏) = nblock ‚àídiag n w[1]I(1)(Œ∏ [1]),...,w[K]I(1)(Œ∏ [K]),M o (2.21) where I(1)(Œ∏ [m]) is the Fisher matrix for a single observation known to have been produced by the mth component, and M is the Fisher matrix of a multinomial distribution (recall that |M| = (w[1]w[2] ...w[K])‚àí1) [52]. The approximation of I(Œ∏) by Ic(Œ∏) becomes exact in the limit of non overlapping components. We adopt a prior expressing lack of knowledge about the mixture pa- rameters. Naturally, we model the parameters of different components as a priori independent and also independent from the mixing probabilities, i.e., p(Œ∏) = p(w[1],...,w[K]) K ‚àè m=1 p(Œ∏ [m]) (2.22) For each factor p(Œ∏ [m]) and p(w[1],...,w[K]), we adopt the standard",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_44"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " = p(w[1],...,w[K]) K ‚àè m=1 p(Œ∏ [m]) (2.22) For each factor p(Œ∏ [m]) and p(w[1],...,w[K]), we adopt the standard non informative Jeffreys‚Äô prior (see, for example [85]) p(Œ∏ [m]) ‚àù q |I(1)(Œ∏ [m])| (2.23) p(w[1],...,w[K]) ‚àù p |M| = (w[1]w[2] ...w[K])‚àí1/2 (2.24) for 0 < w[1],w[2],...,w[K] < 1 and w[1] +w[2] +...+w[K] = 1. With these choices and noticing that for a K-component mixture, c = NK + K, where N is the number of parameters specifying each 28 Unsupervised Learning of Gaussian Mixture Models component, i.e., the dimensionality of Œ∏ [m], Equation (2.19) becomes ÀÜŒ∏ = argmin Œ∏ L (Œ∏,Y) (2.25) Now we can deÔ¨Åne the MDL intuition as follow: Given a set of hypotheses H = {H1,H2,...} and a data set Y, the goal is to Ô¨Ånd the hypoth- esis or combination of hypotheses in H that most compress Y. For the particular case of a data set Y = {Y1,...,Yn}, that has been generated according to Equations (2.1-2.3), which has to be encoded and transmitted, the description length can be obtained as follow [19, 86]: L (Œ∏,Y) = N 2 K ‚àë m=1 log(nw[m] 12 )+ K 2 log n 12 + K(N +1) 2 ‚àílog p(Y|Œ∏) (2.26) Apart from the order-1 term K(N+1) 2 (1‚àílog12), this criterion has the following intuitively appeal- ing interpretation in the spirit of the standard two-part code formulation of MDL and MML: ‚Ä¢ As usual, ‚àílog p(Y|Œ∏) is the code-length of the data. ‚Ä¢ The expected number of data points generated by the mth component of the mixture is nw[m]; this can be seen",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_45"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " of MDL and MML: ‚Ä¢ As usual, ‚àílog p(Y|Œ∏) is the code-length of the data. ‚Ä¢ The expected number of data points generated by the mth component of the mixture is nw[m]; this can be seen as an effective sample size from which Œ∏ [m] is estimated; thus, the ‚Äúoptimal\" (in the MDL sense) code length for each Œ∏ [m] is (N/2)log(nw[m]). ‚Ä¢ According to [19], we assume that the minimum number of points needed to support a d-dimensional Gaussian is N/2 where N is a constant that grows quadratically with the dimension d of the data and for a case of free covariance matrix equals (d +d(d +1)/2). ‚Ä¢ The w[m]s are estimated from all the n observations, giving rise to the (K/2)log(n) term. As mentioned before, all w[m]s in Equation (2.26) are considered to be non zero. Otherwise the objective function does not make sense if any on them becomes zero (it becomes ‚àí‚àû). This is the Ô¨Ånal cost function, whose minimization with respect to Œ∏ will constitute our mixture estimate. 2.4.4 Gaussian Mixture Reduction Gaussian mixture reduction algorithms are useful in many areas, including in error correction codes, supervised learning of multimedia data, distributed data fusion, and pattern recognition, to name a few. In many target tracking problems, data association uncertainty manifests itself as multiple hypotheses, each corresponding to a component in a multivariate Gaussian mixture posterior distribution. It is naturally of interest to reduce their number with minimal loss of Ô¨Ådelity. The simplest method of managing the complexity is to eliminate Gaussian components having low probabilities, as used, for example, in the track or hypothesis-oriented Multi-Hypothesis Tracker (MHT) [87]. Alternatively, instead of pruning components of the Gaussian mixture, one could merge components according to a similarity measure. Hypothesis merging can be considered more 2.4 Preliminaries and basic results 29 attractive than (MHT-style) pruning, since the information lost in removing mixture elements is, in some sense, preserved in the uncertainty (covariances) of those retained. Salmond is among the Ô¨Årst to consider a tracker based on merging hypotheses according to an ad-hoc similarity measure [88]. Such trackers, which are based upon hypothesis merging,",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_46"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " preserved in the uncertainty (covariances) of those retained. Salmond is among the Ô¨Årst to consider a tracker based on merging hypotheses according to an ad-hoc similarity measure [88]. Such trackers, which are based upon hypothesis merging, may be considered to be variants of the hypothesis-oriented MHT or as multimodal generalizations of the Joint Probabilistic Data Association Filter (JPDAF), as described, for example, in [89]. More advanced techniques for Gaussian mixture reduction optimize the parameters of the reduced mixture according to a global optimality criterion. One of the Ô¨Årst uses of optimization-based mixture reduction was by Scott and Szewczyk [90], who introduced the so-called L2E measure of similarity as well as a correlation measure of similarity. The L2E measure is more commonly known as the Integral Squared Error (ISE). Next, we introduce of a number of greedy initialization algorithms for mixture reduction. Most greedy algorithms for Gaussian mixture reduction try to decide which components of a Gaussian mixture should be merged or pruned in order to reduce the mixture to the desired number of components. 2.4.4.1 Component extinction Pruning is the simplest approach to mixture reduction. Given a Gaussian mixture consisting of K Gaussian components, one can discard the K ‚àíL components having the lowest cost (according to some measure), and then renormalizing the weights of the remaining components. An important feature of Algorithm 1 (which is the proposed Unsupervised Learning of Gaussian Mixture Models algorithm that will be described in Section 2.5) is that it performs component annihilation, thus being an explicit rule for reducing the complexity of the GMM hypothesis. Ac- cording to [19], we assume that the minimum number of points needed to support a d-dimensional Gaussian is N/2 where N is a constant that grows quadratically with the dimension d of the data and for a case of free covariance matrix equals (d + d(d + 1)/2). Notice that this approach can tackle overÔ¨Åtting issue and prevents the algorithm from approaching to the boundary of the pa- rameter space: When one of the components does not have enough evidence, meaning that it is not supported by the data, it is simply annihilated and the weights of other components are normalized to satisfy the Equation (2.2). However, this pruning has proven inferior to more sophisticated greedy methods [91]. Instead of pruning, one can perform mixture reduction",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_47"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " by the data, it is simply annihilated and the weights of other components are normalized to satisfy the Equation (2.2). However, this pruning has proven inferior to more sophisticated greedy methods [91]. Instead of pruning, one can perform mixture reduction utilizing merging, whereby the merging of the com- ponents comes from taking an expected value across the set of components that are to be merged, as is described in the sequel. 2.4.4.2 Merging two components From Equation (2.4) it can be seen that the log-likelihood increases by choosing a more complex model, i.e. with higher number of components to estimate Y in time. On the other hand, Equa- tion (2.26) shows that more complex model demands higher description length in turn. Therefore at each time we check if we can reduce the complexity of the best hypothesis H1 by 30 Unsupervised Learning of Gaussian Mixture Models merging two most similar components in that hypothesis (in case the number of components is more than one). This can be interpreted as the over-Ô¨Åtting problem because instead of describing the random process Y, the over-Ô¨Åtted result will describe the set of observations Y. One way to tackle this problem is to employ a model complexity reduction scheme by reducing the GMM to lower number of components. Diverse algorithms in components reduction can be found in the literature. The goal is to maintain the mean and the variance of the original mix- ture or at least with a negligible deviation so that the resulting GMM should properly represent the structure of the original mixture [92]. A common approach is successively to merge pairs of components, replacing the pair with a single Gaussian component whose moments up to second order match those of the merged pair. Salmond [88] and Williams [93, 94] have each proposed algorithms along these lines, but using different criteria for selecting the pair to be merged at each stage. Salmond [88], proposed an algorithm in which the mixture reduction happens by repeat- edly merging the two most similar components. His criterion of similarity, based on concepts from the statistical analysis of variance, seeks to minimise the increase in ‚Äúwithin-component‚Äù variance resulting from merging two chosen components. The proposed dissimilarity measure has two properties that may be considered undesirable. First, the measure depends on the mean of the components, but not on their individual covariance matrices, leading to merging the pair of components",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_48"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " variance resulting from merging two chosen components. The proposed dissimilarity measure has two properties that may be considered undesirable. First, the measure depends on the mean of the components, but not on their individual covariance matrices, leading to merging the pair of components with the closest means even if their covariance matrices are very different. The sec- ond drawback arises from the fact that inclusion of a new component, especially if it is far remote from the existing components, can greatly affect the merging candidates by increasing the overall covariance in the mixture [95]. Williams [93, 94], proposed an integrated squared difference (ISD) dissimilarity measure to eval- uate the difference between two arbitrary Gaussian mixture in closed form. The ISD criterion circumvents both of the drawbacks of the Salmond‚Äôs method. On the other hand, it is more time consuming than the Salmond method. The Williams algorithm has its own puzzling behaviour, specially when the components are radially symmetric or when the system state vector has high dimensionality [95]. Kullback-Leibler The Kullback-Leibler (KL) dissimilarity measure B, is a non-symmetric mea- sure of the difference between two probability distributions g1 and g2. At each iteration of the algorithm outlined in Algorithm 1, we wish to choose two components from the mixture for merging. Our ultimate objective is to Ô¨Ånd a weighted mixture of K ‚àí1 Gaus- sian components in such a way as to keep the KL discrimination of the post-merged mixture from the original pre-merged K-component mixture as small as possible, subject to being able to accom- plish this with a method that is computationally reasonably fast. A reasonable criterion, therefore, is to choose two components in such a way as to minimise the KL discrimination of the mixture after the merge from the mixture before the merge. As mentioned in [95], unfortunately there appears to be no closed-form expression for the KL discrimination of one (nontrivial) Gaussian mixture from another. (This fact deterred Williams [93] from pursuing a cost measure based on KL discrimination; were it not for this, he says it would be the ‚Äúideal cost function\" for Gaussian 2.4 Preliminaries and basic results 31 mixture reduction). However, Runnals et al. [95] provided an upper bound on the discrimination of the mixture after the merge from the mixture before the merge. The dissimilarity",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_49"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " 2.4 Preliminaries and basic results 31 mixture reduction). However, Runnals et al. [95] provided an upper bound on the discrimination of the mixture after the merge from the mixture before the merge. The dissimilarity measure B((¬µ[g1],Œ£[g1],w[g1]),(¬µ[g2],Œ£[g2],w[g2])) is deÔ¨Åned as 2B \u0010 (¬µ[g1],Œ£[g1],w[g1]),(¬µ[g2],Œ£[g2],w[g2]) \u0011 = tr(Œ£[g12]‚àí1 ÀòŒ£[g12]) +(w[g1] +w[g2])logdet(Œ£[g12])‚àíw[m] logdet(Œ£[g1])‚àíw[g2] logdet(Œ£[g2]) (2.27) where ÀòŒ£[g12] = w[g1]Œ£[g1] +w[g2]Œ£[g2] ‚àí(w[g1] +w[g2])Œ£[g12] + w[g1]w[g2] w[g1] +w[g2] (¬µ[g1] ‚àí¬µ[g2])(¬µ[g1] ‚àí¬µ[g2])T We propose that, in each iteration of Algorithm 1, we select for merging two components g1 and g2, g1 Ã∏= g2, such that B(g1,g2) is minimized. The dissimilarity measure B(g1,g2) as given in Equation (2.27) is reasonably easy to compute, with computational complexity at most O(d3). Consequently, if our task is to reduce a mixture of K components to a mixture of K ‚àí1, this will have total computational complexity of O(K3d3). This criterion has qualitatively the right properties. Roughly speaking, it will tend to select for merging: 1) components with low weights. Note how the weights appear outside the logarithm in Equa- tion (2.27), and so can have a dominant effect, 2) components whose means are close together in relation to their variances, 3) components whose covariance matrices are similar. For further details see [95]. The fact that B(g1,g2) is merely an upper bound on the KL discrim- ination, rather than an exact value",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_50"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " relation to their variances, 3) components whose covariance matrices are similar. For further details see [95]. The fact that B(g1,g2) is merely an upper bound on the KL discrim- ination, rather than an exact value, is admittedly a drawback. Moreover, since KL discrimination does not satisfy the triangle inequality, there is no simple way of bounding the discrimination that arises over the course of two or more iterations of the algorithm. However, obtaining a direct estimate of the KL bound would appear to require a numerical method, e.g. numerical integration. Worse, this integration would need to be carried out multiple times: OK3 times if, as above, our task is to reduce K components to K ‚àí1 components. In many appli- cations this will be computationally prohibitive. A possible compromise approach would be to use the B(g1,g2) criterion to compile a shortlist of possible component merges, selection from within this shortlist being by direct numerical integration. In this work, we chose a pairwise merging of components method that measures the dissimilarity between the post-merge mixture with respect to the pre-merge mixture based on an easily-computed upper bound of the Kullback-Leibler (KL) discrimination measure presented in [95]. Suppose we are given a mixture of two Gaussian components g1, g2 with the parameters Œ∏ and w, where Œ∏ [i] ‚â°{¬µ[i],Œ£[i]}, i ‚àà{g1,g2} and w[g1]+w[g2] = 1,and that we wish to approximate this mix- ture as a single Gaussian. A strong candidate is the Gaussian whose zeroth, Ô¨Årst- and second-order moments match these two components, i.e., the Gaussian with mean vector ¬µ[g12] and covariance 32 Unsupervised Learning of Gaussian Mixture Models matrix Œ£[g12] as follows ¬µ[g12] = w[g1]¬µ[g1] +w[g2]¬µ[g2] Œ£[g12] = w[g1]Œ£[g1] +w[g2]Œ£[g2] +w[g1]w[g2](¬µ[g1] ‚àí¬µ[g2])(¬µ[g1] ‚àí¬µ[g2])T (2.28) which is referred to as the moment-preserving merge of two Gaussian components g1, g2. Suppose that we are given a mixture with K",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_51"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "] ‚àí¬µ[g2])(¬µ[g1] ‚àí¬µ[g2])T (2.28) which is referred to as the moment-preserving merge of two Gaussian components g1, g2. Suppose that we are given a mixture with K components, and we wish to approximate it by a mixture of K ‚àí1 components, where K > 1. In this work, we choose the two components that in a sense to be deÔ¨Åned are least dissimilar, based on Kullback-Leibler criterion, and replace them by their moment-preserving merge. Algorithm 1 On-line Unsupervised Learning of GMM Input: Sample data: Y0,Y1,..., Covariance matrix for postulated component Œ£[0], Maximum number of hypotheses: ‚Ñµmax, Dissimilarity measure threshold: Bmax Output: Number of the components: K, Mean and covariance of the components:{Œ∏ [1],...,Œ∏ [K]}, Mixing weights: {w[1],...,w[K]} Initialization: Postulate the Ô¨Årst component Steps: 1.Update the current components in each hypothesis H1,...,H‚Ñµ: Find the a posteriori probabilities Œìn+1 as Equation (2.7) Update the current components by Equations (2.15-2.17) Update the log-likelihood ‚Ñìas in Equation (2.30) Update the description length L as in Equation (2.26) 2.Add a new hypothesis: H‚Ñµ+1 Create a new component according to Equation (2.29) DeÔ¨Åne the log-likelihood of this new hypothesis: ‚Ñì‚Ñµ+1 = ‚Ñì1 Obtain the description length of this new hypothesis: L‚Ñµ+1 in Equation (2.26) 3.Check if we can add another hypothesis: H‚Ñµ+2 Find B for every pair of components in H1 according to Equation (2.27) if min(B) < Bmax then Merge two components according to Equation (2.28) Estimate the expected log-likelihood ‚Ñì‚Ñµ+2 based on Equation (2.30) Obtain the description length for this new hypothesis L‚Ñµ+2 in Equation (2.26) end if 4.Check if we can add another hypothesis: H‚Ñµ+3 Component annihilation, Section 2.4.4.1 Estimate the expected log-likelihood ‚Ñì‚Ñµ+3 based on Equation",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_52"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " (2.26) end if 4.Check if we can add another hypothesis: H‚Ñµ+3 Component annihilation, Section 2.4.4.1 Estimate the expected log-likelihood ‚Ñì‚Ñµ+3 based on Equation (2.30) Obtain the description length for this new hypothesis L‚Ñµ+2 in Equation (2.26) 5. Refresh the model Re-order incrementally the hypotheses with given number of components according to their description length L Keep the Ô¨Årst ‚Ñµmax hypotheses Acquire the next sample and go to 1 2.5 The Proposed On-line Unsupervised Learning Algorithm 33 2.5 The Proposed On-line Unsupervised Learning Algorithm In this section we describe the proposed on-line unsupervised learning algorithm, which is com- posed of several models as it will become clear later. Algorithm 1 describes the pseudo-code for one model and its rational is as follows: - Start with one single observation and build the Ô¨Årst hypothesis H1 described by a single Gaussian distribution with mean ¬µ[0] at the point itself, and some predeÔ¨Åned covariance Œ£[0]. Then, calculate the log-likelihood of this hypothesis ‚Ñì1 = ‚àílog p (2œÄ)d|Œ£| and Ô¨Ånd the corresponding description length L1 according to Equation (2.26). - The second acquired sample, updates the Ô¨Årst hypothesis H1 according to Equations (2.15- 2.17), and builds the second hypothesis H2 which contains two components: the Ô¨Årst up- dated component and a second component with mean ¬µ[K+1] at the point itself, with some predeÔ¨Åned covariance Œ£[K+1] ¬µ [K+1] = Yn+1 w[K+1] = 1 n+1 (2.29) where K is the number of components at the time (being K = 1 for the case of the second sample). The selection of the covariance matrix for this new born component is optional and can be done with respect to the type of data that we are dealing with. We used a diagonal matrix where each element was a fraction of the standard deviation of the features of Yn+1. - The third point will update the two current hypotheses and build another one by adding a new component to H1 and so on and so forth. For the sake of computational speed and memory",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_53"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " of the standard deviation of the features of Yn+1. - The third point will update the two current hypotheses and build another one by adding a new component to H1 and so on and so forth. For the sake of computational speed and memory, the number of hypotheses has to be bounded. Thus, after reaching the limit of maximum hypotheses ‚Ñµmax, we rank the hypotheses in an increasing order according to their description length and keep only the Ô¨Årst ‚Ñµmax hypotheses and discard the rest. - As explained above, in each iteration we add a new hypothesis by assuming that the new arriving point is a new component, according to Equation (2.29), beside the current Gaussian mixture in H1. Thus, it is likely that we face the very common problem of over Ô¨Åtting, i.e., there is a tendency for the number of components of the mixture to grow without bound; indeed, if the algorithm were simply to follow the statistical model on which the method is based, the number of components would increase exponentially over time. To combat this, various pragmatic measures must be taken to keep the number of components in check. Typically this will be achieved either by discarding components with low probability, as suggested in [19], and/or by merging components which represent similar state hypotheses. Thus, in each iteration after updating the current components in all hypotheses, we check the possibility of adding another hypothesis by merging two most similar components in H1 (the hypothesis with minimum description length), according to the dissimilarity measure 34 Unsupervised Learning of Gaussian Mixture Models Bmax. For example at time n, if there were 5 components in H1, by receiving a new point Yn+1, Ô¨Årst we would update the components in H1 as we do in all other hypotheses; then if there were two similar components according to a threshold in H1, we would merge them and add another hypothesis H‚Ñµ+2 (see Algorithm 1) composed by the post-merge mixture. For this new hypothesis the log-likelihood is set to be the same as the log-likelihood of the pre-merge mixture in H1, since it is assumed that the two components were very similar to each other. - The dissimilarity measure threshold Bmax is an important quantity since a very small value would not be helpful in tackling the over-Ô¨Åtting problem and setting a very high threshold can cause under-Ô¨Åtting of",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_54"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " each other. - The dissimilarity measure threshold Bmax is an important quantity since a very small value would not be helpful in tackling the over-Ô¨Åtting problem and setting a very high threshold can cause under-Ô¨Åtting of the components. To address this problem, we separate the hy- potheses with given complexity at each time, then resort incrementally the hypotheses in each , set of hypotheses with given K. Basically, in each hypothesis we have the mean, covariance and weights of the mixture beside the number of points in each Gaussian and the description length of the model. Another point that needs to be taken into consideration is the fact that the computation of the log- likelihood has to be done in a recursive on-line format. Thus, after updating Œ∏n and wn, For some practical reasons, in Equations (2.15-2.17), we changed the learning rate 1 n to a faster decaying envelope, i.e. we added a sufÔ¨Åciently large enough constant to n in order to reduce the problem of instability as proposed in [36]. One of the greatest challenges of unsupervised learning of GMMs is the dynamic model order selection. In the last stage of our proposed method, all the current hypotheses are being sorted in- crementally based on their description length value and the Ô¨Årst, Nmax hypotheses are being stored and the rest discarded. As mentioned before, in the third and forth stages, we may add a new hypothesis by merging two candidate components or annihilating some weak components. In order to calculate the descrip- tion length of these hypotheses, we need to have the log-likelihood of them (Equation (2.4)). The problem is that for the computation of p(Y|Œ∏) historical data Y is needed, which is not available. As proposed in [42], instead of p(Y|Œ∏), we use the expected likelihood of the same number of data points and, hence, the expected description length for the new born hypotheses is then computed. More precisely, consider two Gaussian components g1(Y) ‚àºN (Y;Œ∏ [g1]), g2(Y) ‚àºN (Y;Œ∏ [g2]) with the parameters Œ∏ and w, where Œ∏ [i] ‚â°{¬µ[i],Œ£[i]}, i ‚àà{g1,g2} and w[g1] +w[g2] = 1. Let g",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_55"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "2]) with the parameters Œ∏ and w, where Œ∏ [i] ‚â°{¬µ[i],Œ£[i]}, i ‚àà{g1,g2} and w[g1] +w[g2] = 1. Let g12 be the moment preserving merge of these two components can be obtained by Equa- tions 2.28. The expected likelihood of N1 points drawn from the former and N2 points from the latter given model w[g1]g1(Y)+w[g2]g2(Y) is E[p(Y|Œ∏ [g12])] = \u0012Z g1(Y)(w[g1]g1(Y)+w[g2]g2(Y))dY \u0013N1 \u0012Z g2(Y)(w[g1]g1(Y)+w[g2]g2(Y))dY \u0013N2 (2.30) 2.5 The Proposed On-line Unsupervised Learning Algorithm 35 (a) n=3 (b) n=1100 (c) n=4000 (d) n=10300 (e) n=12000 (f) n=15000 Figure 2.3: An example of the execution behaviour of the proposed algorithm. where integrals of type R pi(y)pj(y)dy are recognized as the Bhattacharyya distance, which for Gaussian distributions can easily computed as dB(pi, pj) = Z pi(y)p j(y)dy = exp(‚àíC/2) (2œÄ)(d/2)|Œ£iŒ£jŒ£i j|1/2 (2.31) 36 Unsupervised Learning of Gaussian Mixture Models where Œ£ij = (Œ£i‚àí1 +Œ£j‚àí1) ‚àí1 , ¬µi j = Œ£i j(Œ£i‚àí1¬µi +Œ£j‚àí1¬µ j) C = ¬µiŒ£i‚àí1¬µiT + ¬µ jŒ£ j‚àí1¬µ jT ‚àí¬µi jŒ£i j‚àí1¬µi jT After calculating the expected log-likelihood by Equation (2.30), the description length can be obtained by Equation (2.26). 2.6 Simulation Results This section illustrates the behaviour of the proposed algorithm for two types of experiments: a synthetic Gaussian mixture data set and the Iris data set. 2.6.1 A 2-d",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_56"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " by Equation (2.26). 2.6 Simulation Results This section illustrates the behaviour of the proposed algorithm for two types of experiments: a synthetic Gaussian mixture data set and the Iris data set. 2.6.1 A 2-d Gaussian Mixture Figure 2.3 shows an example of 3 models running in parallel in order to Ô¨Ånd a mixture of well separated synthetic Gaussian components in real time starting with one single observation. The maximum number of hypotheses was set to Nmax = 10 and the merging threshold Bmax to 0.008, 0.08, and 0.8, respectively. This experiment can be split in two steps. For n < 10000, the observed data were randomly extracted, according to Equation (2.1) with 4 components (K=4) and the mixing weights of the components from left to right are w = [0.35,0.25,0.15,0.25]. It can be seen, after some transient situation, that the algorithm merged the two most similar components and were able to correctly determine the 4 components. Then, for n ‚â•10000, we started to extract data from another component beside those previous ones. The algorithm was able to converge to the solution rapidly. 2.6.2 The Iris Data Set We used the well-known 3-component 4-dimensional ‚ÄúIris\" data set [96]. This data set has only 150 samples, and therefore we had to randomize and repeat them 60 times. We set the maximum number of hypotheses Nmax = 50 in 10 different models with the merging threshold starting from Bmax = 0.002. Figure 2.4(a) shows that in 64 out of 100 trials the 3 components were correctly identiÔ¨Åed. By visual inspection we could observe that the linearly separated component (iris se- tosa) could almost perfectly be identiÔ¨Åed. On the other hand, the properly identiÔ¨Åcation of the other two non-linear separable components (iris versicolor and iris virginca) was more challeng- ing since the order in which the data is presented can inÔ¨Çuence the recursive solution. The typical solution is shown in Figure 2.4(b) by projecting the 4-dimensional data to the Ô¨Årst two principal components. 2.7 Conclusion 37 (a) Histogram results",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_57"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "Ô¨Çuence the recursive solution. The typical solution is shown in Figure 2.4(b) by projecting the 4-dimensional data to the Ô¨Årst two principal components. 2.7 Conclusion 37 (a) Histogram results (100 trials) (b) Projected data in 2-D Figure 2.4: Iris Data Set Results 2.6.3 A 1-d Gaussian Mixture In this experiment, the data is a mixture of three linearly separable Gaussian components, as is shown in Figure 2.5(a). The weights of the components are equal. The means of the components are [‚àí40,0,40] and the variance values are [15,10,20] respectively. Figure 2.5(b) illustrates the output of our algorithm at time n = 5000 for a hundred trials. Next, we did the same experiment with data shown in Figure 2.6(a) that represents a mixture where the components are closer together ,i.e., they are not linearly separable any more. The means are [‚àí20,2,25] and variances are [4,60,20]. Figure 2.6(b) shows the results of 100 trials that the algorithm succeeded to Ô¨Ånd the components correctly. A more complex case is represented in Figure 2.7(a), where the components are highly overlapped. The weights of the components are the same. The mean and variance values are [‚àí10,0,10,20] and [6,2,8,4] respectively. Figure 2.7(b) illustrates the output of 100 trials. There is no surprise to witness over Ô¨Åtting in some cases, due to the nature of the mixture. 2.7 Conclusion This chapter proposed an on-line unsupervised learning of GMMs algorithm in the presence of uncertain dynamic environments. The algorithm relies on a multi-hypothesis adaptive scheme that continuously updates the number of components and estimates the model parameters as the measurements (sample data) are being acquired. The hypothesis models are ranked according to the MDL. In this work we propose an unsupervised learning of Gaussian mixture models algo- rithm, that is Ô¨Çexible in terms of shape of the components, can deal with high dimensional data, is robust toward outliers and noises and with minimum dependency on initialization or prior knowl- edge. In general",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_58"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " models algo- rithm, that is Ô¨Çexible in terms of shape of the components, can deal with high dimensional data, is robust toward outliers and noises and with minimum dependency on initialization or prior knowl- edge. In general, we could conclude that the algorithm has a good performance specially when the components are well separated. However, it is worth to mention that a critical issue is the initial selection of the covariance when a new component is created. This has to be done carefully 38 Unsupervised Learning of Gaussian Mixture Models ‚àí60 ‚àí40 ‚àí20 0 20 40 60 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 (a) Mixture of 3 components 1 2 3 0 10 20 30 40 50 60 70 80 90 100 (b) Number of Components (K) Figure 2.5: Linearly separable mixture ‚àí40 ‚àí20 0 20 40 60 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 (a) Non-linearly separable components 1 2 3 0 10 20 30 40 50 60 70 80 90 100 (b) Number of Components (K) Figure 2.6: Fairly overlapped mixture (a) A more complex mixture 1 2 3 4 5 0 10 20 30 40 50 60 70 80 90 100 (b) Number of Components (K) Figure 2.7: Highly overlapped mixture 2.7 Conclusion 39 because choosing a very small covariance can be experimentally problematic since in the process of calculating the a posteriori probability in Equation (2.7), the result in Equation (2.3) could be zero due to Ô¨Ånite precision. On the other hand, choosing an extremely large covariance can lead to the ‚Äúunder-Ô¨Åtting\" problem. This is something that deserves further investigation. 40 Unsupervised Learning of Gaussian Mixture Models Chapter 3 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles 3.1 Introduction An Autonomous Underwater Vehicle",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_59"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "ÔøΩÔøΩtting\" problem. This is something that deserves further investigation. 40 Unsupervised Learning of Gaussian Mixture Models Chapter 3 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles 3.1 Introduction An Autonomous Underwater Vehicle (AUV) is a robot designed to operate underwater. It is typ- ically a free swimming body and is not attached to the support vessel to which is launched. Au- tonomous Underwater Vehicles (AUVs), by taking advantage of sophisticated, smart, small and inexpensive on-board sensors and marine robotic platforms, have brought together speciÔ¨Åc com- plementary knowledge in computer science, electrical and mechanical engineering. Nowadays, we are able to carry out ocean expeditions thoroughly without actually being there. These vehicles, are a vital tool in gathering detailed ocean data with much higher resolution and at reasonable cost in order to target speciÔ¨Åc set of oceanography questions. Further, the idea of using inexpensive multiple AUVs, acting in cooperation to perform speciÔ¨Åc tasks, like for example ocean sampling, mapping, mine detection and neutralization, offers po- tentially signiÔ¨Åcant advantages in performance and efÔ¨Åciency as well as redundancy in case of failure, compared with the use of a single AUV, see [97] and [98]. ScientiÔ¨Åc applications include geoscience to map particular features such as hydrothermal events or submarine volcanoes [3]. In archeology for documenting shipwrecks and submerged cities [4]. In oceanography for mapping the physical structure of the ocean. In ecological applications for surveying the marine habitants and document their states to understand the changes through time. In industry they are used ex- tensively used for conducting surveys for minerals and in oil and gas exploration. AUVs are also used in defence applications to fulÔ¨Ål dangerous roles such as mine counter measures and rapid environmental assessments. The rest of this chapter is organized as follows. Section 3.2 describes the state of the art of adap- tive sampling and motion learning for AUVs. Section 3.3 explains our proposed real-time motion learning strategy for multiple AUVs . The applicability of the proposed algorithm presented in 41 42 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Chapter 2, is investigated in Section 3.6. Two different scenarios are deÔ¨Åned:",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_60"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "UVs . The applicability of the proposed algorithm presented in 41 42 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Chapter 2, is investigated in Section 3.6. Two different scenarios are deÔ¨Åned: Real-time unsuper- vised motion learning for AUVs in an uniform environment, and a more complex scenario, where the environment is non-uniform. This chapter ends with some conclusions. 3.2 Literature Review on Adaptive Sampling using AUVs In oceanographic sampling the goal is to produce a map of a given environmental quantity (e.g., temperature, or sound speed, or bottom morphology, depending on the speciÔ¨Åc payload) accu- rately and in the minimum amount of time. When a hundred percent coverage is not strictly required, or it is not possible because the payload can only make a point-wise measurement (as in the temperature/salinity case), the produced map is an estimate of the true map based on the available samples. To meet the accuracy speciÔ¨Åcation while minimizing the number of sampled points, one intuitive idea is that of increasing the spatial sampling rate where the environmental map is rapidly changing, while decreasing it when the environmental map is almost constant. As sample progress, the smoothness (or the spatial correlation length) of the map can be estimated from the data themselves; the next sampling location can then be established on-line on the basis of the previous measurements. This approach is called ‚Äúadaptive sampling\". If the sampling is performed by a team of AUVs, then the sampling strategy must be chosen in order to exploit the availability of multiple vehicles through some coordination strategy, possibly implemented in a distributed fashion. To this end, the following questions need to be addressed: How to program the individual robots so that they have their own on-board fast decision making ability? How to collect data in most efÔ¨Åcient way? How to increase the robustness of the group to uncertainty or disturbances in the environment? How to conveniently use the network of sensors available to robustly collect data to reveal desired features of the environment? How to stabilize the formation of the vehicles so that they could change the resolution of the formation, shape of the formation of individual agents moving around? In the literature, it is possible to Ô¨Ånd several interesting works that have proposed adaptive sam- pling strategies for marine systems. Inspired by natural systems, for example Ô¨Åsh schools that are able to climb the",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_61"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " of individual agents moving around? In the literature, it is possible to Ô¨Ånd several interesting works that have proposed adaptive sam- pling strategies for marine systems. Inspired by natural systems, for example Ô¨Åsh schools that are able to climb the gradients even through noisy Ô¨Åelds, Leonard et al. in [99] presents a framework, relatively simple at the individual level but with greater functionality and intelligence at the group level, for coordinated and distributed control of multiple autonomous vehicles using artiÔ¨Åcial po- tentials and virtual leaders. Each of these potentials is a function of the relative distance between a pair of neighbours. ArtiÔ¨Åcial potentials deÔ¨Åne interaction control forces between neighbouring vehicles and are designed to manipulate the formation and geometry of the Ô¨Çeet. A virtual leader is a moving reference point, at the center of the formation, that attracts or repels the neighbouring vehicles by means of additional artiÔ¨Åcial potentials. In the reported work, the closed-loop stability using the system kinetic energy and the artiÔ¨Åcial potential energy is guaranteed by constructing a Lyapunov function. By considering no ordering of the vehicles in Ô¨Çeet, the adapted setup is more robust in comparison with a single vehicle usage. In [100], following the approach proposed 3.2 Literature Review on Adaptive Sampling using AUVs 43 in [99], a robotic ocean sampling network is developed where AUVs move around on their own, collecting data on the ocean physics and biology to gain a better understanding of ecosystem and ocean climate change. This idea in simple words can be described as follow. Having a group of sensors, maybe in a formation measuring a scalar like temperature, by themselves each individual can not know about the gradient but collectively, if they act like Ô¨Åsh, they can pass the infor- mation and somehow get an estimation of the gradient and climb that gradient. The algorithm used in that work is based on artiÔ¨Åcial potential. Three vehicles at the corners of a triangle, with this ability that the center of the triangle can track a line. The ability to control the formation to change the resolution or one edge of the triangle be normal to the path. They have built some other related things based on this idea of dynamic gradient climbing by extending the approach to estimating the second derivative and understand the curvature of the level sets, and also by changing the resolution of the Ô¨Çeet so",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_62"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " the path. They have built some other related things based on this idea of dynamic gradient climbing by extending the approach to estimating the second derivative and understand the curvature of the level sets, and also by changing the resolution of the Ô¨Çeet so that minimize the estimation error. The agents not only do sampling while tracking, but they can reconÔ¨Ågure as they go. This is a signiÔ¨Åcant advantage of using mobile sensor networks. Ogren et al. in [101], present a stable control strategy for a group of vehicles to direct and reconÔ¨Ågure cooperatively based on changes in acquired measurements. In the reported work, the vehicles follow the thermal gradient direction by sending the sampled data, during each resurfacing, to a central unit to update the mission plan and send it for each ve- hicle. In [102], the authors propose a cooperation algorithm for adaptive oceanographic sampling, taking into account range communication constraints. In a Ô¨Çeet of AUVs with static topology, a distributed dynamic programming algorithm is applied to solve the global optimization problem of maximizing the oceanographic sampling area coverage. Worth to be mentioned that the solution ( added to a cost function) is computed in a distributed fashion, since each vehicle makes the cost computation for its own candidate points. In the reported work, for practical issues and to preserve underwater communication possibilities, the maximum distance between adjacent agents is lim- ited by an upper bound. Every vehicle submerges vertically to capture the measurements and then resurface while carrying a payload of Conductivity, Temperature and Depth (CTD) data. The data is transmitted to a measuring station on the surface of the sea. When on the surface, the vehicle navigates with the help of GPS. A land-station link enables almost real-time data transmission and on-line modiÔ¨Åcation of the mission plan. In [103], a map is used to decrease the uncertainty of the sampling by considering the correlations among the ocean values. In [104] an A‚àóapproach to trajectory planning and Ô¨Ånding feasible paths through a detailed map of known obstacles and unsafe regions is presented. SigniÔ¨Åcant computation times for A‚àópath planning (order 10-100s CPU time with currents sampled only once every nautical mile) is stressed by the authors. Smith et al. in [105], present a near-real time path planning solution for tracking and sampling an evolving ocean feature",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_63"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " planning (order 10-100s CPU time with currents sampled only once every nautical mile) is stressed by the authors. Smith et al. in [105], present a near-real time path planning solution for tracking and sampling an evolving ocean feature using one or more glider(s). In the reported work, a Regional Ocean Model System (ROMS), which is known a priori, generates a sampling plan that steers deployed gliders to re- gions of scientiÔ¨Åc interest based upon the given feature. Throughout the execution of the sampling plan, the collected data are transmitted and assimilated into the ocean model. We believe that the performance of the proposed approach strongly depends on ROMS as it predicts the behaviour of the objective feature and steer the vehicles toward new trajectories. Since the existence of outliers 44 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles in sampling, specially in highly unstructured underwater environment, can affect the 2D gradient direction dramatically, outlier detection in sampling is an open study. In [106], the authors propose an adaptive control of autonomous mobile sensor platforms approach for oceanographic sampling purposes. To investigate the viability of their approach, an experiment with the goal of adaptively following the ocean thermal gradient was conducted. Considering the fact that the optimum sam- pling path was not predeÔ¨Åned, the sensor platform should have adaptively manoeuvre itself based on the real-time measurements. The experiment consisted in 4 segments, in each, the CTD au- tonomy sensor could go down and rise in a certain direction and in a predeÔ¨Åned zigzag path to measure the temperature proÔ¨Åle of the ocean. The authors in this work, developed an autonomy architecture to support adaptive sampling. With the aim of reducing the model uncertainty, and considering the fact that the optimum sampling path is not predeÔ¨Åned, the sensor platform must adaptively manoeuvre itself based on the real-time measurements. The sampling process, records the ocean temperature at each proper depth. The direction of any segment, except the Ô¨Årst segment that was predeÔ¨Åned, was the 2D thermal gradient of the batch of data captured during the previous segment. The authors used autonomous surface craft as a mobile sampling platform, which in comparison with AUV, has the advantage of better navigation and communication. As the authors stated, higher sampling density could be achieved in shorter time and with less power consump- tion,",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_64"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " authors used autonomous surface craft as a mobile sampling platform, which in comparison with AUV, has the advantage of better navigation and communication. As the authors stated, higher sampling density could be achieved in shorter time and with less power consump- tion, if AUV had been used instead of an autonomous surface craft. It seems that, this method is less resilient to outlier and noise in sampling which is very likely in unstructured underwater environment. Note that the existence of outlier can change the direction of the 2D gradient dra- matically. By spreading the use of autonomous vehicles, congestion and highly dynamic trafÔ¨Åc on the surface is becoming more challenging. Svec et al. in [107] tackles this problem by devel- oping a model-predictive, local path planning algorithm for an unmanned surface vehicle (USV). The goal is to map the spatio-temporal obstacle regions, with increasing resolution and focused sampling, by introducing the velocity obstacle concept to the systems with nonlinear dynamics, nonholonomic constraints, and any form of low level feedback control. In the reported work, to grant the International Regulations for Prevention of Collisions at Sea (COLREGs), the sampling of motion goals is constrained. Our proposed approach consist in one leader AUV and two or more follower AUVs, all equipped with conductivity, temperature and depth (CTD) sensor devices. The CTD data is modelled as a Gaussian mixture model (GMM) by running the proposed algorithm in Chapter 2 in each vehicle separately. In the setup adopted, a leader AUV is tasked to acquire CTD data by running a set of user-deÔ¨Åned mission instructions like for example following a desired path proÔ¨Åle. The aim of each follower AUVs is to follow the leader closely with a desired formation that will adaptively change according to the CTD data that they are acquiring. More precisely, each AUV is in charge of running in real-time the unsupervised learning algorithm for GMMs that is fed by the CTD data. To make the scheme robust to fault of underwater communications, which is very prone to happen, in this approach we assume that the followers only on the surface can receive the GMM hypothesis of the leader. In other words, each time the vehicles resurface (and this is done in a coordinated fashion), the leader AUV broadcast its currently estimated parameters of the GMM, 3.3 Problem Formulation 45 and",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_65"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "MM hypothesis of the leader. In other words, each time the vehicles resurface (and this is done in a coordinated fashion), the leader AUV broadcast its currently estimated parameters of the GMM, 3.3 Problem Formulation 45 and the followers based on this and their own estimated GMM compute the variational distance error between these GMMs. This error is the variational distance between two GMMs that gives a notion of how different is the CTD environment of each follower with respect to the leader. Thus, during each resurfacing, the calculated error and the geographical position of the leader is used to guide the next formation conÔ¨Åguration, which typically scales the distance between the AUVs in the formation (making a zoom-in and zoom-out), in order to improve the efÔ¨Åciency of data ac- quisition in the given region. Therefore, every follower has to explore the environments where, in terms of CTD data, are desirably different from the leader. Comparing with the related literature described above, in our approach we have the following ad- vantages: The vehicles do not need to have communication underwater. No prior knowledge of the dynamics of the environment is required in unsupervised motion learning scenario. Moreover, no signiÔ¨Åcantly payload to save data is also needed since each vehicle only saves a GMM proÔ¨Åle of the captured CTD data. Furthermore, our proposed GMM based method is much more resilient toward outlier and noise by nature, because outliers do not carry enough evidence to manipulate the GMM signiÔ¨Åcantly. Also, it is more efÔ¨Åcient in terms of resources since followers can cover a larger area and expand the formation with respect to the position and GMM of sampling proÔ¨Åle of the leader. 3.3 Problem Formulation We address the problem of real-time adaptive sampling using a coordinated Ô¨Çeet of AUVs. To this end, we provide a motion control algorithm that includes the unsupervised learning of Gaus- sian Mixture Models (GMMs) described in the previous chapter. The system set up consist of one leader AUV and two or more followers AUVs. All vehicles are equipped with CTD sensor devices. The leader moves around, in a predeÔ¨Åned path, while acquiring CTD data. Meanwhile, it constructs a GMM proÔ¨Åle by running",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_66"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " or more followers AUVs. All vehicles are equipped with CTD sensor devices. The leader moves around, in a predeÔ¨Åned path, while acquiring CTD data. Meanwhile, it constructs a GMM proÔ¨Åle by running the unsupervised learning of GMM algorithm described in Chapter 2, see also in [64]. The objective is to execute a coordinated formation maneuver, by driv- ing and maintaining the other vehicles, henceforth known as followers, at a desired position with respect to the leader that is a function of the dissimilarity of the CTD proÔ¨Åles of the leader and the followers. This dissimilarity measure is the variational distance between two GMM proÔ¨Åles. To make the scheme robust to fault of underwater communications, which is very prone to happen, in this approach we consider that follower only on the surface can learn the GMM hypothesis of the leader to calculate the error (dissimilarity measure). while on the surface, the vehicles can also use GPS to correct their navigation errors. 3.4 Preliminaries and Background AUVs are equipped with a variety of sensor systems and communication devices. There are some concepts and devices found in nearly every AUV and others, which are only used for speciÔ¨Åc 46 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Figure 3.1: The earth-Ô¨Åxed inertial frame {U} and the body-Ô¨Åxed frame {B} with position, orien- tation and linear and angular velocities mission tasks. The following section gives an overview of sensor and communication systems that are used in AUVs. 3.4.1 Coordinate Frames The equations of motion for an AUV require the deÔ¨Ånition of an earth-Ô¨Åxed inertial frame {U} with the orthogonal axes {xU,yU,zU} and a body-Ô¨Åxed frame {B} with the orthogonal axes {xB,yB,zB}. The position and orientation of the vehicle is usually given with respect to the inertial frame {U}. The linear and angular velocities are expressed in the body-Ô¨Åxed frame. The body-Ô¨Åxed frame usually coincides with the center of gravity of the vehicle. The body axes are deÔ¨Åned as fol- lows [108]: ‚Ä¢ xB is the axis from aft to fore ‚Ä¢ yB is the axis from port",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_67"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "-Ô¨Åxed frame usually coincides with the center of gravity of the vehicle. The body axes are deÔ¨Åned as fol- lows [108]: ‚Ä¢ xB is the axis from aft to fore ‚Ä¢ yB is the axis from port to starboard ‚Ä¢ zB is the axis from top to the bottom Figure 3.1 shows the two frames. For the sake of more clarity, we deÔ¨Åne the following entities: ‚Ä¢ Œ∑1 = [x,y,z]T, the origin of {B} with respect to {U} ‚Ä¢ Œ∑2 = [œÜ,Œ∏,œà]T, the angles of orientation of {B} with respect to {U}. œÜ is called roll, Œ∏ pitch and œà yaw. ‚Ä¢ v1 = [u,œÖ,w]T, the linear velocities of the origin of {B} relative to {U} expressed in {B}. u is called surge, œÖ is called sway and w is called heave. 3.4 Preliminaries and Background 47 Figure 3.2: SimpliÔ¨Åed kinematic model of an underwater vehicle that maintains in a horizontal plane. ‚Ä¢ v2 = [p,q,r]T, the angular velocities of the origin of {B} relative to {U} expressed in {B}. ‚Ä¢ œÑ1 = [X,Y,Z]T, the actuating forces expressed in {B} ‚Ä¢ œÑ2 = [K,M,N]T, the actuating torques expressed in {B} The following vectors are introduced for convenience:Œ∑ = [Œ∑T 1 ,Œ∑T 2 ]T, v = [vT 1 ,vT 2 ]T, œÑ = [œÑT 1 ,œÑT 2 ]T. 3.4.2 SimpliÔ¨Åed Kinematic Equations In this thesis, we consider the control of the vehicles in horizontal plane. The kinematic equations relate the position and orientation vector Œ∑, which is expressed in the inertial frame {U}, to the velocity vector v, which is expressed in the body-Ô¨Åxed frame {B}. The dynamic equations, which are not considered in here, relate the velocity vector v, which is expressed in the body-Ô¨Åxed frame {B}, to the force and torque vector œÑ, which is also expressed in the body-Ô¨Åxed frame {B}. Fig- ure 3.",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_68"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ", relate the velocity vector v, which is expressed in the body-Ô¨Åxed frame {B}, to the force and torque vector œÑ, which is also expressed in the body-Ô¨Åxed frame {B}. Fig- ure 3.2 shows a simpliÔ¨Åed version of the kinematic model of an underwater vehicle. Interested readers are encouraged to see [109, 108]. This assumption leads to simpliÔ¨Åed kinematic equations Ô£Æ Ô£ØÔ£∞ Àôx Àôy Àôœà Ô£π Ô£∫Ô£ª= Ô£Æ Ô£ØÔ£∞ ucosœà ‚àíœÖ sinœà usinœà ‚àíœÖ cosœà r Ô£π Ô£∫Ô£ª (3.1) with p = [x,y,œà]T denoting the position and orientation of the vehicle on the two-dimensional plane and v = [u,œÖ,r]T denoting the velocity. Equation (3.4) can be written in the form Àôp = R(œà)v, (3.2) 48 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Figure 3.3: A close up of the CTD sensor of the AUV (image source: [1]) with the rotational matrix R(œà) R(œà) = Ô£Æ Ô£ØÔ£∞ cosœà ‚àísinœà 0 sinœà ‚àícosœà 0 0 0 1 Ô£π Ô£∫Ô£ª (3.3) 3.4.3 CTD Sensors A CTD, an acronym for Conductivity, Temperature, and Depth, is a package of electronic instru- ments and a primary tool for determining essential physical properties of sea water, see Figure 3.3. The depth of the vehicle from the surface is determined by means of a pressure sensor. The pri- mary function of a CTD device is to detect how the conductivity and temperature of the water column changes relative to depth. Figure 3.4 represents the 2-D and 3-D temperature proÔ¨Åle in a trial. Conductivity is a measure of how well a Ô¨Çuid conducts electricity. Figure Conductivity is directly related to salinity, which is the concentration of salt and other inorganic compounds in seawater. Salinity",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_69"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "Ô¨Åle in a trial. Conductivity is a measure of how well a Ô¨Çuid conducts electricity. Figure Conductivity is directly related to salinity, which is the concentration of salt and other inorganic compounds in seawater. Salinity is one of the most basic measurements used by ocean scientists. When com- bined with temperature data, salinity measurements can be used to determine seawater density which is a primary driving force for major ocean currents. Ocean explorers often use CTD measurements to detect evidence of volcanoes, hydrothermal vents, and other deep-sea features that cause changes to the physical and chemical properties of seawater. CTDs can provide proÔ¨Åles of chemical and physical parameters through the entire water column. By analysing these parameters, scientists can make inferences about the occurrence of certain biological processes, such as the growth of algae. Knowledge obtained from CTD devices can, in turn, lead scientists to a better understanding of such factors as species distribution and abundance in particular areas of the ocean. Sudden changes or anomalies, in one or more of the properties being measured may alert scientists to an unusual occurrence, such as an active hy- drothermal vent [1]. The main advantages of CTDs are accuracy and light weight. On the Ô¨Çip-side the calibration of the devices especially for long term missions can be challenging. Until recently, once an AUV was launched it was completely isolated from its human operators until it returned 3.4 Preliminaries and Background 49 0 2 4 6 8 10 12 19.4 19.6 19.8 20 20.2 20.4 20.6 Depth [m] Temperature [¬∞C] (a) Temperature based on Depth 38.4524 38.4526 38.4528 ‚àí8.994 ‚àí8.993 ‚àí8.992 ‚àí8.991 ‚àí8.99 ‚àí15 ‚àí10 ‚àí5 0 Depth [m] Latitude [¬∞] Longitude [¬∞] Temperature [¬∞C] 19.559 19.655 19.751 19.848 19.944 20.040 20.137 20.233 20.329 20.426 (b) 3-D Temperature ProÔ¨Åle Figure 3.4: Temperature ProÔ¨Åles (images source: [17]). from its mission. Because there",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_70"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "20.137 20.233 20.329 20.426 (b) 3-D Temperature ProÔ¨Åle Figure 3.4: Temperature ProÔ¨Åles (images source: [17]). from its mission. Because there was no effective means for communicating with a submerged AUV, everything depended upon instructions programmed into the AUV‚Äôs on-board computer. Today, it is possible for AUV operators to send instructions and receive data with acoustic com- munication systems that use sound waves with frequencies ranging roughly between 50 Hz and 50 kHz [7]. These systems allow greater interaction between AUVs and their operators, but basic functions are still controlled by the computer and software on-board the AUV. Basic systems found on most AUVs include: propulsion, usually propellers or thrusters (water jets); power sources such as batteries or fuel cells; environmental sensors such as video and de- vices for measuring water chemistry; computer to control the robot‚Äôs movement and data gathering functions; and a navigation system. Navigation has been one of the biggest challenges for AUV engineers. Today, everyone from back- packers to ocean freighters use global positioning systems (GPS) to Ô¨Ånd their location on Earth‚Äôs surface. But GPS signals do not penetrate into the ocean. One way to overcome this problem is to estimate an AUV‚Äôs position from its compass course, speed through the water, and depth. This method of navigation is called ‚Äúdead reckoning\", and was used for centuries before GPS was available. Dead reckoning positions are only estimates however, and are subject to a variety of errors that can become serious over long distances and extended time periods. In a conÔ¨Åned area, the position of an AUV can be determined using acoustic transmitters that are set around the perimeter of the operating area, see Section 3.4.4.3. These transmitters may be moored to the seaÔ¨Çoor, or installed in buoys. Some buoy systems also include GPS receivers, so the buoys‚Äô positions are constantly updated. Signals from at least three appropriately positioned transmitters can be used to accurately calculate the AUV‚Äôs position. Although this approach can be very accurate, AUV operators must install the transmitters, and the AUV must remain within a rather small area [109, 110]. A more sophisticated approach uses Inertial Navigation Systems (INS) that measure the AUV‚Äôs 50",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_71"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " very accurate, AUV operators must install the transmitters, and the AUV must remain within a rather small area [109, 110]. A more sophisticated approach uses Inertial Navigation Systems (INS) that measure the AUV‚Äôs 50 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles acceleration and angular velocity in all directions. These systems provide highly accurate position estimates, but require periodic position data from another source for greatest accuracy. On surface vessels and aircraft equipped with INS, additional position data are often obtained from GPS. On underwater vessels, the accuracy of INS position estimates is greatly improved by using a Doppler Velocity Logger (DVL) to measure velocity of the speed of the vessel. On some AUVs, several of these systems are combined to improve the overall accuracy of on-board navigation. 3.4.4 Navigation With recent advances in battery capacity and the development of hydrogen fuel cells, autonomous underwater vehicles (AUVs) are being used to undertake longer missions that were previously performed by manned or tethered vehicles. Navigation is one of the most critical factors in deter- mining the operational suitability of any unmanned vehicle for its designated environment. In fully autonomous vehicles, due to the lack of a human operator to perform the navigation task, there is a fundamental requirement to incorporate estimation techniques that can provide the desired in- formation necessary for navigation. Such information includes position, attitude, and velocity of the vehicle. Unlike unmanned underwater vehicles (UUVs) which are usually operated remotely by an acoustic modem link, AUVs present a uniquely challenging navigational problem because they operate autonomously in a highly unstructured environment where satellite-based navigation is not directly available, see e.g. [111]. As a result, more advanced navigation systems are needed to maintain an accurate position over a larger operational area. Generally speaking, all underwater navigation systems problems fall into the 2D position local- ization (i.e. longitude and latitude). It is due to the fact that all submersible vehicles are outÔ¨Åtted with a pressure sensor and are capable of determining their absolute depth with high accuracy and a high update rate. The accuracy of a navigation system is critical for the oceanographers to more fully exploit quan- titative data from high resolution sensors such as high-frequency bathymetric sonar sensors and optical cameras. Furthermore, the closed-loop feedback control of underwater robotic vehicles and improvement of the quality of collected data during survey missions are eminently dependent on",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_72"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "- titative data from high resolution sensors such as high-frequency bathymetric sonar sensors and optical cameras. Furthermore, the closed-loop feedback control of underwater robotic vehicles and improvement of the quality of collected data during survey missions are eminently dependent on the accuracy of the navigation system. In this work, the need for precise navigation is more evident because the trajectories of the follow- ers are a function of the GMM hypothesis of the leader which in turn, depends on how accurate the leader moves in a predeÔ¨Åned path. If the AUV does not follow the path accurately during the mission, critical features may not be recorded and the position of any features recorded during the mission will be uncertain. In the literature, many different methods for navigation in different under-water environments have been proposed, see e.g., [110, 111]. Most AUV navigation breaks down into Ô¨Åve major categories: GPS, inertial, visual, dead-reckoning and acoustic. 3.4 Preliminaries and Background 51 Figure 3.5: A two-dimensional kinematic model of an AUV. The angle Œ∏ of the resulting velocity V does not necessarily correspond with the heading angle œà 3.4.4.1 Global Positioning System (GPS) An easily accessible global frame is the International Terrestrial Reference Frame 2000 (ITRF2000) available by GPS positioning [112]. The GPS can be used for navigation with bounded-error when the vehicle is operating on the surface. The GPS system‚Äôs radio-frequency signals are blocked by sea water, thus GPS signals cannot be directly received by deeply submerged ocean vehicles. However, GPS commonly aides a variety of underwater vehicle navigation techniques, including surveying of acoustic transponders, alignment calibration of Doppler sonar systems [113]. 3.4.4.2 Magnetic Compass Digital compass plays a vital role in autonomous vehicles. It provides the 3D-vector of the local magnetic Ô¨Åeld. It can not only determine bearing, but when used as an element for dead reckoning, can determine location. Placement in a vehicle, however, exposes compasses to a variety of hard to quantify inÔ¨Çuences. Digital compasses are subject to hard and soft iron errors, acceleration errors, and severe inclinations, which can affect a heading calculation and increase error. Therefore, before computing the heading angle œà of the vehicle from the magnetic Ô¨Åeld vector it is necessary to carefully",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_73"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " subject to hard and soft iron errors, acceleration errors, and severe inclinations, which can affect a heading calculation and increase error. Therefore, before computing the heading angle œà of the vehicle from the magnetic Ô¨Åeld vector it is necessary to carefully calibrate the compass each time we have a mission in a new environment, as the ‚Äúvariation\", difference between the orientation of the 3D magnetic Ô¨Åeld vector and the direction of true north, changes in new geographic location. In the Ô¨Åeld, if something goes wrong, it can be difÔ¨Åcult to determine what has happened; by testing compass accuracy in a lab one can better understand the limitations of a given device. The two-dimensional heading angle œà of the vehicle can be measured by a magnetic compass. Such a compass is found in almost every underwater vehicle. Furthermore, the compass suffers from local magnetic anomalies and magnetic Ô¨Åelds induced by the vehicle itself [109]. All mentioned aspects lead to noisy measurements, which can hardly assumed to be Gaussian. In contrary to most land vehicles, for marine vehicles the heading angle œà does not necessarily correspond with the angle Œ∏ of the resulting velocity V of the vehicle (see Figure 3.5). 52 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Figure 3.6: A typical DVL device (image source: [1]) 3.4.4.3 Doppler velocity log (DVL) The Doppler velocity log (DVL) is a device that is used to obtain the three-dimensional speed vector of the vehicle. A typical DVL device (see Figure 3.6) consists of 4 transceiver units. This instrument, mounted on the vehicle, sends out a sound signal and the acoustic pulses are reÔ¨Çected from the seaÔ¨Çoor or from the surface. Then, the vehicle measures the Doppler shift of its return. From this shift, the vehicle‚Äôs velocity is calculated and is used to determine position and depth. The measurement is called ‚Äúbottom-lock\" if the measured reÔ¨Çection is from the seaÔ¨Çoor or ‚Äúsurface- lock\" if the reÔ¨Çection from the surface is measured. DVL can be used to obtain a three-dimensional linear velocity vector as well as a three dimensional angular velocity vector in the body-Ô¨Åxed frame of the vehicle. They have become increasingly popular in AUVs and ROVs, which",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_74"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " measured. DVL can be used to obtain a three-dimensional linear velocity vector as well as a three dimensional angular velocity vector in the body-Ô¨Åxed frame of the vehicle. They have become increasingly popular in AUVs and ROVs, which is a result of the signiÔ¨Åcantly decreased size of available devices [109, 2]. 3.4.4.4 Dead-reckoning Navigation A Dead-Reckoning system is a basic requirement for any AUV. It involves simple measurements of bearing or magnetic heading, depth, ground velocity, and travelled distance. The AUV uses an on-board digital compass for bearing and a pressure sensor to measure the depth, Section 3.4.4.2. It also calculates the velocity and displacement based on thruster commands, with this assumption that there is a certain linear dependency between propeller RPM and forward vehicle speed. Ease of use and affordability are the main advantages of this approach. When using dead reckoning, due to the integrative nature of the position estimate, the error of the position estimate will grow unbounded. The growth in this error is caused by errors in the velocity and attitude estimates which are in turn affected by the accuracy of the navigational Ô¨Ålter and the accuracies of the measurements observing these states. 3.4.4.5 Inertial Navigation System (INS) Inertial navigation involves the detection of acceleration of the vehicle with the use of three orthogonally-mounted gyroscopic sensors. 3.4 Preliminaries and Background 53 (a) A stable platform IMU (b) Strap-down Systems Figure 3.7: Two categories of INSs (image sources: Left [4], Right [7]). Inertial navigation is a self-contained navigation technique in which measurements provided by accelerometers and gyroscopes are used to track the position and orientation of an object relative to a known starting point, orientation and velocity. Inertial Measurement Units (IMUs) typically contain three orthogonal rate-gyroscopes and three orthogonal accelerometers. This allows the system to measure linear and rotational accelerations in 3-dimensions, thereby track the posi- tion and orientation of the device and characterizing vehicle motion in all 6-Degree Of Freedom, see [111, 114, 115]. Nearly all IMUs fall into one of the two categories outlined below. The difference between the two categories is the frame of reference in which the",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_75"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "izing vehicle motion in all 6-Degree Of Freedom, see [111, 114, 115]. Nearly all IMUs fall into one of the two categories outlined below. The difference between the two categories is the frame of reference in which the rate-gyroscopes and accelerometers operate. ‚Ä¢ Stable Platform Systems In stable platform type systems the inertial sensors are mounted on a platform which is isolated from any external rotational motion. In other words the platform is held in alignment with the global frame, Figure 3.7(a). This is achieved by mounting the platform using frames which allow the platform freedom in all three axes, The platform mounted gyroscopes detect any platform rotations. These signals are fed back to torque motors which rotate the gimbals in order to cancel out such rotations, hence keeping the platform aligned with the global frame. ‚Ä¢ Strap-down Systems In strap-down systems the inertial sensors are mounted rigidly onto the device, and therefore output quantities measured in the body frame rather than the global frame, Figure 3.7(b). To keep track of orientation the signals from the rate gyroscopes are ‚Äúintegrated\". To track position the three accelerometer signals are resolved into global co- ordinates using the known orientation, as determined by the integration of the gyroscope signals. The global acceleration signals are then integrated as in the stable platform algo- rithm. 54 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Figure 3.8: Overall visual servoing control scheme.(image source: [117]) Stable platform and strap-down systems are both based on the same underlying principles. Strap- down systems have reduced mechanical complexity and tend to be physically smaller than stable platform systems. These beneÔ¨Åts are achieved at the cost of increased computational complexity. As the cost of computation has decreased strap-down systems have become the dominant type of INS. However, the problem with this approach is that the accuracy of navigation can deteriorate rapidly due to accumulated error in integrating of these accelerations over time. This error can be reduced through state-estimation methods such as Kalman Filtering, and/or completely bounded by peri- odic resurfacing and using absolute position Ô¨Åxes, through the use of Differential GPS (see [111] and [116]). This is a signiÔ¨Åcant improvement over dead reckoning and is often combined with a Doppler velocity log (DVL) that can measure the vehicle relative velocity [111]. 3.4.",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_76"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "see [111] and [116]). This is a signiÔ¨Åcant improvement over dead reckoning and is often combined with a Doppler velocity log (DVL) that can measure the vehicle relative velocity [111]. 3.4.4.6 Visual Navigation Visual navigation systems are mainly used for object identiÔ¨Åcation, following, and collision avoid- ance. Due to attenuation of light underwater, this approach only is suitable for short distance. In literature, a set of algorithms for the creation of underwater mosaics and their use as visual maps for underwater vehicle navigation are presented, Figure 3.8. An automatic video mosaics is being created, which deals with the problem of image motion estimation in a robust and automatic way. The motion estimation is based on a initial matching of corresponding areas over pairs of images, followed by the use of a robust matching technique, which can cope with a high percentage of incorrect matches. Several motion models, established under the projective geometry framework, allow for the creation of high quality mosaics where no assumptions are made about the camera motion [118, 117]. 3.5 CTD adaptive sampling strategy 55 3.4.4.7 Acoustic Navigation Acoustic navigation systems can be used for navigation over long distances, due to high speed of sound underwater (avg. 1500 m/s in seawater). This method can be used in environments that are opaque to the radio-frequencies upon which the GPS relies, as in subsurface, and are more affordable than conventional INSs. Several types of acoustic systems are available for AUVs, in- cluding Long-Base-Line (LBL), Ultra-Short-Base-Line (USBL), Sound Navigation And Ranging (SONAR), and Acoustic Doppler (ADCPs & DVLs) technologies (see [119], [120] and [121]). Deep-sea research got a boost with the invention of sonar in 1914. Developed to detect icebergs at night or in fog, sonar quickly proved to be an excellent depth-Ô¨Ånder, much faster than the old sounding line. Sonar is based on the principle that sound travels through water at a rapid and fairly constant rate. A ‚Äúpinger\" mounted underwater on a ship‚Äôs hull sends out periodic bursts of sound. The sound waves bounce off obstacles and get reÔ¨Çected back to the ship. By measuring how long it",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_77"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " at a rapid and fairly constant rate. A ‚Äúpinger\" mounted underwater on a ship‚Äôs hull sends out periodic bursts of sound. The sound waves bounce off obstacles and get reÔ¨Çected back to the ship. By measuring how long it takes for the reÔ¨Çected waves to return to the ship, the distance to an obstacle can be calculated. Finally, it is concluded that only geophysically referenced methods will enable AUVs to navigate accurately over large areas and that advances in underwater feature recognition are required before these methods can be implemented in operational AUVs. 3.5 CTD adaptive sampling strategy As mentioned before, this work deals with a cooperative coordinated formation of AUVs. We assume that one vehicle always plays the role of leader and the rest as follower(s). The task of the leader vehicle is to follow some predeÔ¨Åned path proÔ¨Åle while is acquiring CTD data. The aim of the each follower is to keep a coordinated formation with respect to the leader by keeping a desired distance from it. This distance is a function of a dissimilarity measure, which is the variational distance between its own GMM hypothesis and the leader. This measure, Œ∂, provides a quantity of how different or similar is the CTD data between the leader and each follower at the time of resurfacing. As mentioned before, we assume that all followers, adjust their position during each resurfacing with respect to the leader. A control strategy is adopted to generate speed and heading commands so as to drive suitably deÔ¨Åned along track and cross track errors to zero. The commands are used as input to local inner loops for yaw and speed control. In practice, executing this type of mission without expensive inertial sensor suites requires the fol- lower vehicles to manoeuvre into formation by relying on measurements of their distances to the leading vehicles and exchanging complementary data. This entails considerable difÔ¨Åculties un- derwater, as conventional communication and localization systems (like GPS) are unavailable and usually replaced by acoustic devices: acoustic modems that allow the exchange of data, and rang- ing devices that estimate distances by measuring time-of-Ô¨Åght of acoustic signals. These devices exhibit a number of constraints that are inherent to the medium, such as temporary communica- tion losses, outliers in the range measurements, and low bandwidth of the acoustic communication systems. In practice, an important consequence of these limitations is the inability to measure",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_78"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " exhibit a number of constraints that are inherent to the medium, such as temporary communica- tion losses, outliers in the range measurements, and low bandwidth of the acoustic communication systems. In practice, an important consequence of these limitations is the inability to measure 56 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Figure 3.9: Schematic representation of the setup or communicate frequently, with inter-sample times often in the range of seconds, making the problem of underwater range-based multiple vehicle formation keeping very challenging. 3.5.1 Path Following As it can be seen in Figure 3.9, the vehicles are required to follow segments of line, which for simplicity and without loss of generality are perpendicular to the y axis. During each resurfacing, every follower separately regulates the desired linear velocity ud and heading œàd. These are then fed to inner loop controllers speciÔ¨Åc to the vehicle. A simpliÔ¨Åed version of the kinematic model of an underwater vehicle can be described as follows Ô£Æ Ô£ØÔ£∞ Àôx Àôy Àôœà Ô£π Ô£∫Ô£ª= Ô£Æ Ô£ØÔ£∞ ucosœà ‚àíœÖ sinœà usinœà ‚àíœÖ cosœà r Ô£π Ô£∫Ô£ª (3.4) where u is the surge velocity, œÖ is the sway velocity, r is the angular velocity and œà is the heading. Using the path-following algorithm in [124], we have ey = y‚àíyd ‚áíÀôey = Àôy‚àíÀôyd = usinœà ‚àí0 = uU (3.5) where U = sinœà, and yd deÔ¨Åne the desired position of the line to be followed by the AUV, which will correspond to the desired distance from the leader AUV (see Figure 3.9). Therefore, if U = sinœà we obtain Àôey = ‚àík1ey, which implies that the error ey will converge exponentially to zero. The desired heading angle can be obtained as œàd = sin‚àí1(sat(U)) (3.6) 3.5 CTD adaptive sampling strategy 57 Table 3.1: Simulation parameters Œµ k1 kœà ku k2 0.8 1 1.5 1.",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_79"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "(sat(U)) (3.6) 3.5 CTD adaptive sampling strategy 57 Table 3.1: Simulation parameters Œµ k1 kœà ku k2 0.8 1 1.5 1.2 1 where sat(U) = Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥ U if |U| < Œµ Œµ if U > Œµ ‚àíŒµ if U < ‚àíŒµ (3.7) and Œµ ‚àà(0,1). A possibility for the inner-loop in heading can be derived by noting that Àúœà = œà ‚àíœàd ‚áíÀôÀúœà = r ‚àíÀôœàd (3.8) Thus, if r = ‚àíkœà Àúœà = ‚àíkœà(œà ‚àíœàd) , kœà > 0 it can be concluded that œà will converge to œàd for œàd constant. Note that it is possible to show, using Lyapunov-based analysis tools, that the above nonlinear control law yields convergence of the cross track error to zero if the actual vehicle heading equals the desired heading reference œàd. The work in [124] also shows that ‚Äúidentical behaviour\" is obtained when the dynamics of the heading autopilot (inner loop) and the sideslip of the vehicle are taken into account. Table 3.1 contains the parameters of this controller that are Ô¨Åxed throughout the simulation experiment. 3.5.2 Coordinated Formation For simplicity we consider a formation in line parallel with the y axis as illustrated in Figure 3.9. To keep the coordinated formation, a follower during each resurfacing needs to correct its position with respect to the leader. To achieve this goal, a PI controller is used ÀôŒæ = ex ,uf = ‚àíku ex ‚àík2Œæ (3.9) where ex is the difference between the position of the leader and each follower along the x axis (see Figure 3.9). 3.5.3 Variational distance between GMMs The Gaussian mixture model deÔ¨Åned in this work reÔ¨Çects the CTD feature distributions of an environment by a linear combination of Gaussian densities. In this way, the density of a single feature or the probability of regions in the",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_80"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " The Gaussian mixture model deÔ¨Åned in this work reÔ¨Çects the CTD feature distributions of an environment by a linear combination of Gaussian densities. In this way, the density of a single feature or the probability of regions in the feature space depends on all components of the Gaussian mixture model, Equation (2.1). Thus, this model corresponds to the soft assignment approach of modelling image contents [23]. Kullback Leibler (KL) divergence, which is a widely used tool in 58 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Figure 3.10: Schematic representation of the leader statistics and pattern recognition, to measure the similarity between them as follows: D(f‚à•g) = Z f(x)log f(x) g(x) dx (3.10) Note that unlike two single Gaussian distributions, there is no closed form expression to measure the similarity between two GMMs. Thus, in this work we use the variational approximation [20] to measure the dissimilarity between GMM hypotheses, that is, Œ∂ = Dvariational(f‚à•g) = ‚àë a wa log ‚àëa‚Ä≤ wa‚Ä≤e‚àíD(fa‚à•fa‚Ä≤) ‚àëb wbe‚àíD(fa‚à•gb) (3.11) where wa and wa‚Ä≤ are the mixing weights of the components in f(x) and wb is the mixing weights of the components in g(x). 3.6 Simulation Results In this section, the performance of the proposed algorithm is demonstrated in uniform and change- able environments which were reconstructed based on real CTD data. 3.6.1 The Leader AUV Figure 3.10 shows a schematic representation of a leader AUV. As mentioned above, its task is to follow some desired predeÔ¨Åned path, reference position, while acquiring CTD data. This data, is fed to the on-line GMM estimator to create a CTD proÔ¨Åle for the leader. The AUV real-time mission planner is a high-level decision maker on-board the AUV. It monitors all system states and issues the speed and steering commands to the low-level thruster controllers (AUV guidance and navigation block). In literature, the problem of position trajectory-tracking and path-following for AUVs have been addressed repeatedly, e.g. see [122], and [123]. The low-level AUV controller set consists of three",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_81"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "AUV guidance and navigation block). In literature, the problem of position trajectory-tracking and path-following for AUVs have been addressed repeatedly, e.g. see [122], and [123]. The low-level AUV controller set consists of three controllers, depth, speed and heading, which are dedicated to receiving commands 3.6 Simulation Results 59 Figure 3.11: Schematic representation of the follower from the reference controller and generating thruster outputs based on error between commanded and actual depth and heading. 3.6.2 The follower AUV A scheme of a follower AUV, is represented in Figure 3.11. Similar to the leader, each follower AUV captures CTD data in real-time and construct its own GMM hypothesis. Unlike the leader, the desired path is not predeÔ¨Åned and has to be updated in each resurfacing (adaptive sampling). In fact, the task of the follower, can be divided into on-surface and subsurface. In each resurfacing, using the available GPS signals, the follower can correct its own navigation errors as suggested in [123] and learn the position of the leader. Suitable velocity command can be issued to have a coordinated formation with respect to the last seen position of the leaser. Fur- thermore, on surface, the follower can learn the CTD proÔ¨Åle, GMM hypothesis, of the leader and measure the dissimilarity measure, Œ∂, according to Equation (3.11). If the dissimilarity is high, the follower continues the current formation. On the other hand, too small dissimilarity measure means that expanding of the formation, to sample new environment is needed. In subsurface, the vehicle has to follow the last updated mission plan as in [122]. Worth to be mentioned that, some limits were put for the acceleration of the vehicles and expan- sion of the formation, to address the various operational constraints associated with real world applications. To maintaining the group structure: 1) attraction to the leader up to a maximum distance 2) repulsion from the leader when it is too close 3) alignment or velocity matching with the leader. Every follower makes its own decision based on the difference or distance between its GMM and the leader. In particular, for the case of one single follower (which means 2 AUVs), the task would consist in keeping the follower AUV at a convenient distance from the",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_82"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " decision based on the difference or distance between its GMM and the leader. In particular, for the case of one single follower (which means 2 AUVs), the task would consist in keeping the follower AUV at a convenient distance from the leader, whose distance depends on the CTD that is being measured. Figure 3.12, shows a real CTD data that 60 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles 0 50 100 150 200 250 300 4.85 4.9 4.95 5 C [S/m] 0 50 100 150 200 250 300 19 20 21 T [¬∞C] 0 50 100 150 200 250 300 ‚àí10 ‚àí5 0 D [m] Time [s] Figure 3.12: Real CTD data was used in the simulations. A typical scenario is to make the follower vehicle close to the leader when the difference of the CTDs is large, and on the contrary, increase the distance when the dif- ference is small. To implement this strategy, we propose the following steps to compute the error or dissimilarity measure: ‚Ä¢ The CTD data is modelled as a Gaussian Mixture Model (GMM) and each vehicle runs an on-line unsupervised learning algorithm to estimate the GMM parameters. As mentioned in Chapter 2, the number of components of the GMM is not Ô¨Åxed and can change over time, which provides more Ô¨Çexibility to deal with uncertain dynamic environments. ‚Ä¢ During each resurfacing, every follower learn the last seen position of the leader and its GMM hypothesis. Then, together with its own estimated GMM parameters, compute an error that measures the dissimilarity of the two GMM probability density functions given by a closed-form formula (the variational approximation) that measures the Kullback Leibler (KL) divergence, see [20]. The desired position yd for each follower corresponds to the case when variational distance Œ∂ becomes equal to some reference value Œ∂r, and it is given by eŒ∂ = (Œ∂ ‚àíŒ∂r) / Œ∂r yd = yf +Œª eŒ∂ (3.12) where Œª is a constant value and can be positive or negative, depending on which direction we want to guide the follower",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_83"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " (Œ∂ ‚àíŒ∂r) / Œ∂r yd = yf +Œª eŒ∂ (3.12) where Œª is a constant value and can be positive or negative, depending on which direction we want to guide the follower. yd is the desired position in x‚àíy plane and yf is the current position of the follower. The intuition behind the normalization of eŒ∂ between [0,1] is to moderate the changes in 3.6 Simulation Results 61 (a) 3D temperature dynamics (b) coordinated formation in x-y 0 1 2 3 4 5 6 x 10 4 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 Time [s] Dissimilarity Measure Left Follower Right Follower goal_dissimilarity (c) GMM error 0 0.5 1 1.5 2 2.5 3 x 10 4 0 0.5 1 1.5 V1 0 0.5 1 1.5 2 2.5 3 x 10 4 0 0.5 1 1.5 V2 0 0.5 1 1.5 2 2.5 3 x 10 4 0 0.5 1 1.5 V3 (d) Linear velocity Figure 3.13: Uniform environment. the formation with respect to the value of Œ∂ specially at the beginning of the experiment (zoom-in and zoom-out of the formation be more dependent on user-deÔ¨Åned value of Œª than unknown value of Œ∂). 3.6.3 Uniform Environment Simulation Figure 3.13(a) shows the temperature Ô¨Åeld of a reconstructed environment, where the top layer represents the near surface and the lowest one is 12m beneath the surface. In this experiment, we assume that the environment is uniform along the x axis. As expected, we see that the average temperature on the surface is higher than in depth. We assumed a Ô¨Çeet of three vehicles, and the leader is in the middle. Every vehicle could go down to 12m below the surface, in a saw-tooth 62 Real-Time Unsupervised Motion Learning for Autonomous",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_84"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ". We assumed a Ô¨Çeet of three vehicles, and the leader is in the middle. Every vehicle could go down to 12m below the surface, in a saw-tooth 62 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles (a) 3D temperature dynamics (b) coordinated formation in x-y 0 1 2 3 4 5 6 7 x 10 4 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 Time [s] Dissimilarity Measure Left Follower Right Follower goal_dissimilarity (c) GMM error 0 0.5 1 1.5 2 2.5 3 3.5 4 x 10 4 0 0.5 1 1.5 V1 0 0.5 1 1.5 2 2.5 3 3.5 4 x 10 4 0 0.5 1 1.5 V2 0 0.5 1 1.5 2 2.5 3 3.5 4 x 10 4 0 0.5 1 1.5 V3 (d) Linear velocity Figure 3.14: Uneven environment. pattern. The mission plan for the leader is to follow a line, in parallel with the x axis, with a con- stant speed. The followers need to adapt their speed and distance from the leader to maintain the coordinated formation of the Ô¨Çeet. In other words, every follower has to expand the formation to Ô¨Ånd the regions where the CTD data is desirably different from the leader. Figure 3.13(b) shows the overall performance of the Ô¨Çeet, from the top view, and the position of the vehicles during resurfacing intervals in x ‚àíy plane. Figure 3.13(c), compatible with Figure 3.13(b) and based on Equation (3.12), shows by expanding the formation at the beginning of the experiment,the follow- ers Ô¨Ånd the desirable environment. After moving to that position, the Ô¨Çeet goes on as a coordinated group along the x axis. The objective is that during each resurfacing",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_85"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " formation at the beginning of the experiment,the follow- ers Ô¨Ånd the desirable environment. After moving to that position, the Ô¨Çeet goes on as a coordinated group along the x axis. The objective is that during each resurfacing, each follower learn the last seen position of the leader and its GMM hypothesis to update its own mission plan. Figure 3.13(d) shows the linear velocity changes of each vehicle at the beginning of the experiment. As men- tioned before, the leader travels with a constant speed. And each follower, adjust its velocity in 3.7 Conclusion 63 each resurfacing to keep the coordinated formation. 3.6.4 Complex Environment Simulation For the second task, we assume that the environments on the left side of the leader is not uniform and changes at some point in x‚àíy frame, see Figure 3.14(a). Like the previous case, the followers learn their path toward desired position according to Equation (3.12). Figure 3.14(b) shows that at some point the left follower enters a new environment which leads to changes in dissimilarity measure, see Figure 3.14(c). Therefore, after some time the left AUV successfully relearn the desired path. Figure 3.14(d) conÔ¨Årms the results. 3.7 Conclusion This Chapter demonstrated the performance of the unsupervised learning of GMM algorithm pro- posed in the previous chapter, qualitatively and quantitatively in CTD adaptive sampling for a feet of Autonomous Underwater Vehicles (AUVs). The practical implementation requires a careful tuning of the gain parameters. The manoeuvrability of the vehicles, e.g. how fast the vehicles can place themselves in the desired position or the greatness of the displacement based on the dissimi- larity measure can be decisive in the performance of the model. For example with very slow linear velocity the followers would resurface before reaching the desired position which was learned dur- ing the last resurfacing and this could jeopardise the overall performance of the model, especially convergence to the desired position in reasonable time. The simulation results show the feasibility and accuracy of the motion learning strategies in many uniform and complex environments. 64 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Chapter 4 Conclusions and FutureWork 4.1 Conclusions This thesis addressed the problem of motion learning and adaptive sampling for a Ô¨Çeet",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_86"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " and complex environments. 64 Real-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles Chapter 4 Conclusions and FutureWork 4.1 Conclusions This thesis addressed the problem of motion learning and adaptive sampling for a Ô¨Çeet of au- tonomous underwater vehicles. An overview of sensor systems and navigation techniques is given as well as a brief description of the main motion control system formed with a path following controller, a path generator and coordination control. A novel unsupervised learning of Gaussian mixture models in the presence of dynamic environments is presented. The algorithm relies on a multi-hypothesis adaptive scheme that continuously updates the number of components and esti- mates the model parameters as the measurements (sample data) are being acquired. The hypothesis models are ranked according to the minimum description length. The virtue of this approach is the fact that it addresses explicitly the case that the complexity of the GMM is not only unknown, but it also can change over time. The proposed algorithm has the additional feature that it relaxes ‚Äúthe sufÔ¨Åciently large data set‚Äù restriction by not requiring in fact any initial batch of data. The simulations that are presented here led to a variety of conclusions and assumptions. A spar- ingly important assumption is that cooperative unsupervised motion learning for the followers is reasonable, only if the navigation of an individual vehicle is reliable. The performance of the proposed method is demonstrated qualitatively and quantitatively in CTD adaptive sampling for a Ô¨Çeet of Autonomous Underwater Vehicles (AUVs). The practical implementation requires a careful tuning of the gain parameters that has been suc- cessfully done as demonstrated with experimental data. It opens up the possibility of oceano- graphic missions conducted by a team of vehicles. In the simulations a Gaussian noise is con- sidered for the pressure sensor. The communication constraints underwater are extreme, i.e., the followers only on the surface can ‚Äútalk\" to the leader and learn its position and GMM hypothesis. The manoeuvrability of the vehicles, e.g. how fast the vehicles can place themselves in the desired position or the greatness of the displacement based on the dissimilarity measure can be decisive in the performance of the model. For example, if the followers do not move fast enough in the horizontal plane (linear velocity be too low), the vehicles can resurface before reaching to the desired position that was learned during the last resurfacing and this could jeopardise",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_87"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " the model. For example, if the followers do not move fast enough in the horizontal plane (linear velocity be too low), the vehicles can resurface before reaching to the desired position that was learned during the last resurfacing and this could jeopardise the overall 65 66 Conclusions and FutureWork performance of the model and the convergence to the desired position in reasonable time. A further important property of the proposed unsupervised motion learning strategy is that, the leader can distribute its individual errors to the whole formation. Because the position of the fol- lowers is a function of the position of the leader and its sampling proÔ¨Åle in terms of Gaussian mixture models. As a results, high navigation errors and sampling noises can disturb and aggra- vate the coordinated formation dramatically. This suggests that a higher number of vehicles, more than one leader, can improve the quality of the estimations. The simulations have shown that all strategies are very sensitive towards the values of parameters. 4.2 Future Work This thesis showed the strengths and the weaknesses of a novel real-time unsupervised motion learning of AUVs strategy based on Gaussian mixture models. The coordinated formation strat- egy was evaluated through computer simulations but using real CTD data. In order to implement the proposed algorithms in real systems, further steps are necessary. DeÔ¨Åning a more complex scenario, where the number of leader is more than one or the follower AUVs can communicate and exchange GMM hypotheses can help to improve the overall per- formance of the model. This would make the overall system more robust and less vulnerable to navigation and sampling error could be the direct result of that. The most important next step is the validation of this strategy with real data and experiments with real AUVs in a test laboratory and later in an ocean environment. These steps are necessary to study the behaviour of the algorithms under non Gaussian noise and the effect of outliers. References [1] Monterey bay aquarium research institute. http://www.mbari.org/default.htm. [2] Woods hole oceanographic institution. http://www.whoi.edu/. [3] John r. delaney. http://ooi.washington.edu/rsn/jrd/index.html. [4] Interactive oceans. http://www.interactiveoceans.washington.edu/. [5] Douglas A Stow, Allen Hope, David McGuire, David Verbyla, John Gamon, Fred Huemm- rich, Stan Houston, Charles Racine",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_88"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " Interactive oceans. http://www.interactiveoceans.washington.edu/. [5] Douglas A Stow, Allen Hope, David McGuire, David Verbyla, John Gamon, Fred Huemm- rich, Stan Houston, Charles Racine, Matthew Sturm, Kenneth Tape, et al. Remote sensing of vegetation and land-cover change in arctic tundra ecosystems. Remote Sensing of Envi- ronment, 89(3):281‚Äì308, 2004. [6] NN Soreide, CE Woody, and SM Holt. Overview of ocean based buoys and drifters: Present applications and future needs. In OCEANS, 2001. MTS/IEEE Conference and Exhibition, volume 4, pages 2470‚Äì2472. IEEE, 2001. [7] Ocean explorer. http://oceanexplorer.noaa.gov/welcome.html. [8] Steven S Brown, Harald Stark, Steven J Ciciora, and AR Ravishankara. In-situ measure- ment of atmospheric no3 and n2o5 via cavity ring-down spectroscopy. Geophysical re- search letters, 28(17):3227‚Äì3230, 2001. [9] Nuno Cruz, An√≠bal Matos, S√©rgio Cunha, S√©rgio Silva, and RDR Frias. Zarco-an au- tonomous craft for underwater surveys. Proceedings of the 7th Geomatic Week, Barcelona, Spain, 2007. [10] Charles C Eriksen, T James Osse, Russell D Light, Timothy Wen, Thomas W Lehman, Pe- ter L Sabin, John W Ballard, and Andrew M Chiodi. Seaglider: A long-range autonomous underwater vehicle for oceanographic research. Oceanic Engineering, IEEE Journal of, 26(4):424‚Äì436, 2001. [11] Daniel L Rudnick, Russ E Davis, Charles C Eriksen, David M Fratantoni, and Mary Jane Perry. Underwater gliders for ocean research. Marine Technology Society Journal, 38(2):73‚Äì84, 2004. [12] Joseph Curcio, John Leonard, and Andrew Patrikalakis. Scout-a low cost autonomous surface platform for research in cooperative autonomy. In OCEANS, 2005. Proceedings of MTS/IEEE, pages 725‚Äì",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_89"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ". [12] Joseph Curcio, John Leonard, and Andrew Patrikalakis. Scout-a low cost autonomous surface platform for research in cooperative autonomy. In OCEANS, 2005. Proceedings of MTS/IEEE, pages 725‚Äì729. IEEE, 2005. [13] Justin E Manley. Unmanned surface vehicles, 15 years of development. In OCEANS 2008, pages 1‚Äì4. IEEE, 2008. 67 68 REFERENCES [14] Gwyn GrifÔ¨Åths and Ia Edwards. Auvs: designing and operating next generation vehicles. Elsevier Oceanography Series, 69:229‚Äì236, 2003. [15] Elgar Desa, R Madhan, and P Maurya. Potential of autonomous underwater vehicles as new generation ocean data platforms. Current science, 90(9):1202‚Äì1209, 2006. [16] Charles W Warren. A technique for autonomous underwater vehicle route planning. Oceanic Engineering, IEEE Journal of, 15(3):199‚Äì204, 1990. [17] Laborat√≥rio de Sistemas e Tecnologia Subaqu√°tica. Light autonomous underwater vehicles. http://lsts.fe.up.pt/. [18] Thomas B Curtin, James G Bellingham, Josko Catipovic, and Doug Webb. Autonomous oceanographic sampling networks. Oceanography, 6(3):86‚Äì94, 1993. [19] Mario A. T. Figueiredo and Anil K. Jain. Unsupervised learning of Ô¨Ånite mixture models. volume 24, pages 381‚Äì396, 2000. [20] John R Hershey and Peder A Olsen. Approximating the kullback-leibler divergence be- tween gaussian mixture models. In ICASSP (4), pages 317‚Äì320, 2007. [21] Andrea Baraldi and Ethem Alpaydin. Constructive feedforward art clustering networks. i. Neural Networks, IEEE Transactions on, 13(3):645‚Äì661, 2002. [22] Vladimir Cherkassky and Filip M Mulier. Learning from data: concepts, theory, and meth- ods. John Wiley & Sons, 2007. [23] Christopher M. Bishop. Pattern recognition and machine learn- ing. Springer, 2006. URL:",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_90"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " Mulier. Learning from data: concepts, theory, and meth- ods. John Wiley & Sons, 2007. [23] Christopher M. Bishop. Pattern recognition and machine learn- ing. Springer, 2006. URL: /bib/bishop/Bishop2006/ PatternRecognitionAndMachineLearningBishop-.pdf. [24] Bernd Fritzke. Some competitive learning methods. ArtiÔ¨Åcial Intelligence Institute, Dres- den University of Technology, 1997. [25] Ralph Gross, Jie Yang, and Alex Waibel. Growing gaussian mixture models for pose in- variant face recognition. In Pattern Recognition, 2000. Proceedings. 15th International Conference on, volume 1, pages 1088‚Äì1091. IEEE, 2000. [26] Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incom- plete data via the em algorithm. Journal of the royal statistical society. Series B (method- ological), pages 1‚Äì38, 1977. [27] Rui Xu, Donald Wunsch, et al. Survey of clustering algorithms. Neural Networks, IEEE Transactions on, 16(3):645‚Äì678, 2005. [28] Nicola Greggio, Alexandre Bernardino, and Jos√© Santos-Victor. A practical method for self-adapting gaussian expectation maximization. In ICINCO (1), pages 36‚Äì44, 2010. [29] Nizar Bouguila, Djemel Ziou, and Jean Vaillancourt. Unsupervised learning of a Ô¨Ånite mixture model based on the dirichlet distribution and its application. Image Processing, IEEE Transactions on, 13(11):1533‚Äì1543, 2004. [30] Zheng Rong Yang and Mark Zwolinski. Mutual information theory for adaptive mixture models. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 23(4):396‚Äì403, 2001. REFERENCES 69 [31] Nikos Vlassis and Aristidis Likas. A kurtosis-based dynamic approach to gaussian mixture modeling. Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on, 29(4):393‚Äì399, 1999. [32] Jakob J Verbeek, Nikos Vlassis, and B Kr√∂se. Ef",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_91"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "netics, Part A: Systems and Humans, IEEE Transactions on, 29(4):393‚Äì399, 1999. [32] Jakob J Verbeek, Nikos Vlassis, and B Kr√∂se. EfÔ¨Åcient greedy learning of gaussian mixture models. Neural computation, 15(2):469‚Äì485, 2003. [33] Naonori Ueda, Ryohei Nakano, Zoubin Ghahramani, and Geoffrey E Hinton. Smem algo- rithm for mixture models. Neural computation, 12(9):2109‚Äì2128, 2000. [34] Zhihua Zhang, Chibiao Chen, Jian Sun, and Kap Luk Chan. Em algorithms for gaussian mixtures with split-and-merge operation. Pattern recognition, 36(9):1973‚Äì1983, 2003. [35] Sebastian Thrun, Christian Martin, Yufeng Liu, Dirk Hahnel, Rosemary Emery- Montemerlo, Deepayan Chakrabarti, and Wolfram Burgard. A real-time expectation- maximization algorithm for acquiring multiplanar maps of indoor environments with mo- bile robots. Robotics and Automation, IEEE Transactions on, 20(3):433‚Äì443, 2004. [36] Zoran Zivkovic and Ferdinand van der Heijden. Recursive unsupervised learning of Ô¨Å- nite mixture models. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 26(5):651‚Äì656, 2004. [37] P. Hall, D. Marshall, and R. Martin. Merging and splitting eigenspace models. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 22(9):1042‚Äì1049, Sep 2000. doi:10.1109/34.877525. [38] Mingzhou Song and Hongbin Wang. Highly efÔ¨Åcient incremental estimation of gaussian mixture models for online data stream clustering. In Defense and Security, pages 174‚Äì183. International Society for Optics and Photonics, 2005. [39] Yulia Alexandrovna Hicks, Peter M Hall, and Andrew David Marshall. A method to add hidden markov models with application to learning articulated motion. 2003. [40] Peter M Hall, Yulia Hicks, and Tony Robinson. A method to add gaussian mixture",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_92"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ", Peter M Hall, and Andrew David Marshall. A method to add hidden markov models with application to learning articulated motion. 2003. [40] Peter M Hall, Yulia Hicks, and Tony Robinson. A method to add gaussian mixture models. 2005. [41] Nuno Vasconcelos and Andrew Lippman. Learning mixture hierarchies. In NIPS, pages 606‚Äì612. Citeseer, 1998. [42] Ognjen Arandjelovic and Roberto Cipolla. Incremental learning of temporally-coherent gaussian mixture models. Society of Manufacturing Engineers (SME) Technical Papers, pages 1‚Äì1, 2006. [43] P M Hall and Y Hicks. A method to add gaussian mixture models. Other, April 2004. ID number: CSBU-2004-03. URL: http://opus.bath.ac.uk/16849/. [44] Michael R Anderberg. Cluster analysis for applications. Technical report, DTIC Document, 1973. [45] S Zhuang, Yan Huang, Kannappan Palaniappan, and Yunxin Zhao. Gaussian mixture den- sity modeling, decomposition, and applications. Image Processing, IEEE Transactions on, 5(9):1293‚Äì1302, 1996. 70 REFERENCES [46] Dawei Li, Lihong Xu, and Erik Goodman. On-line em variants for multivariate normal mixture model in background learning and moving foreground detection. Journal of math- ematical imaging and vision, 48(1):114‚Äì133, 2014. [47] D Michael Titterington. Recursive parameter estimation using incomplete data. Journal of the Royal Statistical Society. Series B (Methodological), pages 257‚Äì267, 1984. [48] Vaclav Fabian. On asymptotically efÔ¨Åcient recursive estimation. The Annals of Statistics, pages 854‚Äì866, 1978. [49] Lei Xu and Michael I Jordan. On convergence properties of the em algorithm for gaussian mixtures. Neural computation, 8(1):129‚Äì151, 1996. [50] Richard A Redner and Homer F Walker. Mixture densities, maximum likelihood and the em algorithm. SIAM review, 26(2):195‚Äì239, 1984. [51] Richard O Duda, Peter E",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_93"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " [50] Richard A Redner and Homer F Walker. Mixture densities, maximum likelihood and the em algorithm. SIAM review, 26(2):195‚Äì239, 1984. [51] Richard O Duda, Peter E Hart, and David G Stork. Pattern classiÔ¨Åcation. John Wiley & Sons, 2012. [52] Geoffrey McLachlan and David Peel. Finite mixture models. John Wiley & Sons, 2004. [53] Geoffrey McLachlan and Thriyambakam Krishnan. The EM algorithm and extensions, volume 382. John Wiley & Sons, 2007. [54] G.J. McLachlan and T. Krishnan. The EM Algorithm and Extensions. John Wiley & Sons, New York, 1997. [55] Chi-hau Chen, Louis-Fran√ßois Pau, and Patrick Shen-pei Wang. Handbook of pattern recog- nition and computer vision. World ScientiÔ¨Åc, 2010. [56] Glenn W Milligan and Martha C Cooper. An examination of procedures for determining the number of clusters in a data set. Psychometrika, 50(2):159‚Äì179, 1985. [57] B.S. Everitt, S. Landau, M. Leese, and D. Stahl. Cluster Analysis. Wiley series in prob- ability and statistics. Wiley, 2011. URL: http://books.google.pt/books?id= w3bE1kqd-48C. [58] Padhraic Smyth. Clustering using monte carlo cross-validation. In KDD, pages 126‚Äì133, 1996. [59] Hirotugu Akaike. Likelihood of a model and information criteria. Journal of econometrics, 16(1):3‚Äì14, 1981. [60] Michael P Windham and Adele Cutler. Information ratios for validating mixture analyses. Journal of the American Statistical Association, 87(420):1188‚Äì1192, 1992. [61] Dan Pelleg and Andrew W. Moore. X-means: Extending k-means with efÔ¨Åcient estimation of the number of clusters. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000), Stanford University, Stanford, CA, USA, June 29 - July 2,",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_94"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " k-means with efÔ¨Åcient estimation of the number of clusters. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000), Stanford University, Stanford, CA, USA, June 29 - July 2, 2000, pages 727‚Äì734, 2000. [62] Gideon Schwarz et al. Estimating the dimension of a model. The annals of statistics, 6(2):461‚Äì464, 1978. REFERENCES 71 [63] Chris Fraley and Adrian E Raftery. Bayesian regularization for normal mixture estimation and model-based clustering. Journal of ClassiÔ¨Åcation, 24(2):155‚Äì181, 2007. [64] Abdolrahman Khoshrou and Ant√≥nio Pedro Aguiar. Unsupervised learning of gaus- sian mixture models in the presence of dynamic environments. In CONTROLO‚Äô2014‚Äì Proceedings of the 11th Portuguese Conference on Automatic Control, pages 387‚Äì396. Springer International Publishing, 2015. [65] Mark Girolami. Mercer kernel-based clustering in feature space. Neural Networks, IEEE Transactions on, 13(3):780‚Äì784, 2002. [66] Ravi Kothari and Dax Pitts. On Ô¨Ånding the number of clusters. Pattern Recogni- tion Letters, 20(4):405 ‚Äì 416, 1999. URL: http://www.sciencedirect.com/ science/article/pii/S0167865599000082, doi:http://dx.doi.org/10. 1016/S0167-8655(99)00008-2. [67] Gail A Carpenter and Stephen Grossberg. A massively parallel architecture for a self- organizing neural pattern recognition machine. Computer vision, graphics, and image pro- cessing, 37(1):54‚Äì115, 1987. [68] Hichem Frigui and Raghu Krishnapuram. A robust competitive clustering algorithm with applications in computer vision. Pattern Analysis and Machine Intelligence, IEEE Trans- actions on, 21(5):450‚Äì465, 1999. [69] Nozha Boujemaa. Generalized competitive clustering for image segmentation. In Fuzzy Information Processing Society, 2000. NAFIPS. 19th International Conference of the North American, pages ",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_95"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ", 1999. [69] Nozha Boujemaa. Generalized competitive clustering for image segmentation. In Fuzzy Information Processing Society, 2000. NAFIPS. 19th International Conference of the North American, pages 133‚Äì137. IEEE, 2000. [70] Anil K Jain. Data clustering: 50 years beyond k-means. Pattern recognition letters, 31(8):651‚Äì666, 2010. [71] Radford M Neal and Geoffrey E Hinton. A view of the em algorithm that justiÔ¨Åes incremen- tal, sparse, and other variants. In Learning in graphical models, pages 355‚Äì368. Springer, 1998. [72] Masa-Aki Sato and Shin Ishii. On-line em algorithm for the normalized gaussian network. Neural computation, 12(2):407‚Äì432, 2000. [73] Rohan A Baxter and Jonathan J Oliver. Mdl and mml: Similarities and differences. Dept. Comput. Sci. Monash Univ., Clayton, Victoria, Australia, Tech. Rep, 207, 1994. [74] Peter Gr√ºnwald. Model selection based on minimum description length. Journal of Math- ematical Psychology, 44(1):133‚Äì152, 2000. [75] Jorma Rissanen. Stochastic complexity and modeling. The Annals of Statistics, pages 1080‚Äì1100, 1986. [76] Peter D Gr√ºnwald. The minimum description length principle. The MIT Press, 2007. [77] Aaron D Lanterman. Schwarz, wallace, and rissanen: Intertwining themes in theories of model selection. International statistical review, 69(2):185‚Äì212, 2001. [78] Chris S. Wallace and David L. Dowe. Minimum message length and kolmogorov complex- ity. The Computer Journal, 42(4):270‚Äì283, 1999. 72 REFERENCES [79] Chris S Wallace and PR Freeman. Estimation and inference by compact coding. Journal of the Royal Statistical Society. Series B (Methodological), pages 240‚Äì265, 1987. [80] Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons, 2012. [81] [82",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_96"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " Royal Statistical Society. Series B (Methodological), pages 240‚Äì265, 1987. [80] Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons, 2012. [81] [82] Jorma Rissanen. Stochastic complexity. Journal of the Royal Statistical Society. Series B (Methodological), pages 223‚Äì239, 1987. [83] Siddhartha Chib. Calculating posterior distributions and modal estimates in markov mixture models. Journal of Econometrics, 75(1):79‚Äì97, 1996. [84] Jonathan J Oliver, Rohan A Baxter, and Chris S Wallace. Unsupervised learning using- MML. In ICML, pages 364‚Äì372, 1996. [85] Jos√© M Bernardo and Adrian FM Smith. Bayesian theory, volume 405. John Wiley & Sons, 2009. [86] Sarunas J Raudys and Anil K. Jain. Small sample size effects in statistical pattern recog- nition: Recommendations for practitioners. IEEE Transactions on pattern analysis and machine intelligence, 13(3):252‚Äì264, 1991. [87] Samuel S Blackman. Multiple hypothesis tracking for multiple target tracking. Aerospace and Electronic Systems Magazine, IEEE, 19(1):5‚Äì18, 2004. [88] David J Salmond. Mixture reduction algorithms for target tracking in clutter. In OE/LASE‚Äô90, 14-19 Jan., Los Angeles, CA, pages 434‚Äì445. International Society for Optics and Photonics, 1990. [89] Yaakov Bar-Shalom, Peter K Willett, and Xin Tian. Tracking and data fusion. A Handbook of Algorithms. Yaakov Bar-Shalom, 2011. [90] David W Scott and William F Szewczyk. From kernels to mixtures. Technometrics, 43(3):323‚Äì335, 2001. [91] David F Crouse, Peter Willett, Krishna Pattipati, and Lennart Svensson. A look at gaus- sian mixture reduction algorithms. Proceedings of the 14th International Conference on Information Fusion, 2011. [92] G Valverde, J Quir√≥s Tort√≥s, and V Terzija. Comparison of gaussian mixture reductions for probabilistic studies in power systems",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_97"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": ". Proceedings of the 14th International Conference on Information Fusion, 2011. [92] G Valverde, J Quir√≥s Tort√≥s, and V Terzija. Comparison of gaussian mixture reductions for probabilistic studies in power systems. In Power and Energy Society General Meeting, 2012 IEEE, 2012. [93] Jason L Williams. Gaussian mixture reduction for tracking multiple maneuvering targets in clutter. Technical report, DTIC Document, 2003. [94] Jason L Williams and Peter S Maybeck. Cost-function-based gaussian mixture reduction for target tracking. In Proceedings of the Sixth International Conference of Information Fusion, volume 2, pages 1047‚Äì1054, 2003. [95] Andrew R Runnalls. Kullback-leibler approach to gaussian mixture reduction. Aerospace and Electronic Systems, IEEE Transactions on, 43(3):989‚Äì999, 2007. REFERENCES 73 [96] Iris data set. http://archive.ics.uci.edu/ml/datasets/Iris. [97] A Aguiar, J Almeida, M Bayat, B Cardeira, R Cunha, A Hauslery, P Maurya, A Oliveira, A Pascoal, A Pereira, et al. Cooperative autonomous marine vehicle motion control in the scope of the eu grex project: theory and practice. In OCEANS 2009-EUROPE, pages 1‚Äì10. IEEE, 2009. [98] Jos√© Pinto, Paulo Sousa Dias, Jo√£o Borges Sousa, and Fernando L Pereira. Large scale data collection using networks of heterogeneous vehicles and sensors. In OCEANS 2009- EUROPE, pages 1‚Äì6. IEEE, 2009. [99] Naomi Ehrich Leonard and Edward Fiorelli. Virtual leaders, artiÔ¨Åcial potentials and coor- dinated control of groups. In Decision and Control, 2001. Proceedings of the 40th IEEE Conference on, volume 3, pages 2968‚Äì2973. IEEE, 2001. [100] Edward Fiorelli, Naomi Ehrich Leonard, Pradeep Bhatta, Derek A Paley, Ralf Bachmayer, and David M Fratantoni. Multi-auv control and adaptive sampling in monterey bay. Oceanic Engineering, IEEE Journal of,",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_98"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": "ich Leonard, Pradeep Bhatta, Derek A Paley, Ralf Bachmayer, and David M Fratantoni. Multi-auv control and adaptive sampling in monterey bay. Oceanic Engineering, IEEE Journal of, 31(4):935‚Äì948, 2006. [101] Petter Ogren, Edward Fiorelli, and Naomi Ehrich Leonard. Cooperative control of mo- bile sensor networks: Adaptive gradient climbing in a distributed environment. Automatic Control, IEEE Transactions on, 49(8):1292‚Äì1302, 2004. [102] A. Alvarez, A. Caffaz, (...) Caiti, A., A. Turetta, and R. Viviani. F√≤laga: A low-cost au- tonomous underwater vehicle combining glider and auv capabilities. Ocean Engineering, 36:24‚Äì38, 2009. [103] Namik Kemal Yilmaz, Constantinos Evangelinos, Pierre FJ Lermusiaux, and Nicholas M Patrikalakis. Path planning of autonomous underwater vehicles for adaptive sampling using mixed integer linear programming. Oceanic Engineering, IEEE Journal of, 33(4):522‚Äì537, 2008. [104] Kevin P Carroll, Stephen R McClaran, Eric L Nelson, David M Barnett, Donald K Friesen, and GN William. Auv path planning: an a* approach to path planning with considera- tion of variable vehicle speeds and multiple, overlapping, time-dependent exclusion zones. In Autonomous Underwater Vehicle Technology, 1992. AUV‚Äô92., Proceedings of the 1992 Symposium on, pages 79‚Äì84. IEEE, 1992. [105] R Smith, Arvind Pereira, Yi Chao, Peggy P Li, D Caron, B Jones, and G Sukhatme. Au- tonomous underwater vehicle trajectory design coupled with predictive ocean models: A case study. In Robotics and Automation (ICRA), 2010 IEEE International Conference on, pages 4770‚Äì4777. IEEE, 2010. [106] Donald P Eickstedt, Michael R Benjamin, and J Curcio. Behavior based adaptive control for autonomous oceanographic sampling. In Robotics and Automation, 2007 IEEE Inter- national Conference on, pages 4245‚Äì4250. IEEE, 2007. [107] Petr",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_99"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " Benjamin, and J Curcio. Behavior based adaptive control for autonomous oceanographic sampling. In Robotics and Automation, 2007 IEEE Inter- national Conference on, pages 4245‚Äì4250. IEEE, 2007. [107] Petr Svec, Brual C Shah, Ivan R Bertaska, Jose Alvarez, Armando J Sinisterra, Karl Von El- lenrieder, Manhar Dhanak, and Satyandra K Gupta. Dynamics-aware target following for an autonomous surface vehicle operating under colregs in civilian trafÔ¨Åc. In Intelligent Robots and Systems (IROS), 2013 IEEE/RSJ International Conference on, pages 3871‚Äì3878. IEEE, 2013. 74 REFERENCES [108] Craig A Woolsey. Review of marine control systems: Guidance, navigation, and con- trol of ships, rigs and underwater vehicles. Journal of Guidance, Control, and Dynamics, 28(3):574‚Äì575, 2005. [109] Alexander Bahr, John J Leonard, and Maurice F Fallon. Cooperative localization for au- tonomous underwater vehicles. The International Journal of Robotics Research, 28(6):714‚Äì 728, 2009. [110] James C Kinsey, Ryan M Eustice, and Louis L Whitcomb. A survey of underwater vehicle navigation: Recent advances and new challenges. In IFAC Conference of Manoeuvering and Control of Marine Craft, 2006. [111] Luke Stutters, Honghai Liu, Carl Tiltman, and David J Brown. Navigation technologies for autonomous underwater vehicles. Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on, 38(4):581‚Äì589, 2008. [112] Zuheir Altamimi, Patrick Sillard, and Claude Boucher. Itrf2000: A new release of the inter- national terrestrial reference frame for earth science applications. Journal of Geophysical Research: Solid Earth (1978‚Äì2012), 107(B10):ETG‚Äì2, 2002. [113] Neil Harvey Kussat, C David Chadwell, and Richard Zimmerman. Absolute positioning of an autonomous underwater vehicle using gps and acoustic measurements. Oceanic Engi- neering, IEEE Journal of, 30(1):153‚Äì164, 2005. [114] HR Everett. Sensors for",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_100"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " and Richard Zimmerman. Absolute positioning of an autonomous underwater vehicle using gps and acoustic measurements. Oceanic Engi- neering, IEEE Journal of, 30(1):153‚Äì164, 2005. [114] HR Everett. Sensors for mobile robots: theory and application. AK Peters, Ltd., 1995. [115] Oliver J Woodman. An introduction to inertial navigation. University of Cambridge, Com- puter Laboratory, Tech. Rep. UCAMCL-TR-696, 14:15, 2007. [116] Stephen D McPhail and Miles Pebody. Navigation and control of an autonomous under- water vehicle using a distributed, networked, control architecture. Underwater Technology, 23(1):19‚Äì30, 1998. [117] Nuno Ricardo Gracias, Sjoerd Van Der Zwaan, Alexandre Bernardino, and Jos√© Santos- Victor. Mosaic-based navigation for autonomous underwater vehicles. Oceanic Engineer- ing, IEEE Journal of, 28(4):609‚Äì624, 2003. [118] Nuno Gracias and Jos√© Santos-Victor. Underwater video mosaics as visual navigation maps. Computer Vision and Image Understanding, 79(1):66‚Äì91, 2000. [119] A.D. Waite. Sonar for practising engineers. Wiley, 2002. URL: http://books. google.pt/books?id=GXgZAQAAIAAJ. [120] Lee Freitag, Matthew Grund, Sandipa Singh, James Partan, Peter Koski, and Keenan Ball. The whoi micro-modem: an acoustic communications and navigation system for multiple platforms. In OCEANS, 2005. Proceedings of MTS/IEEE, pages 1086‚Äì1092. IEEE, 2005. [121] Ryan M Eustice, Louis L Whitcomb, Hanumant Singh, and Matthew Grund. Experimental results in synchronous-clock one-way-travel-time acoustic navigation for autonomous un- derwater vehicles. In Robotics and Automation, 2007 IEEE International Conference on, pages 4257‚Äì4264. IEEE, 2007. REFERENCES 75 [122] A Pedro Aguiar and Joao P Hespanha. Trajectory-tracking and path-following of under- actuated autonomous vehicles with parametric modeling uncertainty. Automatic Control, IEEE Transactions on, 52(",
    "token_count": 500,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_101"
  },
  {
    "id": "305dc82b-e89f-4986-bea3-65268d987970",
    "created_at": "2025-07-26T15:28:57.523015+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/143403205.pdf",
    "title": "143403205",
    "text": " REFERENCES 75 [122] A Pedro Aguiar and Joao P Hespanha. Trajectory-tracking and path-following of under- actuated autonomous vehicles with parametric modeling uncertainty. Automatic Control, IEEE Transactions on, 52(8):1362‚Äì1379, 2007. [123] X Yun, ER Bachmann, RB McGhee, RH Whalen, RL Roberts, RG Knapp, AJ Healey, and MJ Zyda. Testing and evaluation of an integrated gps/ins system for small auv navigation. Oceanic Engineering, IEEE Journal of, 24(3):396‚Äì404, 1999. [124] PK Maurya, AP Agular, and Ant√≥nio M Pascoal. Marine vehicle path following using inner-outer loop control. 8th IFAC International Conference on Manoeuvring and Control of Marine Craft 2009, September 16-18, 2009, Guaruja-Brazil. 6 pp., 2009.",
    "token_count": 209,
    "chunk_id": "305dc82b-e89f-4986-bea3-65268d987970_102"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": "1 The influence of the switch from fossil fuels to solar and wind energy on the electricity prices in Germany Andr√© Dorsman1), Abdolrahman Khoshrou2) and Eric J. Pauwels2) Paper to be presented at the Isini conference in Groningen, August 24-27 2016 1) VU University Amsterdam 2) CWI Amsterdam corresponding author Andr√© Dorsman a.b.dorsman@vu.nl 2 The influence of the switch from fossil fuels to solar and wind energy on the electricity prices in Germany1 Andr√© Dorsman, Abdolrahman Khoshrou and Eric J. Pauwels Abstract Germany is actively pursuing a switch from fossil fuel to renewables, the so-called Energiewende (energy transition). Due to the fact that the supply of wind and solar energy is less predictable than the supply of fossil fuel, stabilizing the grid has become more challenging. On sunny and windy days the supply in Germany substantially exceeds demand, and the surplus needs to be exported to the neighboring countries. In this study we analyze data from the German day-ahead market in the period 2009 through 2015 and show that the realized day-ahead price experiences significant downward pressure from high predictions for the day-ahead solar and wind supply. This conclusion is based on a regression analysis using the singular value decomposition (SVD) method. SVD decomposes the time series as a sum of data-determined profiles. During the observed period the market share of solar and wind energy in the total energy supply increased in Germany. The larger the market share, the more impact solar and wind energy have. Key words: solar energy; wind energy; electricity price, day-ahead market 1. Introduction In Abudaldah, Dorsman, Franx and Pottuijt (2014), hereafter ADFP (2014), we looked at the influence of wind and solar energy on the electricity prices in Germany. In that article we found for the period January 1 2011 through December 31 2012 strong evidence that solar energy and wind energy have a negative impact on the electricity price in Germany. Before the energy switch we saw that prices during peak periods (8.00 - 20.00 hours) are higher than during off-peak periods (20.00 - 8.00 hours). However, a substantial supply of solar and wind energy can push the peak price below the off-peak price.",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_1"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": ".00 - 20.00 hours) are higher than during off-peak periods (20.00 - 8.00 hours). However, a substantial supply of solar and wind energy can push the peak price below the off-peak price. In recent times we have 1 The authors thank Matthijs Nijpels of APX (Amsterdam Power Exchange) and Mr. Khou (Powernext) for their support in collecting the data for this research and Paul Pottuijt of TenneT for our discussions that has improved the paper substantially. Of course, the authors are solely responsible for any final opinions, conclusions and remaining errors in the paper. 3 occasionally seen negative energy prices in Germany caused by the exceptional high supply of solar and wind energy. The switch from fossil fuels to renewables in Germany has continued unabatedly since the period reported upon in ADFP (2014) and at the time of writing this (May 13 2016) 33% of the energy supply in Germany is sustainable. The German minister of Finance has indicated that this percentage will increase to 45% in 2025. Therefore it is interesting to see whether a growing penetration of renewables in the total energy supply has an increasing impact on the electricity price, not only in Germany but also in neighboring countries. A main disadvantage of solar and wind energy is volatility in supply, caused by the difficulties of storing the occasional surplus of electricity. However, the last years have witnessed a considerable evolution in storage technologies (see for example Papaefthymiou et al. (2014)).2 Nevertheless, the cost of storing electricity supplied by solar and wind energy is not negligible and can cause additional volatility in electricity prices. In this paper we will look at the influence of the predicted supply of renewables on the realized day-ahead electricity prices on the German day-ahead market. This research has clear practical implications. Indeed, if an abundance of German renewables impact the price and volatility of the electricity in Germany substantially, it effects the position of fossil fuel suppliers. In addition, the price volatility will increase, causing additional market risks for suppliers and consumers on the German electricity market. It is also conceivable that it would negatively impact the reliability of the electricity grid. Due to the integration of the European grids the problems will not be limited to the German grid. Increasing instability on the German grid means also a higher instability on the neighboring grids. The research question in this study is: Is there a correlation",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_2"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " electricity grid. Due to the integration of the European grids the problems will not be limited to the German grid. Increasing instability on the German grid means also a higher instability on the neighboring grids. The research question in this study is: Is there a correlation between the day-ahead predictions for solar and wind energy supply on the one hand, and the day-ahead electricity price in Germany on the other? In section 2 we will give an overview of the literature, followed by section 3 that focuses on the data description and analysis for Germany. Electricity is a commodity and not a virtual product likes stocks or bonds. We start this section with a descriptive analysis of the time series for the electricity price, and the supply of both solar and wind energy. Next we use a regression analysis to quantify the impact of the predicted supply of renewables on the predicted day-ahead price. Section 4 concludes and outlines possibilities for further research. 2 The US company UniEnergy Technologies (UET) and the Chinese company Rongke Power will jointly develop the largest battery up to now (June 2016). The maximum storage capacity of this battery is 800 MWH. The battery has to absorb the volatility in the supply of wind energy (http://www.duurzaambedrijfsleven.nl/industrie/15265/grootste-batterij-ter-wereld-wordt-game-changer- voor-energiesysteem). 4 2. Literature The power market faces substantial changes. Large power companies like E.ON and RWE are planning to break up in two independent companies, namely in a company that produces electricity with renewables and in a company that produces electricity with fossil fuel. The German government is hesitating to give permission for such a split up because the second company may face high losses caused by large depreciations on fossil fuel plants. The move from fossil fuel to renewables can also mean a switch from centralized to decentralized power generation. The next step is that decentralized produced electricity can also be consumed decentralized. The access to a grid is no longer a necessity. Instead of one (national) grid, a set of decentralized markets will develop. It will be the role of traders to avoid (large) price differences between the decentralized markets. In other words the role of the transmission system operator (TSO) will change or even disappear. The switch from central to decentralized markets is also important for areas where national grids are facing problems with the security of delivery. In Europe we have",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_3"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " markets. In other words the role of the transmission system operator (TSO) will change or even disappear. The switch from central to decentralized markets is also important for areas where national grids are facing problems with the security of delivery. In Europe we have mostly a central grid with several sidelines. When there is a problem on the grid it is mostly possible to deliver electricity to the demanders by using alternative lines. However, this is not always the case. For example, Italy has the mountain chain the Apennines. The grid exists of two main lines at both sides of the mountain chain. In the Netherlands, we have the same problems in the province of Zeeland, with its islands and peninsulas. Decentralized markets can in that case be an advantage. After the liberalizations of the electricity markets at the end of the last century, we saw a tendency towards integration of various markets. Interconnectors linked the markets and as long as the capacity of the interconnectors was not fully used, the deviations of the prices between the linked markets was very limited. The general idea was that bringing all the demand and all the supply together on one market, the best price was guaranteed. The volatility of the electricity prices should be reduced and the price differences between the markets should be reduced. See for example Dorsman, Franx and Pottuijt (2012). Integrated markets created the possibility to transform additional supply from one market to another. In case every country tries to keep its own grid in balance this system works well. However, the energy switch (Energiewende) in Germany makes the German grid less stable due to the unpredictable supply of solar and wind energy. The German Transmission system operator (TSO) cannot always handle this unexpected additional supply which not only causes negative prices from time to time, but also the necessity to export the additional supply to the neighboring grids. In other words, the integrated markets gives Germany the possibility to export its grid problems for free. Gullberg et al. (2014) conclude that German actors see Norwegian electricity as a means for enhancing the stability of their electricity system. In other words, a cooperation with Norway can compensate the higher volatility in electricity supply due to the higher percent of wind 5 and solar energy. However, Gullberg et al. also conclude that Norwegian state-owned electricity producers and grid operators are interested in cooperation largely out of profit motives and expect that Germany creates a favorable environment for investors. In the discussions",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_4"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " of wind 5 and solar energy. However, Gullberg et al. also conclude that Norwegian state-owned electricity producers and grid operators are interested in cooperation largely out of profit motives and expect that Germany creates a favorable environment for investors. In the discussions about a new connector between the grids of Norway and Germany (more than 600 km underwater cable, price more than ‚Ç¨ 2 billion), the Norwegian state-owned partner has some doubts about the profitability of this project due to the (increasing) supply of wind and solar energy in Germany (Financieele Dagblad, March 28 2014). Swift-Hook (2010) argues that grid-connected intermittent renewables like wind energy will never be stored unless nothing else is available and that storage is counterproductive for fuel saving. Due to the fact that the marginal costs of wind (and solar) energy are (nearly) zero, wind (and solar) energy will be used first, if it is available. Only in the case wind (and solar) energy is 100% of the total supply, you will store it. In other words, a shift in energy supply to renewables like wind energy are increasing the instability of the energy system on the grid. A switch in supply to more wind and solar energy means that you are driving out other alternatives with higher marginal costs and therefore are reducing the storage capacity of the system. However, Grant Wilson et al. (2011) show that for the United Kingdom there is evidence that grid-connected intermittent renewables have been, and will continue to be stored. If so, the shift to renewables is less destabilizing than was previously assumed. In his reply Swift-Hook (2013) argues that Grant Wilson et al. made some erroneous denials. Storing on a power system will normally takes place during night time when the electricity price will be low. Solar energy therefore is not compatible with storing. Supply of wind energy can take place during day- or nighttime. However, in all cases it is better to use the wind energy for direct consumption because - as we already mentioned - the marginal costs are very low. We disagree with Swift-Hook. It is not only the price, but also the risk that counts. The certainty of supply is an essential element to get the grid in balance. Storing electricity generated by solar and wind energy can reduce the volatility of the supply of renewables energy and is therefore valuable. The last years several initiatives have been started to store the electricity generated by",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_5"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " supply is an essential element to get the grid in balance. Storing electricity generated by solar and wind energy can reduce the volatility of the supply of renewables energy and is therefore valuable. The last years several initiatives have been started to store the electricity generated by solar and wind energy. For example the energy company Wemag AG opened in 2014 in Germany a storage facility for solar and wind energy using batteries with a capacity of 5 MWh. Wemag claims that due to this installation the stability on the grid has been approved. Jensen and Skytte (2002) were among the first who argued that due to the low marginal costs of renewable energy a shift from traditional energy sources (gas, oil, coal, nuclear energy) with higher marginal costs to renewable energy will cause lower electricity prices. Gelabert et al. (2011) show that for the observed period 2005-2009 an increase of 1 GWh of electricity production using renewables and cogeneration gives a reduction of almost ‚Ç¨ 2 per MWh in the electricity price. Due to the difference in marginal costs we will see higher 6 renewable energy supply will cause the turn off of energy sources with higher marginal costs. As we earlier argued, this development leads to a higher instability of the electricity system on the grid. Barnham et al. (2013) conclude that in Germany and Italy the exponential growth in solar energy leads to substantial lower peak electricity prices in both countries. They show that the demand on the German grid can be met by solar and wind energy with back-up from biogas and (pumped hydro) storage. However, the last years we see in Germany an enormous growth in the supply of wind and solar energy and it is questionable whether the backup from biogas and (pumped hydro) storage can follow this speed growth. Nevertheless the backup cannot eliminate a high supply in solar and wind energy when the weather conditions are sunny and windy, causing negative electricity prices. We have doubts about the backup capacity from biogas and hydro power. Real time balancing with biomass plants is very difficult. The flexibility with hydro power is much higher.3 However, in Europe the capacity is relative low and due to the limited capacity of the connectors the possibility to transfer the (additional) supply of hydro power is not large enough to play a substantial role as back up for wind and solar energy. 4 The main benefit of gas plants is that they can be located at the best places for",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_6"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " connectors the possibility to transfer the (additional) supply of hydro power is not large enough to play a substantial role as back up for wind and solar energy. 4 The main benefit of gas plants is that they can be located at the best places for keeping the grids in balance. In that respect is the development: Power to Gas very interesting, because gas has the benefit of storing, easy transfer possibilities and therefore can be very helpful as backup for wind and solar energy. 5 Winkler et al (2016) write that rising renewable shares influence electricity markets in several ways: among others prices are reduced and price volatilities increases. Wozabal et al. (2014) argue that there is not always a direct relationship between renewable shares and price volatility, for example when the renewables share is low and photovoltaics produce mainly during the midday demand peak.6 During our observed period we see an increasing in the market share of renewables and we will test whether for the German market the influence of solar and wind energy on the electricity price increases. However, the earlier described development to one central market with one universal price has been changed by the increasing supply of wind and solar energy. More and more households have solar panels (and wind mills). An excess of their supply can be delivered to the grid. Alanne and Saari (2006) wrote that more and more we will see that local generated supply will be locally used. The role of central grids is weakening and decentralized markets are developing. 3 see http://www.sciencedirect.com/science/article/pii/S0960148104000928 4 See http://www.iea.org/publications/freepublications/publication/impact_of_wind_power.pdf 5 http://en.wikipedia.org/wiki/Power_to_gas) 6 Referral from Winkler et al (2016). 7 In this paper we will look at the influence of day-ahead predicted solar and wind energy on the realized day-ahead electricity price in Germany. In case we find that the supply of German solar and wind energy is a crucial factor in the price forming process. Extending this research to other countries is desirable to quantify the effects of the German energy switch on the stability of the grids in the neighboring countries. 3. The influence of predicted supply of renewables on the realized price in the German day-ahead market 3.1 Data In our research we use the realized German day-ahead prices and the expected day-ahead supply",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_7"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " of the grids in the neighboring countries. 3. The influence of predicted supply of renewables on the realized price in the German day-ahead market 3.1 Data In our research we use the realized German day-ahead prices and the expected day-ahead supply of wind and solar energy. The period of observation started on January 1, 2009 and ended on December 12, 2015. On the day-ahead power exchange, spot prices are fixed for every hour of the next day. The data of the wind and solar energy are the expected data for the next day. For every quarter of an hour the next day the database contains an estimation for the expected solar and wind energy supply (in total: 96 estimations for each day.) This means that for every day we have 24 hourly day-ahead prices for the electricity prices and 96 day ahead solar and wind supplies. To make the data comparable we calculated for every hour the unweighted average of solar and wind supplies of the relevant quarters. Our database contains 60,684 observations (2536 days x 24 hours). On the day-ahead power exchange, the prices for day t+1 are fixed at 11.00 hours on day t. By doing so, the TSO (Transmission System Operator) - who is responsible for balancing demand and supply on the grid - is able to manage the positions on the grid the following day. To facilitate the price formation process, detailed predictions for solar and wind energy production for day t+1 are released on day t. These predictions for day t+1 are collected in the morning of day t and released at 16.00 hours in the afternoon at day t. Strictly speaking this information is not available at the moment the day ahead prices for day t+1 are settled. Nevertheless we will assume that \"the market\" has access to this information about solar and wind energy for day t+1. 3.2. Descriptive statistics: daily and weekly patterns for predicted day-ahead price As explained above, in this paper we are interested in three different data time series for the day-ahead market: the electricity price, supply of solar and supply of wind energy. In this section we decompose the time series of electricity prices to get a better understanding of the price-forming process. This information will be used in the subsequent regression analysis (section 3.3) where we explore how day-ahead electricity prices correlate with the day-ahead predicted supply of renewables (wind",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_8"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " electricity prices to get a better understanding of the price-forming process. This information will be used in the subsequent regression analysis (section 3.3) where we explore how day-ahead electricity prices correlate with the day-ahead predicted supply of renewables (wind and solar). Not surprisingly, all three time series show clear daily and seasonal periods. 8 Fig. 1 gives the predicted day-ahead price for every day at the week, starting with the first timeslot on Sunday (0:00-1:00 hrs) and ending with the last timeslot (23:00-24:00 hrs) of the next Saturday 24.00 hours. During the weekend the price is lower than during the working days and during the day the price will be higher during day-time than during night-time. On Sunday we see a peak in the beginning of the evening which is different from the other days of the week. Leaving the seasonal cycle aside for the time being, we can get a better idea of the daily and weekly profile by averaging the data out over the periods of interest. In fact, we will opt for a slightly more versatile analysis which decomposes the time series as a sum of data- determined profiles. Apart from its intrinsic interest, this decomposition will also be re-used in the regression analysis later on (see section 3.3). Fig. 1: Detail from the predicted day-ahead price showing 168 values (corresponding to one week of hourly values). The daily peaks during the work week are clearly visible. The technical insight that allows us to explore this possibility is based on a mathematical technique called singular value decomposition (SVD for short). The idea is straightforward and can easily be explained using a concrete example. Since this analysis will be used throughout the rest of the paper we will spend some time expounding the underlying principles in the next paragraphs. Suppose we have a time series covering hourly observations (24/day) during a year (365 days). We can now re-write this time series as a matrix by taking the first 24 observations and using them as the first row of the matrix, the next 24 observations go into the second row and so on, resulting in the time series being represented as a matrix with 365 rows and 24 columns. If the time series happened to be perfectly periodic, then all the rows would be identical. Such a matrix could be more economically expressed as the product of a column matrix (size = 365x1) and the",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_9"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": "365 rows and 24 columns. If the time series happened to be perfectly periodic, then all the rows would be identical. Such a matrix could be more economically expressed as the product of a column matrix (size = 365x1) and the row matrix with the day profile (size = 1x24). If, on the other hand, the day-profiles still had identical shape but different amplitudes, the column matrix 9 would no longer be a column of ones, but a column filled with values proportional to the amplitudes of the profile. Generalizing even further, if there were slight intra-day variations in the shape of the profile, then the product of a simple column and row matrix would no longer suffice to recover the original matrix. Instead it would be the first (and dominant) term in the sum of similar products, each of which providing additional corrections on the first order approximation detailed by the first term in the decomposition. Put differently, the SVD-based expansion yields a decomposition analogous to the well-known Fourier decomposition of periodic signals, except in this case the basis functions are not specified upfront (trigonometric function in case of Fourier analysis) but are determined by the data. Fig. 2 illustrates the above by providing some examples from the actual price data (for the period 2013-2015). Fig. 2: First three components in the SVD decomposition of the price timeseries (using the timespan of a day as the fundamental period). 10 In the left column we get the first three (i.e. most dominant) daily price profiles (one data point for each of the 24 hour slots). The first component (top-left) is the daily average, showing the expected bi-modal appearance corresponding to high prices at peak times in the morning and afternoon. The flanking time series on the right specifies the amplitudes (one data point for each day) by which the profile needs to be scaled to obtain a first approximation for the data on the actual day. However, not every day in the year has the same predicted day-ahead price. The price depends on several variables, such as time of the year, holiday on no holiday and possible - but that is the research question in this study - the supply of solar and wind energy. In other words, there is not a predicted day-ahead price which is for every day the same. We decompose the data series in components and try to label the components to factors like",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_10"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " question in this study - the supply of solar and wind energy. In other words, there is not a predicted day-ahead price which is for every day the same. We decompose the data series in components and try to label the components to factors like weekend, season etc. To make a good prediction of the electricity price during the day, we have to correct the predicted price on the first graph for additional factors, for example the components 2 and 3. The next profiles (rows 2 and 3 in the left column) attempt to capture this intra-day variation. More specifically, the second component (Fig. 2, 2nd row, left column) attempts to increase the value in the middle of the day (peak times) while simultaneously decreasing the values in the evening and night period (for which it shows negative values). Flanking on its right hand side, we find the corresponding coefficients (one per day) which we need to apply to the profile in order to find the appropriate correction for each day. Notice that when this coefficient is positive, the correction will result in a less pronounced bi-modal profile, while a negative coefficient will give rise to a more pronounced bi-modal profile. The explanation for the last row is similar: this time the correction (at least in combination with a positive coefficient) will increase the price in the afternoon, while lowering it in the morning. The ordering of the component profiles is such that successive terms have corresponding lower impact, hence truncating the series after k terms results in the best possible approximation with at most k terms. The effect of the approximation is further illustrated in the Figure 3: 11 Fig. 3: Illustrating the effect of adding successive components in the SVD expansion for the predicted day-ahead price for one particular day. The actual price values for a single day are shown in black. The first approximation based on the globally averaged day-profile is shown in blue. Two further approximations are also shown (3rd order in green, and 5th order in red). It is clear that (at least in this case) the 5th order approximation (based on the blue global approximation to which 4 successively smaller correcting profiles have been added) is already fairly accurate. In summary (see Fig. 4): Because of the strong periodicities in the time series we use the SVD algorithm to decompose the observed data into a sum of periodic components (of decreasing importance). Truncating this expansion",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_11"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " fairly accurate. In summary (see Fig. 4): Because of the strong periodicities in the time series we use the SVD algorithm to decompose the observed data into a sum of periodic components (of decreasing importance). Truncating this expansion at the k-th term results in a data-driven approximation the residuals for which are now a (mean) stationary time series. Because of the stationarity of the residuals, identifying outliers can be done by straightforward thresholding. 12 Fig. 4: Top: Actual time series. Middle: Approximation based on the first seven SVD components. Bottom: Residuals (stationary time series). 3.3 Daily and weekly pattern for realised price on day-ahead market Daily pattern: The top graph in Fig. 5 shows the averaged day profile obtained from the SVD analysis (which in fact is equivalent to averaging out over all days in the time series). The electricity price during peak hours is - as expected - higher than during off-peak hours. The bottom panel in Fig. 5 graphs the inter-day variability between the day averages. It is 13 basically a down-sampled version of the original time series. Put differently, we can get a first order approximation of the original data by multiplying the day profile (top panel) by the amplitude of each point (one per day) in the time series depicted in the bottom panel and concatenating all the results (to reconstruct a time series that has the same length as the original one). Fig. 5: SVD (Rank-1) approximation of the realized day-ahead price for Germany during the observed period 1 Jan 2009 through 11 Dec 2015. Top: Averaged daily profile (24 values per day). Bottom: Inter-day variability for the averaged day-profile. Weekly pattern: All of the analysis in the preceding paragraphs focused on the daily patterns. Of course, since price depends on human activity, it also exhibits a weekly periodicity. Fig. 6 gives the weekly pattern of the German electricity price. On the horizontal axis we have the 7x24 =168 hour-slots (ranging Monday through Sunday). The graph (average over the week) clearly shows the seven days. The influence of the weekend (last two days) is already noticeable on Friday afternoons which is in line with expectations. The accompanying plot shows the scale factors that need to be applied to this weekly profile account for the inter-week variation (",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_12"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " days. The influence of the weekend (last two days) is already noticeable on Friday afternoons which is in line with expectations. The accompanying plot shows the scale factors that need to be applied to this weekly profile account for the inter-week variation (at least to a first approximation). 14 Fig. 6: SVD (Rank-1) approximation of the realized day-ahead price for Germany during the observed period 1 Jan 2009 through 11 Dec 2015. Top: Averaged weekly profile (24 values per day). Bottom: Inter-week variability for the averaged week-profile. 3.4. Periodic patterns in day-ahead forecasts for solar and wind energy Obviously, the supply of solar and wind energy varies across days and seasons, which is going to be reflected in the day-ahead predictions. However it is important to notice that the predictions for solar and wind show very different volatility. Solar: In Fig. 7 we have plotted the day-ahead prediction for solar energy during one particular week, i.e. a sample of seven successive days. 15 Fig. 7: The solar day-ahead prediction during seven successive days. From the sample figure above it is clear that prediction of solar is relatively rough: it is basically rectified sine wave, of which the amplitude is scaled up or down (depending on weather forecasts). Using the SVD-based rank-1 approximation to get a daily profile we obtain the following results: Fig. 8: LEFT: Average daily profile for predicted day-ahead solar supply. RIGHT: Inter-day variation in predicted solar supply during 6 years. Repeating the same analysis but this time taking the period to be equal to one year, yields an annual profile that clearly peaks in the summer (middle months, see Fig 9). The horizontal axis of the left graph of fig. 9 gives the hours of the year 8760 (= 24 * 365) and starts with 0.00 hours on January 1 and ends on December 31 24.00 hours. For every day in the year we calculated the unweighted averages of the expected solar energy during that day in the several years during the observed period. For example the predicted solar energy for June 8 18.00 -19.00 hours is the unweighted average of predicted solar energy during that time frame of the June 8 in 2009, 2010, ..., 2015. In the right graph of fig. ",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_13"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": "8 18.00 -19.00 hours is the unweighted average of predicted solar energy during that time frame of the June 8 in 2009, 2010, ..., 2015. In the right graph of fig. 9. we look ath the 16 predicted solar energy as function of the time. During the observed period we see that the supply of solar energy increases very rapidly during the first years (2010-2013), but after that period there seems to be a marked leveling off. Fig. 9: Solar supply, annual pattern. LEFT: Predicted pattern averaged over several years. RIGHT: Inter-year trend from 2010 through 2015. Wind: The forecasts for wind energy are more sophisticated and consequently show a higher volatility as can be seen in the figure 10 which again charts the predicted wind for each hour-slot in a particular week (i.e. a sample of seven consecutive days). Fig. 10: Day-ahead prediction for wind supply for one week (168 hourly values). 17 Although the wind data look erratic it is interesting to apply the SVD-based rank-1 decomposition to the dataset (covering 2009 through 2015) to extract the average daily profile. The result can be seen in Fig. 11: Fig. 11: WIND: SVD-based rank-1 approximation. LEFT: Averaged daily profile. RIGHT: Inter-day variation. The daily profile shows a marked peak during the early afternoon (around 15.00 hours). The inter-day variation on the other hand shows the steady increase in the total wind supply over the course of the seven year period. It is not surprising that the supply of wind energy is the highest during that period of the day. Wind is the flow of air from places with high air pressures to places with low air pressures. During the day the sun warms the air, more above land than above see. The air pressures decreases and a (see) wind will start or increase in power. A first indication that the supply of wind energy influences the electricity price is that the graph of the electricity price (see fig. 3) shows a price decrease after the morning peak and the local minimum is around 15.00 hours, exactly the time when the supply of wind energy is at its highest. To highlight this trend more clearly we conduct the same analysis as above, but this time we take a year (365*24 obs) as",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_14"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " is around 15.00 hours, exactly the time when the supply of wind energy is at its highest. To highlight this trend more clearly we conduct the same analysis as above, but this time we take a year (365*24 obs) as the relevant period. This result in the following profiles (see Fig. 12) : 18 Fig. 12: WIND, LEFT: Averaged annual profile. RIGHT: inter-year trend. The horizontal axis gives the 8760 hours of the year, starting with 0.00 hours of January 1 and ending with 24.00 hours December 31. Our observed period encompasses nearly six years, which means that every value of the predicted wind energy in the annual profile is the unweighted average of seven individual observations (with exception of the period December 12-December 31; they are the unweighted average of six observations). The annual profile on the left clearly shows that wind is expected to be stronger in the winter than in the summer months (middle of the year). Furthermore, the inter-year variation clearly shows that the total capacity grows approximately linearly starting in 2010. The right graphs of fig. 9 and fig. 12 show a decreasing growth of supply of solar energy and a continuous growth of supply of wind energy. Comparing to wind energy solar energy is losing market share in the supply of energy. 3.5 The influence of solar and wind energy on the electricity price In this section we return to question considered in an earlier publication (ADFP,2014) in which the authors investigate the influence of the (day-ahead) predicted supply of wind and solar on the realized day-ahead spot price in each hourly timeslot. The complicated nature of the regression function found in (ADFP,2014) is not surprising in view of the fact that (at least on average) wind and solar input shows a clear pattern throughout the day. These patterns have been discussed extensively in the previous sections. Loosely speaking, all variables are connected through their (non-linear) dependence on the time of day. As a consequence, the regression function proposed in (ADFP,2014) turns out to be complicated, involving non-linear effects and interaction terms. In this paper we propose to proceed along different lines by looking at the SVD-based representation of the data. Recall that all the predicted data are issued as a batch (of 24 hour values) on the previous day.",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_15"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " effects and interaction terms. In this paper we propose to proceed along different lines by looking at the SVD-based representation of the data. Recall that all the predicted data are issued as a batch (of 24 hour values) on the previous day. Hence, rather than focusing on individual hour-slots it makes sense to investigate whether, for example, the predicted day-profile for wind has an influence on the corresponding predicted day-profile for price. Since we intend to look at day-profiles, the SVD-decomposition provides us with exactly the sort of information that we need. 19 This is illustrated in the fig. 13 where we regressed the amplitude coefficient for the predicted price on the amplitude coefficient for predicted wind (including all the data ranging from 2009 through 2015). Fig. 13 The electricity price as function of the wind energy for the whole observed period There is a clear negative correlation between the two variables (with correlation coefficient = - 0.42) resulting in a regression line with highly significant coefficients (significance above 99%). Intuitively, this makes sense: high values for the first component in the SVD-expansion for wind, means that the average value for predicted wind is high, resulting in a lower averaged price. In the next paragraph we will look in more detail at these data, and we make a distinction between the more recent period (2013-2015) and the data from earlier period (2011-2012) as supply of wind and solar is quite different in these periods. Period 2013-2015: We first focus on the influence of wind on the price. By regressing the first component of the SVD expansion of the predicted price on the first component of the predicted wind we get the following results (also see Fig. 14): Price_comp_1 = 0.03 - 0.20 Wind_comp_1 (with \u0001\u0001 = 0.21), confirming the expected inverse relationship between price and predicted wind supply. Indeed, the negative coefficient (-0.20) indicates that higher averaged expected wind supply tends to be associated with a reduction in the averaged predicted price. Motivated by this result we investigate other relations between the observed amplitudes in the SVD expansion. 20 Fig. 14 The electricity price as function of the wind energy for the sub period 2013-2015 In Fig. 15 we have plotted the first four components of the S",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_16"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " observed amplitudes in the SVD expansion. 20 Fig. 14 The electricity price as function of the wind energy for the sub period 2013-2015 In Fig. 15 we have plotted the first four components of the SVD expansion of both the predicted price (left column) and wind (right column). The relations between the day- averaged profiles have been discussed above. By comparing the shapes of the successive components, the (rough) equivalence between the second and third components of both columns becomes apparent. More specifically, if the high (predicted) wind yield should have dampening impact on the price we expect a strong negative correlation between the 2nd wind component and the 3rd price one, and also the 3rd wind component and 2nd price one (after flipping its sign). This is confirmed by the detailed regression analysis as illustrated in Fig. 16: 21 Figuur 15: First four components in the SVD expansion of price (left) and wind (right). Notice the similarity in shape between the 3rd price component and the second wind component. 22 Fig. 16: Regression of different components of wind and price. 23 From the above it can be concluded that it makes sense to predict the first five (say) components in the SVD expansion of the price using the first five SVD components in for the wind data. Based on the considerations above, we propose the following regression strategy to investigate the impact of the predicted wind supply on the predicted price. Rather than regressing the predicted price in each hourly timeslot on the predicted wind supply in that slot (the approach that was adopted in ADFP,2014), we regress the whole price profile for the next day on the day-profile for predicted wind. More precisely we proceed as follows: 1. For each day (d) expand the predicted price and wind supply in terms of the SVD components: In the above expansion the basic functions on the right hand side or the SVD components, the first four of which are represented in Fig. 15 (Price in left column, Wind in right column). 2. Now use linear regression to predict the price-coefficients (a‚Äôs) based on the knowledge of the wind-coefficients (b‚Äôs). We refer to Fig. 16 where the regression is performed to compute an estimate for a3 in terms of b2 (top) and a2 in terms of b",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_17"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": "‚Äôs) based on the knowledge of the wind-coefficients (b‚Äôs). We refer to Fig. 16 where the regression is performed to compute an estimate for a3 in terms of b2 (top) and a2 in terms of b3 (bottom). 3. Once we can predict all (or most of) the a-coefficients in terms of the b-coefficients, we can reconstruct the predicted profile for the price. Put differently, this means that we have predicted the price starting from the wind supply. 4. Restricting our attention to the first 10 coefficients in both expansions, the regression- based estimates about 44% of the variation (R2 = 0.44). Fig 17 below shows both the realized day-ahead price and the approximation based on the wind information. Fig. 17: Realized day-ahead price: actual (blue) and prediction based on predicted wind (red). 24 The above results can also be illustrated by looking at the scatter plot of the realized day- ahead price versus the predicted day-ahead price using the predicted wind supply as predictor (see Fig 18 below) Fig. 18 Predicted day-ahead price, based on predicted wind energy This plot is informative because it confirms the numerical results reported above: ‚Ä¢ Fitting a regression line through the scatter plot, essentially coincides with the first bisectrix (y = x), indicating that the predicted price is correct on average. ‚Ä¢ However, the considerable width of variation of scatter plot about the regression line means that only part of the variation has been explained confirming the value R2 = 0.44 reported above. Periods 2009-2010 and 2011-2102 We redo the above analysis for the earlier periods 2009-2010 and 2011-2012, we get similar results, with slightly different values for the amount of explained variation: ‚Ä¢ 2009-2010: R2 = 0.38, ‚Ä¢ 2011-2012: R2 = 0.43 ‚Ä¢ 2013-2015: R2 = 0.44 25 The modest increase in explained variation might reflect the increase in wind-energy penetration and its subsequent impact on the price. Repeating the analysis for solar Repeating the analysis but this time using the day-ahead prediction for solar supply yields similar results, summarized in Fig.19 below. Again we see that the regression plot coincides with",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_18"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": " and its subsequent impact on the price. Repeating the analysis for solar Repeating the analysis but this time using the day-ahead prediction for solar supply yields similar results, summarized in Fig.19 below. Again we see that the regression plot coincides with the first bisectrix (y = x) indicating that the prediction is correct on average. However, the width of the scatterplot about the regression line shows that only part (40%) of the variation has been explained (as can be expected). Fig. 19 Predicted day-ahead price, based on predicted solar energy 4 Summary In this paper we looked at the influence of the German solar and wind energy in the electricity prices in German day-ahead market. During the observed period (January 1 2009 - December 12 2015) the energy policy of Germany changed very rapidly. The German government decided to close down nuclear energy in a couple of years, to reduce the dependency of gas and oil supply and fully supported the production of solar and wind energy. These energy switch (in German: Energiewende) has several causes. Firstly, the marginal costs of solar and wind energy is (nearly) zero. The construction costs of solar panels and wind turbines are high, but when the production facility starts to produce, the 26 costs are very low. The low marginal costs means that solar and wind energy drive the oil and gas suppliers out of the market. Secondly, because the volatility of solar and wind energy is much higher than the supply of electricity generated by gas and oil, the instability of the grid increases. The need for batteries to create storage capacity for solar and wind energy is high. In this study the research question is: What is the influence of solar and wind energy on the electricity price in Germany? Before answering this question we first looked at the time series of electricity prices, supply of solar energy and supply of wind energy. Clearly daily, weekly and annual patterns could be elucidated by applying and SVD-based approximation. Furthermore, these profiles could be used in a regression analysis to highlight the impact of predicted solar and wind supply on the day-ahead price. We show that both solar energy and wind energy has a significant negative influence on the electricity price in Germany. We also showed that the supply of solar energy is reaching a certain level, while the supply of wind energy is still growing. The several European grids (electricity networks) are linked to each other by so-called interconnectors. The impact of",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_19"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": ". We also showed that the supply of solar energy is reaching a certain level, while the supply of wind energy is still growing. The several European grids (electricity networks) are linked to each other by so-called interconnectors. The impact of an imbalance on a certain market can be reduced by transporting it to other grids. TSO's (Transmission System Operators) that have the task to keep the grid in their area in balance can help each other. However, due to the energy switch in Germany, the grid in Germany became less stable. Imbalances on the German grid can cause imbalance on the grids of the neighboring countries. How to reduce the imbalance caused by a higher market share of solar and wind energy is the main topic in the energy sector the coming years. 27 Literature Abudaldah,N. , Dorsman,A.B., Franx,G.J. and Pottuijt,P. (2014), The influence of renewables on the German Day ahead prices, in Perspectives on Energy Risk, Springer, 2014, p. 165-182. Alanne,K. and Saari,A. (2006), Distributed energy generation and sustainable development, Renewable and Sustainable Energy reviews, vol. 10, 539-558. Barnham,K. , Knorr,K. and Mazzer,M. (2013), Benefits of photovoltaic power in supplying national electricity demand, Energy Policy, vol. 54, 385-390. Dorsman, A.B., Franx, G.J. and Pottuijt,P. (2012), Coupling of imperfect power markets, in Energy: Macro economics and financial markets, Springer, October 2012, p. 215-234 Grant Wilson, I.A., McGregor,P.G., Infield,D.G. and Hall,P.J. (2011), Gird-connected renewables, storage, and the UK electricity market, Renewable Energy, vol. 36, 2166-2170. Gullberg,A.T., Ohlhorst,D. and Schreurs,M. (2014), Towards a low carbon energy future - renewable energy cooperation between Germany and Norway, Renewable Energy, vol. 68, 216-222. Jensen,S.G. and Skytte,K. (2002), Interactions between the power and green certificate markets, Energy Policy, vol. 30, 425-435. Papaefthymiou,G. , Grave,K. and Dr",
    "token_count": 500,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_20"
  },
  {
    "id": "cfcce08a-774b-4f2d-9b95-59982cae5af9",
    "created_at": "2025-07-26T15:28:58.165508+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Isini2016_DKP.pdf",
    "title": "Isini2016_DKP",
    "text": ". Jensen,S.G. and Skytte,K. (2002), Interactions between the power and green certificate markets, Energy Policy, vol. 30, 425-435. Papaefthymiou,G. , Grave,K. and Dragoon,K. (2014) , Flexibility options in electricity systems, Ecofys report. Swift-Hook, D.T. (2010), Grid-connected intermittent renewables are the last to be stored, Renewable Energy, vol. 36, 1967-1969. Swift-Hook, D.T. (2013), Wind energy really is the last to be stored and solar energy cannot be stored economically, Renewable Energy, vol. 50, 971-976. Winkler,J., Gaio,A., Pluger,B. and Ragwitz,M. (2016), Impact of renewables on electricity markets - Do support schemes matter?, Energy Policy, vol. 93, p. 157-167. Wozabal,D., Graf,C. Hirschmann,D. (2014), The effect of intermittent renewables on the electricity price, PHD-day University Wien, April 11 2014, Linz, Austria. View publication stats View publication stats",
    "token_count": 249,
    "chunk_id": "cfcce08a-774b-4f2d-9b95-59982cae5af9_21"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "Delft University of Technology Singular value decomposition for time series analysis with applications to smart energy systems Khoshrou, A. DOI 10.4233/uuid:9bf59202-4b7a-4313-b972-c12b7d272c06 Publication date 2022 Citation (APA) Khoshrou, A. (2022). Singular value decomposition for time series analysis with applications to smart energy systems. [Dissertation (TU Delft), Delft University of Technology]. https://doi.org/10.4233/uuid:9bf59202-4b7a-4313-b972-c12b7d272c06 Important note To cite this publication, please use the final published version (if applicable). Please check the document version above. Copyright Other than for strictly personal use, it is not permitted to download, forward or distribute the text or part of it, without the consent of the author(s) and/or copyright holder(s), unless the work is under an open content license such as Creative Commons. Takedown policy Please contact us and provide details if you believe this document breaches copyrights. We will remove access to the work immediately and investigate your claim. This work is downloaded from Delft University of Technology. For technical reasons the number of authors shown on this cover page is limited to a maximum of 10. SINGULAR VALUE DECOMPOSITION FOR TIME SERIES ANALYSIS WITH APPLICATIONS TO SMART ENERGY SYSTEMS SINGULAR VALUE DECOMPOSITION FOR TIME SERIES ANALYSIS WITH APPLICATIONS TO SMART ENERGY SYSTEMS Dissertation for the purpose of obtaining the degree of doctor at Delft University of Technology, by the authority of the Rector MagniÔ¨Åcus, Prof. dr. ir. T.H.J.J. van der Hagen, chair of the Board for Doctorates to be defended publicly on Monday 19th December 2022 at 15:00 o‚Äôclock by Abdolrahman KHOSHROU Master of Science in Information Engineering, University of Porto, Portugal born in Ghaemshahr, Iran This dissertation has been approved by the promotors. Composition of the doctoral committee: Rector MagniÔ¨Åcus chairperson Prof. dr. ir. J.A. La Poutr√© Delft University of Technology and Centrum Wiskunde & Informatica, promotor Dr. E.J.E.M. Pauwels Centrum Wiskunde & Informatica",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_1"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " Prof. dr. ir. J.A. La Poutr√© Delft University of Technology and Centrum Wiskunde & Informatica, promotor Dr. E.J.E.M. Pauwels Centrum Wiskunde & Informatica, copromotor Independent members: Dr. J. Kazempour Technical University of Denmark, Denmark Prof. dr. A.E. √áetin University of Illinois Chicago, USA Prof. dr. A.A. Salah Utrecht University, The Netherlands Prof. dr. W.G.J.H.M. van Sark Utrecht University, The Netherlands Prof. dr. ir. C. Vuik Delft University of Technology Prof. dr. P. Palensky Delft University of Technology, reserve member Copyright ¬© 2022 by Abdolrahman Khoshrou ISBN 978-94-6384-396-6 An electronic version of this dissertation is available at http://repository.tudelft.nl/ SUMMARY In a world replete with observations (physical as well as virtual), many data sets are rep- resented by time series. In its simplest form, a time series is a set of data collected se- quentially, usually at Ô¨Åxed intervals of time. In a number of applications, the mean and the variance of the time series is time-invariant and there is no seasonality in the data (such time series is called stationary). However, in many more applications, e.g., time series that are related to smart energy systems, the data have non-stationary character- istics. This thesis focuses primarily on matrices as an alternative representation of the latter type of time series, in order to take advantage of matrix decomposition methods. The ra- tionale is straightforward: numerically stable matrix decomposition techniques enable us to extract underlying patterns in the data and use them to construct approximations of the corresponding time series. In particular, we will focus on singular value decompo- sition (SVD) as a powerful and numerically stable matrix factorization technique. There- fore, as the Ô¨Årst step in this thesis, the SVD and its geometrical interpretation are exten- sively studied, in order to acquire a Ô¨Årm understanding of how it performs. That in turn enables us to look at different problems in time series analysis from a fresh perspective. For most of the applications of SVD in various Ô¨Åelds, it is important to understand the properties of the S",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_2"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " understanding of how it performs. That in turn enables us to look at different problems in time series analysis from a fresh perspective. For most of the applications of SVD in various Ô¨Åelds, it is important to understand the properties of the SVD of a matrix whose entries show some degree of random Ô¨Çuctu- ations. Therefore, to determine how the noise level affects the singular value spectrum, it is essential to study the singular value decomposition of random matrices. As we will explain in the introductory chapter, one of the early applications of the SVD in time se- ries analysis is in periodicity detection of the time series data. Therefore, we explore how the geometry of a matrix (the position of the data points with respect to the origin) and the aspect ratio of the matrix (the ratio between the number of columns and the number of rows) can affect its SVD results. Matrix factorisation techniques such as principal component analysis (PCA) and sin- gular value decomposition (SVD) are both conceptually simple and effective. However, it is well-known that they are sensitive to the presence of noise and outliers in input data. One way to mitigate this sensitivity is to introduce regularisation. To this aim, we hark back to the interpretation of SVD and PCA in terms of low-rank approximations, which involve the minimisation of speciÔ¨Åc functionals. We then derive algorithms for the min- imisation of the regularised version of such functionals. After the above-described theoretical investigations of SVD, we considered novel ap- plications of SVD to various problems. The Ô¨Årst one concerned challenges related to the integration of renewable energy sources (RES). With increasing RES-integration such as wind and solar energy to the power grid, balancing the grid has become more challeng- ing. This is mostly due to the inherently intermittent nature of RES, on the one hand, and shortcomings in bulk energy storage systems, on the other. Therefore, studies on scenario-based probabilistic energy production and demand forecasts have gained mo- v vi SUMMARY mentum, as they are highly valuable from both a technical and an economic point of view. A particular application of such models in the energy sector is where having the distribution of energy consumption for the coming days is desired. Furthermore, as extensively argued in the literature, a decisive variable in predicting energy demand is temperature data. There are mainly three practical and popular methods for generating temperature scenarios,",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_3"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " energy sector is where having the distribution of energy consumption for the coming days is desired. Furthermore, as extensively argued in the literature, a decisive variable in predicting energy demand is temperature data. There are mainly three practical and popular methods for generating temperature scenarios, namely Ô¨Åxed-date, shifted-date, and bootstrap approaches. Nev- ertheless, these methods have mostly been used on an ad-hoc basis without being for- mally compared or quantitatively evaluated. Moreover, as we discuss, the performance of such models depends to a large extent to the quality of input data. Therefore, we propose a generic, data-driven and computationally efÔ¨Åcient SVD-based approach to simulate temperature scenarios. The strength of our proposed method lies in its sim- plicity and robustness, in terms of the training window size, with no need for subsetting or thresholding in order to generate temperature scenarios. The empirical case studies performed on the data from the load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014-L) show that the proposed method outperforms the top two scenario-based models with a similar set-up. Another topic of considerable interest is to investigate what effect the transition of energy to RES can have on the overall trend and volatility of electricity prices. This im- pact could be complex because there are two contradicting forces at play. The marginal cost of RES is relatively low and even negative (especially if subsidized), therefore, in- creased penetration of wind and solar would result in a downward trend in electricity prices. Opposing this is the associated uncertainty regarding the availability of wind and solar energy, which causes spikes in the market. In other words, the integration of RES provokes assertions that the stability of the power grid can (surely) be compromised due to the inherent intermittency of such sources. Therefore, the increased price volatility will cause additional market risks for suppliers and consumers in the market. In the literature, numerous methods have been introduced to determine the volatil- ity of the time series data. However, as we exemplify, the emergence of non-positive price values in the energy transition era has introduced new challenges in the electricity mar- ket volatility analysis. This new aspect of the market renders many traditional volatility indices ineffective. More precisely, the standard approach to switch to logarithmic mea- sures can be done only after shifting up all values above zero by a certain threshold. On the other hand, price volatility",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_4"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " aspect of the market renders many traditional volatility indices ineffective. More precisely, the standard approach to switch to logarithmic mea- sures can be done only after shifting up all values above zero by a certain threshold. On the other hand, price volatility has a dependence on the price level, which is even more pronounced when the spot prices are low. Therefore, the generalizability of conventional approaches is questioned, as the volatility measures can vary drastically, with respect to the magnitude of the aforementioned thresholds. We tackle this problem by introducing a new notion of volatility which is obtained by reconstructing the time series using the SVD technique. In other words, we detect and remove the deterministic part of the price data using the SVD and consider the stochastic part (residuals) as a notion of volatility. Using the matrix representation of the data, we then highlight the evidence of the effect of renewables on daily price proÔ¨Åles in the German day-ahead market, i.e., the emer- gence of non-positive prices and also shifts of peak price values to hours where solar is less available. Overall, in this thesis, we study in-depth the SVD technique and propose novel appli- cations of it in time series analysis. Our Ô¨Åndings can be used as innovative components SUMMARY vii of future smart grid systems, which are characterized by the increasing uncertainty on both the supply and demand parts. SAMENVATTING In een wereld vol fysieke en virtuele waarnemingen zijn veel datasets opgebouwd in de vorm van tijdreeksen. Een tijdreeks, in zijn eenvoudigste vorm, is een reeks gegevens die opeenvolgend worden verzameld, meestal met vaste tussenpozen. In sommige toe- passingen zijn het gemiddelde en de variantie van de reeks tijdsinvariant en vertonen de gegevens geen seizoenseffecten; een dergelijke tijdreeks wordt stationair genoemd. Voor de meeste toepassingen, bijvoorbeeld tijdreeksen die betrekking hebben op slimme energiesystemen, vertonen de gegevens echter niet-stationaire kenmerken. Dit proefschrift richt zich voornamelijk op alternatieve representaties van de laatste soort tijdreeksen in de vorm van matrices, zodat geproÔøΩ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_5"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "vens echter niet-stationaire kenmerken. Dit proefschrift richt zich voornamelijk op alternatieve representaties van de laatste soort tijdreeksen in de vorm van matrices, zodat geproÔ¨Åteerd kan worden van matrixont- ledingsmethoden. De reden is eenvoudig: numeriek stabiele matrixontledingstechnie- ken stellen ons in staat om onderliggende patronen in de gegevens te extraheren, en hiermee benaderingen van de bijbehorende tijdreeks te construeren. In het bijzonder zullen we ons richten op singuliere waardenontbinding (SWO); een krachtige en nume- riek stabiele matrixfactorisatie techniek. De eerste stap in dit proefschrift is daarom het uitgebreid bestuderen van de SWO en zijn geometrische interpretatie, om zo een goed begrip van de prestaties te verkrijgen. Dit begrip stelt ons in staat om verschillende pro- blemen in tijdreeksanalyses vanuit een nieuw perspectief te bekijken. Voor de meeste toepassingen van SWO is het cruciaal om inzicht te verkrijgen in de eigenschappen van de SWO van een matrix, waarvan de gegevens enige mate van willekeurige Ô¨Çuctuaties vertonen. Om te bepalen hoe ruis het singuliere waardenspec- trum be√Ønvloedt, is het essentieel om de ontleding van singuliere waarden van wille- keurige matrices te bestuderen. Zoals we toelichten in het inleidende hoofdstuk, is pe- riodiciteitsdetectie van tijdreeksgegevens √©√©n van de eerste toepassingen van de SWO in tijdreeksanalyse. Om deze reden onderzoeken we hoe de geometrie van een matrix (de positie van de datapunten ten opzichte van de oorsprong) en de aspectverhouding van de matrix (de verhouding tussen het aantal kolommen en het aantal rijen) de SWO- resultaten kunnen be√Ønvloeden. Matrixfactorisatie technie",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_6"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "orsprong) en de aspectverhouding van de matrix (de verhouding tussen het aantal kolommen en het aantal rijen) de SWO- resultaten kunnen be√Ønvloeden. Matrixfactorisatie technieken zoals principale-componentenanalyse (PCA) en sin- guliere waardeontbinding (SWO) zijn zowel effectief als conceptueel eenvoudig. Het is echter algemeen bekend dat ze gevoelig zijn voor de aanwezigheid van ruis en uitschie- ters in invoergegevens. Het toepassen van regularisatie is een manier om deze gevoe- ligheid te verminderen. Om dit doel te bereiken, grijpen we terug naar interpretaties van SWO en PCA in termen van lage-rangapproximaties, die betrekking hebben op het minimaliseren van speciÔ¨Åeke functionalen. Vervolgens leiden we algoritmen af voor de minimalisatie van de geregulariseerde versie van dergelijke functionalen. Na het hierboven beschreven theoretische onderzoek van SWO hebben we nieuwe toepassingen van SWO voor verschillende problemen bestudeerd. De eerste heeft be- trekking op uitdagingen in verband met de integratie van hernieuwbare energiebron- nen. Met toenemende integraties van bronnen zoals wind- en zonne-energie binnen ix x SAMENVATTING het elektriciteitsnet, is het balanceren van het net een grotere uitdaging geworden. Dit is voornamelijk te wijten aan het inherent intermitterende karakter van hernieuwbare energiebronnen enerzijds, en tekortkomingen in bulkopslag van energie anderzijds. Om die reden hebben studies naar op scenario‚Äôs gebaseerde probabilistische prognoses voor energieproductie en -vraag aan momentum gewonnen, aangezien ze zeer waardevol zijn vanuit zowel technisch als economisch oogpunt. Een speciÔ¨Åeke toepassing van derge- lijke modellen in de energiesector is het bepalen van de gewenste verdeling van energie- verbruik voor",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_7"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " economisch oogpunt. Een speciÔ¨Åeke toepassing van derge- lijke modellen in de energiesector is het bepalen van de gewenste verdeling van energie- verbruik voor de komende dagen. Zoals uitvoerig besproken in de literatuur, zijn tempe- ratuurgegevens een beslissende variabele bij het voorspellen van de energievraag. Er zijn drie praktische en populaire methoden voor het genereren van temperatuurscenario‚Äôs, namelijk benaderingen met vaste datum, verschoven datum en bootstrapping. Deze methoden worden echter meestal op ad-hocbasis gebruikt, zonder formele vergelijking of kwantitatieve beoordeling. Bovendien zijn de prestaties van dergelijke modellen in grote mate afhankelijk van de kwaliteit van de invoergegevens. Om die reden stellen we simulatie van temperatuurscenario‚Äôs voor, als een generieke, datagedreven en rekenkun- dig efÔ¨Åci√´nte op SWO gebaseerde benadering. De kracht van onze voorgestelde methode ligt in zijn eenvoud en robuustheid, in termen van de grootte van het trainingsvenster, zonder noodzaak tot het cre√´ren van deelverzamelingen of drempelwaarden om tempe- ratuurscenario‚Äôs te genereren. Uit de empirische casusstudies, uitgevoerd op de gege- vens van de load forecasting-sessie van de Global Energy Forecasting-competitie 2014 (GEFCom2014-L), blijkt dat de voorgestelde methode beter presteert dan de twee beste scenario-gebaseerde modellen met een vergelijkbare opzet. Een ander belangrijk onderzoeksonderwerp is het effect dat de overgang naar her- nieuwbare energiebronnen kan hebben op de algemene trend en volatiliteit van de elek- triciteitsprijzen. Deze impact kan complex zijn, omdat er twee tegenstrijdige krach- ten spelen. De marginale kosten van hernieuwbare energ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_8"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ene trend en volatiliteit van de elek- triciteitsprijzen. Deze impact kan complex zijn, omdat er twee tegenstrijdige krach- ten spelen. De marginale kosten van hernieuwbare energiebronnen zijn relatief laag of zelfs negatief (vooral indien gesubsidieerd), daarom zou verhoogd gebruik van wind- en zonne-energie resulteren in een neerwaartse trend in elektriciteitsprijzen. Daartegen- over staat de onzekerheid omtrent de beschikbaarheid van wind- en zonne-energie, die pieken in de marktprijs veroorzaakt. Met andere woorden, door de inherente Ô¨Çuctuaties van hernieuwbare energiebronnen kan de integratie van dergelijke bronnen de stabili- teit van het elektriciteitsnet in het gedrang brengen. De verhoogde prijsvolatiliteit zal daardoor leiden tot extra marktrisico‚Äôs voor leveranciers en consumenten. In de literatuur zijn talloze methoden ge√Øntroduceerd om de volatiliteit van tijdreeks- gegevens te bepalen. We illustreren echter dat de opkomst van niet-positieve prijzen in het tijdperk van energietransitie heeft geleid tot nieuwe uitdagingen in de volatili- teitsanalyse van de elektriciteitsmarkt. Dit nieuwe aspect van de markt zorgt ervoor dat veel traditionele volatiliteitindices niet effectief zijn. Preciezer geformuleerd: de stan- daardaanpak om over te schakelen naar logaritmische maten kan alleen worden uitge- voerd nadat alle waarden boven nul met een bepaalde drempel zijn opgeschoven. Aan de andere kant is prijsvolatiliteit afhankelijk van het prijsniveau, een effect dat zelfs meer uitgesproken is wanneer de spotprijzen laag zijn. Daarom wordt de generaliseerbaar- heid van conventionele benaderingen in twijfel getrokken, aangezien de vol",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_9"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " meer uitgesproken is wanneer de spotprijzen laag zijn. Daarom wordt de generaliseerbaar- heid van conventionele benaderingen in twijfel getrokken, aangezien de volatiliteits- maatregelen drastisch kunnen vari√´ren met betrekking tot de hoogte van de bovenge- noemde drempels. We pakken dit probleem aan door een nieuwe notie van volatiliteit SAMENVATTING xi te introduceren, die wordt verkregen door de tijdreeks te reconstrueren met behulp van de SWO-techniek. Met andere woorden: we detecteren en verwijderen het determinis- tische deel van de prijsgegevens met behulp van de SWO en beschouwen het stochasti- sche deel (residuen) als een notie van volatiliteit. Met behulp van de matrixweergave van de gegevens belichten we vervolgens het bewijs van het effect van hernieuwbare ener- giebronnen op dagprijsproÔ¨Åelen in de Duitse day-aheadmarkt, d.w.z. de opkomst van niet-positieve prijzen en ook verschuivingen van piekprijswaarden naar uren waarop zonne-energie is minder beschikbaar. Samenvattend bestuderen we in dit proefschrift op diepgaande wijze de SWO-techniek en stellen we nieuwe toepassingen voor op het gebied van tijdreeksanalyse. Onze bevin- dingen kunnen worden gebruikt als innovatieve componenten van toekomstige slimme elektriciteitsnetwerken, die worden gekenmerkt door toenemende onzekerheid omtrent zowel het vraag- als het aanbodgedeelte. ACKNOWLEDGEMENTS This thesis concludes a big chapter of my life. In the last couple of years, I have grown both as a humble researcher and a person. I have learned to always keep an open mind and embrace all the tough, challenging, rewarding and fulÔ¨Ålling moments that a PhD can offer. I also have honed my hands-on mentality and drive to get things done. I am indebted to many excellent collaborators",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_10"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " always keep an open mind and embrace all the tough, challenging, rewarding and fulÔ¨Ålling moments that a PhD can offer. I also have honed my hands-on mentality and drive to get things done. I am indebted to many excellent collaborators and colleagues for their invaluable time, feedback, and suggestions. Foremost, I express my greatest gratitude to my promotor Prof. dr. ir. J.A. La Poutr√©, and my co-promotor, Dr E.J.E.M. Pauwels for their constant help and guidance during my PhD journey. Throughout the writing of this thesis, I have always received great feed- back and comments from them. Next, I would like to thank all the members of the Intelligent and Autonomous Sys- tems (IAS) group at CWI for making it fun and exciting to come to work every day. My special appreciation goes to Dr Brinn Hekkelman, Roland Saur and Xinyu Hu for their friendship. I have also always beneÔ¨Åted from extensive interactions and conversations with Dr Tim Baarslag, Dr Hoang Luong and Dr Swasti R. Khuntia. I am also grateful to my dear friend, Dr Wouter van Heeswijk for translating this thesis summary into Dutch. And, last but not least, I would like to thank my family for their love and support. You always have encouraged me to chase my dreams without fear. I am so grateful to have you all in my life. xiii CONTENTS Summary v Samenvatting ix Acknowledgements xiii 1 Introduction 5 1.1 Context and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.2 Recasting time series as matrices . . . . . . . . . . . . . . . . . . . . . . 6 1.3 Applying SVD to time series. . . . . . . . . . . . . . . . . . . . . . . . . 8 1.3.1 Period Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.3.2 Time series approximation. . . . . . . . . . . . . . . . . . . . . . ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_11"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " . . . . . . . . . . . . . . . . 9 1.3.2 Time series approximation. . . . . . . . . . . . . . . . . . . . . . 11 1.3.3 Visualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 1.3.4 Pattern extraction . . . . . . . . . . . . . . . . . . . . . . . . . . 17 1.4 Challenges and Research Questions. . . . . . . . . . . . . . . . . . . . . 18 1.5 Thesis Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 1.6 List of Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2 Singular Value Decomposition: A Recap 25 2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 2.2 Singular Value Decomposition . . . . . . . . . . . . . . . . . . . . . . . 25 2.2.1 SVD: Main Result . . . . . . . . . . . . . . . . . . . . . . . . . . 26 2.2.2 Singular values are eigenvalues of squared matrices . . . . . . . . . 27 2.2.3 SVD solves a minimisation problem . . . . . . . . . . . . . . . . . 28 2.3 Geometric Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . 29 2.3.1 Incremental SVD: Computing Best",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_12"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "28 2.3 Geometric Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . 29 2.3.1 Incremental SVD: Computing Best Rank-1 Approximation. . . . . . 29 2.3.2 Intuitive continuity-based argument for SVD . . . . . . . . . . . . 31 2.4 Data Alignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.5 Comparing SVD and PCA . . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.5.1 PCA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.5.2 SVD vs. PCA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 2.6 Addendum: Addressing Computational Artefacts . . . . . . . . . . . . . . 38 2.6.1 SVD computations in Matlab . . . . . . . . . . . . . . . . . . . . 38 2.6.2 Sampling Random Orthogonal Matrices: Gram-Schmidt orthogonalisation (QR decomposition) . . . . . . . 39 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 1 2 CONTENTS 3 Properties of the SVD 41 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3.2 Singular value spectrum of random matrices . . . . . . . . . . . . . . . . 41 3.2.1 Preliminaries. . . . . . . . . . . . . . . . . . . . . . . . .",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_13"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " . . . . . . . . . . . . . . 41 3.2.1 Preliminaries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 3.2.2 Universality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 3.3 Impact of aspect ratio on singular values . . . . . . . . . . . . . . . . . . 44 3.3.1 Problems with the SVR approach . . . . . . . . . . . . . . . . . . 44 3.3.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.3.3 Asymptotic ratio of singular values as function of growing aspect ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 3.4 Impact of the underlying periodic signal . . . . . . . . . . . . . . . . . . 49 3.5 Exploring some properties . . . . . . . . . . . . . . . . . . . . . . . . . 52 3.5.1 Impact of entries mean value . . . . . . . . . . . . . . . . . . . . 52 3.5.2 Impact of the drift on the Ô¨Årst singular value. . . . . . . . . . . . . 54 3.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 4 Regularised Matrix Factorization 61 4.1 Introduction and Motivation . . . . . . . . . . . . . . . . . . . . .",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_14"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " . . . . . . . . . . 59 4 Regularised Matrix Factorization 61 4.1 Introduction and Motivation . . . . . . . . . . . . . . . . . . . . . . . . 61 4.2 Regularisation for PCA-type factorisation . . . . . . . . . . . . . . . . . . 63 4.2.1 Regularised PCA . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 4.2.2 Some special cases. . . . . . . . . . . . . . . . . . . . . . . . . . 64 4.3 Regularisation for SVD-type factorisation . . . . . . . . . . . . . . . . . . 65 4.4 Computational Aspects . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 4.4.1 Gradient and Random Descent on the Unitary Domain . . . . . . . 68 4.4.2 Illustrative example: Smoothing a noisy matrix . . . . . . . . . . . 70 4.5 Earlier results, based on adhoc smoothing . . . . . . . . . . . . . . . . . 73 4.5.1 Finding peaks and valleys . . . . . . . . . . . . . . . . . . . . . . 73 4.5.2 Using SVD to highlight structure . . . . . . . . . . . . . . . . . . . 76 4.5.3 Structure-preserving smoothing . . . . . . . . . . . . . . . . . . . 78 4.6 Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 4.7 Background and Literature Review . . . . . . . . . . . . . . . . . . . . . 80 4.8 Conclusions and Future Research. . . . .",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_15"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " . . . 79 4.7 Background and Literature Review . . . . . . . . . . . . . . . . . . . . . 80 4.8 Conclusions and Future Research. . . . . . . . . . . . . . . . . . . . . . 81 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 5 Hypothesis Generation using SVD 89 5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 5.2 Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90 5.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 5.3.1 Ensemble of regression trees . . . . . . . . . . . . . . . . . . . . . 92 5.3.2 Our proposed forecasting models . . . . . . . . . . . . . . . . . . 93 5.3.3 Singular value decomposition . . . . . . . . . . . . . . . . . . . . 95 5.3.4 Temperature scenario generation . . . . . . . . . . . . . . . . . . 96 5.4 Experimental Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 5.5 Conclusions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 CONTENTS 3 6 Volatility QuantiÔ¨Åcation 107 6.1",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_16"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 CONTENTS 3 6 Volatility QuantiÔ¨Åcation 107 6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 6.2 Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 6.2.1 Day-ahead Auction Spot Market . . . . . . . . . . . . . . . . . . . 109 6.3 Matrix decomposition using SVD . . . . . . . . . . . . . . . . . . . . . . 111 6.4 Quantifying the daily volatility . . . . . . . . . . . . . . . . . . . . . . . 112 6.4.1 Wavelet decomposition . . . . . . . . . . . . . . . . . . . . . . . 112 6.4.2 Volatility quantiÔ¨Åcation . . . . . . . . . . . . . . . . . . . . . . . 115 6.5 Quantifying the hourly volatility . . . . . . . . . . . . . . . . . . . . . . 116 6.6 Extracting the underlying trends . . . . . . . . . . . . . . . . . . . . . . 120 6.6.1 The evolution of the daily proÔ¨Åles . . . . . . . . . . . . . . . . . . 120 6.6.2 The extreme values . . . . . . . . . . . . . . . . . . . . . . . . . 121 6.6.3 The distribution of high and low price values . . . . . . . . . . . . 122 6.6.4 Zero and negative prices . . . . . . . . . . . . . . . . . . . . . . . 122",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_17"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " values . . . . . . . . . . . . 122 6.6.4 Zero and negative prices . . . . . . . . . . . . . . . . . . . . . . . 122 6.7 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127 7 Conclusion 129 7.1 Main Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 7.2 Concluding remarks and future work . . . . . . . . . . . . . . . . . . . . 131 A Appendix 133 A.1 Brief overview of matrix norms . . . . . . . . . . . . . . . . . . . . . . . 133 A.2 SVD solves a matrix norm optimisation problem . . . . . . . . . . . . . . 135 A.3 L2 matrix norms expressed in terms of singular values . . . . . . . . . . . 135 A.4 Gradients for Frobenius norm. . . . . . . . . . . . . . . . . . . . . . . . 136 A.4.1 Some special cases. . . . . . . . . . . . . . . . . . . . . . . . . . 136 A.5 Variance of product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 A.6 Singular values of the ‚Äúfat\" matrices. . . . . . . . . . . . . . . . . . . . . 137 A.6.1 Why are singular values inÔ¨Çated? . . . . . . . . . . . . . . . . . . 143 A.7 Perturbation of eigen-values and -vectors. . . . . . . . . . . . . . .",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_18"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ÔøΩated? . . . . . . . . . . . . . . . . . . 143 A.7 Perturbation of eigen-values and -vectors. . . . . . . . . . . . . . . . . . 145 A.7.1 Perturbation theory for matrices . . . . . . . . . . . . . . . . . . . 146 B Appendix 147 B.1 EPEX market and RES feed-in . . . . . . . . . . . . . . . . . . . . . . . . 147 B.1.1 Day-ahead wind energy feed-in (in GWh) . . . . . . . . . . . . . . 147 B.1.2 Day-ahead solar energy feed-in (GWh). . . . . . . . . . . . . . . . 147 B.1.3 Evolution of German day-ahead price during winter and summer . . 147 B.1.4 Day-ahead traded quantity (GWh) . . . . . . . . . . . . . . . . . . 153 Curriculum Vit√¶ 155 List of Publications 157 4 CONTENTS Abdolrahman KHOSHROU Dead yesterdays and unborn tomorrows, why fret about it, if today be sweet. Omar Khayyam 1 INTRODUCTION 1.1. CONTEXT AND MOTIVATION In a world replete with observations (physical as well as virtual), many data sets come in the shape of time series. In their simplest incarnation, time series represent an ordered sequence of values of a variable at equally spaced time intervals. If the variable of interest is basically stationary (e.g., the output of a stable production process), the global char- acteristics of the time series do not change much. In such cases, one can describe the time series processes in terms of a random variable with constant statistical moments. However, time series that are related to human activities ‚Äî such as data streams pro- duced by smart infrastructures ‚Äî often have a non-stationary structure. For instance, whereas the electrical consumption of households will be similar throughout the week, it will be markedly different from consumption on the weekend. Similarly, signiÔ¨Åcant gradual shifts will be noticeable over the course of a year. This thesis focuses primarily on an alternative representation of the time series",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_19"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " households will be similar throughout the week, it will be markedly different from consumption on the weekend. Similarly, signiÔ¨Åcant gradual shifts will be noticeable over the course of a year. This thesis focuses primarily on an alternative representation of the time series data that offers some advantages when it comes to the analysis of these types of data. Specif- ically, we will focus on representing time series as matrices in order to take advantage of matrix decomposition methods. The rationale is straightforward: since matrix de- composition provides principled methods to Ô¨Ånd low-rank approximations of a matrix, they will also give rise to an approximation of the corresponding time series. However, by their very nature, these methodologies are conceptually different from the standard statistical techniques for averaging or summarizing time series. In particular, in this thesis, we will focus on the singular value decomposition (SVD) as a powerful, numerically stable matrix factorization technique which is then applied to time series analysis. Therefore, the SVD is herein extensively studied to acquire a Ô¨Årm understanding of how it performs. That in turn enables us to look at different applica- tions in time series analysis from a fresh perspective. For now, it sufÔ¨Åces to announce the gist of SVD, but we will provide more details in Chapter 2. Given any matrix A, SVD allows us to represent it as the product of three matrices (also see Figure 1.1) : A =USV T (1.1) 5 6 1. INTRODUCTION Figure 1.1: An overview of matrix decomposition using SVD, in matrix form corresponding to Eq. 1.1 (top) and dyadic form corresponding to Eq. 1.2 (bottom). where U and V have orthonormal columns, and S is essentially diagonal. Because the diagonal matrix is located between the orthogonal matrices, Eq. (1.1) can be expanded as the following simple sum: A = rX i=1 œÉiUiV T i , (1.2) where Ui,Vi are the i-th columns of U and V , respectively. Chapter 2 explains the SVD method in details. 1.2. RECASTING TIME SERIES AS MATRICES To see how matrix decomposition can be applied to time series analysis, let us start with the simplest conceivable example. Suppose we have a perfectly periodic signal (e.g., a pure sine wave",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_20"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "1.2. RECASTING TIME SERIES AS MATRICES To see how matrix decomposition can be applied to time series analysis, let us start with the simplest conceivable example. Suppose we have a perfectly periodic signal (e.g., a pure sine wave) which is sampled at some (large) multiple of the wavelength. Suppose in addition that we observe q (identical) cycles, with each cycle having p sample points. Let us register the observations during one cycle in the p-dim vector p. For reasons that will become clear shortly, let us re-arrange the times series as a matrix, with each cycle in a separate column (from now on we assume that vectors are columns, see Figure 1.2). In that case, we can express the data concisely as data matrix A (denoting the column vector 1q = (1,1,...,1)T ): A = ¬£ p,p,...,p ¬§ | {z } q cycles = p1T q (1.3) 1.2. RECASTING TIME SERIES AS MATRICES 7 A = a1 a2 a3 a1 a2 a3 Figure 1.2: Turning a periodic signal into a matrix. The data of each successive period are stacked next to each other as columns of the matrix. Now suppose that we are dealing with a time series that still has a clear and Ô¨Åxed period, by which we mean that the length of each cycle is constant throughout the observed time window (e.g., due to diurnal activities). The amplitude, however, can vary signiÔ¨Åcantly and erratically from cycle to cycle. This type of time series is often encountered in smart infrastructures. As a case in point, consider trafÔ¨Åc data [1]: ‚Ä¢ These data show Ô¨Åxed periods of 24 hours (due to human activity); ‚Ä¢ Excluding weekends, the shape of the observed patterns is similar, reÔ¨Çecting pat- terns in human activity (e.g., schools and businesses start at a certain time every morning); ‚Ä¢ However, the amplitude could differ from day to day: e.g., depending on the weather ‚Äî which to a Ô¨Årst approximation is stochastic; Pursuing the stance taken by Eq. (1.3) we represent such a variable-amplitude as: A = pqT (1.4) where the q-dimensional vector q now summarizes the amplitude information",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_21"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " a Ô¨Årst approximation is stochastic; Pursuing the stance taken by Eq. (1.3) we represent such a variable-amplitude as: A = pqT (1.4) where the q-dimensional vector q now summarizes the amplitude information. In fact, it is customary to recast the p and q vectors as unit vectors and collect the factored-out amplitudes in a single coefÔ¨Åcient (customarily denoted as œÉ): A = pqT = œÉuvT where u = p/||p||, v = q/||q|| and œÉ = ||p||¬∑||q||. (1.5) 8 1. INTRODUCTION Figure 1.3: A toy example of a noisy time series (blue) that has 10 cycles with length 50. The low-rank approxi- mation (see main text for more details) is drawn in red. For an example of such a time series, see Figure 1.3. The noisy time series (blue) has cycles of length p =50, but the amplitude of each cycle varies erratically. Finally, real data are frequently noisy, so a more appropriate representation of the data matrix A would be: A = œÉuvT +ŒµZ (1.6) where Z has the same size as A and represents independent unit-variance (Gaussian) noise, while Œµ determines the noise amplitude. Notice that in general, adding a noise matrix will inÔ¨Çate the rank rk(A) from rank 1 to full rank. However, as long as the noise is small with respect to the signal, the matrix is essentially ‚Äî in a sense that will be made precise later on in Section 1.3 ‚Äî still a rank-1 matrix. Therefore, we have constructed a data matrix A that is essentially rank-1 as the superposition of a pure rank-1 matrix and a (small amount of) random noise. In what follows we will take the complementary view: take a given data matrix, and decompose it into a rank-1 (or more generally, low rank) approximation and some remaining noise. Up to this point, the examples are artiÔ¨Åcial but throughout most of this thesis, we will take the perspective of smart energy systems applying data-driven approaches to analyse time series data generated by this type of smart infrastructures that often contain underlying patterns that facilitate low-rank representations. Figure 1.4",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_22"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " but throughout most of this thesis, we will take the perspective of smart energy systems applying data-driven approaches to analyse time series data generated by this type of smart infrastructures that often contain underlying patterns that facilitate low-rank representations. Figure 1.4 illustrates an example of one year worth of price and load data (Top), alongside their alternative representation (Bottom). The latter plots were obtained by recasting each time series into a matrix of size 24√ó365. In Chapter 4, we will elaborate on this and put these visual impressions on a more sound, mathematical footing. 1.3. APPLYING SVD TO TIME SERIES In the previous section, we have indicated how we can recast a time series as a matrix. The reason for this alternative representation is to take advantage of matrix decompo- sition techniques to extract useful information from data. In this thesis, we will mainly 1.3. APPLYING SVD TO TIME SERIES 9 0 2000 4000 6000 8000 Hourly values throughout 2016 0 2 4 6 8 10 12 Solar Feed-in (GWh) 0 2000 4000 6000 8000 Hourly values throughout 2016 0 5 10 15 Wind Feed-in (GWh) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4 0.5 Figure 1.4: Top: time series of hourly solar (left) and wind (right) energy feed-in. Bottom: Matrix representation of the derivatives of the solar (left) and wind (right) data. For full description of the data and the methodology see Chapter 4. focus on the following: ‚Ä¢ Period extraction ‚Ä¢ Approximation ‚Ä¢ Visualisation ‚Ä¢ Pattern extraction In what follows we will look at each",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_23"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " solar (left) and wind (right) data. For full description of the data and the methodology see Chapter 4. focus on the following: ‚Ä¢ Period extraction ‚Ä¢ Approximation ‚Ä¢ Visualisation ‚Ä¢ Pattern extraction In what follows we will look at each of these applications in slightly more details. 1.3.1. PERIOD EXTRACTION To handle period estimation for such aforementioned time series, the authors in [2] rea- soned as follows: If we have a noiseless time series with periods that are identical in shape but possibly vary in amplitude, it could be recast as the rank-1 matrix in Eq. (1.4). Hence we could determine the period by reshaping the time series as a matrix with dif- ferent dimensions (i.e., number of rows and columns) until we hit upon a matrix that has rank 1. The corresponding number of rows would correspond to the sought-after period. In practical applications, however, it is rare to come across time series that yields a data matrix of this exact simple form. Therefore, it is more realistic to think of Eq. (1.5) as the Ô¨Årst term in an expansion: A = œÉ1u1vT 1 +œÉ2u2vT 2 +... (1.7) 10 1. INTRODUCTION Figure 1.5: Determining time series period based on SVR. The input time series (top panel) is reshaped in matrices of different column-length (middle panels). For each of these matrices we compute the SVR = œÉ1/œÉ2 and plot it against the column size (p). The actual time series period produces a (dominant) peak in the SVR- curve (bottom panel). Worth to be noted that the smaller the amount of noise is, the closer Eq. (1.7) is to Eq. (1.5). The factorization in Eq. (1.7) can be efÔ¨Åciently computed using the singular value decomposition (SVD ‚Äì for a recap of the important results, see Chapter 2). For such an approximation to make sense, we assume that the signal (captured by the Ô¨Årst term) dominates the noise (captured by the subsequent terms). Mathematically, this amounts to the assumption that œÉ1 ‚â´œÉ2, or equivalently œÉ1/œÉ2 ‚â´1. This latter expres- sion is",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_24"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "rst term) dominates the noise (captured by the subsequent terms). Mathematically, this amounts to the assumption that œÉ1 ‚â´œÉ2, or equivalently œÉ1/œÉ2 ‚â´1. This latter expres- sion is called the singular value ratio (SVR). This observation was the starting point for the authors in [2, 3] who proposed the following simple procedure for period extraction (also see Figure 1.5): ‚Ä¢ For a given time series of length n, rearrange the data as successive columns in a matrix. For each length p of the column this produces a differently shaped matrix of size p √ó q where q = ‚åän/p‚åã1. ‚Ä¢ For each different value of p, compute the SVD expansion in Eq. (1.7) and the cor- responding SV R = œÉ1/œÉ2, for the corresponding matrix. ‚Ä¢ When the dimension of the column corresponds with the actual underlying pe- riodicity, there will be a peak in the SVR. Hence, by identifying the peaks in the p ‚àíSV R plot, one can determine the periodicity. 1where [.] is the Greatest Integer Function. 1.3. APPLYING SVD TO TIME SERIES 11 Figure 1.6: Illustrating alternative ways to quantify the periodicity of the signal in Figure 1.3. Left: FFT spec- trum for time series in Figure 1.3. The highest spectrum indicates the number of cycles in the time series. As can be seen in the aforementioned Ô¨Ågure, it is 10. Right: Period extraction based on singular value ratio (SVR) plotted as a function of the cycle length. The dominant SVR peak indicates the correct cycle length (50). Comparing SVR and FFT for period extraction When introducing a new method for period estimation it is only natural to ask oneself how it compares to standard methods such as Fast Fourier Transform (FFT). Figure 1.6 illustrates the above methodology along with the outcome of the FFT algorithm for the time series of Figure 1.3. It is evident that SVR Ô¨Ånds the correct period of the signal (p), whereas FFT Ô¨Ånds the correct number of cycles (q) which in turn leads to the correct p value. Fourier transform, however, falls short when it comes to more complex time series, especially with erratic behaviour. Figure 1.7 illustrates",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_25"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " whereas FFT Ô¨Ånds the correct number of cycles (q) which in turn leads to the correct p value. Fourier transform, however, falls short when it comes to more complex time series, especially with erratic behaviour. Figure 1.7 illustrates an example of a periodic signal that is amenable to period extraction by SVR but not by FFT. In other words, the recon- structed approximation need not be continuous. This produces high frequency noise due to successive under and overshoots. The reason for that is the sign changes in the amplitude that wreak havoc on the FFT spectrum, as can be seen in the left panel of Figure 1.8, (it shows the FFT-spectrum for the time series in Figure 1.7). In fact, it turns out that the FFT-power at 10 cycles (which is the correct number of cycles) is a relative minimum rather than a maximum. However, p ‚àíSV R plot correctly shows a spike at p = 50. Another difference between approximations based on SVD and Fourier is the choice of basis function used in the expansion. This will be addressed in the next section. 1.3.2. TIME SERIES APPROXIMATION Fourier analysis decomposes a given signal into a Ô¨Åxed set of sine-waves with steadily in- creasing frequencies. This works well for signals that are relatively slowly varying. How- ever, if the signal includes jumps or swings, FFT needs to aggregate a large number of terms in order to reach an acceptable accuracy. In contrast, the basis functions used in the SVD approach are obtained from the data at hand, and are therefore be determined in a data-driven fashion. The following example illustrates this observation. 12 1. INTRODUCTION Figure 1.7: An example of a noisy more complex signal that has 10 cycles with length 50), but the amplitude of each cycle varies erratically. The low-rank approximation (see main text for more details) is drawn in red. Figure 1.8: Left: FFT spectrum for time series in Figure 1.7. The spectrum fails to identify the correct number of cycles (which is 10). Right: Period extraction based on singular value ratio (SVR). There is a clear peak that the correct cycle length (which is 50). EXAMPLE: BURSTS WITH EXPONENTIAL DECAY The left panel of Figure 1.9 provides an example of a noisy periodic time series",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_26"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " ratio (SVR). There is a clear peak that the correct cycle length (which is 50). EXAMPLE: BURSTS WITH EXPONENTIAL DECAY The left panel of Figure 1.9 provides an example of a noisy periodic time series with sharp up-swings followed by exponential decays. In this example the underlying signal has a single and constant wavelength Œª with exponentially decaying bursts that are repeated at the beginning of every wavelength: x0(t) = exp(‚àíŒ±t/Œª) 0 ‚â§t ‚â§Œª To this uncorrupted signal we add various amounts of Gaussian noise: x(t) = xo(t)+œÉw(t) , w(t) ‚àºN(0,œÉ2)i.i.d Because of the burst-like nature of the signal, Fourier analysis is not well-suited for signal reconstruction in this case. The right panel of Figure 1.9 illustrates the power spec- 1.3. APPLYING SVD TO TIME SERIES 13 0 200 400 600 800 1000 number of samples -0.2 0 0.2 0.4 0.6 0.8 1 1.2 Time series: wavelength = 100, noise std = 0.05 0 0.05 0.1 0.15 0.2 0.25 Frequency (=1/p) 0 2 4 6 8 10 12 Fourier Power Spectrum Density Figure 1.9: Left: Burst-like signal with exponential decay, wavelength p = 100, amplitude = 1, Gaussian noise std = 0.05. Right: The corresponding Fourier power spectrum. The slow decay of the power spectrum is an early indication that approximation might be problematic trum density (PSD) of the aforementioned time series. The slow decay of the power spec- trum implies that FFT is not well suited to recover the underlying patterns of such time series. That is the prime motivation in many applications to search for more data-driven methods. Figure 1.10 provides examples of the reconstruction of the aforementioned time se- ries using the Fast Fourier Transform (FFT) approach with a different number of com- ponents. It is evident that FFT, in low-order approximations, is incapable of fully recon- structing the signal due to the burst-like shape of the signal. The left panel of Figure 1.11 illustrates the residuals of",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_27"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " com- ponents. It is evident that FFT, in low-order approximations, is incapable of fully recon- structing the signal due to the burst-like shape of the signal. The left panel of Figure 1.11 illustrates the residuals of the FFT based approach with 9 components. The spikes in this Ô¨Ågure indicates that 9 components were not enough for the FFT to be able to fully cap- ture the high-frequency burst-like shape of the time series. A comparison of the afore- mentioned residuals with a normal distribution is provided on the right panel. Figure 1.12 illustrates the Ô¨Årst two left and right singular vectors (obtained by recast- ing the original time series as a matrix and then applying the SVD). We will discuss the SVD approach in more detail in Chapter 2. The rank-2 SVD-based reconstruction of the time series along with its residuals is illustrated in Figure 1.13. The corresponding resid- uals for this rank-2 reconstruction are presented in Figure 1.14. As can be seen on the right panel the residuals nicely adhere to the normal distribution. Whereas Fourier decomposes all signals into sine waves, this is not the case for SVD. Complicated waves will give rise to complicated initial proÔ¨Åles. Put differently, whereas low-order approximations based on Fourier will be smooth and clearly sinusoidal, low- rank SVD can be arbitrarily complicated. This is already borne out in the example in Figures 1.10 and 1.12. 1.3.3. VISUALIZATION In the previous section, we explained how reshaping a time series as a matrix suggests an alternative way to determine the periodicity. Furthermore, there are additional advan- 14 1. INTRODUCTION 0 200 400 600 800 1000 -0.2 0 0.2 0.4 0.6 0.8 1 1.2 Original time series (blue) and FFT approximation with 3 components (red) 0 200 400 600 800 1000 -0.2 0 0.2 0.4 0.6 0.8 1 1.2 Original time series (blue) and FFT approximation with 5 components (red) 0 200 400 600 800 1000 -0.2 0",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_28"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "4 0.6 0.8 1 1.2 Original time series (blue) and FFT approximation with 5 components (red) 0 200 400 600 800 1000 -0.2 0 0.2 0.4 0.6 0.8 1 1.2 Original time series (blue) and FFT approximation with 9 components (red) 0 200 400 600 800 1000 -0.2 0 0.2 0.4 0.6 0.8 1 1.2 Original time series (blue) and FFT approximation with 50 components (red) Figure 1.10: Signal reconstruction for the time series on the left panel of Figure 1.9. Restricting the number of Fourier components to 3, 5, 9 and 50 fails to capture the discontinuous nature of the bursts. tages of such alternative representation. This change of viewpoint has two important applications: ‚Ä¢ Representing time series as images allow one to visually integrate patterns across longer time spans, and hence improves the discriminatory power. ‚Ä¢ Recasting such time series as matrices also suggest drawing on matrix decompo- sition theorems to elucidate the underlying structure by constructing approxima- tions which are more tightly linked to the structure of the time series. The SVD factorization suggests a straightforward method to smooth time series in such a way that the overall structure is preserved. Figure 1.15 provides another example of how SVD can be used to elucidate the underlying patterns in the data. Chapter 4 provides a detailed description of such a technique. For a given noisy time series, one constructs the corresponding data matrix A and then applies SVD to construct a low-rank approx- imation Ar which is then re-expanded as time series. This is illustrated in Figure 1.7 where a smoothed (red) based on a rank-2 approximation is constructed for the noisy signal (blue). 1.3. APPLYING SVD TO TIME SERIES 15 0 200 400 600 800 1000 number of samples -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 Residuals for FFT reconstructed with 9 components -4 -3 -2 -1 0 1",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_29"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ".6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 Residuals for FFT reconstructed with 9 components -4 -3 -2 -1 0 1 2 3 4 Standard Normal Quantiles -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 Quantiles of Input Sample QQ-plot for FFT-9 residuals Figure 1.11: Left: The residuals and its distribution compared to a normal distribution for a FFT-based recon- struction with 9 components As expected due to the burst-like shape of the signal FFT could not fully capture the pattern of the original time series. Right: QQ-plot of the residuals. Due to the spikes, the residuals are not fully normally distributed. Figure 1.12: Burst-like signal with exponential decay, wavelength = 100, amplitude = 1, Gaussian noise std = 0.05. The extracted proÔ¨Åle (top left) clearly shows the exponentially burst proÔ¨Åle, while the corresponding amplitudes (top right) indicate that the proÔ¨Åle is repeated with constant strength. The second proÔ¨Åle (bottom left) looks like pure noise, an impression further corroborated by the randomly distributed amplitudes (bottom right). 16 1. INTRODUCTION 0 200 400 600 800 1000 number of samples -0.2 0 0.2 0.4 0.6 0.8 1 1.2 Original (blue) and SVD-based rank-2 reconstructed time series (red) Figure 1.13: SVD-based rank-2 reconstruction of the time series. The details of the SVD is discussed in Chap- ter 2. 0 200 400 600 800 1000 number of samples -0.15 -0.1 -0.05 0 0.05 0.1 0.15 Residuals for SVD-based rank-2 reconstructed signal -4 -3 -2 -1 0 1 2 3 4 Standard Normal Quantiles -0.15 -0.1 -0.05 0 0.05 0.1 0.15 Quantiles of Input Sample QQ-plot for SVD-based",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_30"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 1 2 3 4 Standard Normal Quantiles -0.15 -0.1 -0.05 0 0.05 0.1 0.15 Quantiles of Input Sample QQ-plot for SVD-based rank-2 residuals Figure 1.14: Left: Residuals for the SVD-based rank-2 reconstruction of the time series. In contrary to the FFT where even by considering 9 components the reconstruction was not satisfactory (see Figure 1.11), here a rank- 2 reconstructed time series accurately captures the underlying pattern of the time series. Right: The residuals are almost fully normally distributed. 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -1 -0.5 0 0.5 1 Figure 1.15: An example of enhancing the underlying patterns in the data using lower-rank approximation (the original data on the left and the enhanced version on the right) 1.3. APPLYING SVD TO TIME SERIES 17 1.3.4. PATTERN EXTRACTION Figure 1.16 provides an illustrative example of the SVD decomposition. The top left panel shows a noisy zero-mean block signal of length n = 1000 with a pronounced period p = 100 and q = 10 full cycles. In addition to the noise, there are three irregularly occur- ring spikes. After recasting this time series as a 100√ó10 matrix A, we then apply the SVD algorithm to obtain A = USV T where S is a 100√ó10 ‚Äúrectangular diagonal‚Äù matrix with the 10 singular values on its main diagonal. The top right panel shows those ten singular values, clearly illustrating that all except the Ô¨Årst two are negligible, which means that the matrix (and therefore the time series) can be accurately represented by truncating the ex- pansion in Eq. (2.5) after the Ô¨Årst two terms, i.e., rank-2 approximation",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_31"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " are negligible, which means that the matrix (and therefore the time series) can be accurately represented by truncating the ex- pansion in Eq. (2.5) after the Ô¨Årst two terms, i.e., rank-2 approximation (see Figure 1.17). Finally, the bottom panel of Figure 1.16 displays the Ô¨Årst three columns of U (left) and V Figure 1.16: SVD application to pattern-extraction in noisy block signal. Top left: Original data of noisy block signal with period 100. In addition to the noise there are three irregularly occurring spikes. Top right: The 10 singular values for SVD with period p = 100. Clearly, only the two Ô¨Årst are signiÔ¨Åcant and œÉ1 ‚â´œÉ2 conÔ¨Årming that p = 100 corresponds to a valid periodicity. Bottom: The Ô¨Årst three columns of U (left) and V (right). (right), respectively. As they correspond to the most signiÔ¨Åcant singular values, they are most important for the reconstruction of the signal. TheU-columns cover one cycle and can be interpreted as successive proÔ¨Åles needed to reconstruct a generic cycle. In that sense, they are analogous to various trigonometric basis functions in Fourier analysis. The V -columns, on the other hand, specify the amplitudes with which these basis func- 18 1. INTRODUCTION tions need to be combined in order to reproduce the individual cycles observed in the data. Not surprisingly, the main proÔ¨Åle (U1 top left) reÔ¨Çects the step-like behaviour seen during each cycle. As the amplitude of each of these steps is essentially constant, the 10 V1-entries displayed in the top-right panel show little variation. The U2 proÔ¨Åle (middle, left) captures the shape of the additional spikes that occur at irregular intervals. The pos- itive values in the corresponding V2-coefÔ¨Åcients (middle, right) clearly indicate in which intervals these spikes occur. Finally, the erratic appearance of bothU3 and V3 is a further indication (in line with œÉ3 ‚âà0) that all structural information has been extracted from the signal. Figure 1.17: Top: Original (blue) and rank-2 approximation (red) of the block-signal. Bottom: Res",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_32"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " (in line with œÉ3 ‚âà0) that all structural information has been extracted from the signal. Figure 1.17: Top: Original (blue) and rank-2 approximation (red) of the block-signal. Bottom: Residuals with respect to the approximation. 1.4. CHALLENGES AND RESEARCH QUESTIONS So far in this chapter, we have outlined the essential theoretical concepts of the SVD that are used throughout this thesis. We also have introduced the research domain and main motivations of this thesis. In this section, we delve deeper into speciÔ¨Åc issues that arise in time series analysis, and the SVD in its traditional form. We further distinguish vari- ous problems in energy market analysis. In particular, we outline the following research questions: 1.4. CHALLENGES AND RESEARCH QUESTIONS 19 Research Question 1 As explained in section 1.3.1 the authors in [2] introduced the idea of using the ratio of the two largest singular values (i.e., the so-called singular value ratio SVR) to determine the period of a time series (signal). However, they did not re- alise that the SVR depends on the signal mean. As a consequence, thresholding the SVR value is meaningless unless we take this effect into account. This is the topic of our Ô¨Årst research question: Q1: How does the mean of a signal affect the singular value ratio SVR? Chapter 2 provides a thorough understanding of the SVD result and its geometrical in- terpretation. This chapter also contains a number of examples of how the position and orientation of the same cloud of points from the origin have led to different SVD results. After providing a background on random matrices in Chapter 3, we have delved deeper into this question and have measured the effect of distance from the origin on the sin- gular values, in an example. Research Question 2 In the above setup, the number of columns corresponds to the number of observed cycles and will therefore increase as more data are acquired. Indeed, as each column represents the data from one period, observing more periods gives rise to additional columns, making the matrix ‚Äúfatter‚Äù and thus increasing the aspect ratio (i.e. number of columns over the number of rows). Therefore, it is natural to ask how changes in the aspect ratio will affect the results. Many math papers focus on square matrices",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_33"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " the matrix ‚Äúfatter‚Äù and thus increasing the aspect ratio (i.e. number of columns over the number of rows). Therefore, it is natural to ask how changes in the aspect ratio will affect the results. Many math papers focus on square matrices, but for applications to time series, it is important to understand the more general case of rectangular matrices. This is addressed by the next research question: Q2: How does the aspect ratio of a matrix affect the singular value ratio (SVR)? In Chapter 3, we have extended the work in earlier papers by initiating a more systematic analysis of these effects. Research Question 3 Matrix factorisation techniques such as principal component analysis (PCA) and singular value decomposition (SVD) are both conceptually simple and effective. However, it is well-known that they are sensitive to noise and outliers in input data. One way to mitigate this sensitivity is to introduce regularisation terms. In order to do this, in Chapter 4 we hark back to the interpretation of SVD and PCA in terms of low-rank approximation. Adding regularisation terms to these functionals gives rise to new but related minimisation problems. ‚Ä¢ Q3 a: How can we develop a regularized version of the PCA problem? This problem is addressed in Section 4.2. ‚Ä¢ Q3 b: How can we develop a regularized version of the SVD problem? This problem is addressed in Section 4.3. 20 1. INTRODUCTION Research Question 4 Scenario-based probabilistic forecasting models have been ex- tensively explored in the literature in recent years. A particular application of such mod- els is in the energy sector, where e.g., having the distribution of the energy consump- tion for the coming days is desired. A decisive variable in predicting the energy de- mand (target variable) is the temperature data (an attribute or a predictor) [4]. There are mainly three practical and popular methods for generating temperature scenarios, namely Ô¨Åxed-date, shifted-date, and bootstrap approaches [5]. Nevertheless, these meth- ods have mostly been used on an ad-hoc basis without being formally compared or quantitatively evaluated. Q4: In scenario-based probabilistic forecasting problems, how can we sim- ulate realistic proÔ¨Åles for an independent variable? In Chapter 5 we propose a generic, data-driven and computationally efÔ¨Åcient SVD-based approach to simulate different scenarios. Research Question ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_34"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " forecasting problems, how can we sim- ulate realistic proÔ¨Åles for an independent variable? In Chapter 5 we propose a generic, data-driven and computationally efÔ¨Åcient SVD-based approach to simulate different scenarios. Research Question 5 Volatility principally refers to random Ô¨Çuctuations of a time series about its mean or expected value. Generally speaking, in Ô¨Ånancial time series data analytics, volatility is measured by the standard deviation of the logarithmic return or a derivation of that [6]. In the literature, numerous methods have been introduced to determine the volatility of the time series data. However, the emergence of non-positive price values in the energy transition era has introduced new challenges in the market volatility analysis. Q5 a: How can we quantify the volatility of the electricity price time se- ries data with zero or negative prices? In the Ô¨Årst part of Chapter 6, we will address this problem and propose a notion of volatility that can handle negative prices. Furthermore, along with the increase in the utilization of intermittent renewable sources, short-term electricity market studies are becoming increasingly popular. Therefore, in the Ô¨Ånal part of this chapter we address the following question: Q5 b: Has the stimulation of renewable energy sources led to a notice- able changes in the (day-ahead) electricity market? In the Ô¨Ånal part of Chapter 6, we will analyse the evolution of the day-ahead electricity market in Germany in 2006-2016. 1.5. THESIS OUTLINE The rest of this thesis is structured as follows. The SVD technique is the cornerstone of this thesis. Therefore, we Ô¨Årst in Chapter 2 review the relevant theorems underpinning this method. We then delve deeper into the geometrical interpretation of the SVD. This chapter also provides a number of examples of how the position with respect to the ori- gin and the alignment of data points affects the singular vectors and the singular values. That in turn enables us to have an intuitive answer for Research Question 1. However, 1.5. THESIS OUTLINE 21 more in-depth discussions over the Ô¨Årst two research questions are provided in the next chapter. For most applications of the SVD in various Ô¨Åelds, it is vital to understand the proper- ties of SVD of a matrix whose entries show some degree of random Ô¨Çuctuations. There- fore, in order to determine",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_35"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " For most applications of the SVD in various Ô¨Åelds, it is vital to understand the proper- ties of SVD of a matrix whose entries show some degree of random Ô¨Çuctuations. There- fore, in order to determine how the noise level affects the singular value spectrum, it is essential to study the singular value decomposition of random matrices. Having pro- vided a background in random matrices, Chapter 3 addressed Research Question 1 and Research Question 2 in full detail. The SVD and PCA techniques are both conceptually simple and effective. However, it is well-known that they are sensitive to the high level of presence of noise and outliers in input data. In the literature, some modiÔ¨Åcations of the original algorithms of SVD and PCA have been proposed to alleviate the effect of these disturbances. In particular, one way to mitigate this sensitivity is to introduce regularisation terms. To this aim, in Chapter 4 we Ô¨Årst hark back to the interpretation of PCA and SVD in terms of low-rank approximations. We then have offered solutions to Research Question 3a and Research Question 3b in Section 4.2 and Section 4.3, respectively. With the growing integration of renewable energy sources (RES) such as wind and solar energy into the power grid, balancing the grid has become more challenging. It is mostly due to the inherently intermittent nature of RES, on the one hand, and shortcom- ings in bulk energy storage systems, on the other. Therefore, studies on scenario-based probabilistic energy production and demand forecasts have gained momentum, as they are highly valuable from both a technical and an economic point of view [7]. Chapter 5 proposes a generic framework for probabilistic load forecasting using an ensemble of regression trees. This chapter proposes a solution to Research Question 4 by generating various examples of a predictor (temperature in this case) using the SVD results. The generated samples are then used in an ensemble of regression trees to obtain the distri- bution of the target variable (load proÔ¨Åle) in future times. Chapter 6 is dedicated to Research Question 5, i.e., what effect the transition of en- ergy to RES can have on the overall trend and also the volatility of the electricity prices. In this chapter, we exemplify how the emergence of zero or even negative price values in the day-ahead market in Germany in recent years has introduced",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_36"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " en- ergy to RES can have on the overall trend and also the volatility of the electricity prices. In this chapter, we exemplify how the emergence of zero or even negative price values in the day-ahead market in Germany in recent years has introduced new challenges in the electricity market volatility analysis. More precisely, in this new market, the traditional approaches to switch to logarithmic measures can only be done after shifting up all val- ues above zero by a certain threshold. However, price volatility has a dependence on the price level, which is even more pronounced when the spot prices are low. Therefore, the aforementioned pre-processing step can affect the Ô¨Ånal outcome and its generalizability. The Ô¨Årst part of this chapter offers a solution to Research Question 5a by introducing a new notion of volatility which was obtained by reconstructing the time series using the SVD. Our observations indicate price volatility reduction, in the day-ahead market, in the years 2006-2016. The second part of this chapter addressed Research Question 5b and provided pieces of evidence of the effect of renewables on daily price proÔ¨Åles ‚Äì the emergence of non-positive prices and also shifts of peak price values to hours where so- lar is less available. A summary of this thesis along with some future research directions is provided in Chapter 7. 22 1. INTRODUCTION 1.6. LIST OF PUBLICATIONS In this section, we present an overview of the research publications comprising this the- sis. Journals 1. Abdolrahman Khoshrou, Eric J Pauwels. Regularisation for PCA-and SVD-type matrix factorisations. preprint 2021. Springer - Advances in Computational In- telligence2. 2. Abdolrahman Khoshrou, and E.J. Pauwels. Short-term scenario-based proba- bilistic load forecasting: A data-driven approach. 2019. Elsevier - Applied Energy. 3. Abdolrahman Khoshrou, Andr√© Dorsman, Eric J. Pauwels. The evolution of elec- tricity price on the German day-ahead market before and after the energy switch. 2019. Elsevier - Renewable Energy. Conferences 1. Abdolrahman Khoshrou, Eric J. Pauwels. Data-driven pattern identiÔ¨Åcation and outlier detection in time series. 2018.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_37"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 2019. Elsevier - Renewable Energy. Conferences 1. Abdolrahman Khoshrou, Eric J. Pauwels. Data-driven pattern identiÔ¨Åcation and outlier detection in time series. 2018. Springer, Cham - Science and Information Conference. 2. Abdolrahman Khoshrou, Eric J Pauwels. Quantifying volatility reduction in Ger- man day-ahead spot market in the period 2006 through 2016. 2018. IEEE - Power & Energy Society General Meeting (PESGM). 3. Abdolrahman Khoshrou, Andr√© Dorsman, Eric J. Pauwels. SVD-based Visualisa- tion and Approximation for Time Series Data in Smart Energy Systems. 2017. IEEE - Innovative Smart Grid Technologies Conference Europe (ISGT-Europe). 4. Abdolrahman Khoshrou, Eric J Pauwels. Propagating uncertainty in tree-based load forecasts. 2017. IEEE - Electrical and Electronics Engineering (ELECO), 2017 10th International Conference. 5. Andr√© Dorsman, Abdolrahman Khoshrou, Eric J. Pauwels. The inÔ¨Çuence of the switch from fossil fuels to solar and wind energy on the electricity prices in Ger- many. 2016. ISINI conference in Groningen. 2Part of this work was published at Belgian-Netherlands ArtiÔ¨Åcial Intelligence Conference (BNAIC) 2021. REFERENCES 23 REFERENCES [1] V. Verendel and S. Yeh, Measuring trafÔ¨Åc in cities through a large-scale online plat- form, Journal of Big Data Analytics in Transportation 1, 161 (2019). [2] P. P. Kanjilal and S. Palit, On multiple pattern extraction using singular value decom- position, IEEE transactions on signal processing 43, 1536 (1995). [3] P. P. Kanjilal and S. Palit, The singular value decomposition‚Äîapplied in the modelling and prediction of quasi-periodic processes, Signal processing 35, 257 (1994). [4] A. Khoshrou and E. J. Pauwels, Short-term scenario-based probabilistic load forecast- ing: A data-driven approach, Applied Energy 238, ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_38"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " processing 35, 257 (1994). [4] A. Khoshrou and E. J. Pauwels, Short-term scenario-based probabilistic load forecast- ing: A data-driven approach, Applied Energy 238, 1258 (2019). [5] T. Hong et al., Energy forecasting: Past, present, and future, Foresight: The Interna- tional Journal of Applied Forecasting , 43 (2014). [6] Financial chaos theory, http://quantonline.co.za/Articles/article_ volatility.htm. [7] T. Hong and S. Fan, Probabilistic electric load forecasting: A tutorial review, Interna- tional Journal of Forecasting 32, 914 (2016). 2 SINGULAR VALUE DECOMPOSITION: A RECAP 2.1. INTRODUCTION The singular value decomposition (SVD) technique is the cornerstone of this thesis. We hence start this chapter by reviewing the relevant theorems underpinning the SVD method. Before proceeding with that, however, let us Ô¨Årst recall the deÔ¨Ånition of a (multiplica- tive) group of orthogonal matrices of dimension n: O(n) := ¬© U ‚ààRn√ón | UU T = In =U TU ¬™ (2.1) Notice that from the deÔ¨Ånition it immediately follows that det(U) = ¬±1 (2.2) since det(UU T ) = det(U)det(U T ) = (det(U))2 = det(In) = 1. This observation motivates the introduction of a subgroup of special orthogonal matri- ces of unit determinant: SO(n) := ¬© U ‚ààRn√ón | UU T = In =U TU and det(U) = 1 ¬™ (2.3) 2.2. SINGULAR VALUE DECOMPOSITION As we exempliÔ¨Åed earlier in Chapter 1, the FFT works in an idealized setting. Further- more, the SVD, in a sense, generalizes the concept of FFT. In other words, SVD allows us to transform or tailor a coordinate system, based on the data itself (data-driven). It is a widely adaptive method and is mostly based on simple and interpretable linear algebra. As a result of that, every time we have a matrix of data, we can compute the SVD and",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_39"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ", based on the data itself (data-driven). It is a widely adaptive method and is mostly based on simple and interpretable linear algebra. As a result of that, every time we have a matrix of data, we can compute the SVD and address different problems based on that [2]. The following sections provide a detailed description of the SVD and its geometrical intuitions. Parts of this chapter have been published in [1]. 25 26 2. SINGULAR VALUE DECOMPOSITION: A RECAP 2.2.1. SVD: MAIN RESULT We herein recall the well-known SVD technique and develop an intuition for how to ap- ply it in the following chapters. For more details, we refer to standard textbooks such as [3, 4]. Theorem 1 (Singular Value Decomposition). Any real-valued p √óq matrix A can be fac- torized into the product of three matrices: Ap√óq =Up√ópSp√óqV T q√óq (2.4) where U ‚ààO(p) and V ‚ààO(q) are orthogonal, and S is a p √ó q diagonal matrix where the elements on the main ‚Äúdiagonal‚Äù (so-called singular values ) are non-negative (i.e., œÉi := Sii ‚â•0 for 1 ‚â§i ‚â§min(p,q)). Assuming that the rank rk(A) = r ‚â§min(p,q), we can sort the singular values such that œÉ1 ‚â•œÉ2 ‚â•... ‚â•œÉr > 0 = œÉr+1 = ... = œÉmin(p,q) and recast Eq. (2.4) as (see Figure 2.1, bottom panel, for an ‚Äúeconomic\" expansion of SVD.) A = rX i=1 œÉiUiV T i where Ui,Vi are the i-th columns of U and V , respectively. (2.5) For the singular values sorted as above, we then introduce the short-hand notation U(1:k) and V(1:k) to denote the matrix comprising the Ô¨Årst k columns of U and V , respectively: U(1:k) := [U1,U2,...,Uk] and V(1:k) := [V1,V2,...,Vk] In this notation, Eq. (2.5) can be expressed concisely as (see Figure 2.1, top panel): A =U",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_40"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "k] and V(1:k) := [V1,V2,...,Vk] In this notation, Eq. (2.5) can be expressed concisely as (see Figure 2.1, top panel): A =U(1:r) diag(œÉ1,...,œÉr )V T (1:r) (2.6) To appreciate the signiÔ¨Åcance of Theorem 1, it is helpful to highlight its geometric interpretation. Recall that any p √ó q matrix A gives rise to a corresponding linear trans- formation A : Rq ‚àí‚ÜíRp that maps the standard basis in Rq into the columns of A: Aek = Ak where ek = (0,0,...,0,1,0,...,0)T Roughly speaking, the SVD theorem, therefore, tells us that it is always possible to select an orthonormal basis in Rq (columns of V ) that is mapped (up to non-negative scaling factors, i.e., the singular values) into an orthonormal basis in Rp (columns of U). This is immediately obvious from Eq. (2.5): AV‚Ñì= rX k=1 œÉkUkV T k V‚Ñì= rX k=1 œÉkUkŒ¥k‚Ñì= œÉ‚ÑìU‚Ñì where Œ¥k‚Ñìis a Kronecker delta function. It is worth noting that insisting on the orthog- onality of V (V T V = Iq) is not restrictive. Indeed, a linear transformation is completely 2.2. SINGULAR VALUE DECOMPOSITION 27 Figure 2.1: An overview of matrix decomposition using SVD, in matrix form (top) and dyadic form (bottom). and uniquely determined by specifying its effect on any basis; hence, there is no loss of generality by insisting on the orthonormality of this basis. However, the non-trivial message of this theorem is that orthonormal bases (V ) can be chosen in such a way that their image (transformation) U under A is also orthonor- mal (up to non-negative scaling). Furthermore, in a generic case, where all the singu- lar values are different, the SVD is unique up to an arbitrary relabeling of the basis- vectors and a simultaneous sign-Ô¨Çip of the corresponding columns in U and V , i",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_41"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " generic case, where all the singu- lar values are different, the SVD is unique up to an arbitrary relabeling of the basis- vectors and a simultaneous sign-Ô¨Çip of the corresponding columns in U and V , i.e., (U‚Ñì,V‚Ñì) ‚Üí(‚àíU‚Ñì,‚àíV‚Ñì) for any number of columns. 2.2.2. SINGULAR VALUES ARE EIGENVALUES OF SQUARED MATRICES From A =USV T it follows that AT = V SU T and consequently1: AAT =USSTU T and therefore (AAT )U =U(SST ) (2.7) This means that the columns of U are eigenvectors of the positive deÔ¨Ånite, symmetric matrix AAT , with positive eigenvalues: Œªi(AAT ) = œÉ2 i 1S is diagonal, hence S = ST . 28 2. SINGULAR VALUE DECOMPOSITION: A RECAP A similar observation can be made for V which turn out the be the eigenvectors of AT A and again: Œªi(AT A) = œÉ2 i Because the matrices AAT and AT A are symmetric and semi-positive it follows that all the eigenvalues are real and non-negative. In summary, we derive the following useful relationship between the singular values of a matrix A ‚ààRp√óq and the eigenvalues of the related matrices AAT and AT A: œÉ2 i (A) = Œªi(AAT ) = Œªi(AT A) (2.8) or equivalently: œÉi(A) = q Œªi(AAT ) = q Œªi(AT A) for i = 1 : min(p,q) (2.9) where i = 1 : min(p,q). For a given matrix A we use the notation œÉi(A) or Œªi(A) to denote the i-th (in de- scending order) singular or eigenvalue, respectively. If there is no danger of confusion, the explicit reference to the matrix will be suppressed. 2.2.3. SVD SOLVES A MINIMISATION PROBLEM The importance of the SVD result is the following well-known theorem (more details can be found in [5, 6]). Theorem 2 (Eckart-Young-Mirsky Theorem2). Let us consider a p √ó q matrix A with rank rk",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_42"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "VD result is the following well-known theorem (more details can be found in [5, 6]). Theorem 2 (Eckart-Young-Mirsky Theorem2). Let us consider a p √ó q matrix A with rank rk(A) = r ‚â§min(p,q). For k < r, Ô¨Ånding the rank-k matrix Ak that is closest to A in (Frobenius) norm gives rise to the following constrained minimisation problem: min Ak ||A ‚àíAk||2 subject to rk(Ak) ‚â§k The solution to this problem is obtained by truncating the SVD expansion Eq. (2.5) after the k-th largest singular value: Ak = kX i=1 œÉiUiV T i =U(1:k) diag(œÉ1,...,œÉk)V T (1:k) (2.10) Recall that a rank-k matrix of size p √ó q can always be written as a product Ak = PQT where P ‚ààRp√ók and Q ‚ààRq√ók are matrices of full rank k. In this factorisation, there is no loss of generality in requiring QTQ = Ik. In fact, it is necessary to remove indeterminacy due to arbitrary but trivial rescalings such as P 7‚àí‚ÜírP while Q 7‚àí‚Üí(1/r)Q (with r Ã∏= 0), and the like. We will discuss this alternative formulation of Theorem 2 as the factorisation result in Theorem 3. 2Also referred to as the optimal low rank approximation theorem. 2.3. GEOMETRIC INTERPRETATION 29 2.3. GEOMETRIC INTERPRETATION The following section describes important mathematical properties of SVD including geometric interpretations of the unitary matrices U and V. 2.3.1. INCREMENTAL SVD: COMPUTING BEST RANK-1 APPROXIMATION The general SVD result can be obtained incrementally, by constructing the best rank-1 approximation, then subtracting this approximation and repeating this procedure. This follows directly from Eq. (2.5) which can be recast as: A ‚àíœÉ1U1V T 1 = rX i=2 œÉiUiV T i (2.11) which shows that the next term in the expansion can be obtained by computing the SVD of the residual A‚àíœÉ1U1",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_43"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "1U1V T 1 = rX i=2 œÉiUiV T i (2.11) which shows that the next term in the expansion can be obtained by computing the SVD of the residual A‚àíœÉ1U1V T 1 . Using this insight, it follows that we can focus on computing the Ô¨Årst singular value and vector. This is helpful as it turns out that the Ô¨Årst singular value and vectors have a straightforward interpretation which we will explain next (also see Figure 2.2). To extract the Ô¨Årst singular value and vectors of A we proceed as follows: Figure 2.2: A geometric interpretation on how SVD recursively factorise a given matrix A. ‚Ä¢ Assuming A is a p √ó q matrix, the optimal rank-1 approximation A1 is of the form: A1 = Œ≤pqT where p and q are unit column vectors of size p and q respectively. 30 2. SINGULAR VALUE DECOMPOSITION: A RECAP ‚Ä¢ By virtue of Theorem 2, the p-dimensional vector p can be determined uniquely (up to a sign change) by constructing the regression line L passing from the origin towards the p-dimensional points a1,a2,...,aq. Denote the orthogonal projection of ai onto the regression line by Œ±ip. ‚Ä¢ To determine the corresponding q we use the fact that the rank-1 matrix A1 maps the standard unit vectors ei to Œ±ip (for i = 1,2,...,q). Hence, A1ei = Œ≤pqT ei = Œ≤qip From this it follows that ‚àÄi = 1,2,...,q : Œ±i = Œ≤qi and consequently: Œ≤2 = qX i=1 Œ±2 i since qX i=1 q2 i = 1 ‚Ä¢ From this we can now explicitly determine q: qi = Œ±i Œ≤ = Œ±i qPq i=1 Œ±2 i Take-home message From the above derivation we conclude that the regression line (through the origin) L essentially determines the rank-1 approximation A1 = Œ≤pqT : 1. p is the unit vector along the regression line L; this Ô¨Åxes the coefÔ¨Åcients Œ±i. 2. Singular value: Œ≤ = qPŒ±2 i . 3. q is the unit vector proportional to (Œ±1,Œ±2,...,Œ±q). This observation has a number of important",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_44"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " coefÔ¨Åcients Œ±i. 2. Singular value: Œ≤ = qPŒ±2 i . 3. q is the unit vector proportional to (Œ±1,Œ±2,...,Œ±q). This observation has a number of important consequences: 1. The SVD does not solely depend on the shape of the point cloud, but also on its position with respect to the origin. More precisely: if the position of the cloud is large compared to its size (is far from the origin), the Ô¨Årst singular vectors and the corresponding singular value (and hence the rank-1 approximation) are deter- mined by its position. However, when we shift it closer to the origin, the singular vector switches adapting to the shape of the cloud. Figure 2.3 provides an illustra- tive example of how moving further from the origin can drastically affect the Ô¨Årst singular vector. 2. The above reasoning would also suggest that movement on the line along with the Ô¨Årst singular vector away from the origin will not affect the 2nd singular value/vec- tors (see Figure 2.4). 3. Figure 2.4 exempliÔ¨Åes why the ratio œÉ1/œÉ2 does not necessarily tell us something about the shape (and therefore periodicity) of the point cloud (time series). 2.3. GEOMETRIC INTERPRETATION 31 Figure 2.3: A plain example of how the direction of the Ô¨Årst (and higher order) singular vectors can change with respect to the distance of the cloud of points from the origin. Figure 2.4: Example where the position rather than the shape of the point cloud determines the ratio œÉ1/œÉ2. 2.3.2. INTUITIVE CONTINUITY-BASED ARGUMENT FOR SVD When restricting our attention to the 2-dimensional case, it is easy to get a feel as to why SVD holds. It also hints at why the result is less surprising than might seem at Ô¨Årst blush. The following is not meant as proof, but simply as an aid to intuition. Consider Figure 2.5, we can make the following observations: ‚Ä¢ SubÔ¨Åg 0: Consider an ortho-frame, i.e., orthonormal frame (red and green vector) that is mapped under the linear transformation A to the non-orthonormal basis on the RHS of the",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_45"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " observations: ‚Ä¢ SubÔ¨Åg 0: Consider an ortho-frame, i.e., orthonormal frame (red and green vector) that is mapped under the linear transformation A to the non-orthonormal basis on the RHS of the Ô¨Ågure. Let us assume that the angle between the red and green vectors is acute. ‚Ä¢ SubÔ¨Åg 1: Now rotate the ortho-frame counter-clockwise over 90o to the new po- sition. Notice that the red vector is now in the same position as the green vector previously. This will also rotate the image of the ortho-frame to a new position. 32 2. SINGULAR VALUE DECOMPOSITION: A RECAP Figure 2.5: For more information, see main text, Section 2.3.2 2.4. DATA ALIGNMENT 33 Let‚Äôs once again assume that during this rotation the angle in the RHS remains (strictly) less than 90o (otherwise nothing remains to be proved). ‚Ä¢ SubÔ¨Åg 2: We continue the rotation and use the same assumptions. ‚Ä¢ SubÔ¨Åg 3: Executing a third 90o-rotation now puts the green vector of the ortho- frame in the original position of the red vector, and the red vector in the previous position of the green vector. This means that their images are known. The image for the green vector is known in SubÔ¨Åg 0 and for the red vector in known in SubÔ¨Åg 2. And more importantly, assuming that the angles (between the image vectors) in the previous moves were always less than 90o, it follows that it now must be in ex- cess of 90o. Using the argument from continuity, we can conclude that somewhere during the last rotation of the ortho-frame, its image subtended a right angle, ex- actly what the SVD theorem implies. 2.4. DATA ALIGNMENT One of the common pitfalls of the SVD is associated with misaligned data. Figures 2.7- 2.8 highlight the fact that SVD is geometric, meaning that it depends on the coordinate system in which the data is represented. In other words, SVD is only generically invariant to unitary transformations where only the inner products are preserved (see Figure 2.6). This fact may be viewed as the reason for or against this method",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_46"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " in which the data is represented. In other words, SVD is only generically invariant to unitary transformations where only the inner products are preserved (see Figure 2.6). This fact may be viewed as the reason for or against this method. First, the inner product at the core of such matrix decomposition technique is essential for various insightful geometric interpretations. Furthermore, the results of the SVD contain meaningful units and dimensions. On the negative side, the SVD is liable to the alignment of the data. In fact, the SVD rank of the matrix inÔ¨Çates drastically when ‚Äúobjects\" in matrix data (a certain pattern in data) translate, rotate, or scale, which severely constrains its use for the cases where data has not been heavily pre-processed. In other words, in a given set of coordinates, the SVD is unable to capture translations and rotations of the data. 2.5. COMPARING SVD AND PCA Principal component analysis (PCA), also known as the Karhunen-Lo√®ve transform, is a popular matrix decomposition technique that is used in diverse applications such as dimensionality reduction, lossy data compression, feature extraction, and data visual- ization [7]. There are two commonly used deÔ¨Ånitions of PCA that lead to the same algorithm. PCA can be deÔ¨Åned as the orthogonal projection of the data points onto a lower dimen- sional linear space, known as the principal subspace, in such a way that the variance of the projected data is maximized [8]. On a similar note, PCA can be deÔ¨Åned as the lin- ear projection that minimizes the average projection cost, deÔ¨Åned as the mean squared distance between the data points and their projections [9]. 2.5.1. PCA We herein consider the latter deÔ¨Ånition of PCA mentioned above, and investigate how it relates to the SVD. 34 2. SINGULAR VALUE DECOMPOSITION: A RECAP Figure 2.6: Top: The singular value ratio stays relatively the same if the distance from the origin is the same, regardless of the position of the cloud of points with respect to the origin (bottom). 2.5. COMPARING SVD AND PCA 35 Figure 2.7: The evolution of œÉ1 and œÉ2 (top) and their corresponding ratio (bottom) while the cloud of points moving",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_47"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " to the origin (bottom). 2.5. COMPARING SVD AND PCA 35 Figure 2.7: The evolution of œÉ1 and œÉ2 (top) and their corresponding ratio (bottom) while the cloud of points moving on a circle around the origin. As expected, both singular vectors change depending on the alignment and the position of the cloud with respect to the origin. The black vector is the direction of the Ô¨Årst singular vector and the yellow one is the direction of the second singular vector. 36 2. SINGULAR VALUE DECOMPOSITION: A RECAP Figure 2.8: A representation on how alignment of the could and its distance from the origin affects the singular value ratio. In this Ô¨Ågure cloud with œÜ = ‚àí120o has the highest œÉ1/œÉ2 ratio. Theorem 3 (PCA-type factorisation). Assume that a p√óq matrix A has rank rk(A) = r ‚â§ min(p,q). We now deÔ¨Åne the functional G(P,Q) as follow: G(P,Q) = ||A ‚àíPQT ||2 (2.12) and the corresponding constrained optimisation problem: min P,Q G(P,Q) subject to rk(P) = rk(Q) = k and QTQ = Ik (2.13) where k < r. A solution to the above constrained minimisation problem (in P ‚ààRp√ók and Q ‚ààRq√ók) is given by (using the SVD notation given in Eq. (2.10)): Q = V(1:k) and P =U(1:k) diag(œÉ1,...,œÉk) (2.14) hence: PQT = kX i=1 œÉiUiV T i (2.15) From Eq. (2.14) this it also follows that PT P is diagonal, but not necessarily equal to the identity. Note that if we drop the insistence on the diagonal form for PT P (i.e., P need no longer be an orthogonal frame), then the solution is no longer unique. Indeed, by taking any k √ók orthogonal matrix R with RT R = Ik = RRT , it is clear that P‚Ä≤ = PR and Q‚Ä≤ = QR are also solutions. In this case: Q‚Ä≤TQ‚Ä≤ = RTQTQR = Ik but P‚Ä≤T P‚Ä≤ = RT PT PR = RT (SST )R is in general a",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_48"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " that P‚Ä≤ = PR and Q‚Ä≤ = QR are also solutions. In this case: Q‚Ä≤TQ‚Ä≤ = RTQTQR = Ik but P‚Ä≤T P‚Ä≤ = RT PT PR = RT (SST )R is in general a positive deÔ¨Ånite symmetric matrix. 2.5. COMPARING SVD AND PCA 37 Figure 2.9: ConÔ¨Årmation that PCA and the SVD of the mean-subtracted data are the same (up to a sign change). 2.5.2. SVD VS. PCA In a sense, SVD is equivalent to PCA in multivariate statistics, but in addition, is used to generate low-dimensional representations for complex multidimensional time series. SVD and PCA of a given matrix are related to one another through the covariance matrix. In other words, if X =USV T then for the covariance matrix we can write: X T X = V SU TUSV T = V S2V T now, if we multiply both sides by V , it yields: (X T X )V = V S2 where V is the matrix of the eigenvectors of the matrix X T X and S2 is the diagonal matrix of the eigenvalues. ‚Ä¢ If the actual position of the point cloud matters, SVD is the better option; e.g., the Ô¨Årst singular vector is usually close to the centre of gravity; 38 2. SINGULAR VALUE DECOMPOSITION: A RECAP ‚Ä¢ When only the shape of the data cloud is of importance, then PCA is more appro- priate. Figure 2.9 implies the above-mentioned results. Shifting the data to the origin does not change how the data points are positioned relative to each other. That is why the results of PCA are unbiased with respect to the mean of the matrix. 2.6. ADDENDUM: ADDRESSING COMPUTATIONAL ARTEFACTS In this thesis, we make extensive use of simulation and SVD-based computations. As a consequence, accurate sampling from various matrix distributions is important. Through comprehensive experiments, we have become aware of certain biases and artefacts that are present in the implementations of the algorithms in Matlab and Python. Unless these artefacts are remedied, they might introduce biases that invalidate ensuing results and conclusions. Figure 2.10: Left: Results (sum of the U vectors) from the original computations; Right: same results but with random",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_49"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " and Python. Unless these artefacts are remedied, they might introduce biases that invalidate ensuing results and conclusions. Figure 2.10: Left: Results (sum of the U vectors) from the original computations; Right: same results but with random signs. 2.6.1. SVD COMPUTATIONS IN MATLAB Some of the unexpected results might be the consequence of computational artefacts. From the numerical evidence we have seen, it looks like the computational algorithms have a bias towards the selection of certain singular vectors. This is illustrated in the fol- lowing experiment: Generate a random 2√ó2 matrix A according to the normal and expo- nential distribution. Since the columns ofU (obtained by the SVD) form an orthonormal basis in the plane we can easily depict the result graphically. Rather than showing both vectors, we compute the sum as a 1-vector representation; all of these vectors are on the p 2 circle (see Figure 2.10). The results for the normal distribution are shown in red, and for the exponential in blue. The raw output of the algorithm is shown on the left panel of the Ô¨Ågure. It shows clear artefacts in the distribution (especially for the exponential results). If we randomize the U-vectors by assigning a random sign to them (i.e., ran- 2.6. ADDENDUM: ADDRESSING COMPUTATIONAL ARTEFACTS 39 domly Ô¨Çipping them over) the results change dramatically and agree with expectations. Similar results can be obtained in Python. Another manifestation of this is if we gener- ate a random normal matrix A, and do the SVD A =USV T then detU = +1 always while detV = ¬±1 with equal probabilities. 2.6.2. SAMPLING RANDOM ORTHOGONAL MATRICES: GRAM-SCHMIDT ORTHOGONALISATION (QR DECOMPOSITION) As pointed out earlier in Section 2.2.1, the deÔ¨Ånition of the singular vectors is deter- mined up to a simultaneous sign change in the corresponding left- and right vector: (U‚Ñì,V‚Ñì) ‚Üí(‚àíU‚Ñì,‚àíV‚Ñì). This indeterminacy is exploited in various algorithms to assign a preferred direction to singular vectors. One manifestation of this is apparent in various QR decomposition algorithms (in MATLAB, and",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_50"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ",V‚Ñì) ‚Üí(‚àíU‚Ñì,‚àíV‚Ñì). This indeterminacy is exploited in various algorithms to assign a preferred direction to singular vectors. One manifestation of this is apparent in various QR decomposition algorithms (in MATLAB, and also in python). SpeciÔ¨Åcally: applying Gram-Schmidt orthogonolisation or using the QR decomposition in Matlab always pro- duces frames with right-handed chirality (i.e., the determinant detQ = +1). 40 REFERENCES REFERENCES [1] A. Khoshrou and E. J. Pauwels, Propagating uncertainty in tree-based load forecasts, in Electrical and Electronics Engineering (ELECO), 2017 10th International Confer- ence (IEEE, 2017) pp. 120‚Äì124. [2] S. L. Brunton, B. R. Noack, and P. Koumoutsakos, Machine learning for Ô¨Çuid mechan- ics, Annual Review of Fluid Mechanics 52, 477 (2020). [3] G. Strang, Introduction to linear algebra, Vol. 3 (Wellesley-Cambridge Press Wellesley, MA, 1993). [4] R. Horn and C. Johnson, Matrix Analysis (Cambridge University Press, 1985). [5] G. H. Golub and C. F. Van Loan, Matrix computations, Vol. 3 (JHU press, 2013). [6] C. Eckart and G. Young, The approximation of one matrix by another of lower rank, Psychometrika 1, 211 (1936). [7] C. M. Bishop, Pattern recognition and machine learning (springer, 2006). [8] H. Hotelling, Analysis of a complex of statistical variables into principal components. Journal of educational psychology 24, 417 (1933). [9] K. Pearson, Liii. on lines and planes of closest Ô¨Åt to systems of points in space, The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2, 559 (1901). 3 PROPERTIES OF THE SVD 3.1. INTRODUCTION In the previous chapters we argued that SVD can be used to estimate periodicity in time series, as well as construct appropriate approximations for time series. The latter is based",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_51"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 3 PROPERTIES OF THE SVD 3.1. INTRODUCTION In the previous chapters we argued that SVD can be used to estimate periodicity in time series, as well as construct appropriate approximations for time series. The latter is based on the assumption that a data matrix A can be decomposed as A = A0 + Ar where A0 is a low rank matrix that comprises all the useful signal information, whereas the remainder term Ar collects the (relatively small) noise. For most of the applications of SVD in various Ô¨Åelds, it is important to understand the properties of the SVD of a matrix whose entries show some degree of random Ô¨Çuctuations. Therefore, in order to determine what the impact of noise will be on the singular value spectrum, it is useful to study the singular value decomposition of pure noise matrices, i.e., random matri- ces. This is the topic addressed in the following sections. SpeciÔ¨Åcally, we address the following topics: 1. The impact of the matrix aspect ratio (number of rows versus number of columns); 2. The impact of shifts of the mean of the underlying distribution as this will become relevant in applications where a signal will in general have a non-zero mean. 3.2. SINGULAR VALUE SPECTRUM OF RANDOM MATRICES In order to disentangle the impact of signal and noise, we Ô¨Årst focus on the effect of pure noise (i.e., random matrices). The spectral study of random matrices (i.e., matrices for which the entries are independent, identically distributed (i.i.d.) random variables) has been a very active research domain in recent years and uncovered a number of key insights (see e.g., [2‚Äì4]). Parts of this chapter have been published in [1]. 41 42 3. PROPERTIES OF THE SVD 3.2.1. PRELIMINARIES Let N be a random p√óq matrix such that the individual entries are i.i.d, random variables with zero mean and unit variance: E(Ni j ) = 0 and V ar(Ni j ) = 1 As previously mentioned in Section 2.2.2, to compute the singular values of the given matrix N, we are interested in the eigenvalues of either one of the following two sym- metric, quadratic matrices: Q(q) = N T N ‚ààRq",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_52"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " Section 2.2.2, to compute the singular values of the given matrix N, we are interested in the eigenvalues of either one of the following two sym- metric, quadratic matrices: Q(q) = N T N ‚ààRq√óq or Q(p) = NN T ‚ààRp√óp Denoting by N i and Ni the i-th row or column of N, respectively, we observe that the elements of Q(q) and Q(p) can be expressed as inner products of either rows and columns of N; i.e., the inner product of columns: Q(q) i j = Ni ¬∑ Nj = Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥ pX k=1 Nki Nk j i Ã∏= j pX k=1 N 2 ki i = j (3.1) and similarly (inner product of rows), Q(p) i j = N i ¬∑ N j = Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥ qX k=1 NikNjk i Ã∏= j qX k=1 N 2 ik i = j (3.2) Since we are typically interested in what happens when we gather more data (i.e., q ‚Üí‚àû), we will focus mostly on Q(p) as there are only p non-zero singular values, which correspond to the p (square roots of the) eigenvalues of Q(p). From here on, we will drop the superscripts for the Q-matrix as it will be clear from the context which one we are using. It then is straightforward to compute the Ô¨Årst moments1: E(Qi j ) = Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥ qX k=1 E(Nik)E(Njk) = 0 i Ã∏= j qX k=1 E(N 2 ik) = q i = j (3.3) and similarly: V ar(Qi j ) = Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥ qX k=1 V ar(Nik)V ar(Njk) = q i Ã∏= j",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_53"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " = Ô£± Ô£¥ Ô£¥ Ô£¥ Ô£≤ Ô£¥ Ô£¥ Ô£¥ Ô£≥ qX k=1 V ar(Nik)V ar(Njk) = q i Ã∏= j qX k=1 V ar(N 2 ik) = Œ≤2q i = j (3.4) 1Here for Q = Q(p), similar results hold for Q(q). 3.2. SINGULAR VALUE SPECTRUM OF RANDOM MATRICES 43 Figure 3.1: The intuition of why the singular values of N are equal to the eigenvalues of Q. where Œ≤2 := V ar(N 2 ik) is a common value since all variables are i.i.d.2 The above results can be recast in more compact matrix notation: E(Q) = qIp and V ar(Q) = q ¬° (Œ≤2 ‚àí1)Ip +1p√óp ¬¢ (3.5) Normalised version Notice that the above results show that the normalised matrix Qn := 1 q Q has constant moments: E(Qn) = Ip and V ar(Qn) = (Œ≤2 ‚àí1)Ip +1p√óp (3.6) 3.2.2. UNIVERSALITY From Eqs. (3.1) and (3.2), it is evident that the elements of the Q-matrices are sums of in- dependent i.i.d. random variables. In particular, each Qi j is the sum of q independent terms and it therefore asymptotically converges to a normal distribution (based on the Central Limit Theorem [5]). We hence can conclude that irrespective of the initial dis- tribution of the N-entries, the Q-entries will converge to a normal distribution, i.e., the individual entries Qi j will ‚Äúforget\" the original distribution when q ‚Üí‚àû. In other words, 2As mentioned before, the entries of N need to be zero mean and unit variance for the results to hold. 44 3. PROPERTIES OF THE SVD Figure 3.2: Comparison of the distribution of the highest singular values of two random matrices: normal and exponential distributions. According to the universality theorem, as the dimension grows, these distributions become closer to each other (for the sake of comparison œÉ1/pq has been considered, where q is the size of the",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_54"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " of two random matrices: normal and exponential distributions. According to the universality theorem, as the dimension grows, these distributions become closer to each other (for the sake of comparison œÉ1/pq has been considered, where q is the size of the square matrix. The distributions are the results of 200 iterations.). since the singular values of N are determined by the eigenvalues of Q it follows that, as q ‚Üí‚àû, the distribution of the singular values becomes independent of the distribution of N-matrix (apart from the Ô¨Årst two moments). This is called the universality property. Figure 3.2 provides a comparison between the distribution of the Ô¨Årst singular value of the two random matrices, one a random normal and the other random exponential. As can be seen in the case of the 50 √ó50 matrix (the left panel) the difference between the two distributions is discernible. However, as the dimensionality grows (for the 450√ó450 matrices of the right panel) the distributions of the Ô¨Årst singular values for two matrices (random normal and exponential matrices) become more similar. In a similar way, Figure 3.3 illustrates a comparison of the singular values (averaged over 200 trials) of 50 √ó 50 random matrices for two different distributions of the indi- vidual matrix entries: standard normal and exponential (shifted to become zero-mean). These two Ô¨Ågures combined show that as long as the mean and variance of the noise is kept constant, its actual distribution has very little inÔ¨Çuence on the distribution of the resulting singular values, assuming the size of the matrix is not too small. In addition to the above result, we also know that rescaling the variance of the en- tries in a zero-mean random matrix induces the corresponding rescaling of the singu- lar values: œÉi(Œ±A) = Œ±œÉi(A). This follows immediately from the observation that Œ±A = U(Œ±S)V T . In other words, the singular value ratio SV R = œÉ1/œÉ2 is not affected by a uni- form increase in the noise variance. However, a shift in the mean of the noise does affect the SVR, as will be explained in the following sections. 3.3. IMPACT OF ASPECT RATIO ON SINGULAR VALUES 3.3.1. PROBLEMS WITH THE SVR APPROACH As mentioned before",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_55"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " affect the SVR, as will be explained in the following sections. 3.3. IMPACT OF ASPECT RATIO ON SINGULAR VALUES 3.3.1. PROBLEMS WITH THE SVR APPROACH As mentioned before, Kanjilal et. al. [6] use the singular value ratio (SVR) spectrum to Ô¨Ånd the periodicity p in the time series and consequently decompose a signal into 3.3. IMPACT OF ASPECT RATIO ON SINGULAR VALUES 45 Figure 3.3: Singular values (averaged over 200 trials) for 50 √ó 50 random matrices generated by drawing i.i.d. entries from the standard normal (red) and (shifted to ensure zero mean and unit variance) exponential (blue) distributions. its constituent periodic components. This idea of period estimation based on the SVR seems intuitive and straightforward. However, there are some complications that need to be addressed as they could bias and invalidate the results. SpeciÔ¨Åcally: ‚Ä¢ The SVR depends on the average value of the signal ‚Ä¢ The SVR depends on the aspect ratio of the data matrix We will illustrate these problems below. Impact of average value In the original paper [6], it was not sufÔ¨Åciently appreciated how a shift in the mean value of the time series (the DC component which is the mean amplitude of the waveform) impacts the SVR. This is important as failure to understand this issue introduces a major bias in the test values and could therefore result in erro- neous conclusions. The left panel of Figure 3.4 provides an example of how the mean of a signal can affect its singular value distributions. Clearly, failing to remove the mean from a noisy time series would inÔ¨Çate the Ô¨Årst singular value (and only the Ô¨Årst one) resulting in an upwardly biased value for the singular value ratio (SVR). Such a blind screening would reduce the power of an SVD method in data mining applications. 3.3.2. MOTIVATION As mentioned before, we recast a given periodic signal in such a way that each column represents a single period. Adding more observations amounts to adding more columns, which in turn makes the corresponding matrix ‚Äúfatter\". This has an impact on its singular values. This is obvious from the fact that the L2 norm (or Frobenius norm) of a matrix ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_56"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " more observations amounts to adding more columns, which in turn makes the corresponding matrix ‚Äúfatter\". This has an impact on its singular values. This is obvious from the fact that the L2 norm (or Frobenius norm) of a matrix 46 3. PROPERTIES OF THE SVD Figure 3.4: Left: Comparison of the singular values of a matrix (10 √ó 10) with zero-mean entries (red) and shifted mean (Œ± = 5). The dotted line indicates that (approximate) upper limit based on Eq. (3.19). Recall that the entries of the matrix A0 are random numbers, but by shifting the global mean the SV R = œÉ1/œÉ2 increases, erroneously suggesting that some underlying periodic structure is present. Right: By proceeding from an square to rectangular matrix, all the singular values increase proportionately. can be expressed in terms of the sum of its singular values, i.e., (see Appendix A.3): ||A||2 F := pX i=1 qX j=1 A2 i j = rX k=1 œÉ2 k where Ai j is the entry of the matrix. If we assume the matrix to be fat (q > p) and full rank (i.e., r := rk(A) = p), it follows that increasing the number of columns q must also inÔ¨Çate the quadratic sum of singular values, without increasing the number of terms in the sum, which is Ô¨Åxed by the rank. This can happen in roughly two ways: 1. Multiplicative: all the singular values are multiplied by a factor Œ± > 1, i.e., œÉ‚Ä≤ i = Œ±(q,i) œÉi 2. Additive: all the singular values are shifted by a Ô¨Åxed amount Œ± > 0, i.e., œÉ‚Ä≤ i = œÉi +Œ±(q,i) Notice that the Ô¨Årst possibility would not signiÔ¨Åcantly impact the SVR, whereas the second one will. Numerical experiments show that the actual mechanism at work is more akin to the second possibility: ‚Äúfattening\" a noise matrix shifts all the singular values upward (see Figure 3.4). To obtain crisp results we return to the case of purely random matrices. For a more detailed explanation of the underlying reasoning behind Figure 3.4, see Appendix A.6. The next section provides an explanation for this observa",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_57"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "3.4). To obtain crisp results we return to the case of purely random matrices. For a more detailed explanation of the underlying reasoning behind Figure 3.4, see Appendix A.6. The next section provides an explanation for this observa- tion. 3.3. IMPACT OF ASPECT RATIO ON SINGULAR VALUES 47 3.3.3. ASYMPTOTIC RATIO OF SINGULAR VALUES AS FUNCTION OF GROW- ING ASPECT RATIO The following section investigates the evolution of the distribution of the singular values of random matrices where the ratio of the number of columns (the number of observa- tions) to the number of rows (Ô¨Åxed number of dimensions of the data) increases over time. Theorem 4. Let A be a (full rank) random p √ó q matrix (where q ‚â•p) such that Ai j are i.i.d, E(Ai j ) = 0 and V ar(Ai j ) = 1. The singular value decomposition theorem ensures that there are (essentially unique) matrices U ‚ààRp√óp and V ‚ààRq√óq, both with orthonormal columns, (i.e., U TU = Ip, V T V = Iq). We denote the SVD decomposition as: A =USV T where S = Rp√óq such that S = (Œ£p√óp, 0p√ó(q‚àíp)) and Œ£p√óp = diag(œÉ1,œÉ2,...,œÉp), and the singular values have been ordered in descending order: œÉ1 ‚â•œÉ2 ‚â•... ‚â•œÉp. Then, if q (the number of columns) tends to inÔ¨Ånity, while keeping the number of rows p constant, all the singular values œÉi will increase to inÔ¨Ånity in such a way that the ratio of the largest to the smallest singular value tends to 1: lim q‚Üí‚àû œÉmax œÉmin = lim q‚Üí‚àû œÉ1 œÉp = 1 Proof. As previously mentioned in Section 2.2.2, singular values and vectors for a matrix A are actually the eigenvalues and eigenvectors of the quadratic matrices AAT and AT A; we, therefore, focus on the quadratic random matrices of the form Q = AAT ‚ààRp√óp where A ‚ààRp√óq, Ai j : i.i.d., E",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_58"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " and eigenvectors of the quadratic matrices AAT and AT A; we, therefore, focus on the quadratic random matrices of the form Q = AAT ‚ààRp√óp where A ‚ààRp√óq, Ai j : i.i.d., E(Ai j ) = 0, and V ar(Ai j ) = 1 Harking back to Eq. (3.5) we had: E(Q) = qIp and V ar(Q) = q ¬° (Œ≤2 ‚àí1)Ip +1p√óp ¬¢ where Œ≤2 := V ar(A2 ik) is a common value since all variables are i.i.d. According to the CLT, we know that asymptotically (as q ‚Üí‚àû) the entries Qi j will be normally distributed. Therefore, we can use the above moment information to specify the following approximation (asymptotically, as q ‚Üí‚àû): ‚Ä¢ Diagonal: diag(Q) ‚âàqIp + Œ≤pqZp, where Zp is a p √ó p diagonal matrix with in- dependent, standard normal random variables on the diagonal. ‚Ä¢ Off-Diagonal: The off-diagonal part is approximated by the symmetric (zero-diagonal) matrix pq M where Mi j = M ji ‚àº ¬Ω N (0,1) if i Ã∏= j 0 if i = j 48 3. PROPERTIES OF THE SVD Figure 3.5: Left: Illustrating the approximation of the singular values of A using (the square roots of) the eigen- values of AAT . Right: Ratio of largest to smallest singular value. Collecting all these we arrive at the following asymptotic approximation: AAT ‚âàqIp +Œ≤pq Zp +pq M = q ¬µ Ip + 1 pq (Œ≤Zp + M) ¬∂ (3.7) Notice that K := Œ≤Zp + M does not depend on q. Furthermore, it is symmetric and therefore can be diagonalized. As a consequence, K has an orthonormal basis of eigenvectors ki (i = 1,2,...,p) and corresponding eigenvalues ŒΩi such that K ki = ŒΩiki. Collecting these eigenvectors and eigenvalues in matrices P and N respectively, we can conclude: K = PNPT where P is orthogonal, i.e., PPT = PT P = Ip Plugging this decomposition in the RHS of Eq.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_59"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ". Collecting these eigenvectors and eigenvalues in matrices P and N respectively, we can conclude: K = PNPT where P is orthogonal, i.e., PPT = PT P = Ip Plugging this decomposition in the RHS of Eq. (3.7) we see that: AAT ‚âàR(q) := q(Ip + 1 pq K ) = q P ¬µ Ip + 1 pq N ¬∂ PT from which we can conclude that R(q) has the same eigenvectors as Q (i.e., the columns of P), but the corresponding eigenvalues are given by: Œªi(Rq) = q ¬µ 1+ ŒΩi pq ¬∂ Notice that the eigenvalues ŒΩi are independent of q and therefore: lim q‚Üí‚àû Œªi(Rq) Œªj (Rq) = lim q‚Üí‚àû 1+ŒΩi/pq 1+ŒΩj /pq = 1 (3.8) Furthermore, for q sufÔ¨Åciently large: œÉi(A) ‚âà q Œªi(Rq) = q q +pqŒΩi (3.9) as can be seen in Figure 3.6. 3.4. IMPACT OF THE UNDERLYING PERIODIC SIGNAL 49 Figure 3.6: Comparison of actual singular values (red) and approximation (in blue) speciÔ¨Åed in Eq. (3.9). 3.4. IMPACT OF THE UNDERLYING PERIODIC SIGNAL Suppose that x = (x1,x2,...,xn) represents a noisy but perfectly stationary and periodic time series with period p. We can then use the methodology explained in Section 1.2 to recast such a time series as a matrix A with size p √ó q. As mentioned in Section 1.2 for a pure rank-1 matrix A0 = a1T q the SVD decomposi- tion is straightforward; all we need to do is to reduce the vectors to unit vectors: A0 = a1T q = apq ¬≥ a a ¬¥√É 1T q pq ! = œÉ1uvT (a = ||a||) (3.10) conÔ¨Årming that the Ô¨Årst (and only non-zero) singular value equals œÉ1(A0) = apq. In general, however, the data is noisy and we model that by adding independent ad- d",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_60"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ".10) conÔ¨Årming that the Ô¨Årst (and only non-zero) singular value equals œÉ1(A0) = apq. In general, however, the data is noisy and we model that by adding independent ad- ditive noise with variance Œµ2 in below: A = a1T q +ŒµN (3.11) Here, similar to Eq. (1.6), N is a p√óq matrix of independent, identically distributed (i.i.d.) noise variables with zero mean and unit variance. Notice that the p-dim column space in Eq. (3.11) can be interpreted as a zero-mean random cloud of q columns of matrix N, each of which is shifted by a. The geometric intuition expounded in Section 2.3, there- fore, suggests that the square of the Ô¨Årst singular value should be shifted by q||a||2. We will now show that this intuition is indeed correct. To investigate the behaviour of the singular values we use the fact that: œÉ2(A) = Œª(AT A) = Œª ¬≥ (a1T q +ŒµN)T (a1T q +ŒµN) ¬¥ = Œª ¬≥ a21q1T q +Œµ(N T a1T q +1qaT N)+Œµ2N T N ¬¥ 50 3. PROPERTIES OF THE SVD where a2 = aT a = ||a||2, œÉ(.) is the singular value and Œª(.) indicates the eigenvalue. Since the entries of the noise matrix N are independent, zero-mean and unit variance stochas- tic variables, we can draw on Eqs. (3.3)‚Äì(3.5) to make the following approximation for the q √ó q matrix N T N: E(N T N)i j = pX k=1 E ¬° Nki Nk j ¬¢ = Ô£± Ô£≤ Ô£≥ Pp k=1 E(Nki)E(Nk j ) = 0 if i Ã∏= j Pp k=1 E(N 2 ki) = p if i = j The last approximation is obtained by taking the expected values and using the fact that E(Nki Nk j ) = 1 if i = j, and zero otherwise. From this, we conclude that approximately: N T N ‚âàpIq Similarly, because the expectation value",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_61"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " taking the expected values and using the fact that E(Nki Nk j ) = 1 if i = j, and zero otherwise. From this, we conclude that approximately: N T N ‚âàpIq Similarly, because the expectation value of the cross-term vanishes, using the linearity of the expectation operator yields: E(N T a1T q +1qaT N) = E(N T )a1T q +1qaT E(N) = 0 whereas V ar ¬≥ N T a1T q +1qaT N ¬¥ = 2a2Iq (3.12) As a consequence, to a good approximation, the singular values of A can be identiÔ¨Åed as the eigenvalues of the following matrix: œÉ2(A) ‚âàŒª(a21q1T q +Œµ2pIq) The structure of the matrix in the RHS allows us to arrive at some conclusions regarding the singular values. Lemma 5. The symmetric q√óq matrix B = a21q1T q +Œµ2pIq has a complete set of q orthog- onal eigenvectors and corresponding eigenvalues Œª1 ‚â•Œª2 ‚â•... ‚â•Œªq (sorted in descending order): eigenvalue eigenvector Œª1 = a2q +œµ2p 1q Œªi = œµ2p (i ‚â•2) ei ‚àíe1 where ei = (0,...,0,1,0,...,0)T are the standard basis vectors. Proof. The above results follow from a straightforward calculation: B1q = a21q(1T q 1q)+Œµ2pIq1q = a2q1q +Œµ2p1q = (a2q +Œµ2p)1q = Œª11q Similarly, B(ei ‚àíe1) = a21q1T q (ei ‚àíe1)+Œµ2pIq(ei ‚àíe1) = 0 + Œµ2p(ei ‚àíe1) 3.4. IMPACT OF THE UNDERLYING PERIODIC SIGNAL 51 Figure 3.7: The inÔ¨Çuence of the underlying signal strength on the Ô¨Årst singular value. The curve for k = 0 corresponds to pure noise (no underlying signal). Notice how increasing the signal strength results in the corresponding increments in the Ô¨Årst singular value",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_62"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ÔøΩuence of the underlying signal strength on the Ô¨Årst singular value. The curve for k = 0 corresponds to pure noise (no underlying signal). Notice how increasing the signal strength results in the corresponding increments in the Ô¨Årst singular value. From the lemma above, we can immediately conclude that to a Ô¨Årst approximation the following (approximate) result for the singular values of A holds. Theorem 6. Let us consider again the p √ó q matrix A in Eq. (3.11); then to a Ô¨Årst approx- imation, the singular values are given by œÉ1(A) ‚âà q a2q +Œµ2p and œÉi(A) ‚âàŒµpp (for i ‚â•2) (3.13) From these results we can make the following observations: ‚Ä¢ The difference between the Ô¨Årst and the subsequent singular values grows pro- portionally to pq, as it means that the more cycles that are present in the data, the more pronounced the difference is. Furthermore, in many cases the noise-level Œµ2 can be neglected with respect to the strength of the signal (a2), resulting in a further approximation: œÉ1(A) ‚âàapq (3.14) Which indeed tallies with the geometric intuition explained in Section 2.3. ‚Ä¢ Impact on SVR: (SV R(A))2 = ¬µœÉ1(A) œÉ2(A) ¬∂2 = a2q +Œµ2p Œµ2p = 1+ a2 œµ2 q p So we can conclude that the SVR is inÔ¨Çuenced by the aspect ratio of the matrix (q/p) as well as the relative size of the signal (a) versus noise (Œµ). 52 3. PROPERTIES OF THE SVD The subsequent singular values correspond to the eigenvectors which are mapped to zero by the rank-1 matrix and therefore are not inÔ¨Çuenced by the a2 term: œÉi(A) ‚âàŒµpp (for i ‚â•2) In other words, these lower-ranked singular values are not inÔ¨Çuenced by the signal a itself, just by the noise. This is illustrated in Figure 3.7 where we took a Ô¨Åxed noise-level œµ = 0.2 and a signal strength a which is a multiple of some basic level a0 = p 12.5 and a = ka0 with k",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_63"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " in Figure 3.7 where we took a Ô¨Åxed noise-level œµ = 0.2 and a signal strength a which is a multiple of some basic level a0 = p 12.5 and a = ka0 with k = 0,1,2,3. The number of full cycles in each case was equal to q = 10. We therefore expect the Ô¨Årst singular value for each of these signal levels to be roughly equal to pq a0k ‚âà11.2k. It is important to realize that this observation is different from the result in Sec- tion 3.5.1 where the Ô¨Årst singular value was affected by a shift in the mean noise level. In this case, the mean (1/p)P i ai of the periodic signal a can still be zero, but it is its L2 norm (a2 = ||a||2) that is seen to affect the Ô¨Årst singular value. Slightly more general result Consider the case of a general rank-1 matrix: A = abT +ŒµN (3.15) In this case the same sort of computation yields: B = a2bbT +Œµ2pIq for which the largest eigenvalue corresponds to the vector b: Bb = (a2b2 +Œµ2p)b 3.5. EXPLORING SOME PROPERTIES As mentioned before, the major goal of this thesis is to investigate the applicability of the SVD in time series analysis. To this end, the impact of the underlying patterns in the signal on the SVD results was touched upon earlier in Section 3.4. Furthermore, as it is illustrated in Figures 2.4-2.8, the distance and positioning from the origin can affect the SVD results drastically. The following section provides more detailed mathematical foundations for the observed results (with a focus on time series analysis). 3.5.1. IMPACT OF ENTRIES MEAN VALUE In the original papers [6, 7], it was not sufÔ¨Åciently appreciated how a shift in the mean value of the time series (the DC component) impacts the SVR. This is important as failure to understand this issue introduces a major bias in the test values and could therefore result in erroneous conclusions. To address this issue, we compare the singular values of a zero-mean p √ó q random matrix A0 and its mean-shifted version",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_64"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " important as failure to understand this issue introduces a major bias in the test values and could therefore result in erroneous conclusions. To address this issue, we compare the singular values of a zero-mean p √ó q random matrix A0 and its mean-shifted version: A = A0 +Œ± which is shorthand for A = A0 +Œ±1p√óq = A0 +Œ±1p1T q . Using the connection between singular values and eigenvalues expounded in the previous section, we can express any singular 3.5. EXPLORING SOME PROPERTIES 53 Figure 3.8: Comparison of the singular values of a matrix (10 √ó 10) with zero-mean entries (red) and shifted mean (Œ± = 5). The stem-plot of the singular values against their index i is also called the singular spectrum or eigenspectrum. The dotted line indicates the (approximate) upper limit based on Eq. (3.19). Recall that the entries of the matrix A0 are random numbers, but by shifting the global mean the SV R = œÉ1/œÉ2 increases, erroneously suggesting that some underlying periodic structure is present. value œÉ(A) as: œÉ2(A) = Œª(AAT ) = Œª((A0 +Œ±1p1T q )(AT 0 +Œ±1q1T p )) = Œª ¬≥ A0AT 0 +Œ±(A01q1T p +1p1T q AT 0 )+Œ±21p1T q 1q1T p ¬¥ = Œª ¬≥ A0AT 0 +Œ±q(R1T p +1pRT )+Œ±2q1p1T p ¬¥ (3.16) where R = (1/q)A01q is a p √ó1 column matrix for which each element is the mean of the corresponding A0 row. However, recall that the entries of A0 are independent zero-mean stochastic variables. Hence, unless the matrix dimensions are very small, it follows that R ‚âà0 can be neglected. We, therefore, derive the approximation: œÉ2(A) ‚âàŒª ¬≥ A0AT 0 +Œ±2q1p1T p ¬¥ (3.17) Next, we make use of the standard results on Rayleigh quotients for eigenvalues which states that the dominant eigenvalue of a symmetric, positive deÔ¨Ånite matrix M is the solution to",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_65"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "p1T p ¬¥ (3.17) Next, we make use of the standard results on Rayleigh quotients for eigenvalues which states that the dominant eigenvalue of a symmetric, positive deÔ¨Ånite matrix M is the solution to the maximization problem: Œª1 = max xÃ∏=0 ¬≥ xT Mx xT x ¬¥ = max ||u||=1(uT Mu). Furthermore, if a unit vector u1 realizes the above maximum, then the second largest eigenvalue is obtained as the solution of the constrained optimization problem: Œª2 = max ||u||=1(uT Mu) s.t. u ‚ä•u1 and so on for the successive eigenvalues. 54 3. PROPERTIES OF THE SVD Combining this with the approximation derived in Eq. (3.17), we get the following approximation for the Ô¨Årst singular value of A: œÉ2 1(A) ‚âà max ||u||=1 uT ¬≥ A0AT 0 +Œ±2q1p1T p ¬¥ u = max ||u||=1 ¬≥ uT A0AT 0 u+Œ±2quT 1p1T p u ¬¥ = max ||u||=1 √É uT A0AT 0 u+Œ±2q ( pX i=1 ui)2 ! (3.18) This derivation shows that œÉ2 1(A) ‚â§max ||u||=1 ¬° uT A0AT 0 u ¬¢ +Œ±2pq = œÉ2 1(A0)+Œ±2pq (3.19) since from the Cauchy-Schwartz inequality it follows: √É pX i=1 ui !2 ‚â§ √É pX i=1 u2 i !√É pX i=1 1 ! = p since ||u|| = 1 However, in general, the unit vector u that maximizes the Rayleigh quotient will not nec- essarily also maximize (Pui)2. In fact, for higher singular values, the number of orthog- onal constraints on u increases proportionally, suggesting that on average Pui ‚âà0, and therefore œÉ2 i (A) ‚âàœÉ2 i (A0). Another argument could be that higher singular vectors are comprised of the noise in the data (low magnitude random-structured data points added to the original signal). Therefore, adding",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_66"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " and therefore œÉ2 i (A) ‚âàœÉ2 i (A0). Another argument could be that higher singular vectors are comprised of the noise in the data (low magnitude random-structured data points added to the original signal). Therefore, adding or removing the mean value will not affect their compounds in higher singular vectors and correspondingly the singular values. This is indeed what is seen in numerical experiments (Figure 3.8). Notice that the Ô¨Årst singular value is very close to the maximal value obtained in Eq. (3.19) which is derived if optimizing both terms in Eq. (3.18), independently and simultaneously had been done. Clearly, failing to remove the mean from a noisy time series would inÔ¨Çate the Ô¨Årst singular value (and only the Ô¨Årst one) 3 resulting in an upwardly biased value for the singular value ratio (SVR). This would reduce the power of an SVD method in data mining applications such a blind screening. In the next section, we will investigate the impact of a genuine underlying periodic signal. 3.5.2. IMPACT OF THE DRIFT ON THE FIRST SINGULAR VALUE Consider a signal that has a periodic component a and a drift component k. For simplic- ity, we assume that k = (‚àík : k)T where q = 2k +1. Now, we consider a p √ó q matrix of the form: A = a1T q +Œ≤1pkT This represents a time series with drift (see Figure 3.9). Since each column (or row) is the 3It may lead to wrong impressions about the importance of the Ô¨Årst singular value with respect to the others! 3.5. EXPLORING SOME PROPERTIES 55 Figure 3.9: Periodic signal with drift. In this case a is a sine wave, while k = 5, and Œ≤ = 0.1. linear combination of two Ô¨Åxed columns, it has rank two (or less), and therefore its SVD is of the form: A = œÉ1u1vT 1 +œÉ2u2vT 2 These two decomposition terms are very similar, but the second one is more speciÔ¨Åc in the sense that the vectors involved are orthogonal (and unit length). The main outcome of the Ô¨Ågure is that pre-processing (removing the",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_67"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " These two decomposition terms are very similar, but the second one is more speciÔ¨Åc in the sense that the vectors involved are orthogonal (and unit length). The main outcome of the Ô¨Ågure is that pre-processing (removing the mean value) in the time series analysis is important. Only looking at the singular values may lead to biased results. One must investigate the evolution of the singular vectors to have a better understanding of the underlying patterns in the time series. DERIVATION FOR THE SIMPLEST CASE Let us Ô¨Årst look at the case when there is no drift Œ≤ = 0 and we assume that the base signal is zero mean, i.e., P i ai = 0. In that case A = a1T q and we get u1 = a/||a|| and v1 = 1q/pq and œÉ1 = pq||a|| Without loss of generality, if we then introduce a small amount of drift (i.e., Œ≤ ‚â™1) we can simply use the fact that 1p is orthogonal with respect to a since aT 1p = P i ai = 0 (signal must be zero mean value, otherwise it will not work). As a consequence we can take u2 = 1p/pp which yields the decomposition: A = pq||a||u1v1 +Œ≤ppu2kT Finally, we notice that k is also orthogonal to v1 since P i ki = 0, and therefore v2 = k/||k||. Now, recall that ||k||2 = 2 kX ‚Ñì=1 ‚Ñì2 = 2k(k +1)(2k +1) 6 ‚âà2k3/3 ‚âàq3/12. 56 3. PROPERTIES OF THE SVD Figure 3.10: An example of a drifted time series in the absence of noise, and ¬µ Ã∏= 0. Perhaps we could say that u2 or v2as an indication for the direction of that drift! Plugging all this into the formula above we see that the singular values are equal to: œÉ1 = pq||a|| and œÉ2 = 1 2|Œ≤| s pq3 3 . (3.20) where |.| is the absolute value operator. From Eq. (3.20) it transpires that the Ô¨Årst singular value is determined by the periodic",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_68"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 1 2|Œ≤| s pq3 3 . (3.20) where |.| is the absolute value operator. From Eq. (3.20) it transpires that the Ô¨Årst singular value is determined by the periodic patterns, whereas the second one is determined by the drift. Of course, there are other ways to derive similar results and also provide an argument why |Œ≤| is used: ||a1q T +Œ≤1pkT ||2 F = ||a1q T ||2 F +||Œ≤1pkT ||2 F +2 < a1q T ,Œ≤1pkT >F = (3.21) q||a||2 + p|Œ≤|||k||2 +2Œ≤ < a1q T ,1pkT >F One can argue that the largest term in the above formula is associated with the Ô¨Årst sin- gular value, and the second term is with the second; this explains the switches of the two terms in the numerical analysis. The third term is (close to) zero; as in our example k = [‚àík : k] is symmetric and a1qT is a rank‚àí1 matrix. Numerical veriÔ¨Åcation Here, we also can argue that a zero mean random process with drift will exhibit a similar singular value spectrum; therefore, SVR by itself (without con- sidering u and v proÔ¨Åles) can lead to erroneous results (Figure 3.12). 3.5. EXPLORING SOME PROPERTIES 57 Figure 3.11: when there is a drift and in the absence of noise ¬µ = 0. notice the changes in the u and v proÔ¨Åles. 0 2 4 6 8 10 12 index of the singular values 0 10 20 30 40 50 60 70 80 singular values : 0.05 : 0.1 : 0.15 : 0.2 : 0.25 : 0.3 : 0.35 : 0.4 : 0.45 : 0.5 : 0.55 : 0.6 : 0.65 : 0.7 0 2 4 6 8 10 12 index of the singular values 0 10 20 30 40 50 60 70",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_69"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " : 0.6 : 0.65 : 0.7 0 2 4 6 8 10 12 index of the singular values 0 10 20 30 40 50 60 70 80 singular values : -0.05 : -0.1 : -0.15 : -0.2 : -0.25 : -0.3 : -0.35 : -0.4 : -0.45 : -0.5 : -0.55 : -0.6 : -0.65 : -0.7 Figure 3.12: InÔ¨Çuence of drift on 2nd singular value for the input in the Ô¨Ågure above. Notice how the Ô¨Årst singular value is unaffected (the Ô¨Årst singular value is unaffected as long as the drift is small. from some point upward, the drift will change u1, and accordingly œÉ1). 58 3. PROPERTIES OF THE SVD 0 500 1000 1500 2000 2500 -2 0 2 4 6 8 10 12 0 500 1000 1500 2000 2500 -2 0 2 4 6 8 10 12 0 10 20 30 40 50 60 70 1st singular value 0 5 10 15 20 25 0 5 10 15 20 2nd singular value 0 5 10 15 20 25 Figure 3.13: Top: An example of the frequency of the occurrence of an extra event. Bottom: The evolution of the second singular value. As expected when the occurrence is too often, the rank of the matrix decreases. 3.6. CONCLUSION In this chapter, we have argued that the well-known singular value decomposition (SVD) (which is usually applied to matrix problems) can also be successfully applied to identify periodic patterns (proÔ¨Åles) in time series. Furthermore, these proÔ¨Åles are completely deÔ¨Åned by the data and do not require the speciÔ¨Åcation of user-deÔ¨Åned parameters, apart from the period (which itself can be estimated using this approach). As such, this methodology offers a purely data-driven approach to adaptive signal approximation and based on",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_70"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " and do not require the speciÔ¨Åcation of user-deÔ¨Åned parameters, apart from the period (which itself can be estimated using this approach). As such, this methodology offers a purely data-driven approach to adaptive signal approximation and based on that, outlier detection. Moreover, we have shown that a judicious comparison of the V -coefÔ¨Åcients and residuals allows one to distinguish between different ways in which data points can be atypical or salient. From a data mining perspective, this opens up new ways of analyzing time series in a data-driven, bottom-up fashion. However, it then becomes essential to thoroughly understand how the spectrum of time series is inÔ¨Çuenced by various charac- teristics of the signal and noise. REFERENCES 59 REFERENCES [1] A. Khoshrou and E. J. Pauwels, Data-driven pattern identiÔ¨Åcation and outlier detec- tion in time series, in Science and Information Conference (Springer, 2018) pp. 471‚Äì 484. [2] T. Tao and V. H. Vu, Random matrices: The distribution of the smallest singular values, ArXiv: 0903:0614 (2009). [3] D. Paul and A. Aue, Random matrix theory in statistics: A review, Journal of Statistical Planning and Inference 150, 1 (2014). [4] H. H. Nguyen, V. Vu, et al., Random matrices: Law of the determinant, The Annals of Probability 42, 146 (2014). [5] M. Rosenblatt, A central limit theorem and a strong mixing condition, Proceedings of the National Academy of Sciences of the United States of America 42, 43 (1956). [6] P. P. Kanjilal and S. Palit, On multiple pattern extraction using singular value decom- position, IEEE transactions on signal processing 43, 1536 (1995). [7] L. H. L. J. Z. Ying and Q. Liangsheng, Improved singular value decomposition tech- nique for detecting and extracting periodic impulse component in a vibration signal, Chinese Journal of Mechanical Engineering 17, 1 (2004). 4 REGULARISED MATRIX FACTORIZATION 4.1. INTRODUCTION AND MOTIVATION Singular Value Decomposition (SVD) and its close relative,",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_71"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " a vibration signal, Chinese Journal of Mechanical Engineering 17, 1 (2004). 4 REGULARISED MATRIX FACTORIZATION 4.1. INTRODUCTION AND MOTIVATION Singular Value Decomposition (SVD) and its close relative, Principal Component Analy- sis (PCA), are linear matrix factorisation techniques that are widely used in applications as varied as dimension reduction and clustering [3], matrix completion [4] (e.g., for rec- ommender systems), dictionary learning [5] and time series analysis [6]. In a surprising turn of events, (deep) matrix factorisation also plays a role in the implicit regularisation that enables acceptable generalisation in deep learning [7]. Although these factorisation techniques are both conceptually simple and effective, it is well-known that they are sensitive to noise and outliers in input data. As a conse- quence, some modiÔ¨Åcations of the original algorithms have been proposed to alleviate the effect of these disturbances [8, 9]. Candes et al. [10] introduce Robust PCA (RPCA) which aims to separate signal from outliers by decomposing any given matrix into the sum of a low-rank approximation and a sparse matrix of outliers. An extension of this work for the inexact recovery of the data is presented in [11]. Another example of sparse PCA using low rank approximation is proposed in [12]. Adding a regularisation term is another versatile way to tackle the problem of noisy input. For instance, Dumitrescu et al. [13] show how a regularized version of the K-SVD algorithm can be adapted to the Dictionary Learning (DL) problem. Although, the pres- ence of noise in the input is not the only reason to invoke regularisation. Recent re- search [14] shows that in many real-world data sets, not only do the observed data lie on a (non-)linear low dimensional manifold, but this also applies to the features. Similar to our approach, He et al. [15] consider a given matrix A where the columns are interpreted as data points and the rows are features. The neighbourhood structure of both the data points and the features then gives rise to distinct graphs (the so-called data and feature Parts of this chapter have been published in [1, 2]. 61 62 4. REGULARISED MATRIX FACTORIZATION graphs) and hence, to corresponding graph Laplacians (Ld and L f",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_72"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "the so-called data and feature Parts of this chapter have been published in [1, 2]. 61 62 4. REGULARISED MATRIX FACTORIZATION graphs) and hence, to corresponding graph Laplacians (Ld and L f respectively). The re- sulting regularised PCA is referred to as the graph-dual Laplacian PCA (gDLPCA), which for a given data matrix A is obtained by minimising the below functional: J(V,Y ) = ||A ‚àíV Y ||2 +Œ±Tr(V T LdV )+Œ≤Tr(Y L f Y T ) subject to V T V = I (4.1) where ||.|| and Tr are the L ‚àí2 norm and the trace operators, respectively. The ability of the graph dual regularization technique to incorporate both data and feature struc- tures has deservedly attracted considerable attention in dimensionality reduction appli- cations [15‚Äì17]. In their abstract form, SVD and PCA amount to two different but related types of matrix factorisation. More precisely, given a general (data) matrix A, the aim is to ap- proximate it as a product of simpler (i.e., lower-rank) matrices. SpeciÔ¨Åcally: ‚Ä¢ PCA-type decomposition: A ‚âàPQT where the columns of Q are orthonormal, i.e., QTQ = I; ‚Ä¢ SVD-type decomposition: A ‚âàPBQT where B is diagonal, while P and Q are uni- tary matrices, i.e., PT P = I, QTQ = I. The approximation in the above equations is measured in terms of the Frobenius (ma- trix) norm which for an arbitrary matrix X ‚ààRp√óq is deÔ¨Åned as: ||X ||2 F = pX i=1 qX j=1 x2 i j = Tr(X X T ) = Tr(X T X ) = ||X T ||2 F . (4.2) In the remainder of this chapter, we will drop the subscript F. We herein take the func- tional Eq. (4.1) as a starting point and investigate the two factorisation approaches men- tioned above (invoking Eq. (4.2) to recast the trace as a norm): ‚Ä¢ PCA-type decomposition (A ‚âàPQT ) by minimising the regularisation functional: ||A ‚àíPQT ||2",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_73"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " men- tioned above (invoking Eq. (4.2) to recast the trace as a norm): ‚Ä¢ PCA-type decomposition (A ‚âàPQT ) by minimising the regularisation functional: ||A ‚àíPQT ||2 +Œª||DP||2 +¬µ||GQ||2 (4.3) ‚Ä¢ SVD-type decomposition (A ‚âàPBQT ) by minimising the regularisation functional: ||A ‚àíPBQT ||2 +Œª||DP||2 +¬µ||GQ||2 (4.4) The minimisation of the functional Eq. (4.3) was discussed in [15], however, their pro- posed solution contains an error which we correct in this chapter. In addition, we also provide an algorithm to solve functional Eq. (4.4), which somewhat surprisingly is quite different from the one for Eq. (4.3). The remainder of this chapter is organised as follows: In Sections 4.2 and 4.3 we derive algorithms for minimisation of the regularised version of PCA-type and SVD-type factorisations, respectively. Section 4.4 discusses how the gradient descent method can be implemented by drawing on some elementary facts from Lie-group theory. Finally, we conclude this chapter by giving some pointers to potential extensions. 4.2. REGULARISATION FOR PCA-TYPE FACTORISATION 63 4.2. REGULARISATION FOR PCA-TYPE FACTORISATION 4.2.1. REGULARISED PCA The following theorem outlines an obvious generalisation to the regularised version of the minimisation problem. Theorem 7 (Regularised PCA). Let A be a p √ó q matrix of rank r ‚â§min(p,q). For k ‚â§r, let P ‚ààRp√ók and Q ‚ààRq√ók full rank matrices (i.e., of rank k). Furthermore, for arbitrary strictly positive integers d and g, we introduce regularisation matrices D ‚ààRd√óp and G ‚àà Rg√óq, as well as weights Œª,¬µ ‚â•0. We now deÔ¨Åne the following functional F in the variables P and Q: F(P,Q) := ||A ‚àíPQT ||2 +Œª||DP||2 +¬µ||GQ||2 (4.5) and pose the corresponding constrained optimisation problem: min P,Q F(P,Q) subject to QTQ = Ik. (4.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_74"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "A ‚àíPQT ||2 +Œª||DP||2 +¬µ||GQ||2 (4.5) and pose the corresponding constrained optimisation problem: min P,Q F(P,Q) subject to QTQ = Ik. (4.6) Introducing short-hand notation L := DT D ‚ààRp√óp and M := GTG ‚ààRq√óq (both symmet- ric and positive semi-deÔ¨Ånite), the solution of the constrained optimisation problem (4.6) is constructed as follows: ‚Ä¢ The k columns of the q √ók matrix Q are the eigenvectors of the q √ó q matrix: K := AT (Ip +ŒªL)‚àí1A ‚àí¬µM corresponding to the k largest eigenvalues; ‚Ä¢ Furthermore: P = (Ip +ŒªL)‚àí1AQ For the sake of completeness, let us reiterate that the condition QTQ = Ik is not re- strictive but necessary to eliminate arbitrary rescalings. In passing, we point out that the result above corrects an error in [15] where it is incorrectly stated that P = AQ. Proof. Since the variable P in the functional (4.5) is unconstrained, we can identify the optimum in P (for Ô¨Åxed Q) by computing the gradient: 1 2‚àáPF = (PQT ‚àíA)Q +ŒªDT DP (4.7) and solving for P: ‚àáPF = 0 ‚áí P QTQ | {z } Ik ‚àíAQ +ŒªLP = 0 ‚áí (Ip +ŒªL)P = AQ. (4.8) This condition needs to hold at the solution point. By Ô¨Årst re-writing F(P,Q) formula as the trace of matrices and then plugging in Eq. (4.8), we have: F(P,Q) = Tr ¬£ (A ‚àíPQT )(AT ‚àíQPT ) ¬§ +ŒªTr(PT LP)+¬µTr(QT MQ) = Tr ¬£ AAT ‚àíAQPT ‚àíPQT AT +PQTQPT ¬§ +ŒªTr(PT LP)+¬µTr(QT MQ) 64 4. REGULARISED MATRIX FACTORIZATION Considering the fact that the trace operator is invariant under transposition as well as cyclic permutation, we arrive at: F(P,Q) = Tr ¬£ AAT ‚àí2(Ip +ŒªL)PPT +PPT ¬§ +ŒªTr(PT",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_75"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " the fact that the trace operator is invariant under transposition as well as cyclic permutation, we arrive at: F(P,Q) = Tr ¬£ AAT ‚àí2(Ip +ŒªL)PPT +PPT ¬§ +ŒªTr(PT LP)+¬µTr(QT MQ) = Tr ¬° AAT ‚àíPPT ‚àí2ŒªLPPT ¬¢ +ŒªTr(PT LP)+¬µTr(QT MQ) = Tr(AAT )‚àíTr(PPT )‚àí2ŒªTr(LPPT )+ŒªTr(PT LP)+¬µTr(QT MQ) = Tr(AAT )‚àíTr(PT P)‚àíŒªTr(PT LP)+¬µTr(QT MQ) = Tr(AAT )‚àíTr Ô£Æ Ô£ØÔ£∞PT (Ip +ŒªL)P | {z } AQ Ô£π Ô£∫Ô£ª+¬µTr(QT MQ). (4.9) Extracting P and its transpose from Eq. (4.8): P = (Ip +ŒªL)‚àí1AQ ‚áí PT = QT AT (Ip +ŒªL)‚àí1 as L is symmetric. (4.10) hence: F(P,Q) = Tr(AAT )‚àíTr ¬£ QT ¬° AT (Ip +ŒªL)‚àí1A ‚àí¬µM ¬¢ Q ¬§ . (4.11) Therefore, in order to minimize F, one must maximize the right-most term in Eq. (4.11), as Tr(AAT ) is a constant value. This is achieved by selecting for Q, eigenvectors corre- sponding to the k largest eigenvalues of (AT (Ip +ŒªL)‚àí1A ‚àí¬µM). Once Q is determined, P is obtained via Eq. (4.10). As a concluding remark, we point out that the matrix Ip + ŒªL is always invertible. Indeed, since L = DT D is positive semi-deÔ¨Ånite and symmetric, it has a complete set of eigenvectors with corresponding non-negative eigenvalues, i.e., L = W ŒõW T , where W is orthogonal (i.e., W T W = W W T = Ip) and Œõ ‚â•0. Hence, the matrix (Ip +ŒªL) = W (Ip +ŒªŒõ)W T has a complete set of strictly positive eigenvalues, and is therefore invertible. Some illustrative numerical experiments can be found in [",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_76"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " ‚â•0. Hence, the matrix (Ip +ŒªL) = W (Ip +ŒªŒõ)W T has a complete set of strictly positive eigenvalues, and is therefore invertible. Some illustrative numerical experiments can be found in [18]. 4.2.2. SOME SPECIAL CASES ‚Ä¢ Œª = 0 and ¬µ = 0 : In that case, Q comprises the Ô¨Årst k eigenvectors of K = AT A and P = AQ, which means that we end up with the standard SVD, as expected. Some numerical experiments can be found in [19]. ‚Ä¢ D = Ip and ¬µ = 0 : These conditions correspond to what is assumed in [13] where a regularized K-SVD problem is addressed. In the aforementioned work, the au- thors consider a special case, where ¬µ = 0 and D = Ip. Since this implies that L = DT D = Ip and ¬µ M = 0, the matrix K simpliÔ¨Åes to: K = 1 1+Œª AT A 4.3. REGULARISATION FOR SVD-TYPE FACTORISATION 65 The eigenvectors of K are therefore the right singular vectors of A (i.e., the eigen- vectors of AT A). Hence Q = V(1:k), and as a result: P = 1 1+Œª AQ and AQ =U(1:k) diag(œÉ1,...,œÉk). In particular, for k = 1 (the rank-1 reconstruction), we obtain: Q = V1 and P = œÉ1 1+Œª U1 which is the result that can be found in [13]. The experiments are available in [20]. 4.3. REGULARISATION FOR SVD-TYPE FACTORISATION Having discussed the PCA-type factorisation, let us next turn our attention to the SVD- type factorisation which looks for an approximation of the form: A ‚âàPBQT subject to: QTQ = Ik, ||Pi|| = 1 ‚àÄi ‚àà{1,2,...,k}, and B diagonal. Loosely speaking, since the columns of P and Q are of unit length, they only pin down the structure of A, whereas the diagonal matrix B = diag(Œ≤1,Œ≤2,...,Œ≤k) captures the amplitude of the corresponding structures. Similar to SVD, discussed in Chapter 2",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_77"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " are of unit length, they only pin down the structure of A, whereas the diagonal matrix B = diag(Œ≤1,Œ≤2,...,Œ≤k) captures the amplitude of the corresponding structures. Similar to SVD, discussed in Chapter 2, the columns of Q are orthonormal, i.e., we again insist on QTQ = Ik. However, unlike before, the columns of P are now only required to have unit length. In respect of the SVD-type matrix factorisation technique, Theorems 8 and 9 provide alternative solutions to the lower-rank matrix approximation problem. For notational convenience, Theorem 8 Ô¨Årst addresses a simpliÔ¨Åed case of functional (4.4) where ¬µ = 0. Following that, Theorem 9 discusses a more general case of the SVD-type factorisation. Theorem 8 (Regularised SVD). Let A be a p √ó q matrix of rank r ‚â§min(p,q). More- over, for k ‚â§r, let P ‚ààRp√ók and Q ‚ààRq√ók of rank k, while B ‚ààRk√ók diagonal (i.e., B = diag(Œ≤1,Œ≤2,...,Œ≤k)). Furthermore, for an arbitrary positive integer d, we introduce a reg- ularisation matrix D ‚ààRd√óp, as well as weight Œª ‚â•0. Finally, we introduce the short-hand notation L := DT D ‚ààRp√óp (symmetric and positive-deÔ¨Ånite). We are now in a position to deÔ¨Åne the following functional F of the variables P,Q and B: F(P,Q,B) = ||A ‚àíPBQT ||2 +Œª||DP||2, (4.12) and the corresponding constrained optimisation problem: min P,Q,B F(P,Q,B) subject to: QTQ = Ik, ||Pi|| = 1 ‚àÄi ‚àà{1,2,...,k}, and B diagonal. (4.13) This problem is solved by the solution speciÔ¨Åed below in Algorithm 1. Proof. Since B is unconstrained, we can determine its optimal value by computing the derivative with respect to B and equating it to zero: ‚àáBF(P,Q,B) = ‚àáB||A ‚àíPBQT ||2. (4.14) 66 4. REGULARISED MATRIX FACTORIZATION Algorithm 1: Regularised S",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_78"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " B and equating it to zero: ‚àáBF(P,Q,B) = ‚àáB||A ‚àíPBQT ||2. (4.14) 66 4. REGULARISED MATRIX FACTORIZATION Algorithm 1: Regularised SVD method (version 1: ¬µ = 0) Input: A, k, Œª, D Output: P, B, Q Initialization while no convergence do 1. Determine the q √ók matrix Q = [Q1,Q2,...,Qk] (with orthonormal columns, i.e., QTQ = Ik) such that the sum of the smallest eigenvalue of each of k symmetric matrices S(Qi) (see Eq. (4.21)) is minimal, i.e.,: min Q œà(Q) = min Q kX i=1 Œª1(Qi) such that QTQ = Ik where Œª1(Qi) = min(eig(S(Qi)). To this end we use gradient descent (see Section 4.4). 2. For each Qi as determined above, take Pi to be the eigenvector W1(Qi) corresponding to the smallest eigenvalue Œª1(Qi). Construct the p √ók matrix P = [P1,P2,...,Pk]. 3. Finally, set B = diag(Œ≤1,...,Œ≤n) where Œ≤i = (PT AQ)ii. end Expanding the norm in terms of a trace (cf. Eq. (4.2)), then using the invariance of a trace under transposition, we arrive at (recall QTQ = Ik ): ||A ‚àíPBQT ||2 = Tr ¬£ (A ‚àíPBQT )(AT ‚àíQBPT ) ¬§ = Tr(AAT )‚àí2Tr(AQBPT )+Tr(PB2PT ) = ||A||2 ‚àí2Tr(PT AQB)+Tr(B2PT P) = ||A||2 ‚àí2 kX i=1 (PT AQ)ii Œ≤i + kX i=1 (PT P)ii Œ≤2 i = ||A||2 ‚àí2 kX i=1 (PT AQ)ii Œ≤i + kX i=1 Œ≤2 i (4.15) The last simpliÔ¨Åcation is obtained due to the fact that ||Pi|| = 1 ‚áí(PT P)ii = 1. Therefore the gradient of the functional F with respect to B is calculated as",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_79"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " i (4.15) The last simpliÔ¨Åcation is obtained due to the fact that ||Pi|| = 1 ‚áí(PT P)ii = 1. Therefore the gradient of the functional F with respect to B is calculated as follow: ‚àÇ ‚àÇŒ≤i ||A ‚àíPBQT ||2 = 2(Œ≤i ‚àí(PT AQ)ii). For given P and Q matrices, we then Ô¨Ånd the optimal B by insisting that the resulting gradient vanishes, which yields: Œ≤i = (PT AQ)ii ‚àÄi ‚àà{1,2,...,k}. (4.16) 4.3. REGULARISATION FOR SVD-TYPE FACTORISATION 67 Plugging this optimal choice back into Eq. (4.15) the functional (4.12) simpliÔ¨Åes to ||A ‚àíPBQT ||2 = ||A||2 ‚àí kX i=1 Œ≤2 i (4.17) In order to recast Eq. (4.17) in terms of P and Q (and consequently eliminate B), we ob- serve that for an arbitrary matrix H, we have Hi j = eT i Hej , where ei = (0,0,...,1,...,0)T vectors are the standard bases (similarly for ej ). Hence, using the fact that the diagonal of a matrix is unchanged under transposition, we conclude that: Œ≤i = Ô£± Ô£≤ Ô£≥ (PT AQ)ii = eT i PT AQ ei = PT i AQi (QT AT P)ii = eT i QT AT P ei = QT i AT Pi where Pi,Qi are the i-th columns of P and Q, respectively. i.e., P = [P1,P2,...,Pk] and Q = [Q1,Q2,...,Qk]. As a consequence: kX i=1 Œ≤2 i = kX i=1 PT i AQi QT i AT Pi. (4.18) As a Ô¨Ånal step, we introduce the notation L = DT D to recast the regularisation term as: ||DP||2 = Tr(PT LP) = kX i=1 eT i PT LP ei = kX i=1 PT i L Pi. (4.19) Plugging Eqs. (4.18) and (4.19) into Eq. (",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_80"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " LP) = kX i=1 eT i PT LP ei = kX i=1 PT i L Pi. (4.19) Plugging Eqs. (4.18) and (4.19) into Eq. (4.12), we obtain the following simpliÔ¨Åed form for the functional F (assuming that we eliminate B using its optimal value): F(P,Q) = ||A||2 +F1(P,Q), where F1(P,Q) = kX i=1 PT i (ŒªL ‚àíAQiQT i AT )Pi (4.20) Introducing the notation S(Qi) := ŒªL ‚àíAQiQi T AT , we derive: F1(P,Q) = kX i=1 PT i S(Qi)Pi (4.21) Since each S(Qi) is a symmetric p√óp matrix, it can be diagonalised with respect to an or- thonormal basis, i.e., there is an orthogonal p √ó p matrix W (such that W T W = W W T = Ip) and a diagonal matrix Œõ = diag(Œª1,...,Œªp) (ordered Œª1 ‚â§Œª2 ‚â§... ‚â§Œªp), both de- pending on Qi such that S(Qi) = W (Qi)Œõ(Qi)W (Qi)T i.e., the columns of W are the eigenvectors of S(Qi), with the corresponding eigenval- ues on the diagonal of Œõ. By introducing the notation Œª1(S(Qi)) to denote the smallest eigenvalue of Œõ(Qi), we obtain the minimal value PT i S(Qi)Pi = Œª1(Qi), by choosing Pi to be the (unit) eigenvector (W1(Qi)) corresponding to the smallest eigenvalue. As a conse- quence, the solution strategy boils down to steps in Algorithm 1. This choice of P,Q and B solves the constrained minimisation problem (4.13). Notice that due to the fact that P and B matrices are determined after Ô¨Ånding Q, this optimi- sation problem can essentially be translated into a search problem in the space of Q matrices. Some illustrative numerical experiments are available at [21]. 68 4. REGULARISED MATRIX FACTORIZATION Below we proceed further by giving a slightly more general version of the previous theorem where ¬µ Ã∏= 0",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_81"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " space of Q matrices. Some illustrative numerical experiments are available at [21]. 68 4. REGULARISED MATRIX FACTORIZATION Below we proceed further by giving a slightly more general version of the previous theorem where ¬µ Ã∏= 0, thus re-establishing the symmetry between P and Q. Theorem 9 (Regularised SVD, symmetric version). Similar to the previous theorem, let A be a p √ó q matrix of rank r ‚â§min(p,q). For k ‚â§r, let P ‚ààRp√ók and Q ‚ààRq√ók of rank k, while B ‚ààRk√ók diagonal (i.e., B = diag(Œ≤1,Œ≤2,...,Œ≤k)). Furthermore, for arbitrary strictly positive integers d and g we introduce regularisation matrices D ‚ààRd√óp, and G ‚ààRg√óq, as well as weights Œª,¬µ ‚â•0. Finally, we introduce the short-hand notation L := DT D ‚ààRp√óp and M := GTG ‚ààRq√óq symmetric and positive-deÔ¨Ånite. We are now in a position to deÔ¨Åne the following functional F in the variables P,Q and B: F(P,Q,B) = ||A ‚àíPBQT ||2 +Œª||DP||2 +¬µ||GQ||2 (4.22) and the corresponding constrained optimisation problem: min P,Q,B F(P,Q,B) subject to: QTQ = Ik, ||Pi|| = 1, ‚àÄi ‚àà{1,2,...,k} and B diagonal. (4.23) A solution to this problem is proposed in Algorithm 2. Proof. Following the notations and results introduced above and in Theorem 8, let us add: ||GQ||2 = Tr(QT MQ) = kX i=1 QT i MQi Hence, the functional (4.22) can be recast as: F(P,Q) = ||A||2 +F2(P,Q), where F2(P,Q) = kX i=1 PT i (ŒªL ‚àíAQiQT i AT )Pi +¬µ kX i=1 QT i MQi (4.24) The minimum of each term in the Ô¨Årst summation in F2 is equal to the smallest eigen- value Œª1(S(Qi)). Finding the minimum for the constrained optimisation problem (4.23) therefore amounts to Ô¨Ånding",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_82"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " The minimum of each term in the Ô¨Årst summation in F2 is equal to the smallest eigen- value Œª1(S(Qi)). Finding the minimum for the constrained optimisation problem (4.23) therefore amounts to Ô¨Ånding the minimum of the functional: œà(Q) := kX i=1 ¬° Œª1(S(Qi))+¬µQT i MQi) ¬¢ (4.25) subject to the constraint QTQ = Ik. Therefore, the minimisation problem again calls for minimisation in Q space, as the optimal choice for P (corresponding eigenvectors) fol- lows automatically. We, therefore, arrive at the following Algorithm 2. Some illustrative numerical examples are available in [21]. 4.4. COMPUTATIONAL ASPECTS 4.4.1. GRADIENT AND RANDOM DESCENT ON THE UNITARY DOMAIN Gradient Descent From Algorithm 2 it becomes clear that the full regularisation prob- lem can be reduced to a simpler constrained minimisation problem detailed in Eq. (4.25). Since the œà-functional is smooth on a compact domain, this minimum is guaranteed to 4.4. COMPUTATIONAL ASPECTS 69 Algorithm 2: Regularized SVD method (version 2: ¬µ Ã∏= 0) Input: A, k, ¬µ, Œª, D, G Output: P, B, Q Initialization L = DT D, M = GTG while no convergence do 1. Recall that for any unit vector Qi ‚ààRq we deÔ¨Åne S(Qi) = ŒªL ‚àíAQiQi T AT . Since this is a symmetric p √ó p matrix, it has a complete set of eigenvectors and corresponding eigenvalues. Denote the smallest eigenvalue of each S(Qi) as Œª1(S(Qi)), and the corresponding (unit) eigenvector as w1(S(Qi)). 2. For a given q √ók matrix Q = [Q1,Q2,...,Qk] (with orthonormal columns: QTQ = Ik) compute the functional: œà(Q) := kX i=1 ¬° Œª1(S(Qi))+¬µQT i MQi) ¬¢ and use gradient descent (on the compact torus domain, see Section 4.4) to Ô¨Ånd the minimum. 3. For each Qi as determined above, take Pi to be the eigenv",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_83"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "QT i MQi) ¬¢ and use gradient descent (on the compact torus domain, see Section 4.4) to Ô¨Ånd the minimum. 3. For each Qi as determined above, take Pi to be the eigenvector W1(Qi) corresponding to the smallest eigenvector Œª1(S(Qi)). Construct the p √ók matrix P = [P1,P2,...,Pk]. 4. Finally, set B = diag(Œ≤1,...,Œ≤n) where Œ≤i = (PT AQ)ii. end exist and one can use gradient descent to locate it. However, gradient descent needs to respect the constraint QTQ = Ik, i.e., the Q-columns need to constitute orthonor- mal bases (or frames). This can be achieved by applying an orthogonal transformation (‚Äúrotation\") to the current Q matrix, as it will preserve orthonormality. Put differently, applying a rotation R to an orthonormal frame Q results in a new orthonormal frame (say ÀúQ). In mathematical parlance, recall that all orthogonal q √óq matrices with a deter- minant equal to 1 (rather than ‚àí1) constitute a multiplicative group denoted as SO(q) and formally deÔ¨Åned as: SO(q) = ¬© R ‚ààRq√óq | RRT = Iq = RT R, and det(R) = 1 ¬™ It is then straightforward to check that for any R ‚ààSO(q), it holds that if ¬ØQ = RQ, the condition QTQ = Ik implies that ¬ØQT ¬ØQ = Ik. In view of the above, it follows that we can generate the ‚ÄúinÔ¨Ånitesimal variations\" needed to compute the gradient ‚àáQœà(Q) by applying ‚ÄúsufÔ¨Åciently small‚Äù orthogonal ma- trices to the current value of Q. More precisely, we draw on the fact that SO(q) is actually a Lie-group [22] and that therefore each R ‚ààSO(q) can be generated by exponentiat- ing an element from its Lie-algebra SO(q) = ¬© K ‚ààRq√óq | K T = ‚àíK ¬™ (the skew-symmetric 70 4. REGULARISED MATRIX FACTORIZATION matrices): R = exp(tK ) ‚â°Iq + tK + 1 2! t2K 2 +...+ ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_84"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " ‚àíK ¬™ (the skew-symmetric 70 4. REGULARISED MATRIX FACTORIZATION matrices): R = exp(tK ) ‚â°Iq + tK + 1 2! t2K 2 +...+ 1 n! t pK p +... (with K T = ‚àíK ) By choosing t sufÔ¨Åciently small, one obtains an orthogonal transformation that is close to the identity Iq. Furthermore, it sufÔ¨Åces to restrict the variations to orthogonal trans- formations that result from exponentiating a basis for the space of skew-symmetric ma- trices. Such a basis is provided by the q(q ‚àí1)/2 skew-symmetric matrices Ki j (where 1 ‚â§i < j ‚â§q) for which the matrix element k,‚Ñìis given by: Ki j (k,‚Ñì) = Ô£± Ô£≤ Ô£≥ 1 if k = i, ‚Ñì= j ‚àí1 if k = j, ‚Ñì= i 0 otherwise Worth noting that SO(q) can equivalently be generated, using any random K matrix that satisÔ¨Åes K = ‚àíK T [23]. Given the current value Q0, we construct nearby values for Q by looping over K12,K13,K23,...etc and constructing the corresponding orthogonal matri- ces R12(t) = exp(tK12),...,etc. Denoting these ‚ÄúinÔ¨Ånitesimal‚Äù rotation matrices as RŒ± (where Œ± = 1,...,q(q ‚àí1)/2), we see that the partial derivatives with respect to these ro- tations can be estimated as: ‚àÇœà(Q) ‚àÇRŒ± ‚âàœà(RŒ±(t)Q0)‚àíœà(Q0) t (for t sufÔ¨Åciently small). From these results we can select the inÔ¨Ånitesimal rotation that results in the steepest descent. Random Descent It is worth mentioning that since computing œà(Q) is computation- ally expensive (it requires determining eigenvalues), a viable alternative to computing the gradient is random descent: generate random rotations (by exponentiating random skew matrices) and check whether they result in a lower œà-value. As soon as one is found, proceed in that direction, and repeat the process. 4.4.2. ILLUSTRATIVE EXAMPLE: SMOOTHING A NOISY MATRIX One way",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_85"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " whether they result in a lower œà-value. As soon as one is found, proceed in that direction, and repeat the process. 4.4.2. ILLUSTRATIVE EXAMPLE: SMOOTHING A NOISY MATRIX One way to think about the regularisation based on the matrix product DP (a similar argument holds for GQ), is that the rows of D specify Ô¨Ålters (with applications e.g., in image processing) that will be applied to the columns of P. Indeed, using the convention that Ai and Ai denote the i-th column and row of A respectively, we observe that: DP = Ô£´ Ô£¨Ô£≠ D1 ... Dd Ô£∂ Ô£∑Ô£∏(P1,...,Pk) = Ô£´ Ô£¨Ô£≠ D1P1 ... D1Pk ... ... ... DdP1 ... DdPk Ô£∂ Ô£∑Ô£∏ Since the functional minimisation attempts to keep the norm of the resulting matrix small, this amounts to keeping the response of the Ô¨Ålters on the P-columns sufÔ¨Åciently small. 4.4. COMPUTATIONAL ASPECTS 71 To illustrate the above, let us start from the assumption, common in the literature e.g., [14, 15, 24], that the p √óq data matrix A has a relatively smooth underlying structure that is corrupted by noise: A =UV T +œÑZ where the p √ó q matrix Z has independent standard normal entries, and œÑ controls the size of the noise. To recover the underlying ‚Äúsignals\" U and V , we minimise the SVD-type regularisa- tion functional (4.22) where the smoothness of the result is enforced by using regulari- sation matrices D and G that extract the second derivative as follows: D = F = Ô£Æ Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞ ‚àí1 1 0 ¬∑¬∑¬∑ 0 1 ‚àí2 1 0 ¬∑¬∑¬∑ 0 0 1 ‚àí2 1 0 ¬∑¬∑¬∑ 0 0 0 1 ‚àí2 1 ¬∑¬∑¬∑ 0 0 ... ... ... ... 0 ... ¬∑¬∑¬∑ 0 1 ‚àí2 1 0 ¬∑¬∑¬∑ 0 1 ‚àí",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_86"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 1 0 ¬∑¬∑¬∑ 0 0 0 1 ‚àí2 1 ¬∑¬∑¬∑ 0 0 ... ... ... ... 0 ... ¬∑¬∑¬∑ 0 1 ‚àí2 1 0 ¬∑¬∑¬∑ 0 1 ‚àí1 Ô£π Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª A typical result for a rank-1 (k = 1) approximation is depicted in Figure 4.1, and com- pared to the standard SVD solution. This illustrative example is available in [25]. 72 4. REGULARISED MATRIX FACTORIZATION Figure 4.1: Reconstruction of noisy matrix based on RSVD. Top left: noise-less rank-1 matrix UV T , (image) , top right: noisy input image UV T + œÑZ (high noise level), Middle left: standard rank-1 SVD reconstruction, middle right: RSVD reconstruction (D and G are 2nd derive matrices. weight parameters Œª = ¬µ = 1.5). Bottom: comparison of standard SVD U(:,1) (red) versus P (blue), and V (:,1) (red) (left) versus Q (blue) (right). The actual U and V for the noiseless input signal are drawn in green. 4.5. EARLIER RESULTS, BASED ON ADHOC SMOOTHING 73 4.5. EARLIER RESULTS, BASED ON ADHOC SMOOTHING Throughout this thesis, the way we have constructed matrices out of time series means that rows and columns play a slightly different roles. Rows capture the in-period (e.g. in- day) variation, whereas columns represent the between-period variation. Put differently, rows capture the ‚Äúfast dynamics\", and columns the slow dynamics. This shows that we can look at the SVD as a (temporal) multi-scale decomposition. In this chapter, we will use this insight for two applications: ‚Ä¢ Smoothing and image enhancing ‚Ä¢ Forecasting (using V component to predict next day) In below, we Ô¨Årst introduce the second derivative operator as a pre-processing step. The use of SVD to outline the patterns in the data is presented next. Rank-7 reconstruction In addition to appearing visually unbiased, the choice of re- construction rank was done based on the structural",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_87"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " the second derivative operator as a pre-processing step. The use of SVD to outline the patterns in the data is presented next. Rank-7 reconstruction In addition to appearing visually unbiased, the choice of re- construction rank was done based on the structural similarity index (SSIM)‚Äìa popular criterion in image quality assessments [26]. SSIM measures the deviation of a recon- structed image (matrix) Ap from its original matrix A, by comparing their corresponding local means, standard deviations, and cross-covariance matrices [26]. Figure 4.2 displays the fact that the matrices reconstruction quality level off after p = 7, in terms of SSIM. Consequently, we opted for rank-7 as an appropriate approximation in our methodolo- gies. It is worth noting that this Ô¨Ågure also highlights the different levels of the volatility of the various quantities: wind (most erratic) results in the lowest similarity, while solar feed-in (most predictable) agrees best with the approximation. 1 3 5 7 9 11 13 15 17 19 21 23 Reconstruction Rank (r) 0 0.2 0.4 0.6 0.8 1 SSIM from the original data Price Load Quantity Solar Wind Figure 4.2: An overview of SSIM, for different reconstruction ranks (p = 1,...,24). 4.5.1. FINDING PEAKS AND VALLEYS As mentioned previously, the scope of this work, in the context of the electricity market, is to explore how the inherent variability of the supply by RES can change the intra-day volatility of the day-ahead price values. To this end, within this matrix context, we add 74 4. REGULARISED MATRIX FACTORIZATION 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -20 -15 -10 -5 0 5 10 15 20 25 (a) Intra-day 2nd derivative of price 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -3 -2 -1 0 1 2 (b) 1st rank reconstruction of Fig.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_88"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -3 -2 -1 0 1 2 (b) 1st rank reconstruction of Fig. 4.3(a) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -4 -3 -2 -1 0 1 2 3 (c) 7th rank reconstruction of Fig. 4.3(a) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 (d) Intra-day 2nd derivative of solar 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.6 -0.4 -0.2 0 0.2 0.4 0.6 (e) 1st rank reconstruction of Fig. 4.3(d) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.6 -0.4 -0.2 0 0.2 0.4 0.6 (f) 7th rank reconstruction of Fig. 4.3(d) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4 0.5 (g) Intra-day 2nd derivative of wind 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.08 -",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_89"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "-day 2nd derivative of wind 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.08 -0.06 -0.04 -0.02 0 0.02 0.04 0.06 0.08 (h) 1st rank reconstruction of Fig. 4.3(g) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.08 -0.06 -0.04 -0.02 0 0.02 0.04 0.06 0.08 (i) 7th rank reconstruction of Fig. 4.3(g) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -3 -2 -1 0 1 2 (j) Intra-day 2nd derivative of load 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 (k) 1st rank reconstruction of Fig. 4.3(j) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 (l) 7th rank reconstruction of Fig. 4.3(j) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 (m) Intra-day 2nd derivative of quan- tity 50 100 150 200 250 ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_90"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "1.5 -1 -0.5 0 0.5 1 1.5 2 (m) Intra-day 2nd derivative of quan- tity 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -1 -0.5 0 0.5 1 (n) 1st rank reconstruction of Fig. 4.3(m) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -1 -0.5 0 0.5 1 (o) 7th rank reconstruction of Fig. 4.3(m) Figure 4.3: Left: The intra-day 2nd derivative of the daily proÔ¨Åles in 2016, for (top to bottom) price, solar and wind feed-in, load and traded quantity. The underlying trends are magniÔ¨Åed using rank-1 (middle) and rank-7 (right) reconstruction. 4.5. EARLIER RESULTS, BASED ON ADHOC SMOOTHING 75 an initial pre-processing step- an additional transformation on the daily proÔ¨Åles of the quantities of interest (viz. price, load, traded quantity, solar and wind feed-in). More pre- cisely, any of the above daily proÔ¨Åles (generically denoted by f ) is regarded as a function of two variables: ‚Ä¢ time of the day; hour slots 1 ‚â§h ‚â§24 ‚Ä¢ day of the year; 1 ‚â§d ‚â§366 (2016 is a leap year!) Therefore, for such a function f (h,d), it is feasible to obtain the corresponding intra-day 2nd derivatives with respect to the hour: fhh ‚â°‚àÇ2 f ‚àÇh2 ‚âàf (h +1)‚àí2f (h)+ f (h ‚àí1) h2 (4.26) The resultant 2nd derivative proÔ¨Åles represent the daily dynamics of the original matrix columns; as their extreme values capture the peaks (i.e. local maxima for which fhh < 0 and extreme) or valleys (i.e. local minima for which fhh > ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_91"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "les represent the daily dynamics of the original matrix columns; as their extreme values capture the peaks (i.e. local maxima for which fhh < 0 and extreme) or valleys (i.e. local minima for which fhh > 0 and extreme). Figure 4.4 pro- 1 3 5 7 9 11 13 15 17 19 21 23 10 11 12 13 14 GWh Wind Profile on 2016-11-18 1 3 5 7 9 11 13 15 17 19 21 23 Hourslots (1-24) -1 -0.5 0 0.5 1 GWh.h‚àí2 The Intra-day 2nd derivative Figure 4.4: The day-ahead wind proÔ¨Åle on Nov. 18, and its corresponding intra-day 2nd derivatives. Every sag in the lower proÔ¨Åle corresponds to a swell in upper and vice versa. vides an example where the upper panel contains the wind feed-in proÔ¨Åle on Nov. 18, 2016, and the lower one corresponds to its intra-day 2nd derivative proÔ¨Åle. We contend that comparing the evolution of the intra-day 2nd derivative proÔ¨Åles is useful in investi- gating the impact of the wind and solar energy feed-in on the price and also the traded quantity in 2016. Applying this intra-day 2nd derivative operator to all Ô¨Åve quantities of interest, in the matrix context, facilitates spotting some interesting features of the data. Figure 4.5 76 4. REGULARISED MATRIX FACTORIZATION illustrates the 2nd derivatives for both solar (left) and wind feed-in (right). In the left panel, the gradual shift of the daybreak and the nightfall over the seasons is clearly visi- ble. Closer inspection of this Ô¨Ågure also reveals the dates of the switch to daylight saving summer time (days 87 and 304). As expected, the wind values (right panel) are more er- 50 100 150 200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) 0 2 4 6 8 10 Solar Feed-in (GWh) 50 100 ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_92"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) 0 2 4 6 8 10 Solar Feed-in (GWh) 50 100 150 200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) 2 4 6 8 10 12 14 Wind (GWh) 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 50 100 150 200 250 300 350 Days of the year (1-366) 5 10 15 20 Hour slots (1-24) -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4 0.5 Figure 4.5: Top Ô¨Ågures provide an overview of the solar (left) and wind (right) day-ahead values. Bottom Ô¨Ågures contains the second derivative of the same data. Using this approach magniÔ¨Åes the underlying patterns in the data and also enables us to spot anomalies and abrupt changes in the data. ratic and less seasonally determined. However, there is a striking ‚Äúeye-like‚Äù shape that faintly mirrors the intra-day wind activities (see, e.g., [27]). 4.5.2. USING SVD TO HIGHLIGHT STRUCTURE SVD is a conceptually simple and numerically stable matrix decomposition technique [28]. An outstanding feature of the SVD method is its ability in separating the fundamen- tal ‚ÄúproÔ¨Åles‚Äù constituting a quasi-periodic time series and also indicating their relative strengths [29]. The geometrical interpretation of the SVD indicates that the columns of U ‚ààO(24√ó 24) represent daily proÔ¨Åles, whereas the columns of V ‚ààO(366√ó366) furnish correspond- ing amplitudes (one for each day). Figure 4.6 shows a concrete illustration of the 24√ó366 price matrix: the upper left panel depicts the",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_93"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ", whereas the columns of V ‚ààO(366√ó366) furnish correspond- ing amplitudes (one for each day). Figure 4.6 shows a concrete illustration of the 24√ó366 price matrix: the upper left panel depicts the most dominant proÔ¨Åle (the Ô¨Årst columnU1) 4.5. EARLIER RESULTS, BASED ON ADHOC SMOOTHING 77 1 3 5 7 9 11 13 15 17 19 21 23 Hourslots (1-24) 0.14 0.16 0.18 0.2 0.22 0.24 0.26 1st dominant daily profile (U1) 1 3 5 7 9 11 13 15 17 19 21 23 Hourslots (1-24) -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 2nd dominant daily profile (U2) 10 50 90 130 170 210 250 290 330 Days of year (1-366) -0.04 -0.02 0 0.02 0.04 0.06 0.08 0.1 Associated weights to U1 (V1) 10 50 90 130 170 210 250 290 330 Days of year (1-366) -0.2 -0.1 0 0.1 0.2 0.3 0.4 0.5 Associated weights to U2 (V2) Figure 4.6: The Ô¨Årst two most dominant U proÔ¨Åles (U1 and U2). The lower two panels contain their corre- sponding amplitudes (V1 and V2) throughout the year. which highly resembles the overall daily proÔ¨Åle (basically, a weighted average over the year). The expected morning and early evening price picks are clearly discernible. Their corresponding daily amplitudes are given by column V1, as displayed in the 3rd panel (bottom left). Exceptional days with notable low or high (average) prices are clearly vis- ible. A rank-1 approximation of the original time series could, therefore, be obtained",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_94"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " V1, as displayed in the 3rd panel (bottom left). Exceptional days with notable low or high (average) prices are clearly vis- ible. A rank-1 approximation of the original time series could, therefore, be obtained by putting p = 1 in Eq. (2.5); i.e. using only the most dominant singular value œÉ1, and the average daily proÔ¨Åle U1 in the top panel and their corresponding magnitude through- out the year using 366 values in V1. Note that in such a rank-1 matrix, all the columns are linearly dependent, i.e., the shape of all the daily proÔ¨Åles are the same and only their am- plitudes vary from one day to another. TheU2 proÔ¨Åle (top right) is considered an account for seasonal variations, as it deÔ¨Ånes the Ô¨Årst correction to U1. Their corresponding am- plitudes for this correction are speciÔ¨Åed in V2 (bottom right). Put differently, this correc- tion implies that any day for which the corresponding V2 coefÔ¨Åcient is positive (mostly during the summer) will have a lower price value between 11h and 18h than would be expected based on the (weighted) annual averageU1. In a similar fashion, increasing the reconstruction rank, by adding additional terms in the SVD expansion will improve the approximation. Figure 4.7 presents a case where the day-ahead price data for a given day (18 Jan. 2016) can be almost fully reconstructed using lower-rank approximation up to rank 7. Figure 4.8 displays V1 and its corresponding smoother version which was applied in the calculation of Ap. Using the smoothed version of the Vk vectors in the low-rank re- 78 4. REGULARISED MATRIX FACTORIZATION 1 3 5 7 9 11 13 15 17 19 21 23 Hourslots (1-24) 20 30 40 50 60 70 Euro/MWh Price on 2016-01-18 Actual profile 1st rank 3rd rank 7th rank Figure 4.7: Low rank approximation of actual data (one particular day, Jan. 18, blue). Including up to 7 SVD components yields the rank-7 approximation (bold red). Lower rank approximations",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_95"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 7th rank Figure 4.7: Low rank approximation of actual data (one particular day, Jan. 18, blue). Including up to 7 SVD components yields the rank-7 approximation (bold red). Lower rank approximations are also shown. 10 50 90 130 170 210 250 290 330 Days of year (1-366) -0.12 -0.1 -0.08 -0.06 -0.04 -0.02 0 0.02 Original Smoothed Figure 4.8: An example of V1 and its smoother version which is used in the reconstruction step. construction of data, is a way of accounting for outliers while magnifying the underlying patterns as depicted in Figure 4.3. The panels on the left-hand column illustrate the orig- inal 2nd derivative proÔ¨Åles for the various quantities of interest (price, solar and wind feed-in, load and traded quantity). The two other adjacent columns display two differ- ent lower-rank reconstructions of the same data, after smoothing their Vk columns; a rough rank-1 approximation (middle) and a much more accurate rank-7 approximation. 4.5.3. STRUCTURE-PRESERVING SMOOTHING In the following section, we propose a straightforward method using SVD factorization to highlight the faint structures seen in Figure 4.5. Recall that the right singular vectors of Vk in the SVD, determine the amplitudes of each corresponding Uk proÔ¨Åle for each day. Therefore, smoothing these amplitudes across the year is a way of diminishing most of 4.6. DATA 79 the inter-day variations without affecting the overall structure. In the current task, the smoothing was done based on the robust local regression (RLOESS) model, but alter- native approaches would be equally valid. We opted for the local regression smoothing method as it alleviates the effect of outliers by assigning a lower weight to them in the regression and also allotting zero weight to data points outside six mean absolute devi- ations [30]. Therefore, in line with the aforementioned smoothing mechanism, matrix factorization can be reformulated as follow: Ap = arg min rank(R)=p (||A ‚àíR||+Œª ||dV ||s) (4.27) where ||.||s is an outlier-resistant robust local regression model as a smoothing func",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_96"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " be reformulated as follow: Ap = arg min rank(R)=p (||A ‚àíR||+Œª ||dV ||s) (4.27) where ||.||s is an outlier-resistant robust local regression model as a smoothing func- tion as in [30]. In the recent applications of SVD, regularization has become an increasing trend. The following section provides an overview of Regularized SVD (RSVD) as the corner- stone of this chapter. 4.6. DATA An exchange for the next-day power delivery contracts, where the tradings are driven by its participants, is the day-ahead electricity market. Energy trading entities, banks and Ô¨Ånancial service providers play a prominent role in increasing the liquidity of the whole- sale power market [31]. These members are mainly focused on market and trade across borders, even though not necessarily own any power assets. Therefore, grid loss com- pensation is a great prime for TSOs to intervene in the spot market [32]. Furthermore, regulating feed-in tariff schemes for marketing zero-carbon energy sources is extensively practiced by the TSO in Germany. Consequently, understanding the market during this post-transition era is of great practical value. Figure 4.9 provides an overview of vari- ous collected sets of data for the German day-ahead market in 2016. The hourly price and the traded quantity auction values were collected from [33]. We obtained the quar- terly (every 15 min) day-ahead solar and wind feed-in forecast data from [34]. In the current work, the hourly values are used instead-obtained by summing up every four quarterly values. The European Network of Transmission System Operators (ENTSO-E) was the platform for downloading the day-ahead load forecast data [35]. Using the afore- mentioned data, we will explore how the intra-day dynamics of day-ahead hourly price values can be affected by the Ô¨Çuctuations of other attributes. As mentioned previously, an alternative way of visualizing quasi-periodic time series (with diurnal patterns) is as matrices [29]. To do so, we partition the data into diurnal pe- riods and place each daily cycle in a column to form a matrix. Figure 4.10 illustrates the alternative representation of the data in Figure 4.9, obtained by recasting each time se- ries into a matrix of size 24√ó366 (recall that 2016 is a leap",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_97"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " form a matrix. Figure 4.10 illustrates the alternative representation of the data in Figure 4.9, obtained by recasting each time se- ries into a matrix of size 24√ó366 (recall that 2016 is a leap year). This change of viewpoint has two important applications: 1) Representing the time series as images allow one to visually integrate patterns across longer time spans, hence improving the discriminatory power. For instance, in the bottom panel of Figure 4.10, a notable correlation between the traded quantity and the solar (eye-like horizontal shape seen in the 2nd panel from the top) as well as the wind (vertical stripes in the 3rd panel from the top) can be spot- ted. In the following section, we will elaborate on this and put these visual impressions 80 4. REGULARISED MATRIX FACTORIZATION on a more sound, mathematical footing. 2) Recasting such time series as matrices also suggest drawing on matrix decomposition theorems to construct approximations which are more tightly linked to the structure of the time series. 0 2000 4000 6000 8000 Hourly values throughout 2016 -150 -100 -50 0 50 100 150 Price (Euro/MWh) 0 2000 4000 6000 8000 Hourly values throughout 2016 0 2 4 6 8 10 12 Solar Feed-in (GWh) 0 2000 4000 6000 8000 Hourly values throughout 2016 0 5 10 15 Wind Feed-in (GWh) 0 2000 4000 6000 8000 Hourly values throughout 2016 30 40 50 60 70 80 Load (GWh) 0 2000 4000 6000 8000 Hourly values throughout 2016 15 20 25 30 35 40 45 50 Traded Quantity (GWh) Figure 4.9: An overview of the German day-ahead market in 2016; each data point represents one hour slot. From top to bottom, the price, solar, wind, load, and traded quantity. 4.7. BACKGROUND AND LITERATURE REVIEW In Europe, Germany is forerunning the others in the switch from conventional energies to renewables, namely wind",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_98"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " From top to bottom, the price, solar, wind, load, and traded quantity. 4.7. BACKGROUND AND LITERATURE REVIEW In Europe, Germany is forerunning the others in the switch from conventional energies to renewables, namely wind and solar. This poses new challenges as wind and solar en- ergy are inherently intermittent and to some extent, unpredictable. Therefore, it is of great interest to investigate what effect these changes can have on the day-ahead elec- tricity market and the price volatility. Denny et al. [36] studied how network expansion and increasing the interconnection between Great Britain and Ireland has facilitated the integration of wind farms into the power system. Their simulation results point to a re- duction in average price and its volatility in Ireland; which was considered an outcome of the large increase in the interconnection capacities. Furthermore, the high penetra- tion of intermittent distributed energy sources enforces the transmission grid extensions and increases the cross-border interconnections capacities, to ensure grid stability. The viability of this methodology and its upshots is investigated in [37], using the projection 4.8. CONCLUSIONS AND FUTURE RESEARCH 81 of the wind and solar data until 2020. Some beneÔ¨Åts of the substantial expansion of pho- tovoltaic (PV) installations in Germany and Italy, especially, their role in daytime peak price drop are discussed in [38]. Continuing further with the studies on the inÔ¨Çuence of renewable energy sources (RES) in Germany, a preliminary study was done in [39]. The authors argued about the recent emergence of zero or negative prices on the German day-ahead market as a piece of convincing evidence for the impact of RES. Inspired by the work in [40], the goal of our work is to determine how the intra-day price variability can be inÔ¨Çuenced by the variability of the wind and solar feed-in. To this end, the intra- day dynamics of different attributes are characterized by their second derivatives as they peak for sharp trend reversals (Section 4.5.1). As mentioned before, in the present work, we will focus on matrices, as an alterna- tive representation of the quasi-periodic time series data. The matrix interpretation also grants elucidation of the underlying structures in the data, using various matrix decom- position techniques. The concept of decomposing a signal by its constituent compo- nents has",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_99"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ive representation of the quasi-periodic time series data. The matrix interpretation also grants elucidation of the underlying structures in the data, using various matrix decom- position techniques. The concept of decomposing a signal by its constituent compo- nents has been addressed by researchers in the past. In [41], the singular value decom- position (SVD) technique is used to obtain the constituent periodic components of a signal. In this work, the singular value ratio (SVR) criterion was also introduced to detect periodicity and determine the period length. Furthermore, reconstructing the principle patterns of a given signal was another outcome of this approach. The applicability of SVD in generalized discriminant analysis is investigated in [42]. Detection and extrac- tion of the periodic impulse components from the vibration signals with small signal-to- noise ratios (SNRs), using SVD, is investigated in [43]. Although the alternative represen- tation of the time series has been deployed in different areas before, to the best of our knowledge, it has never been considered in the context of the energy market analysis. The present work looks into this alternative representation and also the applicability of the SVD in day-ahead electricity market analysis. 4.8. CONCLUSIONS AND FUTURE RESEARCH As mentioned before, we use the proposed SVD-based method in the context of the day- ahead electricity market to quantify the relation between the variability of the day-ahead price values with respect to other attributes. We hence proceed as follows: 1. We compute the intra-day 2nd derivative of the daily proÔ¨Åles (each column of a matrix), in order to highlight peaks and valleys (concavity/convexity is a notion of intra-day variability as can be seen on the left side of Figure 4.3). 2. Next, we lower the rank of those resulting images and enhance their underlying patterns, using a smoothed SVD expansion up to rank 7. Clearly, the rank-7 recon- struction yields an acceptable approximation of the original images on the left. The resulting data are called Cp,Cl,Cq,Cs and Cw where the subscript refers to the corresponding quantity (the rightmost column of Figure 4.3). 3. Finally, a linear regression model is used to quantify the relation between the price volatility Cp with other attributes: Cp = Œ±0 +Œ±l Cl +Œ±q Cq +Œ±s Cs +",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_100"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " column of Figure 4.3). 3. Finally, a linear regression model is used to quantify the relation between the price volatility Cp with other attributes: Cp = Œ±0 +Œ±l Cl +Œ±q Cq +Œ±s Cs +Œ±w Cw (4.28) 82 4. REGULARISED MATRIX FACTORIZATION 50 100 150 200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) -100 -50 0 50 100 Price (Euro/MWh) 50 100 150 200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) 0 2 4 6 8 10 Solar Feed-in (GWh) 50 100 150 200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) 2 4 6 8 10 12 14 Wind (GWh) 50 100 150 200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) 35 40 45 50 55 60 65 70 Load (GWh) 50 100 150 200 250 300 350 Days of the year 5 10 15 20 Hour slots (1-24) 20 25 30 35 40 45 Traded Quantity (GWh) Figure 4.10: An alternative representation of the German day-ahead market by reformatting the time series in Figure 4.9 into matrices of size 24√ó366. Each column contains the 24 hourly values of a single day. From top to bottom, the price, solar, wind, load, and the traded quantity. The regression analyses have been performed for three scenarios on the original (un- treated) 2nd derivative data: 1) using all data; 2) using only day-time data, and 3) using only night-time data. Table 4.1 contains the results of this benchmark case where the original 2nd derivative matrices (leftmost columns in Figure 4.3) were used. Table 4.2 reÔ¨Çects a signiÔ¨Åcant improvement of",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_101"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ".1 contains the results of this benchmark case where the original 2nd derivative matrices (leftmost columns in Figure 4.3) were used. Table 4.2 reÔ¨Çects a signiÔ¨Åcant improvement of the results by using the rank-7 reconstructed ma- trices (rightmost column in Figure 4.3). The signiÔ¨Åcance of our results in the latter case (Table 4.2) was investigated using permutation tests where the days of the year have been shufÔ¨Çed, before applying the regression models. Figure 4.11 demonstrates the histogram of the results of the afore- mentioned randomized data along with the results of the three different scenarios in Table 4.2. The distinct high R2 values for 24h and daytime scenarios conÔ¨Årm a good per- formance of the model and show that the intra-day dynamics of the price proÔ¨Åles can in- deed be modelled as a function of the concavity (intra-day dynamics) of other attributes. We are aware of the fact that the market mechanism is quite complex and a comprehen- sive study on the effects of the RES on the market demands takes into consideration of all the playing factors such as energy policy, subsidies and so on. From a data analyt- ics point of view, however, a number of Ô¨Åndings can be listed. The intra-day dynamics 4.8. CONCLUSIONS AND FUTURE RESEARCH 83 Table 4.1: The initial regression model (before applying SVD-based technique). TimeSlot R2 Œ±l Œ±q Œ±s Œ±w 24h 47.28 1.26 0.44 -2.98 -1.98 day time 53.07 1.34 0.44 -2.97 -1.83 night time 15.60 0.91 0.24 N/A -2.05 Table 4.2: Regression model applied on rank-7 reconstruction of data. TimeSlot R2 Œ±l Œ±q Œ±s Œ±w 24h 81.84 1.12 0.59 -2.83 -3.60 day time 86.27 1.26 0.29 -2.36 -1.27 night time 56.40 0.85 0.09 N/A -17.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_102"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "59 -2.83 -3.60 day time 86.27 1.26 0.29 -2.36 -1.27 night time 56.40 0.85 0.09 N/A -17.59 81.84 20 30 40 50 60 70 80 90 R-square, 24 hours 0 20 40 60 80 100 120 140 160 86.27 20 30 40 50 60 70 80 90 R-square, day time 0 20 40 60 80 100 120 140 160 56.4 20 30 40 50 60 70 80 90 R-square, night time 0 20 40 60 80 100 120 Figure 4.11: Permutation test to indicate the signiÔ¨Åcance of R2 values in all three scenarios which can be found in Table 4.2. Each histogram is the result of randomization tests, repeated 1000 times (no. of bins = 20), where the days are shufÔ¨Çed before applying the regression models. 84 4. REGULARISED MATRIX FACTORIZATION (concavity) of the price is least affected by the traded quantity on the day-ahead market. Moreover, RES have a higher impact on the price dynamics than the load. During the day time, solar is the dominant attribute affecting the price dynamics, whereas, during night hours, it is the wind that affects the most. In is worth noting that in the latter case, the low R2 value urges more extensive research to understand the time price dynamics more satisfactorily. Singular Value Decomposition (SVD) and Principal Component Analysis (PCA) are important matrix factorisation techniques that underpin numerous applications. How- ever, it is well-known that disturbances in the input (noise, outliers or missing values) have a signiÔ¨Åcant effect on the outcome. For that reason, we have investigated regular- isation in two different but related versions of the factorisation, and have detailed the solution algorithms. An important topic for further research would be to Ô¨Ånd ways in which the gradient descent procedure in Algorithms 1 and 2 can be accelerated by taking advantage of the fact that the functional is very smooth and locally approximately quadratic. It would also be useful",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_103"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " important topic for further research would be to Ô¨Ånd ways in which the gradient descent procedure in Algorithms 1 and 2 can be accelerated by taking advantage of the fact that the functional is very smooth and locally approximately quadratic. It would also be useful to derive some estimates for appropriate values for the weights Œª and ¬µ in terms of noise characteristics corrupting the underlying signal. Finally, although the P matrix in Algorithm 2 has unit-length columns, we were not able to prove that these columns are also orthogonal (PT P = Ik) as is the case in standard SVD. In fact, numerical experiments seem to indicate that such a constraint is not compatible with the minimisation of the functional. This requires further theoretical elucidation. REFERENCES 85 REFERENCES [1] A. Khoshrou, A. B. Dorsman, and E. J. Pauwels, Svd-based visualisation and ap- proximation for time series data in smart energy systems, in Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), 2017 IEEE PES (IEEE, 2017) pp. 1‚Äì6. [2] A. Khoshrou and E. J. Pauwels, Regularisation for pca-and svd-type matrix factori- sations, arXiv preprint arXiv:2106.12955 (2021). [3] J. J. Gerbrands, On the relationships between svd, klt and pca, Pattern recognition 14, 375 (1981). [4] M. A. Davenport and J. Romberg, An overview of low-rank matrix recovery from in- complete observations, IEEE Journal of Selected Topics in Signal Processing 10, 608 (2016). [5] I. To≈°i¬¥c and P. Frossard, Dictionary learning, IEEE Signal Processing Magazine 28, 27 (2011). [6] A. Khoshrou and E. J. Pauwels, Data-driven pattern identiÔ¨Åcation and outlier de- tection in time series, in Science and Information Conference (Springer, 2018) pp. 471‚Äì484. [7] S. Gunasekar, B. E. Woodworth, S. Bhojanapalli, B. Neyshabur, and N. Srebro, Im- plicit regularization in matrix factorization, Advances in Neural Information",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_104"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "] S. Gunasekar, B. E. Woodworth, S. Bhojanapalli, B. Neyshabur, and N. Srebro, Im- plicit regularization in matrix factorization, Advances in Neural Information Pro- cessing Systems 30 (2017). [8] J. P. Brooks, J. H. Dul√°, and E. L. Boone, A pure l1-norm principal component anal- ysis, Computational statistics & data analysis 61, 83 (2013). [9] N. Kwak, Principal component analysis by l_{p}-norm maximization, IEEE Transac- tions on Cybernetics 44, 594 (2013). [10] E. J. Cand√®s, X. Li, Y. Ma, and J. Wright, Robust principal component analysis? Jour- nal of the ACM (JACM) 58, 1 (2011). [11] Z. Zhou, X. Li, J. Wright, E. Candes, and Y. Ma, Stable principal component pursuit, in 2010 IEEE international symposium on information theory (IEEE, 2010) pp. 1518‚Äì 1522. [12] H. Shen and J. Z. Huang, Sparse principal component analysis via regularized low rank matrix approximation, Journal of multivariate analysis 99, 1015 (2008). [13] B. Dumitrescu and P. Irofti, Regularized k-svd, IEEE Signal Processing Letters 24, 309 (2017). [14] T. Jin, J. Yu, J. You, K. Zeng, C. Li, and Z. Yu, Low-rank matrix factorization with multiple hypergraph regularizer, Pattern Recognition 48, 1011 (2015). [15] J. He, Y. Bi, B. Liu, and Z. Zeng, Graph-dual laplacian principal component analysis, Journal of Ambient Intelligence and Humanized Computing 10, 3249 (2019). 86 REFERENCES [16] M. Yin, J. Gao, Z. Lin, Q. Shi, and Y. Guo, Dual graph regularized latent low-rank representation for subspace clustering, IEEE Transactions on Image Processing 24, 4918 (2015). [17] N.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_105"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ao, Z. Lin, Q. Shi, and Y. Guo, Dual graph regularized latent low-rank representation for subspace clustering, IEEE Transactions on Image Processing 24, 4918 (2015). [17] N. Shahid, N. Perraudin, V. Kalofolias, G. Puy, and P. Vandergheynst, Fast robust pca on graphs, IEEE Journal of Selected Topics in Signal Processing 10, 740 (2016). [18] code for pca-type regularisation, https://www.dropbox.com/s/ fjtz7fh1hyf9cdm/theorem_4.m?dl=0, created: 2021, June. [19] code for special case:¬µ = 0 and Œª = 0, https://www.dropbox.com/s/ ngjksurfepn8dml/special_case_mu_0_lambda_0.m?dl=0 (), created: 2021, June. [20] code for special case: ¬µ = 0 and d = in, https://www.dropbox.com/s/ ab1rfiquiyuzuvz/special_case_mu_0_D_In.m?dl=0 (), created: 2021, June. [21] code for factorisation svd-type theorems, https://www.dropbox.com/sh/ f257tzsuttbp1ro/AABaJc1IVXZFQFVQKnpIGjr7a?dl=0 (), created: 2021, June. [22] A. Iserles, H. Z. Munthe-Kaas, S. P. N√∏rsett, and A. Zanna, Lie-group methods, Acta numerica 9, 215 (2000). [23] O. King, On subgroups of the special linear group containing the special orthogonal group, Journal of Algebra 96, 178 (1985). [24] M. Gavish and D. L. Donoho, The optimal hard threshold for singular values is 4/ p 3, IEEE Transactions on Information Theory 60, 5040 (2014). [25] code for the numerical experiments section, https://www.dropbox.com/sh/ tcl7lag80cimibw/AAD3QNx8FST0X-c3-wtAh-UFa?dl",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_106"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "2014). [25] code for the numerical experiments section, https://www.dropbox.com/sh/ tcl7lag80cimibw/AAD3QNx8FST0X-c3-wtAh-UFa?dl=0, created: 2021, June. [26] Structural similarity index, http://nl.mathworks.com/help/images/ref/ ssim.html (). [27] The royal netherlands meteorological institute, http://www.knmi.nl/ nederland-nu/weer/verwachtingen. [28] G. H. Golub and C. Reinsch, Singular value decomposition and least squares solu- tions, Numerische mathematik 14, 403 (1970). [29] P. P. Kanjilal and S. Palit, The singular value decomposition‚Äîapplied in the mod- elling and prediction of quasi-periodic processes, Signal processing 35, 257 (1994). [30] Smooth response data, https://nl.mathworks.com/help/curvefit/smooth. html (). [31] Epexspot, european power exchange‚Äû http://www.epexspot.com/en/ market-coupling (). REFERENCES 87 [32] Energy union and climate, https://ec.europa.eu/commission/priorities/ energy-union-and-climate_en. [33] Epexspot, day-ahead auction, https://www.epexspot.com/en/product-info/ auction/germany-austria (). [34] Taking power further, https://www.tennettso.de/site/en/Transparency/ publications/overview. [35] Entso-e, the european network of transmission system operators, https://www. entsoe.eu/Pages/default.aspx. [36] E. Denny, A. Tuohy, P. Meibom, A. Keane, D. Flynn, A. Mullane, and M. O‚Äômalley, The impact of increased interconnection on electricity systems with large penetrations of wind generation: A case study of ireland and great britain, Energy Policy 38, 6946 (2010). [37] K. Schaber, F. Steinke, and T. Hamacher, Transmission grid extensions for the inte- gration of variable renewable energies in europe: Who beneÔ¨Åts where? Energy Policy 43, 123 (2012). [38",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_107"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " Schaber, F. Steinke, and T. Hamacher, Transmission grid extensions for the inte- gration of variable renewable energies in europe: Who beneÔ¨Åts where? Energy Policy 43, 123 (2012). [38] K. Barnham, K. Knorr, and M. Mazzer, BeneÔ¨Åts of photovoltaic power in supplying national electricity demand, Energy Policy 54, 385 (2013). [39] N. Adaduldah, A. Dorsman, G. J. Franx, and P. Pottuijt, The inÔ¨Çuence of renewables on the german day ahead electricity prices, in Perspectives on Energy Risk (Springer, 2014) pp. 165‚Äì182. [40] L. Hirth, The market value of variable renewables: The effect of solar wind power variability on their relative price, Energy economics 38, 218 (2013). [41] P. P. Kanjilal and S. Palit, On multiple pattern extraction using singular value decom- position, IEEE transactions on signal processing 43, 1536 (1995). [42] P. Howland and H. Park, Generalizing discriminant analysis using the generalized singular value decomposition, IEEE transactions on pattern analysis and machine intelligence 26, 995 (2004). [43] L. H. L. J. Z. Ying and Q. Liangsheng, Improved singular value decomposition tech- nique for detecting and extracting periodic impulse component in a vibration signal, Chinese Journal of Mechanical Engineering 17, 1 (2004). 5 HYPOTHESIS GENERATION USING SVD 5.1. INTRODUCTION Scenario-based probabilistic forecasting models have been extensively explored in the literature in recent years. A particular application of such models is in the energy sector, where e.g., having the distribution of the energy consumption for the coming days is desired. In this chapter, we put the applicability of the SVD into practice to tackle the energy forecasting problem. A decisive variable in predicting the energy demand is the temperature data [2]. In this chapter, we propose a generic, data-driven and computationally efÔ¨Åcient SVD-based approach to simulate temperature scenarios. The generated temperature proÔ¨Åles, along with other variables, are then fed into a regression algorithm to obtain a probabilistic forecast of the electricity consumption proÔøΩ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_108"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " data-driven and computationally efÔ¨Åcient SVD-based approach to simulate temperature scenarios. The generated temperature proÔ¨Åles, along with other variables, are then fed into a regression algorithm to obtain a probabilistic forecast of the electricity consumption proÔ¨Åles (see Section 5.3). There are mainly three practical and popular methods for generating temperature scenarios, namely Ô¨Åxed-date, shifted-date, and bootstrap approaches [3]. Nevertheless, these methods have mostly been used on an ad-hoc basis without being formally com- pared or quantitatively evaluated. As mentioned before, the predictive power of proba- bilistic forecasting models depends a great deal on how the methodology used in gen- erating temperature scenarios is robust and capable of simulating the temperature data sensibly. An important distinction of the current work is the use of matrices as an alter- native representation of the data. The singular value decomposition (SVD) technique is then used to generate temperature scenarios, in a robust and data-driven manner. The strength of our proposed method lies in its simplicity and robustness, in terms of the training window size, with no need for subsetting or thresholding to generate tem- perature scenarios. Furthermore, to systematically account for the non-linear interac- tions between different variables, a new set of features is deÔ¨Åned: the Ô¨Årst and second derivatives of the predictors. The empirical case studies performed on the data from the Part of this chapter has been published in [1, 2]. 89 90 5. HYPOTHESIS GENERATION USING SVD load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014- L) shows that the proposed method outperforms the top two scenario-based models with a similar setup. The rest of this chapter is organized as follows. Section 5.2 provides a brief introduc- tion to the data from the load forecasting track of the Global Energy Forecasting Compe- tition [4]. Section 5.3 is devoted to our methodology. A short description of the Gradient Boosting method is presented, Ô¨Årst, followed by our proposed models for point forecast- ing. After a brief recapitulation of the SVD, we explain how our proposed scenario-based load forecasting models work. The proposed method in this chapter is in fact a marriage between an SVD-based temperature scenario generator and an ensemble of trees (gra- dient boosting",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_109"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " recapitulation of the SVD, we explain how our proposed scenario-based load forecasting models work. The proposed method in this chapter is in fact a marriage between an SVD-based temperature scenario generator and an ensemble of trees (gra- dient boosting algorithm). The experimental results along with a comparison with the results of a number of benchmark models are presented in Section 5.4. We conclude this chapter in Section 5.5. 5.2. DATA For the sake of replicability and comparability of our work with the benchmark mod- els, a case study is constructed based on the data from the load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014-L) [4]. The participants in that competition had been asked to develop a short-term probabilistic load forecasting model, with a forecasting horizon of one month. The publicly available data set consists of hourly temperature values from 25 anonymous weather stations and the aggregated hourly load proÔ¨Åles; for a detailed description of data and the competition instructions see [5]. The electricity consumption patterns are subject to a variety of factors, such as me- teorological conditions, calendar information, season, working schedules, energy cost and economic activities [6]. In the current work, however, consistent with the require- ments in the GEFCom2014-L, only temperature and calendar information are taken into consideration as the available predictors (besides historic load proÔ¨Åles). Temperature is believed to be a major driving force behind electricity demand. The non-linear effect of the temperature on electricity demand is hence at the centre of our attention. The left panel of Figure 5.1 provides an overview of the typical electricity consumption proÔ¨Åles throughout the week. This Ô¨Ågure afÔ¨Årms that the consumption patterns differ notably during the weekends from the weekdays. Interestingly enough, on Friday afternoons, the demand proÔ¨Åle gets closer to the weekends, whereas, during working hours, it is akin to other working days. Furthermore, the right panel in Fig- ure 5.1, illustrates the evolution of daily load proÔ¨Åles in the year 2010; this Ô¨Ågure was obtained by recasting the time series into a 24 √ó 365 matrix, where every column con- tains 24 hourly values for each daily proÔ¨Åle [7]. As expected, in spring and fall, when the temperature is moderate,",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_110"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " by recasting the time series into a 24 √ó 365 matrix, where every column con- tains 24 hourly values for each daily proÔ¨Åle [7]. As expected, in spring and fall, when the temperature is moderate, electricity demand tends to be lower than at any other time of the year (winter and summer times). It underscores the fact that electricity demand is driven by climate conditions (e.g., air conditioning usage), and also the lifestyle changes followed by that. This Ô¨Ågure also highlights the non-linear relation between load and temperature throughout the year. In the literature, the temperature is arguably the most dominant predictor of the load; however, in and of itself, it is not sufÔ¨Åcient for two main reasons: 5.3. METHODOLOGY 91 Figure 5.1: Left: Comparison of typical daily consumption patterns during the week. Right: An overall repre- sentation of the evolution of the load proÔ¨Åles throughout a year. ‚Ä¢ Diurnal human activities: As it is seen in the left panel of Figure 5.1, the typical electricity demand behaviour changes throughout the week. These diurnal human activities are plainly not reÔ¨Çected in the temperature data. ‚Ä¢ Recency and cross effects: Even for similar days (weekends or weekdays), the trend of daily load proÔ¨Åles, corresponding to similar temperature data, might not be necessarily alike; the recency and cross effects can play a vital role. For instance, the rise of temperature in early spring might not necessarily lead to high electricity consumption, in comparison with summer times, as people might appreciate the rise in outside temperature after a cold winter. This, of course, can deviate across different seasons. Figure 5.2 illustrates an overview of the trend (Ô¨Årst derivative) changes in daily temperature and load proÔ¨Åles in 2010. These Ô¨Ågures were ob- tained by taking the Ô¨Årst derivatives of daily temperature and load matrices. It is seen that e.g. in early spring and summer time, with the rise of temperature, after- noon peak proÔ¨Åles start to disappear. Although, the overall relationship between load and temperature is clear; it is, however, non-trivial how to robustly address the non-linear effect between temperature and load proÔ¨Åles. Experiment results in [2] afÔ¨Årm that including the 1st and 2",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_111"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " and temperature is clear; it is, however, non-trivial how to robustly address the non-linear effect between temperature and load proÔ¨Åles. Experiment results in [2] afÔ¨Årm that including the 1st and 2nd derivatives of the daily proÔ¨Åles can in- deed enhance the performance of the forecasting model. 5.3. METHODOLOGY In the present work, we opt to use an ensemble of regression trees (Gradient Boosting method) to predict day-ahead load prognoses, with a forecasting horizon of one month, given hourly temperature proÔ¨Åles, historical (or estimated) load proÔ¨Åles, and calendar information. After a brief recapitulation of an ensemble of regression trees, the de- tailed explanation of our methodology for the probabilistic Short Term Load Forecasting (STLF) problem is in turn provided below. 92 5. HYPOTHESIS GENERATION USING SVD Figure 5.2: An overview of the evolution of the Ô¨Årst derivative of the temperature (Left) and load (Right) pro- Ô¨Åles. 5.3.1. ENSEMBLE OF REGRESSION TREES The use of ‚Äúensemble learning‚Äù methods in various classiÔ¨Åcation and regression prob- lems has taken off over the last few years. Ensembles generally rely on ‚Äúresampling‚Äù techniques to obtain different training sets for each individual regression or classiÔ¨Åca- tion model. Two popular methods for creating accurate ensembles are bootstrap aggre- gating (Bagging) and Boosting. In the Bagging method, the training data for each individual model is drawn ran- domly, i.e., n instances with replacement-where n are the number of observations in the training set. In this approach, successive members (e.g., trees or neural networks) are independent of each other; since each member of the ensemble is trained individually using a bootstrap sample of the data set [8]. In other words, Bagging methods control the generalization error through perturbation and averaging of sub-models. In the present work, we opt to use an ensemble of trees which is fast to train and provides more insight into the importance of the predictors. Worth noting that in this approach, to ensure that every training sample is predicted at least a few times, the num- ber of trees needs to be large enough. Since the trees are independent of each other, the distribution",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_112"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " the importance of the predictors. Worth noting that in this approach, to ensure that every training sample is predicted at least a few times, the num- ber of trees needs to be large enough. Since the trees are independent of each other, the distribution function and the quantiles of each hourly forecast can be easily computed based on the output of all the trees [9]. It becomes apparent in Section 5.4. In the Gradient Boosting method, however, the training set for each member of the ensemble depends on the performance of the previous model(s). More precisely, in or- der to alleviate the error in earlier models, extra weights are assigned to samples with higher prediction error rates; those are hence more likely to take part in the training of the next model [10, 11]. A comprehensive evaluation of both these techniques on 23 data sets, using two popular classiÔ¨Åers, i.e., decision trees and neural networks is presented in [12]. The applicability of the Gradient Boosting method in quantile regression load forecasting applications has been put into practice in [9, 13]. The goal of every typical prediction problem is to determine an estimate or approxi- mation ÀÜF(x), of the true mapping function F‚àó(x) which assigns a y ‚ààR to any given set of covariates x ‚ààRp. This process is optimized by minimizing the expected value of some 5.3. METHODOLOGY 93 speciÔ¨Åed loss function L(y,F(x)) over the set of the joint distribution of all {y,x} pairs. In mathematical parlance, we have: F‚àó(x) = argmin F(x) Ey,xL(y,F(x)) = argmin F(x) Ex[Ey(L(y,F(x)))|x] (5.1) where E(.) is the expectation operator, and L(y,F(x)) is a loss function, e.g., the popular choice of squared-error {y ‚àíF(x)}2, for regression problems. F(x) is a member of ‚Äúaddi- tive‚Äù class of functions of the form: F(x;{Œªk,ak}K 1 ) = KX k=1 Œªkh(x;ak). (5.2) where K is the number of members of the ensemble model, Œªk is the coefÔ¨Åcient of the additive model, the generic function h(x;a) in Eq.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_113"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "X k=1 Œªkh(x;ak). (5.2) where K is the number of members of the ensemble model, Œªk is the coefÔ¨Åcient of the additive model, the generic function h(x;a) in Eq. (5.2) is called a weak learner or base learner-it is usually a simple parameterized function of the explanatory variables, speci- Ô¨Åed by parameters a = {a1,a2,...}. In the present work, each h(x;ak) is a small regression Algorithm 3: The Gradient Boosting Algorithm, with a squared-error loss function. Initialization: F0(x) = ¬Øy for k=1 to K do Àúyi = yi ‚àíFk‚àí1(xi), i ‚àà[1 : N] (œÅk,ak) = arg min œÅ,a NP i=1 [ Àúyi ‚àíœÅ h(xi;a)]2 Fk(x) = Fk‚àí1(x)+œÅkh(x;ak) tree as introduced in [14]. For a regression tree, the parameters ak are the splitting vari- ables, split locations and means of the terminal node of the individual trees. An overview of the Gradient Boosting algorithm, with a squared-error loss function, is presented in Algorithm 3, where the multiplier œÅk is given by the line search: œÅk = arg min Ey,xL(y,Fk‚àí1(x)‚àíœÅgk(x)) œÅ , (5.3) and gk(x) = Ey ¬∑‚àÇL(y,F(x)) ‚àÇF(x) ¬∏ F(x)=Fk‚àí1(x) (5.4) It is worth to be mentioned that the rationale underpinning the choice of the en- semble of the trees is their ability to better handle the heterogeneous input data‚Äìwhich comprise both continuous and discrete variables. Additionally, tree models are effective, adaptive and modular, in that new predictors can be easily added. It is perceived that en- semble models, unlike their other ML-based counterparts, are less prone to overÔ¨Åtting; they promise to strike a good trade-off between bias and variance [15]. 5.3.2. OUR PROPOSED FORECASTING MODELS Generally speaking, a regression tree is an adaptive nearest neighbours-like algorithm. However, it usually shows a better performance in comparison with other counterparts 94 5. HYPOTHESIS GENER",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_114"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "3.2. OUR PROPOSED FORECASTING MODELS Generally speaking, a regression tree is an adaptive nearest neighbours-like algorithm. However, it usually shows a better performance in comparison with other counterparts 94 5. HYPOTHESIS GENERATION USING SVD Attribute Description Model no. mn month of year: 1,2,...,12 I,II wk day of week: 1,2,...,7 I,II hr hour of day: 1,2,...,24 I,II L(d‚àí1) previous day (estimated) hourly load I,II L(d‚àí7) previous week (estimated) hourly load I,II T(d) hourly temperature (generated proÔ¨Åles) I,II L‚Ä≤(d‚àí1) 1st derivative of L(d‚àí1) II L‚Ä≤‚Ä≤(d‚àí1) 2nd derivative of L(d‚àí1) II L‚Ä≤(d‚àí7) 1st derivative of L(d‚àí7) II L‚Ä≤‚Ä≤(d‚àí7) 2nd derivative of L(d‚àí7) II T‚Ä≤(d) 1st derivative of T(d) II T‚Ä≤‚Ä≤(d) 2nd derivative of T(d) II L(d) hourly load (forecast target) I,II Table 5.1: An overview of the attributes used in our proposed models. nearest neighbour-based methods. It tends to Ô¨Ånd the homogeneous portions of the sampling space locally, on contrary to other conventional methods which incline to treat all distances equally [16, 17]. In the present work, we follow a homogeneous forecast combination framework, i.e., we Ô¨Årst train a single-value load forecasting model, then, vary the input data (differ- ent temperature scenarios) to obtain a series of forecasts, and accordingly, the quantiles (Section 5.4). We consider two Gradient Boosting based methods to predict the day- ahead load prognoses. In the Ô¨Årst model, only calendar information, temperature data along with historical load data are the input variables. We proceed further in the second model to incorporate the daily dynamics of the temperature and load proÔ¨Åles. It is done using the Ô¨Årst and second derivatives of the daily proÔ¨Åles. Power consumption is subject to a wide range of exogenous variables, including cal- endar effects, electricity price and so on. In the literature, the previous consumption pat-",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_115"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " the Ô¨Årst and second derivatives of the daily proÔ¨Åles. Power consumption is subject to a wide range of exogenous variables, including cal- endar effects, electricity price and so on. In the literature, the previous consumption pat- terns and calendar information have been extensively used in developing various load forecasting models. However, accounting for the interaction between different variables, namely the recency and cross effects can be an onerous task; it demands some domain expertise to be done sensibly [18, 19]. A number of common deterministic (categorical) explanatory variables used in our methodologies are as follows: month of the year mn ‚àà{1,2,...,12}, day of the week wk ‚àà{1,2,...,7} (starting from Sunday=1), and hour of the day hr ‚àà{1,2,...,24}. As it is principled in [5] the forecasting horizon herein is one month, therefore, the estimated values for the Ô¨Årst week of the month are being used to estimate the load proÔ¨Åles in the second week of the month and so on. In all cases, the aim is to predict L(d), 24 hourly load values for the target day d. Below we discuss the models in more detail, but for ease of reference, Table 5.1 summarizes all the common and distinctive attributes used in the two proposed models. 5.3. METHODOLOGY 95 Model I The Ô¨Årst model provides us with a benchmark to measure the credibility of our proposed method in incorporating the recency and cross effects in data in Model II. Here, we introduce six different attributes to predict the hourly load values on the target day d. The three above-mentioned common discrete (categorical) values, namely, mn,wk and hr, along with the (estimated) load value for a given hour on the previous day or week (L(d‚àí1) and L(d‚àí7), respectively). The intuition for this choice is to reÔ¨Çect the diurnal and weekly patterns of human activities on electricity consumption (Figure 5.1). The last covariate T(d) is the hourly temperature forecast for the target day d. As it is ex- plained in Section 5.3.3, we generate a hundred independent temperature proÔ¨Åles, using the singular value decomposition, to correspondingly obtain 100 independent load fore- casts for each target day;",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_116"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ". As it is ex- plained in Section 5.3.3, we generate a hundred independent temperature proÔ¨Åles, using the singular value decomposition, to correspondingly obtain 100 independent load fore- casts for each target day; the combination of these forecasts is then used to obtain the load quantiles for each hour. Model II To reÔ¨Çect the lagging effect of temperature on load changes, in the second model, we add the daily dynamics of the temperature and load proÔ¨Åles (1st and 2nd derivatives) [1]. For a given hour slot h the corresponding Ô¨Årst derivative of the variable z ‚àà{L,T} can be obtained by z‚Ä≤(h) = 0.5[z(h +1)‚àíz(h ‚àí1)]; with obvious analogues for the 2nd derivative. The reasoning for doing so is that oftentimes the actual values are not as important as the general underlying trends captured by the Ô¨Årst or second deriva- tives of the covariates. In other words, load value at any moment is inÔ¨Çuenced by the variations of the other attributes (namely, temperature proÔ¨Åles) prior to that moment. Including the derivatives are, in fact, a relatively simple and generic means to account for the recency effect in the data. In comparison with most time-varying models, where the data is typically divided into subsets (based on thresholds), or a lagging window is optimized, our proposed approach is more straightforward and user-friendly. A major contribution herein is the use of the SVD to generate temperature scenarios T(d) for the target day d; it is done to determine the distribution (99 percentiles) of the load proÔ¨Åle in our proposed probabilistic forecasting models. A brief recapitulation of the singular value decomposition (SVD) technique is provided below. 5.3.3. SINGULAR VALUE DECOMPOSITION As previously mentioned, the SVD technique is used herein to generate new temperature proÔ¨Åles (matrices). To be more precise, we recast one year‚Äôs worth of hourly temperature values as a matrix T ‚ààR24√ó365 such that every column corresponds to 24 hourly values of a day. Consequently, the matrix T can conveniently be represented by a low-rank approximation. To review the SVD results see Chapter 2. If there are only a few dominant singular values",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_117"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " such that every column corresponds to 24 hourly values of a day. Consequently, the matrix T can conveniently be represented by a low-rank approximation. To review the SVD results see Chapter 2. If there are only a few dominant singular values (as is the case for the temperature matrices, in Figure 5.3), the expansion of the matrix in Eq. (2.5) can be sufÔ¨Åciently trun- cated after just the Ô¨Årst few K terms to yield AK , an adequate lower rank approximation of A, as obtained in Eq. (2.10). To elaborate more, Figure 5.4 illustrates the Ô¨Årst three columns of Uk (left) and Vk (right) for temperature matrix for the year 2009. In geometrical terms, Uk columns can be interpreted as the fundamental daily proÔ¨Åle and its successive increments; Vk values represent the corresponding scaling factors for each Uk proÔ¨Åles for each day. In other words, SVD decomposes the original time series into a linear combination of a num- 96 5. HYPOTHESIS GENERATION USING SVD 5 10 15 20 200 400 600 800 1000 1200 1400 1600 Temperature: singular values 2005 2006 2007 2008 2009 2010 Figure 5.3: The evolution of the singular values of the temperature matrices over the years; it suggests that a reconstruction of rank-4 approximation would sufÔ¨Åce, indicating that temperature is quite regular. ber of (data-driven) orthonormal proÔ¨Åles, speciÔ¨Åed by Uk columns; each proÔ¨Åle is then scaled up (or down) according to their corresponding weights in Vk. For instance, U1 in the top left panel of Figure 5.4 strikingly resembles the averaged daily temperature proÔ¨Åle. Moreover, its corresponding V1 proÔ¨Åle (top right panel) out- lines the evolution of that proÔ¨Åle throughout the year; it is in agreement with the fact that temperature is higher in summer time (middle part of the graph). Recall that these pro- Ô¨Åles are weighted based on the magnitude of their corresponding singular values which are sorted in descending order from left to right (Figure 5.3). The most dominant ‚Äúcor- rective‚Äù incremental proÔ¨Åle",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_118"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " Recall that these pro- Ô¨Åles are weighted based on the magnitude of their corresponding singular values which are sorted in descending order from left to right (Figure 5.3). The most dominant ‚Äúcor- rective‚Äù incremental proÔ¨Åle U2 and its corresponding coefÔ¨Åcients V2 are displayed in the middle panel of Figure 5.4. This correction hence needs to be added to the Ô¨Årst proÔ¨Åle to get a better approximation, i.e., K = 2 in Eq. (2.5). Similar interpretations are valid for the third proÔ¨Åle (bottom panels) and so on. It is worth noting that Vk proÔ¨Åles on the right-hand side of Figure 5.4 imply a distinct impression that temperatures are less variable during the summer (middle parts of the graph). In the following Section, SVD is used to simulate pragmatic temperature scenar- ios, in a systematic and data-driven manner. The generated proÔ¨Åles are accordingly fed to Models I and II to obtain the probability distribution (99 quantiles) of the load values for every given hour. 5.3.4. TEMPERATURE SCENARIO GENERATION A common approach in probabilistic load forecasting problems is to vary the input (e.g., temperature proÔ¨Åles) to obtain a series of forecasts and combine them [20]. One of the major challenges, however, is how to create realistic temperature proÔ¨Åles, e.g., sim- ply adding independent Gaussian noise to the hourly values of individual temperature curves results in some preposterously jagged proÔ¨Åles. In the literature, a number of solutions have been proposed to simulate temperature scenarios. In [21], it is proposed to combine different weather station measurements to generate new temperature proÔ¨Åles. Nonetheless, it can be argued that normal weather scenarios cannot precisely be simulated by averaging the temperature proÔ¨Åles, as they tend to underestimate the peaks. Furthermore, such approaches are not resilient toward 5.3. METHODOLOGY 97 5 10 15 20 0.2 0.22 U1 100 200 300 0.02 0.04 0.06 V 1 5 10 15 20 -0.2 0 0.2 U2 100 200 300 -0.1 0 0.1 V 2 5 10 15",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_119"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ".06 V 1 5 10 15 20 -0.2 0 0.2 U2 100 200 300 -0.1 0 0.1 V 2 5 10 15 20 -0.2 0 0.2 0.4 U3 100 200 300 -0.1 0 0.1 0.2 V 3 Figure 5.4: SVD-based decomposition of hourly temperature data for 2009. On the left, there are the Ô¨Årst three Uk columns; whereas the right column displays their corresponding Vk‚Äôs. outliers, as even one instance, can change the whole proÔ¨Åle as long as it takes part in gen- erating new temperature scenarios. The performance of the forecasting model can con- sequently be diminished as a result of that. Worth noting that shifting the temperature data by one, two or even three days was initially used to generate temperature scenarios; it was later abandoned for obvious reasons. Some cumbersome approaches in terms of computational costs, such as Monte Carlo-based methods are also popular, especially among utilities, to simulate thousands of temperature proÔ¨Åles - an approach which is used in scenario analysis in LTLF problems [22]. In [23], new temperature scenarios are generated, again, by averaging the temperature of stations 3 and 9 (GEFCom2014-L data was used). The reason for that is mentioned to be due to the existence of a good in- sample Ô¨Åt with a cubic relation between the temperature records of those two stations and the load data. Besides pre-processing there are not a lot of solutions in the literature on how to generate robust and pragmatic input (temperature) scenarios. The SVD allows us to create hundreds of sensible and realistic temperature proÔ¨Åles for any target day d, in a fairly fast and robust manner. Figure 5.3 afÔ¨Årms the fact that the singular values œÉk of the temperature matrices over the years have not changed much; similar conclusions can be drawn for the left singular vectorsUk. Furthermore, it is plain to see in Figure 5.4 that the Vk coefÔ¨Åcients implicate the variability of the temperature proÔ¨Åles throughout the year. Since the forecasting horizon is one month, hereafter tem- perature matrix is referred to a month worth of temperature data for the coming month (test",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_120"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " coefÔ¨Åcients implicate the variability of the temperature proÔ¨Åles throughout the year. Since the forecasting horizon is one month, hereafter tem- perature matrix is referred to a month worth of temperature data for the coming month (test data in Section 5.4). We, therefore, proceed with the following steps, to create tem- perature scenarios: 98 5. HYPOTHESIS GENERATION USING SVD -0.4 -0.2 0 0.2 0.4 0.6 0 1 2 3 4 5 6 7 8 9 10 Figure 5.5: Histogram of the v2 coefÔ¨Åcients for June 2011 temperature data (30 values). Note that the distribu- tion is approximately normal with zero mean and std(v2) ‚âà0.18. 1. In the Ô¨Årst step, we estimate the corresponding standard deviation sk for a number of right singular vectors Vk (V2, ..., V4). Figure 5.5 illustrates the histogram for V2, which shows that s2 ‚âà0.18. Interestingly enough, similar experiments on all three Vk columns (k ‚â•2) yield similar results; however, their contribution to the Ô¨Ånal rank K reconstructed proÔ¨Åle is scaled up or down by the magnitude of their corresponding singular values. 2. Next, for any given day d of the test month, for which a number of temperature scenarios are desired, we take the actual temperature proÔ¨Åle for that day T = T(d), Ô¨Ånd the corresponding Vk coefÔ¨Åcients (V 0 2 ,V 0 3 ,V 0 4 ); then blend them with zero- mean Gaussian noise: V n k = V 0 k + N (0,œµ2). These perturbed Vk coefÔ¨Åcients are then used to generate a new (noisy) temperature scenario (reconstruct the matrix). 3. According to the scheme outlined above, for each actual daily proÔ¨Åle T(d), a hun- dred temperature scenarios are generated. This new data set is then fed into the proposed prediction models. In the Ô¨Ånal step, the forecasts are duly compared to the real load values. This approach enables us to determine the distribution of the hourly load values (99 quantiles) and compute the corresponding",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_121"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " set is then fed into the proposed prediction models. In the Ô¨Ånal step, the forecasts are duly compared to the real load values. This approach enables us to determine the distribution of the hourly load values (99 quantiles) and compute the corresponding pinball er- ror values (Section 5.4). Figure 5.6 illustrates an example of one hundred generated temperature proÔ¨Åles (Left), and their corresponding daily load proÔ¨Åles (Right). 4. For the sake of completeness, it should be noted that V1 is left unperturbed as this is a proxy of the average temperature on a particular day, for which the uncertainty is negligible. Similarly, there is not much to be gained from perturbing other right singular vectors (V5 etc), as their impact on the proÔ¨Åle is insigniÔ¨Åcant (their corre- sponding œÉk are small). In [1], a preliminary study was done to investigate how the effect of the perturbation vari- ance in temperature proÔ¨Åles T(d) propagates into uncertainty on the target load proÔ¨Åle L(d). 5.3. METHODOLOGY 99 10-Jan 11-Jan 12-Jan 13-Jan 14-Jan 15-Jan 15 20 25 30 35 40 45 50 55 10-Jan 11-Jan 12-Jan 13-Jan 14-Jan 15-Jan 120 140 160 180 200 220 240 260 280 300 Figure 5.6: An illustrative example of 100 generated temperature scenarios for each day and their correspond- ing daily load proÔ¨Åles (obtained by Model II) for January 10-15, 2011. The spotted points are the actual values and the noise level is N (0,0.09). These 100 different load values for every hour are then used to calculate the 99 quantiles. 100 5. HYPOTHESIS GENERATION USING SVD 5.4. EXPERIMENTAL RESULTS Probabilistic forecasts provide more comprehensive information about future uncer- tainties than point forecasts can do [20]. As previously mentioned, the aim of the GEFCom2014- L was to estimate the quantiles of the hourly load values for a utility in the US, on a rolling basis [5]- with a forecasting horizon of one month. Furthermore",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_122"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "]. As previously mentioned, the aim of the GEFCom2014- L was to estimate the quantiles of the hourly load values for a utility in the US, on a rolling basis [5]- with a forecasting horizon of one month. Furthermore, it was expected from the contestants to investigate the weather scenario generation methods for probabilistic load forecasting. The scenario-based probabilistic forecasting methodology proposed in [22] was used by two top 8 teams (Jingrui Xie, top 3; Bidong Liu, top 8) in GEFCom2014-L. Therefore, we opt to compare our results with similar works. A least absolute shrinkage and se- lection operator (LASSO) estimation based method is proposed in [23] for probabilistic forecasting applications. This work is reported to outperform the methodology used by Bidong Liu [18] to win a top 8 place in GEFCom2014-L. We hence have considered the proposed method in [23] as one of the benchmark models. The reported work uses a bi- variate time-varying threshold autoregressive (AR) process for the hourly load YL ,t and temperature YT ,t data (D = {L ,T }). The time series of interest are accordingly modeled for i ‚ààD as follows: Yi,t = œÜi,0(t)+ X j‚ààD X c‚ààCi,j X k‚ààIi,j,c œÜi,j,c,k(t)max{Yj,t‚àík,c}+œµi,t (5.5) where œÜi,0 are the time-varying intercepts and œÜi,j,c,k are time-varying autoregressive coefÔ¨Åcients. Furthermore, Ci,j are the set of all considered thresholds for the load and temperature data (all set manually). Ii,j,c are the index sets of the corresponding lags and œµi,t is the error term. The modelling process is done in three parts: 1) choice of thresholds Ci,j ; 2) choice of lag sets Ii,j,c; and 3) time-varying structure of the coefÔ¨Åcients. For further details see [23]. Another winning team (top 3) in the GEFCom2014-L was Jingrui Xie, who developed an integrated solution for probabilistic load forecasting [21]. Her proposed methodol- ogy consists of",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_123"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " details see [23]. Another winning team (top 3) in the GEFCom2014-L was Jingrui Xie, who developed an integrated solution for probabilistic load forecasting [21]. Her proposed methodol- ogy consists of three parts: 1) pre-processing, which includes data cleaning and tem- perature station selection; 2) forecasting (which focuses on the development of point forecasting models), forecast combination, and temperature scenario generation; and 3) post-processing, which embodies the residual simulation for probabilistic forecast- ing purposes. Inspired by the Vanilla model in [18], their core forecasting model is as follows: Lt = Œ≤0 +Œ≤1Trendt +Œ≤2Tt +Œ≤3T 2 t +Œ≤4T 3 t +Œ≤5Montht +Œ≤6Weekdayt +Œ≤7Hourst+ Œ≤8HourstWeekdayt +Œ≤9TtMontht +Œ≤10T 2 t Montht +Œ≤11T 3 t Montht+ Œ≤12TtHourt +Œ≤13T 2 t Hourt +Œ≤14T 3 t Hourt (5.6) It is in fact a multiple linear regression (MLR) model with the following main and cross effects: ‚Ä¢ Main effects: a chronological Trendt variable, Ô¨Årst to third-order polynomials of the temperature (Tt,T 2 t ,T 3 t ), and a number of categorical variables namely, Month, weekday, and Hour. 5.4. EXPERIMENTAL RESULTS 101 Mar-20 Mar-21 Mar-22 Mar-23 Mar-24 Mar-25 Mar-26 Mar-27 Mar-28 Mar-29 Mar-30 60 80 100 120 140 160 180 200 220 240 1-th 25-th 50-th 75-th 99-th actual Figure 5.7: Probabilistic load forecast of 11 days from March 20, 2011 to March 30, 2011; the solid line in black is the actual value and the dash-dot lines are the forecast quantiles. ‚Ä¢ Cross effects: similar to [18], the cross effects are incorporated using the multi- plications of different attributes such as HourtWeekdayt, TtMontht, T 2 t Montht, T 3 t Montht, TtHourt, T 2 t",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_124"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " the cross effects are incorporated using the multi- plications of different attributes such as HourtWeekdayt, TtMontht, T 2 t Montht, T 3 t Montht, TtHourt, T 2 t Hourt, and T 3 t Hourt. In the next step, the residuals obtained from Eq. (5.6) are modeled using four differ- ent techniques, namely unobserved component models (UCM), exponential smoothing models (ESM), three-layer feedforward neural network (NN), and autoregressive inte- grated moving average models (ARIMA). Four different sets of point forecasts are accord- ingly generated by adding each set of residuals to the values obtained from the previous stage. The average of each four values is the Ô¨Ånal estimation for the load forecast for ev- ery given hour. In the end, 10 different temperature scenarios are generated according to [22], to obtain the 99 percentiles from the 10-point forecasts. The regression-based models are arguably vulnerable towards outliers, especially in scenario-based applications. Due to the recency effects, outliers e.g., in temperature scenarios can affect the load forecasts for a longer time span. Our proposed SVD-based model is more robust and capable of handling this issue. As mentioned before, for every hour of the target day L(d), we obtain 100 different load values (see Figure 5.6). The re- sults are then used to determine the distribution of the hourly load values (99 different quantiles) for any given hour, by employing linear extrapolations [24]. An illustrative ex- ample of the predicted quantiles for 11 days, March 20-30, 2011, is provided in Figure 5.7. Model Evaluation: Pinball loss is a comprehensive index to evaluate the reliability, sharpness, and calibration of the forecasts. It is an extensively used error measure for quantile forecasts in probabilistic forecasting problems. The performance of the fore- casting models in GEFCom2014 was evaluated by the overall mean of the pinball loss values. Recall that the pinball loss function can be written as: Pinball( ÀÜyt,q, yt,q) = ( (1‚àíq)( ÀÜyt,q ‚àíyt) if ÀÜyt,q > yt q(yt ‚àíÀÜyt,q) if ÀÜyt,q ‚â§yt (5.7",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_125"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "yt,q, yt,q) = ( (1‚àíq)( ÀÜyt,q ‚àíyt) if ÀÜyt,q > yt q(yt ‚àíÀÜyt,q) if ÀÜyt,q ‚â§yt (5.7) 102 5. HYPOTHESIS GENERATION USING SVD Month [23] [21] Model I Model II 1 9.88 11.87 3.43 3.23 2 9.54 10.93 3.24 2.89 3 7.79 8.44 2.69 2.56 4 4.89 4.50 2.53 2.30 5 5.96 7.27 3.33 3.50 6 5.86 6.99 4.98 4.66 7 7.66 9.05 3.63 3.42 8 10.70 11.26 8.71 8.58 9 6.28 5.49 4.46 4.05 10 5.20 3.36 2.97 2.76 11 6.38 5.90 3.50 3.59 12 8.99 9.73 3.57 3.36 Table 5.2: The left two columns are the reported results in [23], and [21]. The results of our proposed two different models are presented in the right part. The results reported here are the average of 100 iterations (no. of trees is 100, and MaxNumSplits=128). where yt is the target hourly value of the load proÔ¨Åle from [5], and ÀÜyt,q is the correspond- ing forecast value at the q‚àíth quantile (q ‚àà{0.01,0.02,...,0.99}); it is obtained from one of the models speciÔ¨Åed above. To evaluate the full predictive densities, pinball scores obtained from Eq. (5.7) are averaged over the time horizon (99 quantiles for every hour, 24 hours of the day, n days of the month). A better forecast yield a lower pinball score. For more details on the pinball loss function and the evaluation methods used in GEF",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_126"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " time horizon (99 quantiles for every hour, 24 hours of the day, n days of the month). A better forecast yield a lower pinball score. For more details on the pinball loss function and the evaluation methods used in GEFCom2014, see [5]. Table 5.2 contains the results of our proposed models along with two benchmark models. It is worth noting that all the data prior to the target month have taken part in the training of each model, i.e., the Ô¨Årst eleven months in 2011 were used for training a model to predict the load proÔ¨Åles in December 2011. Furthermore, the average of 100 different hourly load values (top panel in Figure 5.6) is used as a proxy for the actual load value anytime needed. The reason for that is that in the later days of the month, the earlier load proÔ¨Åles are needed in the form of L(d‚àí1) or L(d‚àí7). The results in Table 5.2 highlights the fact that including the derivatives (especially the 2nd derivatives) is indeed helpful in enhancing the performance of the forecasting model. Diebold-Mariano test is another well-known metric to determine whether forecasts are signiÔ¨Åcantly different. Let ei1 and ei2 be the residuals for Model I and II, respectively (i ‚àà[1 : n]). n is the number 5.4. EXPERIMENTAL RESULTS 103 Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec -3 -2 -1 0 1 2 3 4 5 6 Diebold-Mariano Test Figure 5.8: Comparison of the two models I and II, using Diebold-Mariano test (h = 1 and k = 0). of data points, and k is the lagging variable [25]. di = |ei1|2 ‚àí|ei2|2 ¬Ød = 1 n nX i=1 di Œ≥k = 1 n nX i=k+1 (di ‚àí¬Ød)(di‚àík ‚àí¬Ød), n > k ‚â•1 DM = ¬Ød s [Œ≥0 +2 h‚àí1 P k=1 Œ≥k]/n , h ‚â•1 (5.8) Figure 5.8 contains the Diebold-Mariano test [26], [27] to determine whether the two models are",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_127"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "Œ≥0 +2 h‚àí1 P k=1 Œ≥k]/n , h ‚â•1 (5.8) Figure 5.8 contains the Diebold-Mariano test [26], [27] to determine whether the two models are signiÔ¨Åcantly different. These results were obtained by comparing the error between the median (q = 0.5) of the forecasts from the two models and the actual values. The results are the average of 100 iterations, calculated according to Eq. (5.8). Suppose that the signiÔ¨Åcance level of the test is Œ± = 0.05. For a two-tailed test, therefore, the upper and lower tails would each be 0.025. Accordingly, the upper and lower z‚àívalues are 1.96 and ‚àí1.96, respectively [28]. The null hypothesis of no difference between the two models (forecasts) will be rejected if the computed Diebold-Mariano statistic falls outside the range of [-1.96, 1.96]. Consistent with the results in Table 5.2, in February, June and September 2011, Models I and II are most signiÔ¨Åcantly different. On the other hand, in August, when both models have the highest pinball score, the Diebold-Mariano (DM) test is low. Finally, DM tests in May and November 2011, are negative, as Model I outperforms Model II. 104 REFERENCES 5.5. CONCLUSIONS This chapter proposes two generic scenario-based probabilistic load forecasting models using an ensemble of regression trees. An important distinction of the current work is in recasting quasi-periodic time series data as matrices. The singular value decomposition technique is then used to generate temperature scenarios, in a robust, data-driven and timely manner. In the second model, we extend the Ô¨Årst one by adding the Ô¨Årst and second derivatives of the non-deterministic attributes (temperature and historical load data). It was done to partially account for the recency effects and interactions among the data. The empirical case studies performed on the data from the load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014-L) show how the proposed models outperform two benchmark scenario-based models with a similar set-up. REFERENCES [1] A. Khoshrou and E. J. Pauwels",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_128"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " Forecasting Competition 2014 (GEFCom2014-L) show how the proposed models outperform two benchmark scenario-based models with a similar set-up. REFERENCES [1] A. Khoshrou and E. J. Pauwels, Propagating uncertainty in tree-based load forecasts, in Electrical and Electronics Engineering (ELECO), 2017 10th International Confer- ence (IEEE, 2017) pp. 120‚Äì124. [2] A. Khoshrou and E. J. Pauwels, Short-term scenario-based probabilistic load fore- casting: A data-driven approach, Applied Energy 238, 1258 (2019). [3] T. Hong et al., Energy forecasting: Past, present, and future, Foresight: The Interna- tional Journal of Applied Forecasting , 43 (2014). [4] T. Hong, P. Pinson, and S. Fan, Global energy forecasting competition 2012, (2014). [5] T. Hong, P. Pinson, S. Fan, H. Zareipour, A. Troccoli, and R. J. Hyndman, Proba- bilistic energy forecasting: Global energy forecasting competition 2014 and beyond, (2016). [6] P. Lusis, K. R. Khalilpour, L. Andrew, and A. Liebman, Short-term residential load forecasting: Impact of calendar effects and forecast granularity, Applied Energy 205, 654 (2017). [7] A. Khoshrou, A. B. Dorsman, and E. J. Pauwels, Svd-based visualisation and ap- proximation for time series data in smart energy systems, in Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), 2017 IEEE PES (IEEE, 2017) pp. 1‚Äì6. [8] L. Breiman, Bagging predictors, Machine learning 24, 123 (1996). [9] Y. Wang, N. Zhang, Y. Tan, T. Hong, D. S. Kirschen, and C. Kang, Combining proba- bilistic load forecasts, IEEE Transactions on Smart Grid (2018). [10] Y. Freund, R. E. Schapire, et al., Experiments with a",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_129"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " Kirschen, and C. Kang, Combining proba- bilistic load forecasts, IEEE Transactions on Smart Grid (2018). [10] Y. Freund, R. E. Schapire, et al., Experiments with a new boosting algorithm, in Icml, Vol. 96 (Citeseer, 1996) pp. 148‚Äì156. [11] Y. Freund, R. Schapire, and N. Abe, A short introduction to boosting, Journal- Japanese Society For ArtiÔ¨Åcial Intelligence 14, 1612 (1999). REFERENCES 105 [12] D. Opitz and R. Maclin, Popular ensemble methods: An empirical study, Journal of artiÔ¨Åcial intelligence research 11, 169 (1999). [13] S. B. Taieb and R. J. Hyndman, A gradient boosting approach to the kaggle load fore- casting competition, International journal of forecasting 30, 382 (2014). [14] L. Breiman, J. Friedman, C. Stone, and R. Olshen, ClassiÔ¨Åcation and Regression Trees, The Wadsworth and Brooks-Cole statistics-probability series (Taylor & Fran- cis, 1984). [15] L. Breiman, Random forests, Machine learning 45, 5 (2001). [16] S. C. Lemon, J. Roy, M. A. Clark, P. D. Friedmann, and W. Rakowski, ClassiÔ¨Åcation and regression tree analysis in public health: methodological review and comparison with logistic regression, Annals of behavioral medicine 26, 172 (2003). [17] W.-Y. Loh, ClassiÔ¨Åcation and regression trees, Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1, 14 (2011). [18] B. Liu, J. Nowotarski, T. Hong, and R. Weron, Probabilistic load forecasting via quan- tile regression averaging on sister forecasts, IEEE Transactions on Smart Grid 8, 730 (2017). [19] P. Wang, B. Liu, and T. Hong, Electric load forecasting with recency effect: A big data approach, International Journal of Forecasting 32, 585 (2016). [20] T. Hong",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_130"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "). [19] P. Wang, B. Liu, and T. Hong, Electric load forecasting with recency effect: A big data approach, International Journal of Forecasting 32, 585 (2016). [20] T. Hong and S. Fan, Probabilistic electric load forecasting: A tutorial review, Interna- tional Journal of Forecasting 32, 914 (2016). [21] J. Xie and T. Hong, Gefcom2014 probabilistic electric load forecasting: An integrated solution with forecast combination and residual simulation, International Journal of Forecasting 32, 1012 (2016). [22] T. Hong, J. Wilson, and J. Xie, Long term probabilistic load forecasting and normal- ization with hourly information, IEEE Transactions on Smart Grid 5, 456 (2014). [23] F. Ziel and B. Liu, Lasso estimation for gefcom2014 probabilistic electric load fore- casting, International Journal of Forecasting 32, 1029 (2016). [24] E. Langford, Quartiles in elementary statistics, Journal of Statistics Education 14 (2006). [25] Diebold-Mariano Test Statistic, https://nl.mathworks.com/matlabcentral/ fileexchange/33979-diebold-mariano-test-statistic?focused= 7267180&tab=function (). [26] D. Harvey, S. Leybourne, and P. Newbold, Testing the equality of prediction mean squared errors, International Journal of forecasting 13, 281 (1997). [27] F. X. Diebold and J. A. Lopez, 8 forecast evaluation and combination, Handbook of statistics 14, 241 (1996). 106 REFERENCES [28] Comparing predictive accuracy of two forecasts: The diebold-mariano test, http: //www.phdeconomics.sssup.it/documents/Lesson19.pdf (). 6 VOLATILITY QUANTIFICATION 6.1. INTRODUCTION Renewable Energy Sources (RES) are assuming an increasingly pre-eminent role in Ger- man electricity production. To secure an economic and environmentally compatible supply, Germany has substantially expanded its RES-capacity, in particular wind and solar [4]. This creates new challenges as wind and solar energy are fundamentally in- termittent, weather-dependent and unpredictable. It hence raises concerns about the overall reliability of the power supply",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_131"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " has substantially expanded its RES-capacity, in particular wind and solar [4]. This creates new challenges as wind and solar energy are fundamentally in- termittent, weather-dependent and unpredictable. It hence raises concerns about the overall reliability of the power supply and its Ô¨Çexibility. It is therefore of considerable in- terest to investigate what effect this energy transition could have on the overall trend and volatility of electricity prices. This impact could be complex because there are a number of contradicting forces at play. The marginal cost of RES is relatively low and even nega- tive (especially if subsidized); therefore, increased penetration of wind and solar would result in a downward trend in electricity prices. Moreover, a perceived advantage of mar- ket coupling is to reduce price volatility [5]. On the contrary, the associated uncertainty regarding the availability of wind and solar energy is expected to cause spikes in the mar- ket. In other words, the integration of RES provokes the assertion that the stability of the power grid can be compromised due to the inherent intermittency of such sources. Con- sequently, the increased price volatility will cause additional market risks for suppliers and consumers on the market. Volatility principally refers to random Ô¨Çuctuations of a time series about its mean or expected value. Generally speaking, in Ô¨Ånancial time series data analytics, volatility is measured by the standard deviation of the logarithmic return or a derivation of that [6]. In the literature, numerous methods have been introduced to determine the volatility of the time series data. Diverse methods, from applied models such as Garman-Klass and Rogers-Satchell volatility estimators to the coefÔ¨Åcient of variation based, and formal stochastic volatility models including GARCH, Heston models and [7]. Recently, how- ever, new concepts and notions of volatility have been explored, especially in Ô¨Ånancial data analysis. Ruiz et. al., in [8] propose the permutation entropy, topological entropy Parts of this chapter have been published in [1‚Äì3]. 107 108 6. VOLATILITY QUANTIFICATION and the modiÔ¨Åed permutation entropy as alternative measures for volatility quantiÔ¨Åca- tion. In the reported work, the degree of randomness or determinism of a time series is considered as the notion of the volatility of data. Simonsen [9] studies different volatility features (including volatility clustering, log-normal distribution, and long-range",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_132"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ". In the reported work, the degree of randomness or determinism of a time series is considered as the notion of the volatility of data. Simonsen [9] studies different volatility features (including volatility clustering, log-normal distribution, and long-range corre- lations) of the Nordic day-ahead power spot market for the course of 12 years (1992 till May 2004). The aforementioned work also reports the presence of cyclic behavior of the time-dependent volatility for the quasi-periodic (with almost diurnal patterns) power market data. Additionally, the striking differences between the range of price data in different years are reported to be an obstacle in developing a generic approach to an- alyzing the market from different perspectives. The volatility has namely dependence on the price level, which is even more pronounced when spot prices are low. There- fore, in terms of analyzing EPEX data shifting up all the values for different years by a certain threshold in order to use the traditional Ô¨Ånancial data methodologies, does not appear to be a viable approach, as the results may vary drastically for different thresh- olds. A frequency domain-based method is deployed in [10] to systematically separate out the periodic components of the prices from random variations. After removing the deterministic part, the price volatility is determined by Ô¨Åtting a Wiener process to the remaining random stochastic (residual) part. Because of the aforementioned characteristics of the EPEX price values, in the Ô¨Årst step, we pre-process the raw data to eliminate the underlying patterns; and subsequently, focus on quantifying the volatility of data on an hourly or daily bases. The nature of this pre-processing is discussed in the following subsections. Along with the increase in the utilization of intermittent renewable sources, short- term electricity market studies (including day-ahead, intraday and imbalance market) are becoming increasingly popular. We herein opt to focus on the day-ahead market as it represents an important and growing segment where market mechanisms are clearly visible. In particular, we focus on the following question: How can the evolution of the price volatility of the day-ahead market over the past eleven years (i.e., 2006-2016) be quantiÔ¨Åed? Inspired by the work in [11], we consider matrices as an alternative rep- resentation of the electricity market data where the time series demonstrates periodic patterns. In the next step, a popular and numerically stable matrix decomposition tech- nique,",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_133"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "? Inspired by the work in [11], we consider matrices as an alternative rep- resentation of the electricity market data where the time series demonstrates periodic patterns. In the next step, a popular and numerically stable matrix decomposition tech- nique, namely the singular value decomposition (SVD), is used to disentangle the matrix of daily price proÔ¨Åles (one year‚Äôs worth of hourly values) based on the most dominant daily proÔ¨Åles (left singular vectors as a notion of trend) and their corresponding variabil- ity (the right singular vectors). Accordingly new, yet easy-to-quantify, notions of hourly and daily volatility are proposed using a lower-rank matrix reconstruction (as a mea- sure of hourly volatility) and the right singular vectors (as a measure of daily volatility). The second part of this chapter is dedicated to exploring the possible effect of RES on the overall price proÔ¨Åles (e.g., shifts in peak price hours, emergence of zero or negative prices). The rest of this chapter is organized as follows. Section 6.2 focuses on the data de- scription for the day-ahead market; it also explains the source and a brief summary of the day-ahead market mechanism. Section 6.3 provides a brief recapitulation of SVD. Sections 6.4 and 6.5 are dedicated to our methodologies and detailed description of the proposed daily and hourly volatility quantities. We conclude in Chapter in Section 6.7. 6.2. DATA 109 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 Years -100 -50 0 50 100 150 200 250 300 350 Price (Euro/MWh) Day-Ahead Market 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 -300 -200 -100 0 100 200 300 Price (Euro/MWh) Figure 6.1: Left: Evolution of the German day-ahead spot prices from 2006 through 2016 (daily averages). Right: The corresponding box-plots of the hourly price data (for the sake of visualization, only values between [‚àí300,300] are illustrated). It is evident to see that zero or negative prices started to",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_134"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 2016 (daily averages). Right: The corresponding box-plots of the hourly price data (for the sake of visualization, only values between [‚àí300,300] are illustrated). It is evident to see that zero or negative prices started to appear in late 2008 after- wards. 6.2. DATA The European Power Exchange (EPEX SPOT SE) operates on the Central Western Euro- pean (CWE) spot market. To guarantee a single integrated and transparent market, the EPEX SPOT SE acts as a neutral intermediary market operating service provider between the market members active in the central western European countries - viz. Switzerland, France, Germany and Austria. This market consists of non-Ô¨Ånal consumers and big players in the energy sector such as utilities, wind and solar farm owners, hydroelectric power stations, aggregators, transmission system operators (TSOs), Ô¨Ånancial service providers and also energy trad- ing entities that are working within the energy sector on a daily basis [12]. The following sections describe the functionality of the day-ahead market. 6.2.1. DAY-AHEAD AUCTION SPOT MARKET An exchange for short-term (one day before the power delivery) electricity contracts is the day-ahead market. It is a single integrated market where the participants themselves propel the trading. An electricity buyer, typically a utility or TSO, determines the amount of energy ( and the purchase price) it will need to fulÔ¨Ål its customer‚Äôs requirements for the coming day. The seller, e.g., the owner of a wind or solar farm, also submits the quantity which they are prepared to deliver the next day and the price level for each hour. These ‚Äúbids‚Äù are then fed into a complex algorithm to calculate the clearing price. In the end, the Ô¨Ånancial and physical transactions are settled. The output of the algorithm is in fact a number of time series of prices (bounded between [‚àí500,3000]), and traded volumes which are going to be exchanged, per area and period of the day, for the next day [5, 13]. Day-Ahead Spot Prices (in AC/MWh) Figure 6.1 illustrates an overview of the hourly values of the price on the day-ahead market in Germany and Austria from 2006 until 110 6. VOLATILITY QUANTIFICATION Year 2006 2007 2008 2009 201",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_135"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " illustrates an overview of the hourly values of the price on the day-ahead market in Germany and Austria from 2006 until 110 6. VOLATILITY QUANTIFICATION Year 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 ¬µ 50.79 37.98 65.76 38.85 44.48 51.12 42.59 37.78 32.76 31.63 28.98 std 49.42 30.35 28.65 19.40 13.98 13.60 18.69 16.45 12.77 12.67 12.48 Cv 97.31 79.91 43.58 49.94 31.42 26.60 43.87 43.53 38.99 40.05 43.08 Table 6.1: Annual mean, standard deviation and the coefÔ¨Åcient of variation Cv of EPEX price data, in the years 2006-2016. 2016 (data source: [12]). Interestingly enough, it is plain to see that after triggering the energy transition in 2011, occurrences of zero or negative price values are more frequent. Furthermore, a cursory glance at this time series suggests an overall downward trend in price range as well as its volatility. As mentioned before, it is reasonable to question whether the intermittency of renewables would render the price more erratic. Loosely speaking, volatility refers to the random Ô¨Çuctuations of a time series about its expected value. There are various methods to deÔ¨Åne and quantify volatility, from ap- plied models like Garman/Klass to coefÔ¨Åcient of variation and formal Stochastic Volatil- ity models such as GARCH, Heston models and the like e.g. [7, 14]. There are at least two reasons why it is problematic to blindly transfer standard Ô¨Åntech methodology to the current setting: ‚Ä¢ While the stock market prices are only available on trading days, EPEX prices cover the whole year, 24 hours 7 days a week. Accordingly, the underlying variability of the data could wrongly be conceived as volatility whereas it in fact simply reÔ¨Çects the diurnal patterns of human",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_136"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ", EPEX prices cover the whole year, 24 hours 7 days a week. Accordingly, the underlying variability of the data could wrongly be conceived as volatility whereas it in fact simply reÔ¨Çects the diurnal patterns of human activities. ‚Ä¢ More importantly, EPEX prices can be zero or even negative; therefore, the stan- dard approach to switch to logarithmic measures can be done only after shifting up all values above zero by a certain threshold. On the other hand, price volatility has a dependence on the price level, which is even more pronounced when the spot prices are low [9]. Therefore, the generalizability of conventional approaches can be questioned, as the volatility measures can vary drastically, with respect to the magnitude of the aforementioned thresholds. Table 6.1 contains the annual mean, standard deviation and coefÔ¨Åcient of variations of the German day-ahead market. Interestingly enough, despite a consistent reduction in the annual mean (¬µ) and the standard deviation (std), the coefÔ¨Åcient of variation (Cv = std ¬µ √ó100) has increased from 2015 afterwards. Figure 6.2 provides a comparison of the annual standard deviation of the logarithmic returns of the EPEX data, for three different cases. As mentioned before, since the original time series contain non-positive values, in the Ô¨Årst step, we shift up all the hourly price values P = {p1,p2,...,p8760} (p8784 for a leap year) by a positive Œ± value (xt = pt + Œ±). Considering the upper and lower limit of the EPEX price values (recall that pt ‚àà[‚àí500,3000]), three different scenarios have been deÔ¨Åned as follow: 1) Œ± = |min(P)| + 1; 2) Œ± = |max(P)| + 1; and 3) Œ± = 501. The logarithmic returns are then calculated as follows: Œ≤t = log(xt)‚àílog(xt‚àí1) (6.1) 6.3. MATRIX DECOMPOSITION USING SVD 111 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 0 5 10 15 20 25 Annual standard deviation of log returns =|min(P)|+1 =|max(P)|+",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_137"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "0 2011 2012 2013 2014 2015 2016 0 5 10 15 20 25 Annual standard deviation of log returns =|min(P)|+1 =|max(P)|+1 =501 Figure 6.2: Comparison of annual standard deviation of logarithmic returns of EPEX data for different Œ± values. In the Ô¨Ånal step, the standard deviation of the logarithmic return values Œ≤t is considered as a notion of annual volatility. It is plain to see that different Œ± values have led to con- tradictory results. We herein deÔ¨Åne a new notion of hourly and daily volatility (using the SVD method) which is robust in terms of non-positive values, as fully elaborated in the following sections. 6.3. MATRIX DECOMPOSITION USING SVD As previously mentioned, the SVD is applied extensively in matrix computations, but can also be put to good use in the study of time series that have exogenously induced periods. This is often the case in economics time series, where the variables of interest show cyclic patterns. As it is explained in the previous chapters, to obtain a matrix format of the data for each year, we reshape the time series data into matrix Ah√ód, where h = 24 is the num- ber of hours of the day, and d = 365 (366 for a leap year) is the number of days of the year [11]. The SVD method is then used to decompose the matrix Ah√ód into a set of fun- damental daily proÔ¨Åles and their corresponding weights during the observed time span (it becomes apparent in the following section). This method is more robust, regarding the aforementioned issues with EPEX price data, as it enables us to explore the trend and volatility of each year individually and in a data-driven manner, with no need to add offset values. As an example, Figure 6.3 displays an overview of the German day-ahead electricity prices in 2016. As a Ô¨Årst step, we recast each year‚Äôs worth of data into a matrix Ah√ód where each column contains 24 hourly values for a given day ‚Äì it can be seen as d points in h‚àídimensional space, similar to Figure 1.15. We then obtain its corresponding three fac- torization matrices using the SVD expansion. As discussed in Chapter 2, if",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_138"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " given day ‚Äì it can be seen as d points in h‚àídimensional space, similar to Figure 1.15. We then obtain its corresponding three fac- torization matrices using the SVD expansion. As discussed in Chapter 2, if the price pro- Ô¨Åles for each day were identical (or linearly dependent), i.e. all the columns were identi- cal (or linearly dependent), the matrix would have had a rank equal to one (rank(A) = 1). 112 6. VOLATILITY QUANTIFICATION 0 2000 4000 6000 8000 -100 -50 0 50 100 Price (Euro/MWh) Figure 6.3: An overview of the evolution of the hourly day-ahead price values in 2016. However, in practice, the rank of the matrix Ah√ód exceeds one since the daily price pro- Ô¨Åles for subsequent days tend to differ, depending on the calendar information, supply availability and demand. Figure 6.4 illustrates the Ô¨Årst two dominant Uk and Vk proÔ¨Åles, corresponding to the two largest singular values œÉk (k = 1,2). It is plain to see that the most dominantU proÔ¨Åle (U1, top left), highly resembles an appropriately weighted average of daily proÔ¨Åles (aver- aged over the year). The morning and late afternoon price peaks are clearly discernible in this plot. The second column of U (U2 bottom left) acts as a correcting factor, which needs to appropriately be added to the Ô¨Årst proÔ¨Åle to build up a more detailed represen- tation of the data. The panels on the right display the corresponding Vk coefÔ¨Åcients that specify the magnitude of the corresponding Uk proÔ¨Åle for each day of the year. In other words, Vk proÔ¨Åles sensibly reÔ¨Çect the daily variability of their corresponding Uk proÔ¨Åles throughout the year. Figure 6.5 demonstrates the evolution of the singular values for different years. It is plain to see that by considering only a few singular values (and their corresponding singular vectors) we are capable of reconstructing the price data with a good approxi- mation. 6.4. QUANTIFYING THE DAILY VOLATILITY The wavelet decomposition technique is used herein to quantify the daily volatility of the EPE",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_139"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " we are capable of reconstructing the price data with a good approxi- mation. 6.4. QUANTIFYING THE DAILY VOLATILITY The wavelet decomposition technique is used herein to quantify the daily volatility of the EPEX price data. 6.4.1. WAVELET DECOMPOSITION In modern mathematics, wavelets are one of the most efÔ¨Åcient and widely used tools to analyse digital signals. As the name suggests, wavelet analysis is akin to Fourier anal- ysis which decomposes the signal of interest as a linear combination of sine waves of different frequencies and phases [15]. Wavelet analysis will not only tell us which frequencies are hidden in the signal, 6.4. QUANTIFYING THE DAILY VOLATILITY 113 1 3 5 7 9 11 13 15 17 19 21 23 Hourslots (1-24) 0.15 0.16 0.17 0.18 0.19 0.2 0.21 0.22 0.23 0.24 0.25 1st dominant daily profile (U1) 10 50 90 130 170 210 250 290 330 Days of year (1-366) -0.04 -0.02 0 0.02 0.04 0.06 0.08 0.1 0.12 Associated weights to U1 (V1) 1 3 5 7 9 11 13 15 17 19 21 23 Hourslots (1-24) -0.2 -0.1 0 0.1 0.2 0.3 2nd dominant daily profile (U2) 10 50 90 130 170 210 250 290 330 Days of year (1-366) -0.5 -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 Associated weights to U2 (V2) Figure 6.4: SVD-based rank-2 approximation: the Ô¨Årst two most dominant Uk proÔ¨Åles are depicted on the left side. The panels on the right contain their corresponding Vk coefÔ¨Åcients. Left column: Ô¨Årst two columns",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_140"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " SVD-based rank-2 approximation: the Ô¨Årst two most dominant Uk proÔ¨Åles are depicted on the left side. The panels on the right contain their corresponding Vk coefÔ¨Åcients. Left column: Ô¨Årst two columns of U-matrix representing a weighted averaged proÔ¨Åle for each day (top) and a Ô¨Årst order correction (again one value for each hour over a 24 hour period). Right column: corresponding amplitudes (V columns). Figure 6.5: An overview of the evolution of the singular value of the price data in recent years. 114 6. VOLATILITY QUANTIFICATION Figure 6.6: Schematic representation of the Haar wavelet decomposition. but can also pinpoint their location in the data stream. From this, it becomes clear that wavelets hand us a useful tool to probe the data for the occurrence and location of high-frequency Ô¨Çuctuations [16]. The Haar wavelet is arguably the simplest wavelet and lends itself to a straightforward interpretation. It basically takes any discrete sig- nal x = (x1,x2,x3,...) and creates an approximation a and detail d signal by running the following simple recipe: 1. Take the Ô¨Årst two elements x1 and x2 and compute the approximation and detail coefÔ¨Åcients: a = x1 + x2 2 and d = x1 ‚àíx2 2 . Notice that this implies x1 = a +d and x2 = a ‚àíd, or more explicitly: the approxi- mation coefÔ¨Åcient equals the mean of the two values, and the detail coefÔ¨Åcient is the amount of deviation between the actual value and the approximation. 2. Store the results in the approximation and detail vector, respectively: a(1) = a d(1) = d. Both vectors have a length equal to half the length of the original input x. 3. Move on to the next pair (x3,x4) and continue until all x-elements have been pro- cessed. This way we get the level-one approximation (a1) and detail (d1) coefÔ¨Å- cient (each vector of half the length of the original x-sequence). 4. To compute the level-two approximation and detail coefÔ¨Åcients we repeat the whole procedure but use a1 as input (instead of x). 5",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_141"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "- cient (each vector of half the length of the original x-sequence). 4. To compute the level-two approximation and detail coefÔ¨Åcients we repeat the whole procedure but use a1 as input (instead of x). 5. This can be continued until we have reached a pre-deÔ¨Åned level. 6.4. QUANTIFYING THE DAILY VOLATILITY 115 Figure 6.7: Evolution of the annual standard deviation of the Haar wavelet detail coefÔ¨Åcients of the absolute values of v1, v2 proÔ¨Åles magniÔ¨Åed by their corresponding singular values, down to three level (starting from the top left). Figure 6.6 exempliÔ¨Åes the decomposition for a (short) discrete signal x = (x1,x2,x3,x4). In the Ô¨Årst analysis step, the original values (the dots) are paired, and each pair is re- placed by its mean or approximation (ai, the dash-dotted lines) and the symmetric de- viation di with respect to the corresponding mean. As a consequence, the original signal x can equally well be represented by the approximation vector a = (a1,a2) and the vec- tor of detail coefÔ¨Åcients d = (d1,d2). The next analysis step (not depicted here) would repeat the procedure, this time starting with the approximation a as input. As a concrete example, imagine that the time series is given by x = (1 5 11 1...), then ‚Ä¢ Level 1: x = (1 5 |{z} 3¬±2 11 1 | {z } 6¬±(‚àí5) ...) ‚àí‚Üí a1 = (3 6...) and d1 = (2 ‚àí5...) ‚Ä¢ Level 2: a1 = (3 6 | {z } 4.5¬±(‚àí1.5) ...) ‚àí‚Üí a2 = (4.5 ...) and d2 = (‚àí1.5 ...) 6.4.2. VOLATILITY QUANTIFICATION It is important to realize that the level-one detail coefÔ¨Åcients capture the highest fre- quency oscillations. Subsequent detail coefÔ¨Åcients correlate with oscillations of succes- sively lower frequencies. As mentioned before, in the present work, the right singular 116 6",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_142"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "Ô¨Åcients capture the highest fre- quency oscillations. Subsequent detail coefÔ¨Åcients correlate with oscillations of succes- sively lower frequencies. As mentioned before, in the present work, the right singular 116 6. VOLATILITY QUANTIFICATION 3900 3950 4000 4050 15 20 25 30 35 40 Original Approximated Figure 6.8: Detail of rank-2 approximation (red) superimposed on original data (blue). vectors Vk are considered to be an indicator of the volatility of the fundamental daily price proÔ¨Åles (Uk) throughout a year. As it was mentioned earlier, Figure 6.5 conÔ¨Årms that there are only a few dominant singular values; we hence opt to consider only the Ô¨Årst two right singular vectors (Vk). Figure 6.7 contains the standard deviation of the values of the Haar wavelet detail coefÔ¨Åcients, down to three-level wavelength decom- position. The downward trend underscores a reduction in the volatility of the German day-ahead market in recent years. Worth noting that V1 and V2 coefÔ¨Åcients have been magniÔ¨Åed using their corresponding singular values œÉ1 and œÉ2. The results here corrob- orate with [2], where the hourly volatility of the German day-ahead market during the same period is studied. 6.5. QUANTIFYING THE HOURLY VOLATILITY A thorough understanding of volatility is crucial for many applications in Ô¨Ånancial eco- nomic studies such as derivative pricing, corporate risk management, market efÔ¨Åciency, and many others. As previously mentioned in Section 6.2.1, some characteristics of the EPEX price data have made it impractical to apply the conventional econometric ap- proaches in the time series volatility quantiÔ¨Åcation. Therefore, we propose an alterna- tive approach to hourly price volatility quantiÔ¨Åcation using the residuals of the matrix reconstruction. To get some idea of what a rank-2 approximation looks like, Figure 6.8 shows a de- tail of the approximation (in red) superimposed on the actual data (blue). Figure 6.9 contains a more general case of the reconstruction of price data in 2016, along with the absolute value of the corresponding residuals. In the current section, we",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_143"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "in red) superimposed on the actual data (blue). Figure 6.9 contains a more general case of the reconstruction of price data in 2016, along with the absolute value of the corresponding residuals. In the current section, we focus on the residuals of the price after compensating for daily patterns using a rank-2 approxima- tion; it is done to quantify the hourly volatility of the data over the years. As previously mentioned, Figure 6.5 illustrates that the singular values of the price data throughout different years follow the same pattern. Therefore, according to the results in Figure 6.5 the choice to focus on rank-2 approximation is relatively arbitrary and unimportant. As can be seen in the top panel of Figure 6.10, the absolute value of the residuals adheres remarkably well to an exponential distribution (with a mean 2.97). It is almost 6.5. QUANTIFYING THE HOURLY VOLATILITY 117 0 2000 4000 6000 8000 -100 -50 0 50 100 Original Approximated 0 2000 4000 6000 8000 0 10 20 30 40 50 60 Absolute value of residuals Figure 6.9: Left: Original and rank-2 approximation of the price data for 2016. Right: Absolute values of the residuals after rank-2 approximation. Residuals are a means to measure volatility. only the top 1% that is substantially higher in value than expected. Moreover, the lower panel of Figure 6.10 highlights the fact that the higher rank approximations yield similar results. Only as expected, by increasing the reconstruction rank, the absolute value of the residuals decreases. Figure 6.11 conÔ¨Årms that this trend is consistent throughout the period of observation (2006-2016). Based on this observation, we propose the following approach to quantify the evolution in (annual) volatility in the years 2006 through 2016: 1. The inÔ¨Çuence of daily and seasonal variations is removed by Ô¨Åtting a rank-2 ap- proximation and extracting the residual of the actual data with respect to this ap- proximation. As volatility is inÔ¨Çuenced by both positive and negative Ô¨Çuctuations, we hence focus on the absolute values of the residuals. Worth noting that",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_144"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " extracting the residual of the actual data with respect to this ap- proximation. As volatility is inÔ¨Çuenced by both positive and negative Ô¨Çuctuations, we hence focus on the absolute values of the residuals. Worth noting that, the bot- tom panel in Figure 6.10 indicates that higher-rank reconstructions yield similar results. 2. For every year, we Ô¨Åt the lowest 99% of the absolute value of the residual with an exponential and compute the corresponding parameter (i.e. mean of the expo- nential). This value corresponds to the size of the residuals. Note that here the absolute value of the residuals is considered, which is the reason for preferring the exponential distribution over the normal distribution in our methodology. 3. Typically, the top 1% of the observed distribution is much larger than expected (based on the bulk of the distribution). We characterize these values by computing the median value of this top 1% segment separately. The results are shown in Figures 6.12 and 6.13. The former Ô¨Ågure shows a robust es- timate for the mean of exponential distribution for each year. The estimate is based on the lowest 99% of the absolute values of the residual and is therefore robust with respect to the top 1% of extremely large values. The 99% vs. 1% is dictated by the exponen- tial prob-plot in Figures 6.10 and 6.11 which show a clear divergence at the 99% mark. To quantify this decreasing trend, we have computed the regression line, which yields a statistically signiÔ¨Åcant downward slope equal to -0.58 (with 95% conÔ¨Ådence interval: - 0.89:-0.26). The quality of this regression can be further improved by Ô¨Åtting a power law, 118 6. VOLATILITY QUANTIFICATION 0 10 20 30 40 50 60 Data 0.01 0.25 0.5 0.75 0.9 0.95 0.99 0.995 0.999 0.9995 0.9999 Probability Probability plot for Exponential distribution 0 20 40 60 80 100 120 Data 0.01 0.25 0.5 0.75 ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_145"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "999 0.9995 0.9999 Probability Probability plot for Exponential distribution 0 20 40 60 80 100 120 Data 0.01 0.25 0.5 0.75 0.9 0.95 0.99 0.995 0.999 0.9995 0.9999 Probability Probability plot for Exponential distribution rank 1 rank 2 rank 3 rank 4 rank 5 Figure 6.10: Top: The residuals of the rank-2 approximation of the day-ahead market prices for the year 2016: almost 99% of residuals adhere to an exponential distribution. Bottom: Higher rank approximations yield similar results. 0 100 200 300 400 500 600 Data 0.01 0.25 0.5 0.75 0.9 0.95 0.99 0.995 0.999 0.9995 0.9999 Probability Probability plot for Exponential distribution 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 Figure 6.11: Exponential distribution of the residuals of the rank-2 approximations for different years. 6.5. QUANTIFYING THE HOURLY VOLATILITY 119 Figure 6.12: Evolution of the price volatility on the German day-ahead market in the period 2006 through 2016 . The individual data points record the estimated exponential parameter (mean) based on all but the 1% highest values of the residuals. The regression line has a slope equal to -0.58 which is highly signiÔ¨Åcant (95% conÔ¨Ådence interval: -0.89 : -0:26). See the main text for more details. but at this point, a linear regression serves the purpose to illustrate the signiÔ¨Åcant down- ward trend. The evolution of the top 1% is shown in Figure 6.13 where these data are represented by their median value. This Ô¨Ågure indicates that whereas extreme residuals were not uncommon prior to 2010, these values fell signiÔ¨Åcantly and have been roughly constant during the years 2012-2016. The message from both Ô¨Ågures combined is that",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_146"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ure indicates that whereas extreme residuals were not uncommon prior to 2010, these values fell signiÔ¨Åcantly and have been roughly constant during the years 2012-2016. The message from both Ô¨Ågures combined is that volatility has decreased signiÔ¨Åcantly over the years 2006 to 2016. Volatility tends to be higher in winter By scrutinizing Figure 6.9 it becomes evident that the volatility tends to be lower in summer (middle part of the graph) than in winter (extremal parts of the graph). To demonstrate that this is indeed the case, we use a mea- sure based on the angular momentum. More precisely, if the (absolute) residual for hour slot h is given by R(h) and the distance between the hour slot h and the central hour slot hm = n/2 = 4392 equals |h ‚àíhm| the observed angular momentum is deÔ¨Åned a: Lobs = nX h=1 R(h)(h ‚àíhm)2 (6.2) where n is equal to the total number of hour slots. If we re-scale the values of the hour slot in such a way that hm = 0 and ‚àí1 ‚â§h ‚â§1 (divided by 1000, for ease of comparison), we obtain Lobs = 10.676. A high value for Lobs refutes the assumption that the residuals are uniformly distributed throughout the year and favours an interpretation in which residuals (and hence volatility) are higher in the winter season. We judge the signiÔ¨Åcance of this result using a permutation test. The rationale is straightforward: if the residuals are uniformly distributed over the hour slots, then a random permutation of the values 120 6. VOLATILITY QUANTIFICATION 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 0 20 40 60 80 100 120 140 Median value of top 1% residuals Evolution of top 1% for day-ahead price residuals Data Regular linear fit Robust bisquared fit Figure 6.13: Evolution of top 1% residuals over the years 2006-2016. Each data point represents the median value of the top one percent residuals (in absolute value). As such, these values characterize the extreme de- viations in",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_147"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "13: Evolution of top 1% residuals over the years 2006-2016. Each data point represents the median value of the top one percent residuals (in absolute value). As such, these values characterize the extreme de- viations in day-ahead prices. The plot clearly shows that these extreme values decreased signiÔ¨Åcantly before 2010, and then stayed approximately constant. should not result in a signiÔ¨Åcantly different value for Lobs. The results of the permutation test for 2016 are depicted in Figure 6.14. Our experiments show that similar results for all the other years can be produced. 6.6. EXTRACTING THE UNDERLYING TRENDS This section is dedicated to a more descriptive study of the evolution of the overall trend of the day-ahead market. 6.6.1. THE EVOLUTION OF THE DAILY PROFILES As mentioned before, the left singular vectors (Uk proÔ¨Åles) represent the most dominant daily proÔ¨Åle (U1) and its additive corrective proÔ¨Åles (U2,U3,...). Figure 6.15 displays the evolution of the most dominant daily price proÔ¨Åles (U1 magniÔ¨Åed by œÉ1) over the years. A continuous downward trend during the decade in the average value of the daily proÔ¨Åle is noticeable. More importantly, the change in the overall shape of the daily proÔ¨Åle is even more telling. Before 2011, the morning peak price values tended to be higher than the afternoon peak values. Whereas this trend has become reversed in recent years. Another intriguing feature of the data is the shift of the time slot (during the day) which more points to the effect of the low-cost subsidized RES on the daily price proÔ¨Åle. Before 2011, the electricity price is most expensive at around 12h00. Evidently, the availability of solar after 2011 has pushed the prices lower and has led to morning peak prices at around 9h00. In a similar way, the afternoon peak price time slot has a shift of an hour from around 19h00 to 20h00. Furthermore, it is plain to see that the ranges of the daily proÔ¨Åles (difference between the maximum and minimum values) show a reduction, in recent 6.6. EXTRACTING THE UNDERLYING TRENDS 121",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_148"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ". Furthermore, it is plain to see that the ranges of the daily proÔ¨Åles (difference between the maximum and minimum values) show a reduction, in recent 6.6. EXTRACTING THE UNDERLYING TRENDS 121 Figure 6.14: Price data for 2016: Results of the permutation test. The histogram of the L-values for 1000 random permutations of the actual data. Obviously, the actually observed value (indicated in red) is signiÔ¨Åcantly larger than the values we would expect for data sets without structure (with a p-value < 10‚àí3). This conÔ¨Årms our observation that volatility shows a seasonal pattern. years. This also can be an indication of less volatility in years. In other words, the change in timing and amplitude of daytime and evening time peak values after 2011 are striking. Before 2011, the midday peak price (around 12h00), was considerably higher than the early evening spike around 20h00. However after 2011, the Ô¨Årst spike is not just lower than the second one, but also shows a clear shift to earlier hours. This makes sense in light of the higher contribution of renewables, and in particular solar; it is reasonable to assume that the typically high supply of solar power around midday is the reason for the drop in prices during these hours. The right panel of Figure 6.15 displays an alternative representation of the same data in the left panel; it conÔ¨Årms the previous Ô¨Åndings by showing a downward trend in average daily prices from left to right. The diminishing contrast in each column indicates a smoother price proÔ¨Åle with a lower daily spread over the years. Looking closely, the shift of the midday and afternoon peak hours is notable. 6.6.2. THE EXTREME VALUES In the next step, the extreme values of the hourly prices during the years have been probed. More speciÔ¨Åcally, collecting all the hour slot values for each year in the pe- riod 2006 through 2016 yields a price distribution for each year. Extreme prices (both high and low) are characterized as prices outside the extreme 5% percentiles. So we get a representative value for high (low) prices by focusing on the values of the 95% (5% re- spectively) percentile for the distribution of each year",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_149"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " are characterized as prices outside the extreme 5% percentiles. So we get a representative value for high (low) prices by focusing on the values of the 95% (5% re- spectively) percentile for the distribution of each year‚Äôs worth of hourly price values. The results are shown in Figure 6.16 where we have plotted both values (high and low) for each year. There is a pronounced continuous downward trend for the high prices, with 2008 being an obvious outlier. The lowest prices show a slight decrease over the years, as there is obviously less room for manoeuvre. The overall spread of the prices is steadily decreasing and less volatile, indicative of a more mature market. 122 6. VOLATILITY QUANTIFICATION 6.6.3. THE DISTRIBUTION OF HIGH AND LOW PRICE VALUES We herein explore the evolution in the distribution of occurrences of extreme prices over the course of the day. Recall that high (low) prices are deÔ¨Åned as values outside the 95th (5th) percentile of price distribution for that year. Figure 6.17 (left panel) shows how the occurrence of low prices is distributed over the day (for the years 2006 through 2016). Whereas in the earlier years of the decade, there is a clear concentration of low price occurrences in the early morning (4h00-5h00), later years show a more uniform daily distribution. A similar distribution for the occurrence of high prices is shown in the right panel of Figure 6.17. It indicates a distinct shift (occurring around 2011) in the time slot of high prices. More precisely, the daytime peak is shifted from noon to the earlier hour of 9h00, while the evening is postponed, shifting from 19h00 to 20h00. In other words, before 2011, the daytime peak values were higher than the afternoon ones and occurred around noon. After 2011, high prices occur predominantly at the beginning and end of the peak period. Each column represents 440 values, which is 5% of the total number of observations during one year. Also apparent is the fact that starting in 2011, the afternoon spikes in the price proÔ¨Åle exceed the daytime ones. 6.6.4. ZERO AND NEGATIVE PRICES Of special interest are zero or negative prices as they reÔ¨Çect the effect of subsidized",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_150"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "2011, the afternoon spikes in the price proÔ¨Åle exceed the daytime ones. 6.6.4. ZERO AND NEGATIVE PRICES Of special interest are zero or negative prices as they reÔ¨Çect the effect of subsidized RES. In Germany, a signiÔ¨Åcant amount of electricity is still produced by conventional sources. In 2015, e.g., lignite, nuclear energy and hard coal were responsible for producing 24, 14.2 and 18.3 % of gross electricity production, respectively [17]. The synchronization speed of these plants is slow and they can not be shut or ramped down very quickly. As a result, on some days when there is an excess of electricity production by subsidized re- newable energy sources, prices may become negative and consumers can actually make a proÔ¨Åt by consuming electricity. Figure 6.18 provides an overview of the frequency along with the magnitude of non-positive prices, in recent years. More speciÔ¨Åcally, the width (on the x-axis) of the interval assigned to each year is proportional to the number of oc- currences of negative (or zero) prices in that year. The y-axis depicts the corresponding magnitude of these negative prices. Starting in 2012, the number of occurrences (length of the interval) seems to increase steadily. This trend is strikingly consistent with the growing contribution of wind and solar energy in Appendix B.1. From this graph it tran- spires that there is a reduction in the magnitude of the negative prices in recent years, although their number is mildly increasing. The distribution of the growing number of instances of zero as well as negative prices in recent years, from a different perspective, is illustrated in Figure 6.19. The left panel highlights the frequency of occurrence of non-positive price values during different hours of the day, for each year. Although, before 2012, the majority of non-positive prices are happening in the early hours of the day, a cluster of non-positive price values appeared during the midday (11h00-18h00). Considering the fact that the electricity demand dur- ing these hours has not changed much (working hours), the most probable explanation for this change can be the oversupply of solar farms. As is seen in Appendix B.1.2, these are the hours with the highest solar energy availability; on average, at 13h00, solar pro-",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_151"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " the most probable explanation for this change can be the oversupply of solar farms. As is seen in Appendix B.1.2, these are the hours with the highest solar energy availability; on average, at 13h00, solar pro- duction can become as high as 5 gigawatt-hour (GWh), which is almost 5 times more than solar feed-in at 10h00. This number can be even more during the summer. Ap- 6.7. CONCLUSIONS 123 pendix B.1.3 highlights the fact that wind and solar energy combined are responsible for almost 10 GWh feed-in at around 13h00, throughout the year. Another conspicuous ob- servation in the left panel of Figure 6.19, is the increased frequency of the occurrences of non-positive prices in the early hours of the day in the last two years. Interestingly enough, Appendix B.1.1 presents how the wind feed-in have notably increased in 2015 afterwards. The right panel of Figure 6.19, conÔ¨Årms the fact the non-positive price val- ues are most frequent during the weekends when the consumption is low. However, we witness more instances of zero or negative prices during the week, from 2011 afterwards. 6.7. CONCLUSIONS In this chapter, we have traced the impact of the integration of renewable energy sources (RES) in Germany on the day-ahead electricity market, in terms of volatility, in the years 2006-2016. Regarding volatility quantiÔ¨Åcation, there are a number of peculiarities that make conducting the empirical methods onerous. EPEX price data have the following characteristics: 1) It covers the whole year, 24 hours 7 days of a week; 2) It can have non- positive values; 3) It depends on the calendar information (working and non-working days), and 4) It shows daily upward and downward trends following the demand and also the supply availability. Therefore, there is a lot of underlying variability in data that simply reÔ¨Çects the diurnal patterns of human activities, and not reÔ¨Çecting the volatility. Furthermore, regarding the second point (non-positive values), the traditional approach in Ô¨Ånancial time series analysis to switch to logarithmic measures are impractical, with- out shifting up all the values by a certain threshold.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_152"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ecting the volatility. Furthermore, regarding the second point (non-positive values), the traditional approach in Ô¨Ånancial time series analysis to switch to logarithmic measures are impractical, with- out shifting up all the values by a certain threshold. On the other hand, price volatility has a dependence on the price level, which is even more pronounced when the spot prices are low. Therefore, with respect to the magnitude of the aforementioned thresh- old, results can vary drastically. We hence have explored an alternative approach by rep- resenting the market data as matrices rather than time series. A novel and generic notion of volatility were accordingly deÔ¨Åned using a well-known and numerically stable matrix decomposition technique, namely the singular value decomposition (SVD), combined with Haar wavelet transforms. Our observations indicate a price volatility reduction and also prominent changes in the day-ahead price proÔ¨Åles, in recent years. There is an overall downward trend in the average electricity price. This undoubtedly has a number of causes, but the increasing penetration of subsidized solar and wind power account for at least part of it. Moreover, the traditional 12h00 peak before the Energiwende (Energy switch) is Ô¨Çattened out and shifted to earlier hours in the morning at 9h00. In a similar manner, the afternoon peak price hours have shifted one hour, from 19h00 to 20h00. Indeed, it is possible to clearly trace the impact of solar on the change of the daily price proÔ¨Åle over the year (this effect is most pronounced in summer). Furthermore, the effect of the growth in wind power is most transparent in the shift in the distribution of low and negative prices during the day. 124 6. VOLATILITY QUANTIFICATION Figure 6.15: Top: Averaged daily proÔ¨Åles of the day-head prices. Bottom: An alternative representation, for the sake of better visualization. 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 0 20 40 60 80 100 120 Euro/MWh Values of 5th and 95th percentiles y = -3.1x + 79.1 y = -0.82x + 26.9 High Percentile Robust bisquared fit of 95th Low Percentile Rob",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_153"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " of 5th and 95th percentiles y = -3.1x + 79.1 y = -0.82x + 26.9 High Percentile Robust bisquared fit of 95th Low Percentile Robust bisquared fit of 5th Figure 6.16: The evolution of extreme prices shows a consistent downward trend in the data. 6.7. CONCLUSIONS 125 Figure 6.17: An overview of the distribution of low prices over the day (top), vs. high prices (bottom), through- out different years. 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 -500 -450 -400 -350 -300 -250 -200 -150 -100 -50 0 Euro/MWh Figure 6.18: An overview of the occurrences of zero or negative prices. 126 6. VOLATILITY QUANTIFICATION Figure 6.19: Top: The abundance of zero as well as negative prices during the period of absence of sunlight provokes the higher impact of wind than solar in this matter. Conversely, there are no negative prices in the evening hours 19h - 23h, as consumption is high, and solar input has vanished. Bottom: The percentage of the distribution of the zero or negative prices on the days of week. REFERENCES 127 REFERENCES [1] A. Dorsman, A. Khoshrou, and E. J. Pauwels, The inÔ¨Çuence of the switch from fossil fuels to solar and wind energy on the electricity prices in germany, (2016). [2] A. Khoshrou and E. J. Pauwels, Quantifying volatility reduction in german day- ahead spot market in the period 2006 through 2016, in 2018 IEEE Power & Energy Society General Meeting (PESGM) (IEEE, 2018) pp. 1‚Äì5. [3] A. Khoshrou, A. B. Dorsman, and E. J. Pauwels, The evolution of electricity price on the german day-ahead market before and after the energy switch, Renewable Energy 134, 1 (2019). [4] Information portal renewable energy, http://www.erneuerbare-energien. de/EE/",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_154"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " of electricity price on the german day-ahead market before and after the energy switch, Renewable Energy 134, 1 (2019). [4] Information portal renewable energy, http://www.erneuerbare-energien. de/EE/Navigation/DE/Service/Erneuerbare_Energien_in_Zahlen/ Zeitreihen/zeitreihen.htm. [5] Epexspot, european power exchange‚Äû http://www.epexspot.com/en/ market-coupling (). [6] Financial chaos theory, http://quantonline.co.za/Articles/article_ volatility.htm. [7] R. T. Baillie, C.-F. Chung, and M. A. Tieslau, Analysing inÔ¨Çation by the fractionally integrated arÔ¨Åma‚Äìgarch model, Journal of applied econometrics , 23 (1996). [8] M. d. C. Ruiz, A. Guillam√≥n, and A. Gabald√≥n, A new approach to measure volatility in energy markets, Entropy 14, 74 (2012). [9] I. Simonsen, Volatility of power markets, Physica A: Statistical Mechanics and its Applications 355, 10 (2005). [10] F. L. Alvarado and R. Rajaraman, Understanding price volatility in electricity mar- kets, in System Sciences, 2000. Proceedings of the 33rd Annual Hawaii International Conference on (IEEE, 2000) pp. 5‚Äìpp. [11] A. Khoshrou, A. B. Dorsman, and E. J. Pauwels, Svd-based visualisation and approx- imation for time series data in smart energy systems, in 2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe) (2017) pp. 1‚Äì6. [12] Epexspot, day-ahead auction, https://www.epexspot.com/en/product-info/ auction/germany-austria (). [13] B. Corn√©lusse, How the european day-ahead electricity market works, (2014). [14] L. C. G. Rogers and S. E. Satchell, Estimating variance from high, low and closing prices, The Annals of Applied Probability , 504 (1991). [15] C. Torrence",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_155"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " [14] L. C. G. Rogers and S. E. Satchell, Estimating variance from high, low and closing prices, The Annals of Applied Probability , 504 (1991). [15] C. Torrence and G. P. Compo, A practical guide to wavelet analysis, Bulletin of the American Meteorological society 79, 61 (1998). 128 REFERENCES [16] I. Daubechies, The wavelet transform, time-frequency localization and signal anal- ysis, IEEE transactions on information theory 36, 961 (1990). [17] Federal statistical ofÔ¨Åce of germany, https://www.destatis.de/ EN/FactsFigures/EconomicSectors/Energy/Production/Tables/ GrossElectricityProduction.html. 7 CONCLUSION In a world replete with observations (physical as well as virtual), many data sets are represented by time series. In its simplest form, a time series is a set of data collected sequentially, usually at Ô¨Åxed intervals of time. In a number of applications, the mean and the variance of the time series is time-invariant and there is no seasonality in the data (such time series is called stationary). However, in many more applications, e.g., time series that are related to smart energy systems, the observed data often have non- stationary characteristics. For instance, whereas the electrical consumption of house- holds is similar throughout the week, it shows a markedly different consumption pattern in the weekend. An important research thread of the work in this thesis is the introduction of an alter- native representation (as matrices) for such a time series. This offers some advantages when it comes to the analysis of these types of data. The rationale is straightforward: we then can use matrix factorization techniques to address different problems in a robust, numerically-stable manner. In particular, in this thesis, we have focused on the singular value decomposition (SVD) as a powerful, numerically stable matrix factorization tech- nique which is then applied to time series analysis. That in turn has enabled us to look at different applications in time series analysis from a fresh perspective. 7.1. MAIN CONTRIBUTIONS As announced in Chapter 1, one of the earliest applications of SVD in time series analy- sis is to detect periodicity and the number of components in the time series. To be more precise, in the literature, the ratio",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_156"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " MAIN CONTRIBUTIONS As announced in Chapter 1, one of the earliest applications of SVD in time series analy- sis is to detect periodicity and the number of components in the time series. To be more precise, in the literature, the ratio of the Ô¨Årst to the second singular values has been in- troduced as a reliable measure to detect the periodicity in a time series. However, what has not been much appreciated is that the mean level of the data as well as the number of observed cycles (which determines the dimensions of the data matrix) affects the dis- tributions of the singular values. Especially the latter case is more relevant to us, as the matrix size is not Ô¨Åxed and the number of columns can increase in time by adding new data. In this chapter, we also have provided an example of a complex time series where 129 130 7. CONCLUSION the Fast Fourier Transform (FFT) fails to correctly determine its periodicity. We also have provided an introduction to different applications of the SVD in time series analysis. We harked back to the SVD approach and the relevant theorems in Chapter 2. Fur- thermore, we have extensively studied the SVD and its geometrical interpretation to ac- quire a Ô¨Årm understanding of how it performs. We also have provided a number of ex- amples of how the position with respect to the origin and the alignment of data points affects the singular vectors and accordingly the singular values. We also have explained how the results of the SVD and PCA are related to one another. This chapter also provides an intuitive answer to Research Question 1. However, an in-depth discussion of the Ô¨Årst two research questions is provided in the next chapter. In this thesis, we make extensive use of simulation and SVD-based computations. As a consequence, accurate sampling from various matrix distributions is important. Through comprehensive experiments, we have become aware of certain biases and artefacts. We have concluded this chapter by pointing out the presence of such artefacts in the implementations of the algorithms in Matlab and Python. For most applications of the SVD in various Ô¨Åelds, it is important to understand the properties of SVD of a matrix whose entries show some degree of random Ô¨Çuctuations. Therefore, in order to determine how the noise level affects the singular value spectrum, it is essential to study the singular value decomposition of random matrices. Having provided a background in",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_157"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " of a matrix whose entries show some degree of random Ô¨Çuctuations. Therefore, in order to determine how the noise level affects the singular value spectrum, it is essential to study the singular value decomposition of random matrices. Having provided a background in random matrices, Chapter 3 addressed Research Question 1 and Research Question 2 in full detail. In this chapter, we have proved some more prop- erties of the SVD. In particular, we have provided estimates on how the drift in a simple periodic time series can affect its singular values. The SVD and PCA techniques are both conceptually simple and effective. However, it is well-known that they are sensitive to the presence of noise and outliers in input data. In the literature, some modiÔ¨Åcations of the original algorithms of SVD and PCA have been proposed to alleviate the effect of these disturbances. In particular, one way to mitigate this sensitivity is to introduce regularisation terms. To this end, in Chapter 4 we Ô¨Årst hark back to interpreting PCA in terms of low-rank approximations. We then added regularisation terms to its functionals and devised a solution algorithm for the new constrained optimization problem. This offers a solution to Research Question 3a. We next turned our attention to the SVD factorisation and Research Question 3b. Al- gorithm 1 proposes a solution to a simpler case where only one regularisation term was added. In Algorithm 2 we offer a solution for the more general case. We then have shown how to tackle the computational aspects of the random and gradient descent techniques. To this end, we used ideas from Lie-group and -algebra to come up with a convenient parametrisation of the search problem. We have concluded this chapter by providing some examples of how regularisation can enable us to enhance the underlying patterns in the data. With the increasing integration of renewable energy sources (RES) such as wind and solar energy into the power grid, balancing the grid has become more challenging. It is mostly due to the inherently intermittent nature of RES, on the one hand, and shortcom- ings in bulk energy storage systems, on the other. Therefore, studies on scenario-based probabilistic energy production and demand forecasts have gained momentum, as they are highly valuable from both a technical and an economic point of view. A particular 7.2. CONCLUDING REMARKS AND FUTURE WORK 131 application of such models in the",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_158"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "istic energy production and demand forecasts have gained momentum, as they are highly valuable from both a technical and an economic point of view. A particular 7.2. CONCLUDING REMARKS AND FUTURE WORK 131 application of such models in the energy sector is where having the distribution of the energy consumption for the coming days is desired. The performance of such models evidently depends to a large extent on how different input (temperature) scenarios are being generated. There are mainly three practical and popular methods for generating temperature scenarios, namely Ô¨Åxed-date, shifted-date, and bootstrap approaches. Nev- ertheless, these methods have mostly been used on an ad-hoc basis without being for- mally compared or quantitatively evaluated. Chapter 5 provides a data-driven solution for Research Question 4. In this chapter, we proposed a generic framework for proba- bilistic load forecasting using an ensemble of regression trees. A major distinction of the current work was in using matrices as an alternative representation for quasi-periodic time series data. The SVD technique was then used to generate temperature scenarios in a robust and timely manner. The strength of our proposed method lies in its simplic- ity and robustness, in terms of the training window size, with no need for subsetting or thresholding to generate temperature scenarios. The empirical case studies performed on the data from the load forecasting track of the Global Energy Forecasting Competi- tion 2014 (GEFCom2014-L) show that the proposed method outperforms the top two scenario-based models with a similar set-up. In Chapter 6, we investigated Research Question 5, i.e., what effect the transition of energy to RES can have on the overall trend and also the volatility of the electricity prices. As it was exempliÔ¨Åed in this chapter, the emergence of non-positive price values in the energy transition era has introduced new challenges in the electricity market volatility analysis. More precisely, traditional approaches to switch to logarithmic measures can only be done after shifting up all values above zero by a certain threshold. However, price volatility has a dependence on the price level, which is even more pronounced when the spot prices are low. Therefore, the aforementioned pre-processing step can affect the Ô¨Å- nal outcome. In other words, the generalizability of conventional approaches can be questioned, as the volatility measures can vary drastically, with respect to the magni- tude of the thresholds mentioned above. The ÔøΩ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_159"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " step can affect the Ô¨Å- nal outcome. In other words, the generalizability of conventional approaches can be questioned, as the volatility measures can vary drastically, with respect to the magni- tude of the thresholds mentioned above. The Ô¨Årst part of this chapter offers a solution to Research Question 5a by introducing a new notion of volatility which was obtained by reconstructing the time series using the SVD. Our observations indicate price volatil- ity reduction, in the day-ahead market, in the years 2006-2016. The second part of this chapter addressed Research Question 5b; it provided shreds of evidence of the effect of renewables on daily price proÔ¨Åles ‚Äì the emergence of non-positive prices and shifts of peak price values to hours where solar is less available. 7.2. CONCLUDING REMARKS AND FUTURE WORK In this thesis, we have argued that the well-known singular value decomposition (SVD) (which is usually applied to matrix problems) can also successfully be applied to identify the periodic patterns in time series. Furthermore, these proÔ¨Åles are completely deÔ¨Åned by the data and do not require the speciÔ¨Åcation of user-deÔ¨Åned parameters, apart from the period (which itself can be estimated using this approach). As such, this methodol- ogy offers a purely data-driven approach to adaptive signal approximation. Our Ô¨Åndings can be used as innovative components of future smart grid systems, which are charac- terized by the increasing uncertainty on both the supply and demand parts. An important topic for further research would be to Ô¨Ånd ways in which the gradient 132 7. CONCLUSION descent procedure used in Algorithms 1 and 2 of Chapter 4 can be accelerated by tak- ing advantage of the fact that the functional is very smooth and locally approximately quadratic. It would also be useful to derive some estimates for appropriate values for the weights Œª and ¬µ in terms of noise characteristics corrupting the underlying signal. Fi- nally, although the P matrix in Algorithm 2 has unit-length columns, unlike the standard SVD, we were unable to conÔ¨Årm the orthogonality of the P vectors, i.e., PT P Ã∏= Ik. In fact, numerical experiments seem to indicate that such a constraint is not compatible with the minimisation of the functional. This requires further theoretical elucidation. A APPEND",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_160"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ality of the P vectors, i.e., PT P Ã∏= Ik. In fact, numerical experiments seem to indicate that such a constraint is not compatible with the minimisation of the functional. This requires further theoretical elucidation. A APPENDIX A.1. BRIEF OVERVIEW OF MATRIX NORMS Matrix norms come in two Ô¨Çavours (more details are discussed below): ‚Ä¢ Vector interpretation: entry-based norm The matrix is seen as a vector (general- isation of n-tuples), and the norms are based on the values of the matrix entries. ‚Ä¢ Operator interpretation: operator or induced Norm A matrix can also be inter- preted as representing a linear transformation, and the norm is associated with the effect of the linear transformation on vectors. VECTOR INTERPRETATION (ENTRY-WISE NORMS) In this case we simply interpret a p √óq matrix as an pq-tuple and use the corresponding vector norm. For instance, for A ‚ààRp√óq: ‚Ä¢ L2 norm (squared for notational convenience): ||A||2 2 = pX i=1 qX j=1 |ai j |2 = Tr(AT A) = Tr(AAT ) This norm is also called the Frobenius norm (which is the same as the sum of squares of the singular values.). ‚Ä¢ L1 norm: ||A||1 = pX i=1 qX j=1 |ai j | = 1T p |A|1q where 1n is a column matrix of length n for which all entries are equal to 1. ‚Ä¢ L‚àûnorm: ||A||‚àû= max i,j |ai j | 133 134 APPENDIX ‚Ä¢ Small entries in a vector contribute more to the 1‚àínorm of the vector than to the 2‚àínorm. That is in contrast to the contribution of large entries in a vector to the 1-norm and 2-norm. OPERATOR INTERPRETATION (INDUCED NORM) In this case the matrix norm is induced by the norm(s) for vectors. More speciÔ¨Åcally, the matrix norm is determined by the maximal (ampliÔ¨Åcation) effect the linear transfor- mation can have on any vector. Because of linearity we can restrict our attention to the effect on vectors of unit norm. Assuming that we are working in a Ô¨Ånite dimensional vectors",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_161"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "pliÔ¨Åcation) effect the linear transfor- mation can have on any vector. Because of linearity we can restrict our attention to the effect on vectors of unit norm. Assuming that we are working in a Ô¨Ånite dimensional vectorspace (V ) equipped with a norm ||¬∑||V , the induced operator norm (which will be denoted as ||¬∑||(V ) ) becomes: ||A||(V ) := max ¬Ω||Ax||V ||x||V : x ‚ààV0 ¬æ = max{||Ax||V : x ‚ààV, ||x||V = 1} This equation has a straightforward geometrical interpretation. The linear transforma- tion characterized by A transforms the unit sphere into an ellipsoid. The induced norm is equal to (half) the length of the maximal principal axis of this ellipsoid. ‚Ä¢ L2 norm (spectral norm): is in fact the largest singular value of the matrix. The 2-norm is the square root of the sum of squared distances to the origin along the direction that maximizes this quantity. ‚Ä¢ L1 norm: ||A||1 = max j ( qX i=1 |ai j |) where j = 1...p ‚Ä¢ In general, if one splits a matrix A into its column vectors: Ap√óq = [A1, A2,... Ap] the the one-norm of A in the maximum of the one-norms of the column vectors Ai of A. ||A||1 = max{||Ai||1 : Ai is a column vector of A } ‚Ä¢ Similarly, in general if one splits a matrix A into its row vectors: Ap√óq = Ô£Æ Ô£ØÔ£ØÔ£ØÔ£ØÔ£∞ A1 A2 ... Aq Ô£π Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª then the ‚àû‚àínorm of A is the maximum of the one-norms of the row vectors A j of A. ||A||‚àû= max{||A j ||1 : A j is a row vector of A } ‚Ä¢ L2 norm: is in fact the largest singular value of the matrix. The 2-norm is the square root of the sum of squared distances to the origin along the direction that maxi- mizes this quantity. A.2. SVD SOLVES A MATRIX NORM OPTIMISATION PROBLEM 135",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_162"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": ". The 2-norm is the square root of the sum of squared distances to the origin along the direction that maxi- mizes this quantity. A.2. SVD SOLVES A MATRIX NORM OPTIMISATION PROBLEM 135 A.2. SVD SOLVES A MATRIX NORM OPTIMISATION PROBLEM There are some essential connections between matrix norms and SVD. In this context we will explore two: 1. The L2 matrix norms can be expressed in terms of the singular values; 2. Using L2 matrix norms as an objective function, SVD provides the solution to a non-convex optimization problem. We will look at both in turn. A.3. L2 MATRIX NORMS EXPRESSED IN TERMS OF SINGULAR VAL- UES Suppose A is an n √óp matrix which has r non-zero singular values, arranged in decreas- ing order: œÉ1 ‚â•œÉ2 ‚â•... ‚â•œÉr > 0 Theorem 10. Both L2 norms (Frobenius and spectral) can be expressed in terms of the singular values. More speciÔ¨Åcally: 1. Frobenius norm (entry-wise): ||A||2 F = P i œÉ2 i . 2. Spectral norm (induced): ||A||2 2 = œÉ2 1. Proof. The proofs amount to straightforward calculations: 1. Frobenius: ||A||2 2 = Tr(AT A) = Tr(V STU T USV T ) = Tr(V ST SV T ) = Tr(ST S) = X i œÉ2 i 2. Spectral: max|Av| where |v| = 1 is a unitary matrix. Previously we saw that v1 maximize this argu- ment and the result of that is œÉ2 1. SVD SOLVES THE LOW-RANK APPROXIMATION PROBLEM The connection between SVD and matrix norms is given by the fact that the SVD provides the solution to the question: for a given matrix A, Ô¨Ånd the best approximation for a pre- speciÔ¨Åed rank. The notion of matrix norm enters when we need to specify what we mean by \"best\". Reformulating the problem in a more precise manner, we arrive at: Lemma 11. Matrices A and B are identical if and only if for all vectors v, Av = Bv. 136",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_163"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " to specify what we mean by \"best\". Reformulating the problem in a more precise manner, we arrive at: Lemma 11. Matrices A and B are identical if and only if for all vectors v, Av = Bv. 136 APPENDIX Related results For any matrix A, the sequence of singular values is unique and if the singular values are distinct, the the sequence of singular vectors is also unique. How- ever, when some set of singular values are equal, the corresponding singular vectors span same subspace. Ant set of orthonormal vectors spanning this subspace can be used as the singular vectors. Lemma 12. Let Ap be deÔ¨Åned as above, then the extension of the earlier expression of the norm in terms of the singular values are given by: ‚Ä¢ ||A ‚àíAp||2 2 = Pr k=p+1 œÉ2 k ‚Ä¢ ||A ‚àíAp||2 2 = œÉ2 p+1 A.4. GRADIENTS FOR FROBENIUS NORM Suppose that A ‚ààRp√ók, X ‚ààRk√óq and B ‚ààRp√óq and deÔ¨Åne the real-valued function (based on the Frobenius norm): f (X ) = ‚à•AX +B‚à•2 F Then we have the following gradient: ‚àáX f = 2AT (AX +B) (A.1) Similarly, g(X ) = ‚à•X A +B‚à•2 F =‚áí ‚àáX g = 2(X A +B)AT (A.2) Applying eqs. (A.1) and (A.2) to the J1 functional we get: 1 2‚àáU J1 = ‚àí(A ‚àíUV T )V +ŒªU and 1 2‚àáV J1 = (VU T ‚àíAT )U A.4.1. SOME SPECIAL CASES ‚Ä¢ For f (x) = aT xxT a = (aT x)2, then ‚àáx f = 2(aT x)a = 2(xT a)a ‚Ä¢ For For f (x) = xTQx where Q symmetric, ‚àáf = 2Qx A.5. VARIANCE OF PRODUCT ‚Ä¢ If X and Y are independent then: V ar(X Y ) = V ar(X )V ar(Y )‚àíV ar(X )(E",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_164"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " where Q symmetric, ‚àáf = 2Qx A.5. VARIANCE OF PRODUCT ‚Ä¢ If X and Y are independent then: V ar(X Y ) = V ar(X )V ar(Y )‚àíV ar(X )(E(Y ))2 ‚àíV ar(Y )(E(X ))2. (A.3) If both E(X ) = E(Y ) = 0, then V ar(X Y ) = V ar(X )V ar(Y ) (A.4) A.6. SINGULAR VALUES OF THE ‚ÄúFAT\" MATRICES 137 A.6. SINGULAR VALUES OF THE ‚ÄúFAT\" MATRICES ‚Ä¢ A square matrix represents a mapping from a space into itself (or another space of the same dimension). Under such a mapping the unit sphere is mapped to an ellipsoid. ‚Ä¢ A fat matrix represents a linear mapping from a higher dimensional space into a lower one. This means that the kernel is non-trivial. It also means that the unit sphere is mapped into a solid ellipsoid (i.e. including the interior). See Ô¨Åg right What we observe from these experiments is that when we increase the aspect ratio (make the matrix fatter), increasingly more unit vectors are mapped to the interior (making the outline of the ellipsoid more difÔ¨Åcult to spot. In addition, the image becomes less correlated (correlation coefÔ¨Åcient of data points decreases. This means that the singular values become more alike: a perfectly spherical image would result from the identity matrix which has identical singular values. So it seems to me that the explanation for the observed behaviour of the singular values must run along the following lines: ‚Ä¢ Increasing the aspect ratio (making the matrix fatter) results in an increase of the Frobenius norm (after all, we are summing over more matrix entries). Hence this implies that the sum of singular values has to increase. This can be done by in- creasing the incline of the line of singular values, or by shifting this line upwards parallel to itself (the latter is what we observe). ‚Ä¢ The above experiments suggest that increasing the aspect ratio results in an image of the unit-sphere that is increasingly more circular which would suggest that the ratio between the smallest and largest singular value decreases ‚Äî this rules out that the inclination of the singular values line increases, but does correspond to a uniform increase in all the singular values. ‚Ä¢ Basically Figure A.1 conÔ¨Å",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_165"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " which would suggest that the ratio between the smallest and largest singular value decreases ‚Äî this rules out that the inclination of the singular values line increases, but does correspond to a uniform increase in all the singular values. ‚Ä¢ Basically Figure A.1 conÔ¨Årm that for a set of unit vectors ei on n‚àídimensional space i.e., nP j=1 e2 i j = 1, if we increase the dimension n ‚Üí‚àûthen the ei ‚ÜíN (0,œÉ). Theorem 13. If ui (i = 1,...,N) are unit vectors in n-dimensional space Rn, sampled uniformly on the unit sphere Sn‚àí1 ‚äÇRn. Then (denoting vectors as columns): 1 N N X i=1 uiuT i ‚àí‚Üí1 n In as N ‚àí‚Üí‚àû. (A.5) Another way of formulating this would be: Let u1,u2 ‚àºUni f (Sn‚àí1) uniform and independent on the unit-sphere in Rn, then E(uT 1 u2) = 0 while E(u1uT 1 ) = E(u2uT 2 ) = 1 n In 138 APPENDIX Figure A.1: Image of 1000 random points on the unit sphere under a random transformation (unit normal). Top left: Random 2√ó2 matrix. Top right; 2√ó3. Bottom right: 2√ó15. A.6. SINGULAR VALUES OF THE ‚ÄúFAT\" MATRICES 139 Figure A.2: Distribution of correlation coefÔ¨Åcient of the images of 1000 uniformly distributed unit vectors after random transformation of n-dimensional space into 2-dim space (n = 2,3,5,10,20,50). Clearly, higher dimen- sional space tend to project down to less correlated data. This conÔ¨Årms the progression seen in Fig. A.1. 140 APPENDIX Outline of proof ‚Ä¢ If we would take ui = ei to be the standard unit vectors (in which case N = n) the asymptotic result turns into an equality. This follows immediately from the observation that eieT i is a matrix with a single non-zero entry (equal to 1) on the i th diagonal position. ‚Ä¢ Each term in the LHS sum in the LHS always has trace equal to 1 (exactly",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_166"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " observation that eieT i is a matrix with a single non-zero entry (equal to 1) on the i th diagonal position. ‚Ä¢ Each term in the LHS sum in the LHS always has trace equal to 1 (exactly), inde- pendent of N. This follows from the fact that for any rank-1 matrix: Tr(abT ) = X i (abT )ii = X i aibi = atb and hence: Tr(uiuT i ) = uT i ui = 1. As a consequence: Tr √É 1 N N X i=1 uiuT i ! = 1 N N X i=1 Tr(uiuT i ) = 1. (A.6) ‚Ä¢ Notice that the diagonal elements for every matrix uiuT i are just the square entries of ui: diag(uiuT i ) = (u2 i1,u2 i2,...,u2 in) Since the distribution of the unit vectors is uniform over the sphere, the induced distribution of the (squared) entries will be independent of the position along the diagonal (if this weren‚Äôt the case, then there would be a preferred direction space, which contradicts the uniformity). Hence, the sum (from 1 to N for each diagonal element, converges to the same value. This in combination with the fact that the trace needs to be one, shows that at least on the diagonal, Eq. (A.7) holds. ‚Ä¢ The off-diagonal elements of each rank-1 matrix (uuT )k‚Ñì= uku‚Ñìalso have some structure. Hence this means that the k‚Ñìelement of the LHS (where k Ã∏= ‚Ñì) is a (growing) sample mean and therefore converges to the mean of the corresponding mean of the stochastic variable UkU‚Ñì(where we use the capital notation to indicate the stochastic component variables that result from a drawing a unit vector u = (U1,U2,...,Un) uniformly on the unit-sphere: √É 1 N N X i=1 uiuT i ! k‚Ñì ‚àí‚ÜíE(UkU‚Ñì) as N ‚àí‚Üí‚àû. (A.7) Notice that if the components were independent, then this would clinch the proof because EUi = 0 (symmetry), assuming independence, E(UkU‚Ñì) = E(Uk)E",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_167"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "‚Üí‚àû. (A.7) Notice that if the components were independent, then this would clinch the proof because EUi = 0 (symmetry), assuming independence, E(UkU‚Ñì) = E(Uk)E(U‚Ñì) = 0. However, independence does not hold since Pn k=1U 2 k = 1. So there is a weak dependence that becomes weaker as the dimension of the ambient space grows. A.6. SINGULAR VALUES OF THE ‚ÄúFAT\" MATRICES 141 ‚Ä¢ Still, we can expect E(UkU‚Ñì) = 0 because if that weren‚Äôt the case, then there would a non-zero covariance between different components: Cov(Uk,U‚Ñì) = E(UkU‚Ñì)‚àíE(Uk)E(U‚Ñì) = E(UkU‚Ñì) Ã∏= 0 but that seems to contradict the uniformity on the unit-sphere. ‚Ä¢ Further to the above item: the dependence between the components is strongest in the low dimensional spaces and gets weaker in high dim. The strongest dependence is for unit vectors in 2-dim space. Sampling from the unit-circle in 2-dim amounts to u = (u1,u2) = (cos(Œ∏),sin(Œ∏)) where Œ∏ ‚àºU(‚àíœÄ,œÄ). Hence, E(u1u2) = E(cos(Œ∏)sin(Œ∏)) = 1 2E(sin(2Œ∏) = 0 since 2Œ∏ ‚àºU(‚àí2œÄ,2œÄ) ‚Ä¢ I think all of the above are sufÔ¨Åcient to construct a valid proof. At least it explains why the result is true. LetU = (U1,U2,...,Un) where eachUi ‚ààSn‚àí1 ‚äÇRn lies on the unit sphere. We want to prove that E(UiUj ) = 0 if i Ã∏= j. Proof: We can construct U as follow: U = X ‚à•X ‚à• when X ‚àºN (0,In) (A.8) E(UiUj ) = E( Xi ‚à•X ‚à• X j ‚à•X ‚à•) = E( Xi X j ‚à•X ‚à•2 ) (A.9) For the 2-dimensional case we have: X = (X1, X",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_168"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " E( Xi ‚à•X ‚à• X j ‚à•X ‚à•) = E( Xi X j ‚à•X ‚à•2 ) (A.9) For the 2-dimensional case we have: X = (X1, X2) X1, X2 independent random variables in N (0,œÉ) Let us assume the following: ( P = X1X2 R2 = X 2 1 + X 2 2 = Q Therefore we have Ô£± Ô£¥ Ô£≤ Ô£¥ Ô£≥ Q ‚àí2P = (X1 ‚àíX2)2 ‚â•0 Q ‚â•2P Q +2P = (X1 + X2)2 ‚â•0 ‚ÜíQ ‚â•‚àí2P 142 APPENDIX From the above formulas we can derive at the following: ( p = X1X2 q = X 2 1 + X 2 2 or ( q +2p = (X1 + X2)2 q ‚àí2p = (X1 ‚àíX2)2 œï(p,q) = 1 2œÄe‚àí(X 2 1 +X 2 2 )/2| ‚àÇ(X1,X2) ‚àÇ(p,q) | since X1 = X1(p,q),X2 = X2(p,q) therefore, ( X1 + X2 = p q +2p X1 ‚àíX2 = p q ‚àí2p By summing up and subtracting the two equations, we derive: ( 2X1 = p q +2p + p q ‚àí2p 2X2 = p q +2p ‚àí p q ‚àí2p hence |‚àÇ(X1,X2) ‚àÇ(p,q) | = 1 2( 1 p q2 ‚àí4p2 ) or œï(p,q) = 1 4œÄ e‚àíq/2 p q2 ‚àí4p2 therefore we conclude: E( X1X2 R2 ) = E( P Q ) (A.10) therefore we have: * Z Z p q œï(p,q) dp dq = ‚àû Z 0 q 2 Z ‚àíq 2 ( p q e‚àíq p q2 ‚àí4p2 )) dp dq = ‚àû Z 0 e‚àíq q ( q 2 Z ‚àíq 2 p p q",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_169"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ÔøΩ Z 0 q 2 Z ‚àíq 2 ( p q e‚àíq p q2 ‚àí4p2 )) dp dq = ‚àû Z 0 e‚àíq q ( q 2 Z ‚àíq 2 p p q2 ‚àí4p2 dp)dq = 0 since the inner integral is the integral of an odd function over a symmetric interval. We hence can conclude that for i Ã∏= j: E(UiUj ) = E( Xi X j ‚à•X ‚à•2 ) = 0 ‚Ä¢ Some random musing: this result is somewhat counter-intuitive. For each uiuT i is essentially an orthogonal projection on the corresponding unit vector. So you as- sume that because of the uniform distribution, all these contributions cancel out and therefore the result would be the zero mapping rather than the unit mapping. A.6. SINGULAR VALUES OF THE ‚ÄúFAT\" MATRICES 143 To explain the change of correlation in the Ô¨Ågures above, we need to investigate the cor- relation of the images of random unit vectors under random linear transformation, This means that we are interested in images of the form: f = Au where A is (m √ón) matrix with m ‚â§n (fat) Combining N of these results in a matrix we get: F = AU where U = (u1,...,uN) is n √ó N and F = (f1,...,fN) is m √ó N To compute the correlation (covariance) of the image vectors in F we have to compute: Cov(F) = 1 N N X i=1 fifT i = 1 N A √É N X i=1 uiuT i ! AT ‚àí‚Üí1 n AAT . Every entry of the correlation matrix is in fact the inner product of the corresponding two columns of the matrix X . More importantly, because the correlation matrix is symmetric and semi-positive (it contains the inner products) that guarantees that there are real, non-negative eigen values. Using the SVD decomposition to rewrite Am√ón = Um√ómSm√ónV T n√ón we get further- more: Cov(F) = 1 n U S S T U T = 1 n U diag(œÉ2 1,...,œÉ2 m)U T The matrix product in the RHS only depends on m, so increasing the number of columns N does indeed reduce the covariance.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_170"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " n U S S T U T = 1 n U diag(œÉ2 1,...,œÉ2 m)U T The matrix product in the RHS only depends on m, so increasing the number of columns N does indeed reduce the covariance. By increasing N, the covariance matrix is not decreasing but becoming constant on the RHS! But we need to covariance matrix to go to the unit matrix. So basically we need to show that 1 n diag(œÉ2 1,...,œÉ2 m) ‚àí‚Üí In as n ‚àí‚Üí‚àû. This indeed would imply that the singular values tend to the same values. A.6.1. WHY ARE SINGULAR VALUES INFLATED? Notice that if A = (m √ó n) (where m < n ) and we make the SVD decomposition A = U S V T then the last n ‚àím columns of V constitute an orthonormal basis for the null- space Z := ker A. ‚Ä¢ Notice that: (AAT )i j = nX k=1 Aik A jk (inner product of i th and j th row of A) Similarly: (AT A)i j = m X k=1 Aki Ak j (inner product of i th and j th column of A) 144 APPENDIX As a consequence: (AAT )ii = nX k=1 A2 ik ‚àºœá2 n (sum of independent squared standard normals) (A.11) while (AT A)ii = m X k=1 A2 ki ‚àºœá2 m (sum of independent squared standard normals) (A.12) ‚Ä¢ Introducing additional notation: Let U i,Ui be the i-th row, column respectively of U , Moreover, we denote ei = (0,...,0,1,0,...,0)T we can use the SVD decompo- sition A = U S V T to conclude: (AAT )ii = eT i AAT ei = eT i U diag(œÉ2 1,œÉ2 2,...,œÉ2 m)U T ei = U idiag(œÉ2 1,œÉ2 2,...,œÉ2 m)(U i)T = œÉ2 1u2 i1 +œÉ2 2u2 i2 +...+œÉ2 mu2 im =(A.13) m X k=1 œÉ2 ku2 ik ‚àº",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_171"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "2 m)(U i)T = œÉ2 1u2 i1 +œÉ2 2u2 i2 +...+œÉ2 mu2 im =(A.13) m X k=1 œÉ2 ku2 ik ‚àº œá2 n (cf. eq. A.11) . (A.14) Since we know that the columns ofU are orthonormal, it follows that also the rows are orthonormal (ref??): UU T = Im =‚áíU TU = Im (and vice-versa). This implies that m X k=1 u2 ik = 1, hence we can interpret eq. (A.14) as a weighted mean of the squared singular val- ues that needs (on average) be equal to n (the expected value of œá2 n). Hence we see that if we increase n, then the values of œÉk need to increase as well. Furthermore, since the rows and columns of U are random, this increase cannot be shouldered by a small number of the singular values, but needs to happen across the board. ‚Ä¢ We can make a similar argument: (AT A)ii = m X k=1 A2 ki ‚àº œá2 m But also: (AT A)ii = eT i AT Aei = œÉ2 1v2 i1 +...+œÉ2 mv2 im But notice that the factors in weighted sum do not add up to 1 (since m < n ). Notice that increasing n means that fewer components of v enter in the sum, and therefore the singular values need to increase in order to keep the average Ô¨Åxed on m. A.7. PERTURBATION OF EIGEN-VALUES AND -VECTORS 145 Figure A.3: The scaling factor seems to depend on the order of singular value. Left: difference between average sing values of random (standard normal) matrix for square (50√ó50) and fat (50√ó500) matrix. A.7. PERTURBATION OF EIGEN-VALUES AND -VECTORS A small change in the elements of a matrix can have a profound effect on a function of that matrix. Let Q be a symmetric n √ó n matrix with eigenvalue spectrum Œª(Q) = {Œª1,Œª2,...,Œªn}. The corresponding eigenvectors ui form an orthonormal basis for Rn:",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_172"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " a function of that matrix. Let Q be a symmetric n √ó n matrix with eigenvalue spectrum Œª(Q) = {Œª1,Œª2,...,Œªn}. The corresponding eigenvectors ui form an orthonormal basis for Rn: Qui = Œªiui and uT i uj = Œ¥i j . Now consider how a small perturbation of Q + œµdQ will affect the eigen-values and - vectors: Œªi(œµ) = Œªi +œµuT i dQ ui +o(œµ2) (A.15) ui(œµ) = ui +œµ X jÃ∏=i uT j dQ ui Œªi ‚àíŒªj +o(œµ2) (A.16) Note that these formulas hold as long as the unperturbed and perturbed systems in- volve symmetric matrices, to guarantee the existence of N linearly independent eigen- vectors. Let Q be a symmetric matrix which therefore has a orthonormal basis of eigenvectors ui with corresponding eigenvalues Œªi: Qui = Œªiui. Differentiating yields: (dQ)ui +Qdui = (dŒªi)ui +Œªidui. or again: (Q ‚àíŒªi)dui = (dŒªi ‚àídQ)ui. Left-multiplying by uT k and using the fact that Q is symmetric and therefore uT k Q = ŒªkuT k we obtain: uT k (Œªk ‚àíŒªi)dui = uT k (dŒªi ‚àídQ)ui. We now consider the following two cases: 146 APPENDIX ‚Ä¢ k = i : in this case the LHS vanishes, and we get from the RHS: dŒªi = uT i (dQ)ui = (dQ)ii. ‚Ä¢ k Ã∏= i : it then follows that: uT k dui = uT k (dQ)ui Œªi ‚àíŒªk . Since the ui constitute a basis we can expand: dui = X jÃ∏=i œµi j u j since (without loss of generality) œµii = 0. Plugging this in the equation above we get: dui = X kÃ∏=i uT k (dQ)ui Œªi ‚àíŒªk uk A.7.1. PERTURBATION THEORY",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_173"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "ii = 0. Plugging this in the equation above we get: dui = X kÃ∏=i uT k (dQ)ui Œªi ‚àíŒªk uk A.7.1. PERTURBATION THEORY FOR MATRICES Consider a symmetric matrix Q =UŒõU T ; differentiation yields: dQ = dUŒõU T +UdŒõU T +UŒõdU T Next we use the fact that every orthogonal matrix can be written as the exponential of a skew-symmetric: U = eK (where K T = ‚àíK ) and hence: dU =UdK Substituting this in the above yields: U T dQU =U T dUŒõ+dŒõ+Œõ(dU T )U U T dQU = dŒõ‚àí(ŒõdK ‚àídK Œõ) Writing the above equation for diagonal and off-diagonal elements yields the correct perturbation for the eigen-values and -vectors. B APPENDIX B.1. EPEX MARKET AND RES FEED-IN The following section contains some evidences of the impact of the day-ahead estimated wind and solar feed-in on the price changes (Section 6.6), in the recent years. B.1.1. DAY-AHEAD WIND ENERGY FEED-IN (IN GWH) Fig. B.1 provides an overview of the evolution of the wind feed-in (day-ahead forecasts) over the years. The left panel in Fig. B.1 indicates a smooth annual growth. In a similar way, the right panel highlights the fact that the production is relatively constant around the clock. The change in the annual average of the daily proÔ¨Åles from 2014 afterwards is noticeable. Peak production of the wind proÔ¨Åle is eventually moving from early after- noon to late night or early morning. This can become an issue for the stability of the grid, as there might not be enough demand during those particular hours. B.1.2. DAY-AHEAD SOLAR ENERGY FEED-IN (GWH) The developments in energy storage technologies and also the falling costs of harvesting solar power have made it increasingly attractive for the private households [? ]. Fig. B.2 shows the day-time (non-zero values) solar energy feed-in forecast from 2010 to 2016. After the rapid rise in 2010 through 2013",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_174"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " it increasingly attractive for the private households [? ]. Fig. B.2 shows the day-time (non-zero values) solar energy feed-in forecast from 2010 to 2016. After the rapid rise in 2010 through 2013, solar feed-in has leveled off in the last two years. The panel on the right in Fig. B.2 illustrates the annual averaged solar feed-in for each time slot for years 2010-2016. Peak of solar feed-in is around 13h00; that coincides with the high demand during the day. B.1.3. EVOLUTION OF GERMAN DAY-AHEAD PRICE DURING WINTER AND SUMMER To illustrate the impact of solar energy on the price, we scrutinize the data separately for the summer (June through August) and winter (December through February) periods. In winters, days are shorter and the sun, if it emerges at all, traces out a lower path in the sky; therefore, a signiÔ¨Åcantly smaller amount of solar energy is produced (Fig. B.3). Wind 147 148 APPENDIX 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 0 2 4 6 8 10 12 14 16 18 Wind Feed-in(GWh) 1 3 5 7 9 11 13 15 17 19 21 23 Hours 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 Annual Average of Wind(GWh) 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 Figure B.1: Top: The consistent growth in wind energy feed-in over the years. Bottom: Annual average of the daily proÔ¨Åles. B.1. EPEX MARKET AND RES FEED-IN 149 2010 2011 2012 2013 2014 2015 2016 0 2 4 6 8 10 Solar Feed-in (GWh) 1 3 5 7 9 11 13 15 17 19 21 23 Hours 0 0.",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_175"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "6 0 2 4 6 8 10 Solar Feed-in (GWh) 1 3 5 7 9 11 13 15 17 19 21 23 Hours 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5 Annual Average of Solar(GWh) 2010 2011 2012 2013 2014 2015 2016 Figure B.2: Left: Smooth growth in annual solar energy feed-in (only non-zero day-time values have been considered). Right: Annual daily average of the solar feed-in. 150 APPENDIX 1 3 5 7 9 11 13 15 17 19 21 23 Hours 0 2 4 6 8 10 Winters: Annual Average Solar(GWh) 01-Dec-2010:01-Mar-2011 01-Dec-2011:01-Mar-2012 01-Dec-2012:01-Mar-2013 01-Dec-2013:01-Mar-2014 01-Dec-2014:01-Mar-2015 01-Dec-2015:01-Mar-2016 1 3 5 7 9 11 13 15 17 19 21 23 Hours 0 2 4 6 8 10 Summers: Annual Average Solar(GWh) 01-Jun-2010:01-Sep-2010 01-Jun-2011:01-Sep-2011 01-Jun-2012:01-Sep-2012 01-Jun-2013:01-Sep-2013 01-Jun-2014:01-Sep-2014 01-Jun-2015:01-Sep-2015 01-Jun-2016:01-Sep-2016 Figure B.3: Low production of solar and also shorter occurring hours in winters (left), vs. high amount and longer period of solar production during summer (right). energy, on the other hand, is fairly constant throughout the day, but there are marked difference between the seasons (Fig. B.4). Fig. B.5 contrasts the evolution of the daily average of the price proÔ¨Åle during winter (December through February) and summer (June through August) season. During the observed period we see that for",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_176"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " (Fig. B.4). Fig. B.5 contrasts the evolution of the daily average of the price proÔ¨Åle during winter (December through February) and summer (June through August) season. During the observed period we see that for winter time the peak at 19h00 is reduced both in size and sharpness, most likely due to the increase in the wind energy. During the summer period, the morning peak at 12h00 disappears completely over the years, in all likelihood again due to the increasing supply of wind and especially solar energy. In other words, the increasing supply of wind and solar en- ergy is not only reducing the electricity price, but it is also changing the daily proÔ¨Åle substantially. Comparing the solar energy feed-in in winters and summers in Fig. B.3 and also considering the evolution of the price proÔ¨Åles in Fig. B.5 allow us to conclude that so- lar energy, especially in summer, effectively Ô¨Çattens the daytime price proÔ¨Åle. Fig. B.5 highlights the evolution of the daily average of the price proÔ¨Åles during winter (Decem- ber through February) and summer (June through August) season. Every value is the average of the prices for that speciÔ¨Åc hour, with the average ranging over the speci- Ô¨Åed period. The left panel shows that during winter period the maximum values occur from 18h00 to 20h00, with peak at 19h00. Also, there is a steep increase in the morning (around 7h00). On the other hand, during summer (right panel), the price increase in the morning (5h00-9h00) is considerably Ô¨Çatter. Also the price-spike observed during B.1. EPEX MARKET AND RES FEED-IN 151 1 3 5 7 9 11 13 15 17 19 21 23 Hours -2 0 2 4 6 8 Winters: Annual Average Wind(GWh) 01-Dec-2006---01-Mar-2007 01-Dec-2007---01-Mar-2008 01-Dec-2008---01-Mar-2009 01-Dec-2009---01-Mar-2010 01-Dec-2010---01-Mar-2011 01-Dec-2011---01",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_177"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "---01-Mar-2008 01-Dec-2008---01-Mar-2009 01-Dec-2009---01-Mar-2010 01-Dec-2010---01-Mar-2011 01-Dec-2011---01-Mar-2012 01-Dec-2012---01-Mar-2013 01-Dec-2013---01-Mar-2014 01-Dec-2014---01-Mar-2015 01-Dec-2015---01-Mar-2016 1 3 5 7 9 11 13 15 17 19 21 23 Hours -2 0 2 4 6 8 Summers: Annual Average Wind(GWh) 01-Jun-2006---01-Sep-2006 01-Jun-2007---01-Sep-2007 01-Jun-2008---01-Sep-2008 01-Jun-2009---01-Sep-2009 01-Jun-2010---01-Sep-2010 01-Jun-2011---01-Sep-2011 01-Jun-2012---01-Sep-2012 01-Jun-2013---01-Sep-2013 01-Jun-2014---01-Sep-2014 01-Jun-2015---01-Sep-2015 01-Jun-2016---01-Sep-2016 Figure B.4: Almost smooth and steady harvest of constant wind breathe in winters (left), vs. low production of wind in summer (right). 152 APPENDIX 1 3 5 7 9 11 13 15 17 19 21 23 Hours -20 -10 0 10 20 30 40 50 60 70 80 Euro/MWh Average Daily Profile of Price (Winter Time) 01-Dec-2006---01-Mar-2007 01-Dec-2007---01-Mar-2008 01-Dec-2008---01-Mar-2009 01-Dec-2009---01-Mar-2010 01-Dec-2010---01-Mar-2011 01-Dec-2011---01-Mar-2012 01-Dec-2012---01-Mar-2013 01-Dec-2013---01-Mar-2014 01-Dec-2014---01-Mar-2015 01-Dec-2015---01-Mar-2016 1 3 5 ",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_178"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "2---01-Mar-2013 01-Dec-2013---01-Mar-2014 01-Dec-2014---01-Mar-2015 01-Dec-2015---01-Mar-2016 1 3 5 7 9 11 13 15 17 19 21 23 Hours -40 -20 0 20 40 60 80 100 Euro/MWh Average Daily Profile of Price (Summer Time) 01-Jun-2006---01-Sep-2006 01-Jun-2007---01-Sep-2007 01-Jun-2008---01-Sep-2008 01-Jun-2009---01-Sep-2009 01-Jun-2010---01-Sep-2010 01-Jun-2011---01-Sep-2011 01-Jun-2012---01-Sep-2012 01-Jun-2013---01-Sep-2013 01-Jun-2014---01-Sep-2014 01-Jun-2015---01-Sep-2015 01-Jun-2016---01-Sep-2016 Figure B.5: The evolution of the seasonal daily average of the price proÔ¨Åle during winter time (left) and summer time (right). B.1. EPEX MARKET AND RES FEED-IN 153 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 0 5 10 15 20 25 30 35 40 45 50 Traded Quantity (GWh) 1 3 5 7 9 11 13 15 17 19 21 23 25 Hours 0 5 10 15 20 25 30 35 40 Annual Average of Traded Quantity(GWh) 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 Figure B.6: Left: Boxplots for the hourly values of traded volumes on the day-ahead market. Right: Daily evolution of the traded volume for each hour slot. winter evenings (around 19h00) is completely absent in summers. Both observations underscore the impact of solar on the price. B.1.4. DAY-AHEAD TRADED QUANTITY (G",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_179"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " of the traded volume for each hour slot. winter evenings (around 19h00) is completely absent in summers. Both observations underscore the impact of solar on the price. B.1.4. DAY-AHEAD TRADED QUANTITY (GWH) Fig. B.6 displays the evolution of the traded quantity values on the German day-ahead market, in the recent years. Two interesting features are readily apparent. In the left panel the occurrence of a considerable number of outliers (represented as individual points near the upper part of the boxplots) point to unusually high volumes being traded. This highly resembles the wind feed-in proÔ¨Åles in Fig. B.1.1. The panel on the right de- picts the annual averages of a typical daily proÔ¨Åle. Again, the steady increase in the traded volume is evident. However, whereas in the Ô¨Årst half of the decade, the traded volume is essentially constant over the course of the day, the latter part of the decade shows an increasingly more prominent bump that mirrors the average supply of solar energy, and could therefore be an indicator of surpluses generated by the renewable en- ergy sources (in particular solar). In 2016, however, we witness a minor reduction in the traded volume, as it may be a direct outcome of warm winter combined with less solar feed-in in that year. CURRICULUM VIT√Ü Abdolrahman Khoshrou (Majid) was born and raised in the north part of Iran. He graduated from Babol Noshirvani University of Technology, Mazandaran, Iran, with a Bach- elors‚Äôs degree in Power Engineering in 2007. He received a Master‚Äôs degree in Information Engineer- ing from the Technical University of Porto, Portugal, in 2015. During his master‚Äôs study, next to his studies, he enjoyed working at Cyber-Physical Control Systems and Robotics lab as a Machine Learning Research Assistant. During that time, he developed a novel online unsuper- vised learning of Gaussian Mixture Models used for path planning of underwater vehicles. In November 2015, he started his PhD research at the Centrum Wiskunde & Infor- matica (The National Dutch Mathematics and Informatics Center) in Amsterdam. This time has fostered in him a desire and passion for life-long learning and growth. Later on during his work at fast-paced start-ups such as Maistering and",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_180"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": "- matica (The National Dutch Mathematics and Informatics Center) in Amsterdam. This time has fostered in him a desire and passion for life-long learning and growth. Later on during his work at fast-paced start-ups such as Maistering and Sympower, he honed hands-on mentality and drive to get things done. The results of his PhD are presented in this dissertation. 155 LIST OF PUBLICATIONS Journals 1. Abdolrahman Khoshrou, Eric J Pauwels. Regularisation for PCA-and SVD-type matrix factorisations. preprint 2021. Springer - Advances in Computational In- telligence1. 2. Abdolrahman Khoshrou, and E.J. Pauwels. Short-term scenario-based proba- bilistic load forecasting: A data-driven approach. 2019. Elsevier - Applied Energy. 3. Abdolrahman Khoshrou, Andr√© Dorsman, Eric J. Pauwels. The evolution of elec- tricity price on the German day-ahead market before and after the energy switch. 2019. Elsevier - Renewable Energy. Conferences 1. Abdolrahman Khoshrou, Eric J. Pauwels. Data-driven pattern identiÔ¨Åcation and outlier detection in time series. 2018. Springer, Cham - Science and Information Conference. 2. Abdolrahman Khoshrou, Eric J Pauwels. Quantifying volatility reduction in Ger- man day-ahead spot market in the period 2006 through 2016. 2018. IEEE - Power & Energy Society General Meeting (PESGM). 3. Abdolrahman Khoshrou, Andr√© Dorsman, Eric J. Pauwels. SVD-based Visualisa- tion and Approximation for Time Series Data in Smart Energy Systems. 2017. IEEE - Innovative Smart Grid Technologies Conference Europe (ISGT-Europe). 4. Abdolrahman Khoshrou, Eric J Pauwels. Propagating uncertainty in tree-based load forecasts. 2017. IEEE - Electrical and Electronics Engineering (ELECO), 2017 10th International Conference. 5. Andr√© Dorsman, Abdolrahman Khoshrou, Eric J. Pauwels. The inÔ¨Çuence of the switch from fossil fuels to solar and wind",
    "token_count": 500,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_181"
  },
  {
    "id": "a46e43a0-7bd3-434a-be76-5cd60d145a04",
    "created_at": "2025-07-26T15:28:58.207516+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Thesis_Majid.pdf",
    "title": "Thesis_Majid",
    "text": " 2017 10th International Conference. 5. Andr√© Dorsman, Abdolrahman Khoshrou, Eric J. Pauwels. The inÔ¨Çuence of the switch from fossil fuels to solar and wind energy on the electricity prices in Ger- many. 2016. ISINI conference in Groningen. 1Part of this work was published at Belgian-Netherlands ArtiÔ¨Åcial Intelligence Conference (BNAIC) 2021. 157 158 LIST OF PUBLICATIONS",
    "token_count": 109,
    "chunk_id": "a46e43a0-7bd3-434a-be76-5cd60d145a04_182"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "Delft University of Technology Short-term scenario-based probabilistic load forecasting A data-driven approach Khoshrou, Abdolrahman; Pauwels, Eric J. DOI 10.1016/j.apenergy.2019.01.155 Publication date 2019 Document Version Accepted author manuscript Citation (APA) Khoshrou, A., & Pauwels, E. J. (2019). Short-term scenario-based probabilistic load forecasting: A data- driven approach. Applied Energy, 238, 1258-1268. https://doi.org/10.1016/j.apenergy.2019.01.155 Important note To cite this publication, please use the final published version (if applicable). Please check the document version above. Copyright Other than for strictly personal use, it is not permitted to download, forward or distribute the text or part of it, without the consent of the author(s) and/or copyright holder(s), unless the work is under an open content license such as Creative Commons. Takedown policy Please contact us and provide details if you believe this document breaches copyrights. We will remove access to the work immediately and investigate your claim. This work is downloaded from Delft University of Technology. For technical reasons the number of authors shown on this cover page is limited to a maximum of 10. Short-Term Scenario-Based Probabilistic Load Forecasting: A Data-Driven Approach Abdolrahman Khoshroua,b,1,‚àó, Eric J. Pauwelsa,2 aCentrum Wiskunde & Informatica, Science Park 123, 1098 XG, Amsterdam, The Netherlands bDepartment of Mathematics and Computer Science, Delft University of Technology, The Netherlands Abstract Scenario-based probabilistic forecasting models have been explored extensively in the literature in recent years. The performance of such models evidently depends to a large extent on how diÔ¨Äerent input (temperature) scenarios are being generated. This paper proposes a generic framework for probabilistic load forecasting using an ensemble of regression trees. A major distinction of the current work is in using matrices as an alternative representation for quasi-periodic time series data. The singular value decomposition (SVD) technique is then used herein to generate temperature scenarios in a robust and timely manner. The strength of our proposed method lies in its simplicity and robustness, in terms of the training window size, with no need for subsetting or thresholding to generate",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_1"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": ") technique is then used herein to generate temperature scenarios in a robust and timely manner. The strength of our proposed method lies in its simplicity and robustness, in terms of the training window size, with no need for subsetting or thresholding to generate temperature scenarios. Furthermore, to systematically account for the non-linear interactions between diÔ¨Äerent variables, a new set of features is deÔ¨Åned: the Ô¨Årst and second derivatives of the predictors. The empirical case studies performed on the data from the load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014-L) show that the proposed method outperforms the top two scenario-based models with a similar set-up. Keywords: Time-series analysis, Energy forecasting, Probabilistic forecasting, Time-varying eÔ¨Äects, Singular value decomposition 1. Introduction In the energy transition era (transition from conventional to non-conventional energy sources), the balancing of the power grid has become more challenging. It is mostly due to the inherently intermittent nature of renewable energy sources (RES), on the one hand, and shortcomings in bulk energy storage systems, on the other. The studies on probabilistic energy production and demand forecast have hence gained momentum, as they are highly valuable from both a technical and an economic point of view [18]. Generally speaking, load forecasting problems can be contemplated from two main perspectives: 1) time hori- zon; and 2) type of forecasting (point vs. probabilistic forecasting). The time-interval of interest, which can vary from the next few seconds or minutes to a couple of months or even years, categorizes the load forecasting problems into four groups [18]. The future of a grid and its expansion in long run is studied in the context of long term load forecasting (LTLF). Moreover, balance sheet calculations, risk management, purchasing energy and price planning purposes are most relevant from a few weeks up to a few months in advance; that is where medium term load fore- casting (MTLF) techniques come into play. Short term load forecasting (STLF), as a dominant factor in electricity dispatching, scheduling and unit commitment, is mostly concerned with the load estimations for a few hours up to a few days ahead. Finally, very short term load forecasting (VSTLF) approaches are aimed to mitigate the possible mismatches between supply and demand, by generating highly accurate load prognoses for the coming half an",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_2"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "ations for a few hours up to a few days ahead. Finally, very short term load forecasting (VSTLF) approaches are aimed to mitigate the possible mismatches between supply and demand, by generating highly accurate load prognoses for the coming half an hour or less. Although point (single-value) load forecasting methodologies have been implemented since the early days of ‚àóCorresponding author: a.khoshrou@cwi.nl 1Abdolrahman Khoshrou is with the Intelligent and Autonomous Systems Group at CWI; he is also a guest PhD student at TU Delft. 2Eric Pauwels is a senior researcher and the leader of the Intelligent and Autonomous Systems Group at CWI. Postprint: Applied Energy Journal November 2018 ¬© 2019 Manuscript version made available under CC-BY-NC-ND 4.0 license https:// creativecommons.org/licenses/by-nc-nd/4.0/ modern grids, probabilistic load forecasting (PLF) studies have gained prominence in recent years [18]. Moreover, with the growing integration of weather-dependent and intermittent RES, diÔ¨Äerent lines of research on the energy systems data have emerged. These include issues such as data-driven outlier detection, pre-processing, incorporating the dependency between diÔ¨Äerent attributes, and so on demand further exploration. Load forecasting methodologies can typically be classiÔ¨Åed into two groups: statistical and machine learning (ML) based techniques. The major argument in favor of the statistical approaches is the interpretability of their results; noteworthy is that some expert knowledge is usually needed to (partially) guide the learning process. On the other hand, ML based approaches are more independent in the sense that the user interventions are mostly limited to hyper- parameter tuning. Such models are generally more robust, easy to reconÔ¨Ågure, user-friendly and successful in ad- dressing the non-linearity in the data. The major drawback of ML based methods, however, is that being a black box, it is often not clear how diÔ¨Äerent attributes have contributed to the Ô¨Ånal results. A number of single-value and probabilistic load forecasting models using two diÔ¨Äerent statistical and ML based approaches are summarized below. Statistical approaches: Multiple linear regression (MLR) models are among the most fundamental and widely used models for both STLF and LTLF problems. Broadly speaking, such models are",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_3"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "ÔøΩÔøΩerent statistical and ML based approaches are summarized below. Statistical approaches: Multiple linear regression (MLR) models are among the most fundamental and widely used models for both STLF and LTLF problems. Broadly speaking, such models are mostly aimed to learn a relationship between several explanatory variables and a dependent (target) variable. Typically, a goodness-of-Ô¨Åt function is used to estimate the target variable (load) based on other explanatory attributes (such as historical load and temperature data, calendar information or some interaction of them). The performance of such models, consequently, are only satisfactory if the dependent variables are well formulated based on explanatory variables. However, the most striking feature of such models is their need for some expert-knowledge to formulate the interaction between diÔ¨Äerent variables - namely the recency eÔ¨Äect, as it seems unworkable to incorporate the eÔ¨Äects between diÔ¨Äerent variables without some domain expertise. Usually, a large number of lagged temperature data are being used to account for the recency eÔ¨Äect (which leads to an increase of the parameter-space). A solid ground for applying MLR analysis to STLF is provided in [34]. To include in part the interactions between the variables, 24 separate family regression models (one model for every hour of the day) have repeatedly been deployed in the literature to generate the day-ahead load prognoses (see e.g., [35]). Nonetheless, an interesting Ô¨Ånding in [39] is that using 24 separate models (one for every hour of the day) might not necessarily ensure outperformance of such models over one interaction model for all 24 hours. Another category of regression based models are semi-parametric additive models, which generally are designed to address the nonlinear relationships and serially correlated errors. Auto regressive integrated moving average (ARIMA) models, as a class of ARMA models, are well-suited to capture diÔ¨Äerent standard temporal structures in time series data. A family of such statistical models have been used numerously in the literature for time series forecasting problems, as they oÔ¨Äer a baseline regression-based approach to account for the recency eÔ¨Äect in the data. A comprehensive discussion on diÔ¨Äerent types of autoregressive models, such as ARMA, ARIMA and ARMAX models is presented in [32]. Exponential",
    "token_count": 499,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_4"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " account for the recency eÔ¨Äect in the data. A comprehensive discussion on diÔ¨Äerent types of autoregressive models, such as ARMA, ARIMA and ARMAX models is presented in [32]. Exponential smoothing is another capable and eÔ¨Äective approach to systematically assimilate the recency eÔ¨Äect in the data, by assigning weights to the previous data points inside a certain window [22]. However, the major drawback of most statistical models lies in their need for a lot of hyper-parameter tuning; speciÔ¨Åc factors such as threshold sets, the choice of lag sets, and also capturing the time-varying structures of the coeÔ¨Écients are crucial in the overall performance of the model. Furthermore, setting up a good Ô¨Åt enlarges the parameter space, which brings about longer computation time and raises the concern of over-Ô¨Åtting. To better accommodate the various non-linearity in the data, a least absolute shrinkage and selection operator (LASSO) estimation algorithm is introduced in [44]. Machine learning approaches : Machine learning (ML) based approaches are in fact a number of more advanced sta- tistical methods for handling more complex regression and classiÔ¨Åcation problems. Support vector machines (SVM), artiÔ¨Åcial neural networks (ANN), fuzzy regression models, classiÔ¨Åcation and regression trees (CART), and k‚àínearest neighbours are among the most well-recognized ML based techniques. SVM is a powerful method for handling vari- ous regression and classiÔ¨Åcation problems by recognizing patterns and constructing nonlinear decision boundaries. A generic model for STLF problem using SVM is developed in [8]; the strength of this work lies in its novel automatic feature selection algorithms and also the use of a particle swarm global optimization based technique to tweak the hyper-parameters. To enhance the performance of such models, diÔ¨Äerent clustering approaches (e.g., based on hour of the day) have been proposed in the literature to group the data Ô¨Årst, and apply an SVM model on each subset of data. In [14], an unsupervised self organizing map (SOM) is used for clustering the load proÔ¨Åles, Ô¨Årst; an SVM regression model, for each group, is then applied to estimate the daily load proÔ¨Åles. As mentioned before, failing to 2 incorporate the rec",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_5"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "OM) is used for clustering the load proÔ¨Åles, Ô¨Årst; an SVM regression model, for each group, is then applied to estimate the daily load proÔ¨Åles. As mentioned before, failing to 2 incorporate the recency eÔ¨Äects in forecasting methodologies can lead to under performance. An SVM type hourly load forecasting model in [10] accounts for the recency eÔ¨Äects by including a couple of previous ambient temperature values (several hours) as input variables. Nevertheless, the performance of such models relies on a suitable kernel function and hyper-parameter settings. A new approach for choosing an optimal kernel function for an SVM based model is proposed in [9]. Furthermore, fuzzy logic models have been developed to address some limitations of the linear models such as vague relation between diÔ¨Äerent independent and dependent attributes, shortage in the number of observations, and error distribution veriÔ¨Åcation [11], [23]. Such models provides a means to better incorporate the recency and cross eÔ¨Äects in the data, and hence can outperform their corresponding MLR based counterpart mod- els [20]. Over the last few years, artiÔ¨Åcial neural networks (ANN) have seen an explosion of interest in various types of prediction, classiÔ¨Åcation and control applications across diÔ¨Äerent Ô¨Åelds. Typically, ANN do not perform based on modelling the underlying relation between predictors and the target variable; a mapping mechanism is instead in place to assign inputs to a target variable. DiÔ¨Äerent variations of (hybrid) NN-based models for the STLF problems have been proposed [36], [41]. It is a common sense that no individual forecasting model is the best for all data sets. Therefore, it is highly appreciated to combine diÔ¨Äerent forecasts to reduce the overall risk of making poor decisions. In [31], forecast combinations or ensemble models are classiÔ¨Åed into homogeneous and heterogeneous ensemble methods. In the former method, diÔ¨Äerent forecast series are obtained by varying the hyper-parameters, input data, input features, or output targets for the same algorithm. The latter method, however, combines a number of forecasts with the hope that diversity help improving the results. Some examples of the application of diÔ¨Äerent types of ensemble learning methods in energy forecasting tasks are presented in [4], [12],",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_6"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " latter method, however, combines a number of forecasts with the hope that diversity help improving the results. Some examples of the application of diÔ¨Äerent types of ensemble learning methods in energy forecasting tasks are presented in [4], [12], [27]. S. B. Taieb and R. J. Hyndman propose a robust component-wise gradient boosting model for STLF in [38]. The reported work incorporates diÔ¨Äerent non-parametric eÔ¨Äects such as calendar, temperature, lagged demand using an additive framework; it is done by considering a separate model for each hour of the day (24 diÔ¨Äerent models for a day). Furthermore, univariate penalized regression spline functions is used to account for the recency eÔ¨Äect in the data. However, caution should be exercised in the application of most exponential smoothing models, as the performance heavily relies on the window-size and hyper-parameter tuning [38]. Scenario-based probabilistic load forecasting models, as a subcategory of homogeneous models, have been exercised extensively, in recent years. Among the various methods, feeding simulated temperature scenarios to a single-value load forecasting model is being commonly accepted by the industry for its simplicity and interpretability. There are mainly three practical and popular methods for generating temperature scenarios, namely Ô¨Åxed-date, shifted- date, and bootstrap approaches. Nevertheless, these methods have mostly been used on an ad-hoc basis without being formally compared or quantitatively evaluated [43]. The performance of such models evidently depends to a great deal on how diÔ¨Äerent temperature scenarios are being generated. Addressing the issues such as outliers, or gradual drifts in the data is essential in developing an accurate model. Another challenge in load forecasting problems (especially, short term) is the incorporation of recency eÔ¨Äects of the data using time-varying models. The recency eÔ¨Äect refers to the continuous nature of electricity consumption - at any moment it depends on the weather conditions and accordingly load, prior to that [28]. In other words, it mostly reÔ¨Çects the lagging eÔ¨Äect associated with the thermal inertia of the buildings and facilities. In the literature, some heuristic, data-oriented lagging window of a couple hours, or subsetting of the data are typical approaches to incorporate the recency eÔ¨Äect [28], [39]. The",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_7"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " inertia of the buildings and facilities. In the literature, some heuristic, data-oriented lagging window of a couple hours, or subsetting of the data are typical approaches to incorporate the recency eÔ¨Äect [28], [39]. The major concern regarding such methods is the generalizability of the results, as, e.g., the window size or the threshold in the subsetting step can aÔ¨Äect the performance of the models drastically [44]. We herein propose two scenario-based probabilistic load forecasting models using an ensemble of regression trees. The contribution of this paper is as follow. ‚Ä¢ An important distinction of the current work is the use of matrices as an alternative representation of the data. The singular value decomposition (SVD) technique is then used to generate temperature scenarios, in a robust and data-driven manner. ‚Ä¢ In the second model, we extend the Ô¨Årst one by adding the Ô¨Årst and the second derivatives of the non-deterministic attributes (temperature and historical load data). This was done to partially account for the recency eÔ¨Äects and interactions among the data. Unlike some family of time-varying models, our proposed approach is systematic, with no need for subsetting or thresholding the data. ‚Ä¢ The experiment results show that special enhancements can consequently be obtained using this new set of 3 features (Section 4). The rest of this paper is organized as follow. Section 2 provides a brief introduction to the data from the load fore- casting track of the Global Energy Forecasting Competition (GEFCom2014-L). Section 3 is devoted to our methodol- ogy in this paper. A brief recapitulation of the Gradient Boosting method is presented, Ô¨Årst, followed by out proposed models for point forecasting. After an introduction to the singular value decomposition (SVD), we explain how our proposed scenario based load forecasting models works. The proposed method in this paper is, in fact, a marriage between an SVD-based temperature scenario generator and an ensemble of trees (gradient boosting algorithm). The experimental results along with a comparison with the results of a number of benchmark models are presented in Section 4. We conclude this work in Section 5. 2. Data To make the results of the proposed models replicable and accordingly comparable with the benchmark models, a case study was constructed based on the data from the load forecasting track of the Global Energy Forecasting Compe- tition ",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_8"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "5. 2. Data To make the results of the proposed models replicable and accordingly comparable with the benchmark models, a case study was constructed based on the data from the load forecasting track of the Global Energy Forecasting Compe- tition 2014 (GEFCom2014-L). The participants had been asked to develop a short term probabilistic load forecasting model, with the forecasting horizon of one month. The publicly available data set consists of the hourly temperature values from 25 anonymous weather stations and the aggregated hourly load proÔ¨Åles; for detailed description of data and the competition instructions see [19]. The electricity consumption patterns are subject to a variety of factors, such as meteorological conditions, calendar information, season, working schedules, energy cost and economic activ- ities [30]. In the current work, however, consistent with the requirements in the GEFCom2014-L, only the temperature and the calendar information are considered as the available predictors (besides historic load proÔ¨Åles). Temperature is believed to be a major driving force behind the electricity demand; the non-linear eÔ¨Äect of the temperature to the electricity demand is hence at the center of our attention. The left panel of Figure 1 provides an overview of the typical electricity consumption proÔ¨Åles on daily basis. This Ô¨Ågure aÔ¨Érms that the consumption patterns diÔ¨Äer notably during the weekends from the weekdays. Interestingly enough, on Friday afternoons, the demand proÔ¨Åle gets close to the weekends, whereas, during the working hours, it is akin to other working days. Furthermore, the right panel in Figure 1, illustrates the evolution of daily load proÔ¨Åles in the year 2010; this Ô¨Ågure was obtained by recasting the time series into a 24 √ó 365 matrix, where every column contains 24 hourly values for each daily proÔ¨Åle [24]. As expected, in spring and fall, where the temperature is moderate, electricity demand tends to be lower than any other time of the year (winter and summer times). It underscores the fact that electricity demand is driven by climate conditions (e.g., air conditioning usage), and also the lifestyle changes followed by that. This Ô¨Ågure also highlights the non-linear relation between load and temperature throughout the year. In the literature, temperature is arguably the most dominant predictor of the load; however, in and of itself, it is",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_9"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " the lifestyle changes followed by that. This Ô¨Ågure also highlights the non-linear relation between load and temperature throughout the year. In the literature, temperature is arguably the most dominant predictor of the load; however, in and of itself, it is not suÔ¨Écient, for two main reasons: ‚Ä¢ Diurnal human activities: As it is seen in the left panel of Figure 1, the typical electricity demand behaviour changes throughout the week. These diurnal human activities are plainly not reÔ¨Çected in the temperature data. Figure 1: Left: Comparison of typical daily consumption patterns during the week. Right: An overall representation of the evolution of the load proÔ¨Åles throughout a year. 4 Figure 2: An overview of the evolution of the Ô¨Årst derivative of the temperature (Left) and load (Right) proÔ¨Åles. ‚Ä¢ Recency and cross eÔ¨Äects: Even for similar days (weekends or weekdays), the trend of daily load proÔ¨Åles, corresponding to similar temperature data, might not be necessarily alike; the recency and cross eÔ¨Äects can play a vital role. For instance, the rise of temperature in early spring might not necessarily lead to high electricity consumption, in comparison with summer times, as people might appreciate the rise in outside temperature after a cold winter. This, of course, can deviate across diÔ¨Äerent seasons. Figure 2 illustrates an overview of the trend (Ô¨Årst derivative) changes of daily temperature and load proÔ¨Åles in 2010. These Ô¨Ågures were obtained by taking the Ô¨Årst derivatives of daily temperature and load matrices. It is seen that, e.g., in early spring and summer time, with the rise of temperature, afternoon peak proÔ¨Åles start to disappear. Although, the overall relationship between load and temperature is clear; it is, however, non-trivial how to robustly address the non-linear eÔ¨Äect between temperature and load proÔ¨Åles. Experiment results in Section 4 aÔ¨Érm that including the 1st and 2nd derivatives of the daily proÔ¨Åles can indeed enhance the performance of the forecasting model. The following section provides a brief to the ensemble of regression trees, followed by our proposed methodology for probabilistic STLF problem. 3. Methodology In the present work, we opt to use an ensemble of regression",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_10"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " the performance of the forecasting model. The following section provides a brief to the ensemble of regression trees, followed by our proposed methodology for probabilistic STLF problem. 3. Methodology In the present work, we opt to use an ensemble of regression trees (Gradient Boosting method) to predict day-ahead load prognoses, with forecasting horizon of one month, given hourly temperature proÔ¨Åles, historical (or estimated) load proÔ¨Åles, and calendar information. A brief recapitulation of an ensemble of regression trees is Ô¨Årst provided in below. 3.1. Ensemble of regression trees The use of ‚Äúensemble learning‚Äù methods in various classiÔ¨Åcation and regression problems has taken oÔ¨Äover the last few years. Ensembles generally rely on ‚Äúresampling‚Äù techniques to obtain diÔ¨Äerent training sets for each individual regression or classiÔ¨Åcation model. Two popular methods for creating accurate ensembles are bootstrap aggregating (Bagging) and Boosting. In Bagging method, the training data for each individual model is drawn randomly, i.e., n instances with replacement- where n is the number of observations in the training set. In other words, successive members (e.g., trees or neural networks) in this method are independent of each other; since each member of the ensemble is trained individually using a bootstrap sample of the data set [5]. In other words, Bagging methods control the generalization error through perturbation and averaging of sub-models. Worth noting that in this approach, to ensure that every training sample is predicted at least a few times, the number of trees needs to be large enough. Since the trees are independent of each other, the distribution function and the quantiles of each hourly forecast can be easily computed based on the output of all the trees [40]. In Gradient Boosting method, however, the training set for each member of the ensemble depends on the per- formance of the previous model(s). More precisely, in order to alleviate the error in earlier models, extra weights are assigned to samples with higher prediction error rates; those are hence more likely to take part in the training of 5 the next model [16, 15]. A comprehensive evaluation of both these techniques on 23 data sets, using two popular classiÔ¨Åers, i.e., decision trees and neural networks is presented in [33]. The applicability of Gradient Boosting method in quantile regression load",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_11"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "]. A comprehensive evaluation of both these techniques on 23 data sets, using two popular classiÔ¨Åers, i.e., decision trees and neural networks is presented in [33]. The applicability of Gradient Boosting method in quantile regression load forecasting application have been put into practice in [38, 40]. A brief recapitulation of the Gradient Boosting method, as the main methodology used herein to predict the hourly load values, is provided in below. The goal in every typical prediction problem is to determine an estimate or approximation ÀÜF(x), of the true map- ping function F‚àó(x) which assigns a y ‚ààR to any given set of covariates x ‚ààRp. This process is optimized by minimizing the expected value of some speciÔ¨Åed loss function L(y, F(x)) over the set of the joint distribution of all {y, x} pairs. In mathematical parlance, we have: F‚àó(x) = arg min F(x) Ey,xL(y, F(x)) = arg min F(x) Ex[Ey(L(y, F(x)))|x] (1) where E(.) is the expectation operator, and L(y, F(x)) is a loss function, e.g., the popular choice of squared-error {y ‚àíF(x)}2, for regression problems. F(x) is a member of ‚Äúadditive‚Äù class of functions of the form: F(x; {Œªk, ak}K 1 ) = K X k=1 Œªkh(x; ak). (2) where K is the number of members of the ensemble model, Œªk is the coeÔ¨Écient of the additive model, the generic Algorithm 1: The Gradient Boosting Algorithm, with an squared-error loss function, in a nutshell. Initialization: F0(x) = ¬Øy for k=1 to K do Àúyi = yi ‚àíFk‚àí1(xi), i ‚àà[1 : N] (œÅk, ak) = arg min œÅ,a NP i=1 [ Àúyi ‚àíœÅ h(xi; a)]2 Fk(x) = Fk‚àí1(x) + œÅkh(x; ak) end function h(x; a) in (2) is called a weak learner or base learner-it is usually a simple parameterized function of the explanatory variables, speciÔ¨Åed by parameters a = {a1",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_12"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "ÔøΩkh(x; ak) end function h(x; a) in (2) is called a weak learner or base learner-it is usually a simple parameterized function of the explanatory variables, speciÔ¨Åed by parameters a = {a1, a2, . . .}. In the present work, each h(x; ak) is a small regression tree as introduced in [7]. For a regression tree the parameters ak are the splitting variables, split locations and means of the terminal node of the individual trees. An overview of the Gradient Boosting algorithm, with an squared-error loss function is presented in Algorithm 1, where the multiplier œÅk is given by the line search: œÅk = arg min Ey,xL(y, Fk‚àí1(x) ‚àíœÅgk(x)) œÅ , (3) and gk(x) = Ey \"‚àÇL(y, F(x)) ‚àÇF(x) # F(x)=Fk‚àí1(x) . (4) The rationale underpinning the choice of the ensemble of the trees is their ability in better handling the hetero- geneous input data‚Äìwhich comprise both continuous and discrete variables. Additionally, tree models are eÔ¨Äective, adaptive and modular, in that new predictors can be easily added. It is perceived that ensemble models, unlike their other ML based counterparts, are less prone to overÔ¨Åtting; they promise to strike a good trade-oÔ¨Äbetween bias and variance [6]. 3.2. Our proposed forecasting models Generally speaking, a regression tree is an adaptive nearest neighbours like algorithm. However, it usually shows a better performance in comparison with other counterpart nearest neighbour-based methods; it tends to Ô¨Ånd the homogeneous portions of the sampling space locally, on the contrary to the other conventional methods which incline to treat all distances equally [29]. In the present work, we follow a homogeneous forecast combination framework, 6 Attribute Description Model no. mn month of year: 1,2,...,12 I,II wk day of week: 1,2,...,7 I,II hr hour of day: 1,2,...,24 I,II L(d ‚àí1) previous day (estimated) hourly load I,II L(d ‚àí7) previous week (estimated) hourly load I,II T(d) hourly temperature (generated proÔ¨Åles) I,II L‚Ä≤(d ‚àí1) 1",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_13"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": ") previous day (estimated) hourly load I,II L(d ‚àí7) previous week (estimated) hourly load I,II T(d) hourly temperature (generated proÔ¨Åles) I,II L‚Ä≤(d ‚àí1) 1st derivative of L(d ‚àí1) II L‚Ä≤‚Ä≤(d ‚àí1) 2nd derivative of L(d ‚àí1) II L‚Ä≤(d ‚àí7) 1st derivative of L(d ‚àí7) II L‚Ä≤‚Ä≤(d ‚àí7) 2nd derivative of L(d ‚àí7) II T‚Ä≤(d) 1st derivative of T(d) II T‚Ä≤‚Ä≤(d) 2nd derivative of T(d) II L(d) hourly load (forecast target) I,II Table 1: An overview of the attributes used in our proposed models. i.e., we, Ô¨Årst, train a single-value load forecasting model, then, vary the input data (diÔ¨Äerent temperature scenarios) to obtain a series of forecasts, and accordingly, the quantiles. Time series data in smart energy systems often comprise more than one distinct time scales. There are some conspicuous diurnal patterns in the data, reÔ¨Çecting typical patterns for daily or weekly human activities. Furthermore, the overall structure of the data is aÔ¨Äected by a combination of those fast diurnal patterns superimposed on slower seasonal variations [24]. We herein consider two Gradient Boosting based methods to predict the day-ahead load prognoses. In the Ô¨Årst model, only calendar information, temperature data along with the historical load data are the input variables. We proceed further in the second model to incorporate the daily dynamics of the temperature and load proÔ¨Åles. It is done using the Ô¨Årst and second derivatives of the daily proÔ¨Åles. As it was principled in [19] the forecasting horizon is one month, therefore, the estimated values for the Ô¨Årst week of the month are being used to estimate the load proÔ¨Åles in the second week of the month and so on. In all cases, the aim is to predict L(d), 24 hourly load values for the target day d. Power consumption is subject to a wide range of exogenous variables, including calendar eÔ¨Äects, electricity price and so on. In the literature, the previous consumption patterns and calendar information have been extensively used in developing various load forecasting models",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_14"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": ". Power consumption is subject to a wide range of exogenous variables, including calendar eÔ¨Äects, electricity price and so on. In the literature, the previous consumption patterns and calendar information have been extensively used in developing various load forecasting models. However, accounting for the interaction between diÔ¨Äerent variables, namely the recency and cross eÔ¨Äects can be an onerous task; it demands some domain expertise to be done sensibly [28, 39]. A number of common deterministic (categorical) explanatory variables used in our methodologies are as follows: month of the year mn ‚àà{1, 2, . . . , 12}, day of the week wk ‚àà{1, 2, . . . , 7} (starting from Sunday=1), and hour of the day hr ‚àà{1, 2, . . . , 24}. Below we discuss the models in more details, but for ease of reference, Table 1 summarizes all the common and distinctive attributes used in two proposed models. Model I: The Ô¨Årst model provides us with a benchmark to measure the credibility of our proposed method in incor- porating the recency and cross eÔ¨Äects in the data in Model II. Here, we introduce six diÔ¨Äerent attributes to predict the hourly load values on the target day d. The three above mentioned common discrete (categorical) values, namely, mn, wk, hr, along with the (estimated) load value for a given hour on a day or a week before (L(d ‚àí1) and L(d ‚àí7), respectively). The intuition for this choice is the reÔ¨Çection of diurnal and weekly human activities on electricity con- sumption (Figure 1). The last covariate T(d) is the hourly temperature forecast for the target day d. As it it explained in Section 3.3, we generate one hundred independent temperature proÔ¨Åles, using the singular value decomposition, to correspondingly obtain 100 independent load forecasts for each target day; the combination of these forecasts are then used to obtain the load quantiles for each hour. Model II: To reÔ¨Çect the lagging eÔ¨Äect of temperature on load changes, in the second model, we add the daily dynam- ics of the temperature and load proÔ¨Åles (1st and 2nd derivatives)",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_15"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " reÔ¨Çect the lagging eÔ¨Äect of temperature on load changes, in the second model, we add the daily dynam- ics of the temperature and load proÔ¨Åles (1st and 2nd derivatives) [24], [25]. For a given hour slot h the corresponding Ô¨Årst derivative of the variable z ‚àà{L, T} can be obtained by z‚Ä≤(h) = 0.5[z(h + 1) ‚àíz(h ‚àí1)]; with obvious analogues for the 2nd derivative. As previously mentioned (see Figure 2), the thinking here is to include the daily dynamics and 7 An overview of the predictors importance mn wk hr L(d-7) L(d-1) T(d) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 An overview of the predictors importance mn wk hr L(d-7) L(d-1) L‚Äò(d-1) L‚Äò‚Äò(d-1) L‚Äò(d-7) L‚Äò‚Äò(d-7) T(d) T‚Äò(d) T‚Äò‚Äò(d) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Figure 3: An overview of the importance of the predictors used in Model I (top), and Model II (bottom). The horizontal axis represents the predictors used in each model. The vertical axis illustrates their relative importance. 12 diÔ¨Äerent colors represent 12 diÔ¨Äerent models (one for each month, stating from the dark blue on the left for January 2011). Full description is followed in the text. trends of load and temperature proÔ¨Åles as a new predictor. The reasoning for doing so is that oftentimes the actual val- ues are not as important as the general underlying trends captured by the Ô¨Årst or second derivatives of the covariates. In other words, load value at any moment is inÔ¨Çuenced by the variations of the other attributes (namely, temperature proÔ¨Åles) prior to that moment. Including the derivatives is, in fact, a relatively simple and generic means to account for the recency eÔ¨Äect in the data.",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_16"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " the variations of the other attributes (namely, temperature proÔ¨Åles) prior to that moment. Including the derivatives is, in fact, a relatively simple and generic means to account for the recency eÔ¨Äect in the data. In comparison with most time-varying models, where the data is typically divided into subsets (based on thresholds), or a lagging window is optimized, our proposed approach is more straightforward and user-friendly. Figure 3 provides a comparison of the importance of the predictors used to train Model I and II. The importance was determined by summing up all the estimates over all weak learners in the ensemble [3]. Predictor with the highest value is the most important one. The bottom panel of Figure 3 highlights the fact that including the derivatives (especially the second derivatives) can indeed be helpful. As it become clear in Section 4, to predict the load values for every month of the year 2011, we train a new model using all the available data up to the beginning of that month (rolling window mechanism). Each shade of color in Figure 3, hence, corresponds to one experiment (dark blue on the left is for January 2011, and yellow, on the right for December 2011). A major contribution herein is the use of the singular value decomposition (SVD) to generate temperature scenarios T(d) for the target day d; it is done to determine the distribution (99 percentiles) of the load proÔ¨Åle in our proposed probabilistic forecasting models. A brief recapitulation to the singular value decomposition (SVD) technique is provided in below. 8 3.3. Singular value decomposition As mentioned before, time series data in energy systems usually comprises at least two distinct time scales. Recasting such quasi-periodic time series as a matrix such that each column represents the values for a single day, could be helpful in gaining a better understanding of the data. The advantage of this approach is twofold. Primarily, representing a matrix as an image provides a thorough overview of the evolution of data in a certain time span; it hence can lead to better appreciation of indistinct or subtle features. Second, it makes it possible to draw on numerically stable matrix decomposition methods, such as SVD to elucidate the underlying data structure [24]. The SVD technique is used herein to generate new temperature proÔ¨Åles (matrices). To be more precise, we recast",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_17"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " draw on numerically stable matrix decomposition methods, such as SVD to elucidate the underlying data structure [24]. The SVD technique is used herein to generate new temperature proÔ¨Åles (matrices). To be more precise, we recast one year‚Äôs worth of hourly temperature values as a matrix T ‚ààR24√ó365 such that every column corresponds to 24 hourly values of a day. Consequently, the matrix T can conveniently be represented by a low-rank approximation. More speciÔ¨Åcally, given any arbitrary matrix A ‚ààRh√ód, there exist orthogonal matrices U ‚ààRh√óh and V ‚ààRd√ód (both with orthonormal columns) such that: A = USVT = rX k=1 œÉkukvT k (5) where S is a diagonal matrix of the singular values œÉk, such that its non-zero elements œÉ1 ‚â•œÉ2 ‚â•. . . ‚â•œÉr ‚â•0 are positioned uniquely, in a descending order, on the main diagonal (S has the same size as A and r = min{h, d}). Furthermore, uk and vk, called the left and right singular vectors, denote the kth column of U and V, respectively [37]. If there are only a few dominant singular values (as it is the case for the temperature matrices, in Figure 4), the expansion of the matrix in (5) can be suÔ¨Éciently truncated after just the Ô¨Årst few K terms to yield AK, an adequate lower rank approximation of A: AK = K X k=1 œÉkukvT k where K < r. (6) To elaborate more, Figure 5 illustrates the Ô¨Årst three columns of uk (left) and vk (right) for temperature matrix for the year 2009. In geometrical terms, uk columns can be interpreted as the fundamental daily proÔ¨Åle and its successive increments; vk values represent the corresponding scaling factors for each uk proÔ¨Åles for each day. In other words, SVD decomposes the original time series into a linear combination of a number of (data-driven) orthonormal proÔ¨Åles, speciÔ¨Åed by uk columns; each proÔ¨Åle is then scaled up (or down) according to their corresponding weights in vk. For instance, u1 in the top left panel of Figure 5 strikingly resembles the averaged daily temperature proÔ¨Åle.",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_18"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " uk columns; each proÔ¨Åle is then scaled up (or down) according to their corresponding weights in vk. For instance, u1 in the top left panel of Figure 5 strikingly resembles the averaged daily temperature proÔ¨Åle. Moreover, its corresponding v1 proÔ¨Åle (top right panel) outlines the evolution of that proÔ¨Åle throughout the year; it is in agreement with the fact that temperature is higher in summer time (middle part of the graph). Recall that these proÔ¨Åles are weighted based on the magnitude of their corresponding singular values which are sorted in descending order from left to right (Figure 4). The most dominant ‚Äúcorrective‚Äù incremental proÔ¨Åle u2 and its corresponding coeÔ¨Écients v2 are displayed in the middle panel of Figure 5. This correction hence needs to be added to the Ô¨Årst proÔ¨Åle to get a better approximation, i.e., K = 2 in (6). Similar interpretations are valid for the third proÔ¨Åle (bottom panels) and so on. It is worth noting that vk proÔ¨Åles on the right-hand side of Figure 5 imply a distinct impression that temperatures are 5 10 15 20 200 400 600 800 1000 1200 1400 1600 Temperature: singular values 2005 2006 2007 2008 2009 2010 Figure 4: The evolution of the singular values of the temperature matrices over the years; it suggests that a reconstruction of rank-4 approximation would suÔ¨Éce, indicating that temperature is quite regular. 9 5 10 15 20 0.2 0.22 U1 100 200 300 0.02 0.04 0.06 V 1 5 10 15 20 -0.2 0 0.2 U2 100 200 300 -0.1 0 0.1 V 2 5 10 15 20 -0.2 0 0.2 0.4 U3 100 200 300 -0.1 0 0.1 0.2 V 3 Figure 5: SVD-based decomposition of hourly temperature data for 2009. On the left, there are the Ô¨Årst three uk columns; whereas the right",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_19"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "0.1 0 0.1 0.2 V 3 Figure 5: SVD-based decomposition of hourly temperature data for 2009. On the left, there are the Ô¨Årst three uk columns; whereas the right column displays their corresponding vk‚Äôs. less variable during the summer (middle parts of the graph). In the following Section, SVD is practiced to simulate pragmatic temperature scenarios, in a systematic and data-driven manner. The generated proÔ¨Åles are accordingly fed to Models I and II to obtain the probability distribution (99 quantiles) of the load values for every given hour. 3.4. Temperature scenario generation A common approach in probabilistic load forecasting problems is to vary the input (e.g., temperature proÔ¨Åles) to obtain a series of forecasts and combine them. One of the major challenges, however, is how to create realistic temperature proÔ¨Åles, as e.g., simply adding independent Gaussian noise to the hourly values of individual temperature curves results in some preposterously jagged proÔ¨Åles. In the literature, a number of solutions have been proposed to simulate temperature scenarios. In [42], it is proposed to combine diÔ¨Äerent weather station measurements to generate new temperature proÔ¨Åles. Nonetheless, it can be argued that normal weather scenarios cannot precisely be simulated by averaging the temperature proÔ¨Åles, as they tend to underestimate the peaks. Furthermore, such approaches are not resilient toward outliers, as even one instance can change the whole proÔ¨Åle as long as it takes part in generating new temperature scenarios; the performance of the forecasting model can consequently be diminished as a result of that. Worth noting that shifting the temperature data by one, two or even three days was initially used to generate temperature scenarios; it was later abandoned for obvious reasons. Some cumbersome approaches in terms of computational costs, such as Monte Carlo based methods are also popular, especially among utilities, to simulate thousands of temperature proÔ¨Åles - an approach which is used in scenario analysis in LTLF problems [21]. In [44], new temperature scenarios are generated, again, by averaging the temperature of stations 3 and 9 (GEFCom2014-L data was used). The reason for that is mentioned to be due to the existence of a good in-sample Ô¨Åt with a cubic relation between the temperature records of those two stations and the load data. Besides pre-processing there are not a lot of",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_20"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " data was used). The reason for that is mentioned to be due to the existence of a good in-sample Ô¨Åt with a cubic relation between the temperature records of those two stations and the load data. Besides pre-processing there are not a lot of solutions in the literature on how to generate robust and pragmatic input (temperature) scenarios. We herein propose a generic, data-driven and computationally eÔ¨Écient SVD-based approach for simulating tem- perature scenarios. SVD allows us to create hundreds of sensible and realistic temperature proÔ¨Åles for any target day d, in a fairly fast and robust manner. Figure 4 aÔ¨Érms the fact that the singular values œÉk of the temperature matrices over the years have not changed much; similar conclusions can be drawn for the left singular vectors uk. Furthermore, it is plain to see in Figure 5 that the vk coeÔ¨Écients implicate the variability of the temperature proÔ¨Åles throughout the year. Since the forecasting horizon is one month, hereafter temperature matrix is referred to a month worth of 10 -0.4 -0.2 0 0.2 0.4 0.6 0 1 2 3 4 5 6 7 8 9 10 Figure 6: Histogram of the v2 coeÔ¨Écients for June 2011 temperature data (30 values). Note that the distribution is approximately normal with zero mean and std(v2) ‚âà0.18. temperature data for the coming month (test data in Section 4). We, therefore, proceed with the following steps, to create temperature scenarios: 1. In the Ô¨Årst step, we estimate the corresponding standard deviation sk for a number of right singular vectors vk (v2, . . . , v4). Figure 6 illustrates the histogram for v2, which shows that s2 ‚âà0.18. Interestingly enough, similar experiments on all three vk columns (k ‚â•2) yield similar results; however, their contribution to the Ô¨Ånal rank K reconstructed proÔ¨Åle is scaled up or down by the magnitude of their corresponding singular values. 2. Next, for any given day d of the test month, for which a number of temperature scenarios are desired, we take the actual temperature proÔ¨Åle for that day T = T(d), Ô¨Ånd the corresponding vk coe",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_21"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " 2. Next, for any given day d of the test month, for which a number of temperature scenarios are desired, we take the actual temperature proÔ¨Åle for that day T = T(d), Ô¨Ånd the corresponding vk coeÔ¨Écients (v0 2, v0 3, v0 4); then blend them with zero-mean Gaussian noise: vn k = v0 k + N(0, œµ2). These perturbed vk coeÔ¨Écients are then used to generate a new (noisy) temperature scenario (reconstruct the matrix). 3. According to the scheme outlined above, for each actual daily proÔ¨Åle T(d), a hundred temperature scenarios are being generated. This new data set is then fed into the proposed prediction models; in the end, the forecasts are duly compared to the real load values. This enables us to determine the distribution of the hourly load values (99 quantiles) and compute the corresponding pinball error values (Section 4). Figure 7 illustrates an example of one hundred generated temperature proÔ¨Åles (Left), and their corresponding daily load proÔ¨Åles (Right). 4. For the sake of completeness, it should be noted that v1 is left unperturbed as this is a proxy of the average temperature on a particular day, for which the uncertainty is negligible. Similarly, there is not much to be gained from perturbing other right singular vectors (v5 etc), as their impact on the proÔ¨Åle is insigniÔ¨Åcant (their corresponding œÉk are small). In [25], a preliminary study was done to investigate how the eÔ¨Äect of the perturbation variance in temperature proÔ¨Åles T(d) propagates into uncertainty on the target load proÔ¨Åle L(d). 4. Experimental Results Probabilistic forecasts can provide more comprehensive information about future uncertainties that what point forecasts can do [18]. As previously mentioned, the aim of the GEFCom2014-L was to estimate the quantiles of the hourly load values for a utility in the US, on a rolling basis [19]; the forecasting horizon was one month. Furthermore, it was expected from the contestants to investigate the weather scenario generation methods for probabilistic load forecasting. The scenario-based probabilistic forecasting methodology proposed by [21] was used by two top 8 teams (Jingrui Xie, top 3",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_22"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " it was expected from the contestants to investigate the weather scenario generation methods for probabilistic load forecasting. The scenario-based probabilistic forecasting methodology proposed by [21] was used by two top 8 teams (Jingrui Xie, top 3; Bidong Liu, top 8) in GEFCom2014-L. Therefore, we opt to compare our results with similar works. A least absolute shrinkage and selection operator (LASSO) estimation based method is proposed in [44] for probabilistic load forecasting. This work is reported to outperform the methodology used by Bidong Liu to win a top 8 place in GEFCom2014-L. We hence have considered the proposed method in [44] as one of the benchmark models. 11 10-Jan 11-Jan 12-Jan 13-Jan 14-Jan 15-Jan 15 20 25 30 35 40 45 50 55 10-Jan 11-Jan 12-Jan 13-Jan 14-Jan 15-Jan 120 140 160 180 200 220 240 260 280 300 Figure 7: An illustrative example of 100 generated temperature scenarios for each day and their corresponding daily load proÔ¨Åles (obtained by Model II) for January 10-15, 2011. The spotted points are the actual values and the noise level is N(0, 0.09). These 100 diÔ¨Äerent load values for every hour are then used to calculate the 99 quantiles. The reported work uses a bivariate time-varying threshold autoregressive (AR) process for the hourly load YL,t and temperature YT ,t data (D = {L, T }). The time series of interest are accordingly modeled for i ‚ààD as follow: Yi,t = œÜi,0(t) + X j‚ààD X c‚ààCi,j X k‚ààIi,j,c œÜi, j,c,k(t) max{Yj,t‚àík, c} + œµi,t (7) where œÜi,0 are the time-varying intercepts and œÜi, j,c,k are time-varying autoregressive coeÔ¨Écients. Furthermore, Ci, j are the set of all considered thresholds for the load and temperature data (all set manually). Ii,j,c are the index sets of the",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_23"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": ",k are time-varying autoregressive coeÔ¨Écients. Furthermore, Ci, j are the set of all considered thresholds for the load and temperature data (all set manually). Ii,j,c are the index sets of the corresponding lags and œµi,t is the error term. The modelling process is done in three parts: 1) choice of thresholds Ci,j; 2) choice of lag sets Ii,j,c; and 3) time-varying structure of the coeÔ¨Écients. For further details see [44]. Another winning team (top 3) in the GEFCom2014-L was Jingrui Xie, who developed an integrated solution for probabilistic load forecasting [42]. Her proposed methodology consists of three parts: 1) pre-processing, which in- cludes data cleaning and temperature station selection; 2) forecasting (which focuses on the development of point forecasting models), forecast combination, and temperature scenario generation; and 3) post-processing, which em- bodies the residual simulation for probabilistic forecasting purposes. Inspired by the Vanilla model in [28], their core forecasting model is as follow: Lt = Œ≤0 + Œ≤1Trendt + Œ≤2Tt + Œ≤3T 2 t + Œ≤4T 3 t + Œ≤5Montht + Œ≤6Weekdayt + Œ≤7Hourst + Œ≤8HourstWeekdayt+ Œ≤9TtMontht + Œ≤10T 2 t Montht + Œ≤11T 3 t Montht + Œ≤12TtHourt + Œ≤13T 2 t Hourt + Œ≤14T 3 t Hourt (8) It is in fact a multiple linear regression (MLR) model with the following main and cross eÔ¨Äects: ‚Ä¢ Main eÔ¨Äects: a chronological Trendt variable, Ô¨Årst to third order polynomials of the temperature (Tt, T 2 t , T 3 t ), and a number of categorical variables namely, Month, weekday, and Hour. ‚Ä¢ Cross eÔ¨Äects: similar to [28], the cross eÔ¨Äects are incorporated using the multiplications of diÔ¨Äerent attributes such as HourtWeekdayt, TtMontht, T 2 t Montht, T 3 t Montht, TtHourt, T 2 t",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_24"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " are incorporated using the multiplications of diÔ¨Äerent attributes such as HourtWeekdayt, TtMontht, T 2 t Montht, T 3 t Montht, TtHourt, T 2 t Hourt, and T 3 t Hourt. In the next step, the residuals obtained from (8) is modeled using four diÔ¨Äerent techniques, namely unobserved component models (UCM), exponential smoothing models (ESM), three-layer feedforward neural network (NN), and autoregressive integrated moving average models (ARIMA). Four diÔ¨Äerent sets of point forecasts are accordingly generated by adding each set of residuals to the values obtained from the previous stage. The average of each four 12 Mar-20 Mar-21 Mar-22 Mar-23 Mar-24 Mar-25 Mar-26 Mar-27 Mar-28 Mar-29 Mar-30 60 80 100 120 140 160 180 200 220 240 1-th 25-th 50-th 75-th 99-th actual Figure 8: Probabilistic load forecast of 11 days from March 20, 2011 to March 30, 2011; the solid line in black is the actual value and the dash-dot lines are the forecast quantiles. value is the Ô¨Ånal estimation for the load forecast for every given hour. In the end, 10 diÔ¨Äerent temperature scenarios are generated according to [21], to obtain the 99 percentiles from the 10 point forecasts. The regression-based models are arguably vulnerable towards outliers, especially in the scenario based applica- tions. Due to the recency eÔ¨Äects, outliers, e.g., in temperature scenarios, can aÔ¨Äect the load forecasts for a longer time span. Our proposed SVD-based model is more robust and capable of handling this issue. As mentioned before, for every hour of the target day L(d), we obtain 100 diÔ¨Äerent load values (right panel in Figure 7). The results are then being used to determine the distribution of the hourly load values (99 diÔ¨Äerent quantiles) for any given hour by employing linear extrapolations [26]. An illustrative example of the predicted quantiles for 11 days, March 20-30, 2011, is provided",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_25"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " values (99 diÔ¨Äerent quantiles) for any given hour by employing linear extrapolations [26]. An illustrative example of the predicted quantiles for 11 days, March 20-30, 2011, is provided in Figure 8. Pinball loss is a comprehensive index to evaluate the reliability, sharpness, and calibration of the forecasts. It is an extensively used error measure for quantile forecasts in probabilistic forecasting problems. The performance of the forecasting models in GEFCom2014 was evaluated by the overall mean of the pinball loss values. Recall that the Month [44] [42] Model I Model II 1 9.88 11.87 3.43 3.23 2 9.54 10.93 3.24 2.89 3 7.79 8.44 2.69 2.56 4 4.89 4.50 2.53 2.30 5 5.96 7.27 3.33 3.50 6 5.86 6.99 4.98 4.66 7 7.66 9.05 3.63 3.42 8 10.70 11.26 8.71 8.58 9 6.28 5.49 4.46 4.05 10 5.20 3.36 2.97 2.76 11 6.38 5.90 3.50 3.59 12 8.99 9.73 3.57 3.36 Table 2: The left two columns are the reported results in [44], and [42]. The results of our proposed two diÔ¨Äerent models are presented on the right part. The results reported here are the average of 100 iterations (no. of trees is 100, and MaxNumSplits=128). 13 Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec -3 -2 -1 0 1 2 3 4 5 6 Diebold-Mariano Test Figure 9: Comparison of the two models I and II, using Diebold-Mariano test (h = 1 and k = 0). pinball loss function can be written as: Pinball(ÔøΩ",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_26"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " Diebold-Mariano Test Figure 9: Comparison of the two models I and II, using Diebold-Mariano test (h = 1 and k = 0). pinball loss function can be written as: Pinball(ÀÜyt,q, yt, q) = Ô£±Ô£¥Ô£¥Ô£≤Ô£¥Ô£¥Ô£≥ (1 ‚àíq)(ÀÜyt,q ‚àíyt) if ÀÜyt,q > yt q(yt ‚àíÀÜyt,q) if ÀÜyt,q ‚â§yt (9) where yt is the target hourly value of the load proÔ¨Åle from [19], and ÀÜyt,q is the corresponding forecast value at the q‚àíth quantile (q ‚àà{0.01, 0.02, . . . , 0.99}); it is obtained from one of the models speciÔ¨Åed above. To evaluate the full predictive densities, pinball scores obtained from (9) are averaged over the time horizon (99 quantiles for every hour, 24 hours of the day, n days of the month). A better forecast yield a lower pinball score. For more details on the pinball loss function and the evaluation methods used in GEFCom2014, see [19]. Table 2 contains the results of our proposed models along with two benchmark models. It is worth noting that all the data prior to the target month have taken part in the training of each model, i.e., the Ô¨Årst eleven months in 2011 were used for training a model to predict the load proÔ¨Åles in December 2011. Furthermore, the average of 100 diÔ¨Äerent hourly load values (right panel of Figure 7) is used as a proxy for the actual load value anytime needed; it is done because in the later days of the month, the earlier load proÔ¨Åles are needed in the form of L(d ‚àí1) or L(d ‚àí7). The results in Table 2, together with Figure 3 highlights the fact that including the derivatives (especially the 2nd derivatives) is indeed helpful in enhancing the performance of the forecasting model. To investigate further, Figure 9 contains the Diebold-Mariano test [17], [13] to determine whether two models are signiÔ¨Åcantly diÔ¨Äerent. These results were obtained by comparing",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_27"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " the forecasting model. To investigate further, Figure 9 contains the Diebold-Mariano test [17], [13] to determine whether two models are signiÔ¨Åcantly diÔ¨Äerent. These results were obtained by comparing the error between the median (q = 0.5) of the forecasts from two models and the actual values. The results are the average of 100 iterations, calculated according to (10). Suppose that the signiÔ¨Åcance level of the test is Œ± = 0.05. For a two-tailed test, therefore, the upper and lower tails would each be 0.025. Accordingly, the upper and lower z‚àívalues are 1.96 and ‚àí1.96, respectively [1]. The null hypothesis of no diÔ¨Äerence between the two models (forecasts) will be rejected if the computed Diebold- Mariano statistic falls outside the range of [-1.96 , 1.96]. Consistent with the results in Table 2, in February, June and September 2011, Models I and II are most signiÔ¨Åcantly diÔ¨Äerent. On the other hands, in August, where both models have the highest pinball score, the Diebold-Mariano (DM) test is low. Finally, DM tests in May and November 2011, are negative, as Model I outperforms Model II. We use the Diebold-Mariano test to determine whether forecasts are signiÔ¨Åcantly diÔ¨Äerent. Let ei1 and ei2 be the residuals for Model I and II, respectively (i ‚àà[1 : n]). n is the number of 14 data points, and k is the lagging variable [2]. di = |ei1|2 ‚àí|ei2|2 ¬Ød = 1 n n X i=1 di Œ≥k = 1 n n X i=k+1 (di ‚àí¬Ød)(di‚àík ‚àí¬Ød), n > k ‚â•1 DM = ¬Ød s [Œ≥0 + 2 h‚àí1 P k=1 Œ≥k]/n , h ‚â•1 (10) 5. Conclusions This paper proposes two generic scenario-based probabilistic load forecasting models using an ensemble of re- gression trees. An important distinction of the current work is in recasting quasi-periodic time series data as matrices",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_28"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "1 (10) 5. Conclusions This paper proposes two generic scenario-based probabilistic load forecasting models using an ensemble of re- gression trees. An important distinction of the current work is in recasting quasi-periodic time series data as matrices. The singular value decomposition technique is then used to generate temperature scenarios, in a robust and data-driven manner. In the second model, we extend the Ô¨Årst one by adding the Ô¨Årst and second derivatives of the non-deterministic attributes (temperature and historical load data). It was done to partially account for the recency eÔ¨Äects and interac- tions among the data. The empirical case studies performed on the data from the load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014-L) show how the proposed models outperform two benchmark scenario-based models with a similar set-up. Acknowledgment The authors gratefully acknowledge partial support by the Dutch NWO-TTW under project grant Smart Energy Management and Services in Buildings and Grids (SES-BE). The authors also would like to thank the anonymous reviewers for their fruitful comments. References [1] , a. Comparing predictive accuracy of two forecasts: The diebold-mariano test. http://www.phdeconomics.sssup.it/documents/ Lesson19.pdf. [2] , b. Diebold-mariano test statistic. https://nl.mathworks.com/matlabcentral/fileexchange/ 33979-diebold-mariano-test-statistic?focused=7267180&tab=function. [3] , . Estimates of predictor importance. https://nl.mathworks.com/help/stats/compactregressionensemble. predictorimportance.html. [4] Alobaidi, M.H., Chebana, F., Meguid, M.A., 2018. Robust ensemble learning framework for day-ahead forecasting of household based energy consumption. Applied Energy 212, 997‚Äì1012. [5] Breiman, L., 1996. Bagging predictors. Machine learning 24, 123‚Äì140. [6] Breiman, L., 2001. Random forests. Machine learning 45, 5‚Äì32. [7] Breiman, L., Friedman, J., Stone, C., Olshen, R., 1984. ClassiÔ¨Åcation and Regression Trees. The Wadsworth and Brooks-Cole statistics- probability series,",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_29"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "32. [7] Breiman, L., Friedman, J., Stone, C., Olshen, R., 1984. ClassiÔ¨Åcation and Regression Trees. The Wadsworth and Brooks-Cole statistics- probability series, Taylor & Francis. [8] Ceperic, E., Ceperic, V., Baric, A., 2013. A strategy for short-term load forecasting by support vector regression machines. IEEE Transactions on Power Systems 28, 4356‚Äì4364. [9] Che, J., Wang, J., 2014. Short-term load forecasting using a kernel-based support vector regression combination model. Applied energy 132, 602‚Äì609. [10] Chen, Y., Xu, P., Chu, Y., Li, W., Wu, Y., Ni, L., Bao, Y., Wang, K., 2017. Short-term electrical load forecasting using the support vector regression (svr) model to calculate the demand response baseline for oÔ¨Éce buildings. Applied Energy 195, 659‚Äì670. [11] Coelho, V.N., Coelho, I.M., Coelho, B.N., Reis, A.J., Enayatifar, R., Souza, M.J., GuimarÀúaes, F.G., 2016. A self-adaptive evolutionary fuzzy model for load forecasting problems on smart grid environment. Applied Energy 169, 567‚Äì584. [12] Craparo, E., Karatas, M., Singham, D.I., 2017. A robust optimization approach to hybrid microgrid operation using ensemble weather forecasts. Applied energy 201, 135‚Äì147. [13] Diebold, F.X., Lopez, J.A., 1996. 8 forecast evaluation and combination. Handbook of statistics 14, 241‚Äì268. [14] Fan, S., Chen, L., 2006. Short-term load forecasting based on an adaptive hybrid method. IEEE Transactions on Power Systems 21, 392‚Äì401. 15 [15] Freund, Y., Schapire, R., Abe, N., 1999. A short introduction to boosting. Journal-Japanese Society For ArtiÔ¨Åcial Intelligence 14, 1612. [16] Freund, Y., Schapire, R.E., et al., 1996. Experiments with a new boosting",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_30"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " short introduction to boosting. Journal-Japanese Society For ArtiÔ¨Åcial Intelligence 14, 1612. [16] Freund, Y., Schapire, R.E., et al., 1996. Experiments with a new boosting algorithm, in: Icml, Citeseer. pp. 148‚Äì156. [17] Harvey, D., Leybourne, S., Newbold, P., 1997. Testing the equality of prediction mean squared errors. International Journal of forecasting 13, 281‚Äì291. [18] Hong, T., Fan, S., 2016. Probabilistic electric load forecasting: A tutorial review. International Journal of Forecasting 32, 914‚Äì938. [19] Hong, T., Pinson, P., Fan, S., Zareipour, H., Troccoli, A., Hyndman, R.J., 2016. Probabilistic energy forecasting: Global energy forecasting competition 2014 and beyond. [20] Hong, T., Wang, P., 2014. Fuzzy interaction regression for short term load forecasting. Fuzzy optimization and decision making 13, 91‚Äì103. [21] Hong, T., Wilson, J., Xie, J., 2014. Long term probabilistic load forecasting and normalization with hourly information. IEEE Transactions on Smart Grid 5, 456‚Äì462. [22] Hyndman, R., Koehler, A.B., Ord, J.K., Snyder, R.D., 2008. Forecasting with exponential smoothing: the state space approach. Springer Science & Business Media. [23] Keshtkar, A., Arzanpour, S., 2017. An adaptive fuzzy logic system for residential energy management in smart grid environments. Applied Energy 186, 68‚Äì81. [24] Khoshrou, A., Dorsman, A.B., Pauwels, E.J., 2017. Svd-based visualisation and approximation for time series data in smart energy systems, in: Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), 2017 IEEE PES, IEEE. pp. 1‚Äì6. [25] Khoshrou, A., Pauwels, E.J., 2017. Propagating uncertainty in tree-based load forecasts, in: 2017 10th International Conference on Electrical and Electronics Engineering (E",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_31"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": "6. [25] Khoshrou, A., Pauwels, E.J., 2017. Propagating uncertainty in tree-based load forecasts, in: 2017 10th International Conference on Electrical and Electronics Engineering (ELECO), pp. 120‚Äì124. [26] Langford, E., 2006. Quartiles in elementary statistics. Journal of Statistics Education 14. [27] Li, S., Goel, L., Wang, P., 2016. An ensemble approach for short-term load forecasting by extreme learning machine. Applied Energy 170, 22‚Äì29. [28] Liu, B., Nowotarski, J., Hong, T., Weron, R., 2017. Probabilistic load forecasting via quantile regression averaging on sister forecasts. IEEE Transactions on Smart Grid 8, 730‚Äì737. [29] Loh, W.Y., 2011. ClassiÔ¨Åcation and regression trees. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1, 14‚Äì23. [30] Lusis, P., Khalilpour, K.R., Andrew, L., Liebman, A., 2017. Short-term residential load forecasting: Impact of calendar eÔ¨Äects and forecast granularity. Applied Energy 205, 654‚Äì669. [31] Mendes-Moreira, J., Soares, C., Jorge, A.M., Sousa, J.F.D., 2012. Ensemble approaches for regression: A survey. ACM Computing Surveys (CSUR) 45, 10. [32] Misiorek, A., Trueck, S., Weron, R., 2006. Point and interval forecasting of spot electricity prices: Linear vs. non-linear time series models. Studies in Nonlinear Dynamics & Econometrics 10. [33] Opitz, D., Maclin, R., 1999. Popular ensemble methods: An empirical study. Journal of artiÔ¨Åcial intelligence research 11, 169‚Äì198. [34] Papalexopoulos, A.D., Hesterberg, T.C., 1990. A regression-based approach to short-term system load forecasting. IEEE Transactions on Power Systems 5, 1535‚Äì1547. [35] Ramanathan, R., Engle, R., Granger, C.W., Vahid",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_32"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": ". A regression-based approach to short-term system load forecasting. IEEE Transactions on Power Systems 5, 1535‚Äì1547. [35] Ramanathan, R., Engle, R., Granger, C.W., Vahid-Araghi, F., Brace, C., 1997. Short-run forecasts of electricity loads and peaks. International journal of forecasting 13, 161‚Äì174. [36] Singh, P., Dwivedi, P., 2018. Integration of new evolutionary approach with artiÔ¨Åcial neural network for solving short term load forecast problem. Applied Energy 217, 537‚Äì549. [37] Strang, G., 1993. Introduction to linear algebra. volume 3. Wellesley-Cambridge Press Wellesley, MA. [38] Taieb, S.B., Hyndman, R.J., 2014. A gradient boosting approach to the kaggle load forecasting competition. International journal of forecasting 30, 382‚Äì394. [39] Wang, P., Liu, B., Hong, T., 2016. Electric load forecasting with recency eÔ¨Äect: A big data approach. International Journal of Forecasting 32, 585‚Äì597. [40] Wang, Y., Zhang, N., Tan, Y., Hong, T., Kirschen, D.S., Kang, C., 2018. Combining probabilistic load forecasts. IEEE Transactions on Smart Grid . [41] Xiao, L., Shao, W., Yu, M., Ma, J., Jin, C., 2017. Research and application of a hybrid wavelet neural network model with the improved cuckoo search algorithm for electrical power system forecasting. Applied energy 198, 203‚Äì222. [42] Xie, J., Hong, T., 2016. Gefcom2014 probabilistic electric load forecasting: An integrated solution with forecast combination and residual simulation. International Journal of Forecasting 32, 1012‚Äì1016. [43] Xie, J., Hong, T., 2018. Temperature scenario generation for probabilistic load forecasting. IEEE Transactions on Smart Grid 9, 1680‚Äì1687. [44] Ziel, F., Liu, B., 2016. Lasso estimation for gefcom2014 probabilistic electric load forecasting. International Journal of Forecasting 32, ",
    "token_count": 500,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_33"
  },
  {
    "id": "02f27bba-12dc-4d60-af31-e7ad527fa335",
    "created_at": "2025-07-26T15:28:58.600907+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_",
    "text": " Smart Grid 9, 1680‚Äì1687. [44] Ziel, F., Liu, B., 2016. Lasso estimation for gefcom2014 probabilistic electric load forecasting. International Journal of Forecasting 32, 1029‚Äì1037. 16",
    "token_count": 58,
    "chunk_id": "02f27bba-12dc-4d60-af31-e7ad527fa335_34"
  },
  {
    "id": "a79f1f17-438c-461a-96e0-bcd452098b93",
    "created_at": "2025-07-26T15:28:58.661790+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/CV_Majid_Khoshrou.pdf",
    "title": "CV_Majid_Khoshrou",
    "text": "Majid Khoshrou # majid.khoshrou@gmail.com | +31 (0)6 8249 5448 ‚Äôs-Hertogenbosch, The Netherlands √Ø linkedin.com/in/majid-khoshrou-a2728349 | ¬≥ Google Scholar PROFILE Experienced Data Scientist with 10+ years of combined experience in industry and academia. Specialized in machine learning, forecasting, and real-time analytics, with a proven track record of leading data-driven initiatives across domains such as energy, mobility, and infrastructure. Adept at building scalable models, mentoring teams, and translating complex data into actionable insights. Passionate about applying AI to solve real-world challenges and delivering impact across diverse sectors. SKILLS Programming: Python, SQL, MATLAB, PySpark, Bash Libraries/Frameworks: Scikit-learn, Pandas, NumPy, TensorFlow, PyTorch, XGBoost, LightGBM Data & Cloud Platforms: AWS, GCP, Azure, Databricks, Docker, Git Analytics & Visualization: Power BI, Tableau, Matplotlib, Seaborn, Plotly Management & Collaboration: Agile/Scrum, JIRA, Confluence, Stakeholder Engagement Open Source: Contributor to OpenSTEF (Energy Forecasting Library) Languages: English (Fluent), Dutch (Intermediate), Persian (Native) WORK EXPERIENCE Senior Data Scientist, Alliander ‚Äì Arnhem Jan 2023 ‚Äì Present ‚Ä¢ Boosted day-ahead allocation forecast accuracy by 30%, enabling over 1.3 M euro annual cost savings. ‚Ä¢ Identified cost-saving opportunities through in-depth analysis of energy settlement pricing. ‚Ä¢ Contributed to the open-source library OpenSTEF, improving usability and model robustness. ‚Ä¢ Built statistical models to assess and mitigate grid reliability risks. ‚Ä¢ Standardized model validation practices across teams, ensuring consistent performance tracking. ‚Ä¢ Key Skills & Tools: AWS, OpenSTEF, Forecasting, Energy Markets, Risk Modeling, Model Validation, Stakeholder Engagement Postdoctoral Researcher, Centrum Wiskunde & Informatica ‚Äì Amsterdam Jul 2020 ‚Äì Dec 2022 ‚Ä¢ Delivered accurate EV charging demand forecasts, supporting infrastructure planning for urban mo- bility. ‚Ä¢ Introduced carbon impact metrics for server clusters, influencing sustainability reporting practices. ‚Ä¢ Co-taught graduate-level courses, enhancing student engagement in AI and game theory. ‚Ä¢ Key Skills & Tools: PyTorch, TensorFlow, Carbon Accounting, EV Infrastructure Planning, Research Superv",
    "token_count": 500,
    "chunk_id": "a79f1f17-438c-461a-96e0-bcd452098b93_1"
  },
  {
    "id": "a79f1f17-438c-461a-96e0-bcd452098b93",
    "created_at": "2025-07-26T15:28:58.661790+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/CV_Majid_Khoshrou.pdf",
    "title": "CV_Majid_Khoshrou",
    "text": " impact metrics for server clusters, influencing sustainability reporting practices. ‚Ä¢ Co-taught graduate-level courses, enhancing student engagement in AI and game theory. ‚Ä¢ Key Skills & Tools: PyTorch, TensorFlow, Carbon Accounting, EV Infrastructure Planning, Research Supervision, Scientific Writing Data Scientist, Maistering B.V. ‚Äì Amsterdam/Rotterdam Nov 2019 ‚Äì Jul 2020 ‚Ä¢ Developed customer segmentation models that improved marketing campaign targeting and ROI. ‚Ä¢ Delivered ML-powered features that enhanced product value for enterprise clients. ‚Ä¢ Collaborated across teams to accelerate deployment of analytics pipelines. ‚Ä¢ Key Skills & Tools: Azure, Git, Agile, Customer Segmentation, Data Visualization, Product Devel- opment PhD Researcher, CWI & TU Delft ‚Äì Netherlands Dec 2015 ‚Äì Nov 2019 ‚Ä¢ Pioneered probabilistic modeling techniques for smart grid forecasting, improving reliability of energy predictions. ‚Ä¢ Developed anomaly detection methods that enhanced grid health monitoring capabilities. ‚Ä¢ Published peer-reviewed research that contributed to advancements in time series analysis. ‚Ä¢ Key Skills & Tools: Python, Smart Grids, Probabilistic Modeling, Anomaly Detection, Pattern Recog- nition, ML Research, Scientific Writing Project Research Member, C2SR Lab ‚Äì Porto, Portugal May 2013 ‚Äì Oct 2015 ‚Ä¢ Designed real-time learning algorithms that improved navigation efficiency in marine robotics. ‚Ä¢ Enhanced adaptive sampling strategies, enabling more effective data collection in ocean missions. ‚Ä¢ Key Skills & Tools: MATLAB, Unsupervised Learning, Online Learning, Adaptive Sampling, AUV Systems, Real-Time Analytics Project Assistant, EDSAB Co. ‚Äì Tehran, Iran Feb 2011 ‚Äì Feb 2012 ‚Ä¢ Built predictive models that improved detection of electricity theft in smart meter data. ‚Ä¢ Developed long-term forecasting tools that supported national energy infrastructure planning. ‚Ä¢ Key Skills & Tools: SQL, Excel, Electricity Theft Detection, Time Series Forecasting, Infrastructure Planning, Smart Meter Analytics EDUCATION PhD in Artificial Intelligence, CWI and Delft University of Technology 2015 ‚Äì 2020 Thesis: ‚ÄúSingular Value Decomposition for Time Series Analysis in Smart Energy Systems‚Äù Research Group: Intelligent and Autonomous Systems, CWI, Amsterdam MSc in Information Engineering, University of Porto, Portugal 2012 ‚Äì 2015 Specialization: Data Science Thesis: ‚ÄúReal-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles‚Äù BSc in Electrical Power Engineering, Babol Noshirvani University of Technology,",
    "token_count": 500,
    "chunk_id": "a79f1f17-438c-461a-96e0-bcd452098b93_2"
  },
  {
    "id": "a79f1f17-438c-461a-96e0-bcd452098b93",
    "created_at": "2025-07-26T15:28:58.661790+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/CV_Majid_Khoshrou.pdf",
    "title": "CV_Majid_Khoshrou",
    "text": " of Porto, Portugal 2012 ‚Äì 2015 Specialization: Data Science Thesis: ‚ÄúReal-Time Unsupervised Motion Learning for Autonomous Underwater Vehicles‚Äù BSc in Electrical Power Engineering, Babol Noshirvani University of Technology, Iran 2002 ‚Äì 2007 CERTIFICATIONS ‚Ä¢ Advanced Data Analytics Professional Certificate, Google ‚Äì Coursera 2024 Credential: 3XSKUU95JJAB ‚Ä¢ Google IT Support Professional Certificate, Google ‚Äì Coursera 2021 Credential: G8CCK7XL6AWD ADDITIONAL INFORMATION Work Eligibility: EU citizen (Dutch nationality), also holds Iranian citizenship Interests: Fitness, photography, travel, museums, technology, chess References: Available upon request",
    "token_count": 148,
    "chunk_id": "a79f1f17-438c-461a-96e0-bcd452098b93_3"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "Regularisation for PCA- and SVD-type matrix factorisations Abdolrahman Khoshroua,b,1,‚àó, Eric J. Pauwelsa,2 aCentrum Wiskunde & Informatica, Science Park 123, 1098 XG, Amsterdam, The Netherlands bDepartment of Mathematics and Computer Science, Delft University of Technology, The Netherlands Abstract Singular Value Decomposition (SVD) and its close relative, Principal Component Analysis (PCA), are well-known linear matrix decomposition techniques that are widely used in applications such as dimension reduction and clustering. However, an important limitation of SVD/PCA is its sensitivity to noise in the input data. In this paper, we take another look at the problem of regularisation and show that diÔ¨Äerent formulations of the minimisation problem lead to qualitatively diÔ¨Äerent solutions. Keywords: Singular value decomposition (SVD), Principal component analysis (PCA), matrix factorisation, regularisation, dimensionality reduction, graph Laplacian, feature manifold. 1. Introduction and Motivation 1.1. Introduction and Related Work Singular Value Decomposition (SVD) and its close relative, Principal Component Analysis (PCA), are well- known linear matrix factorisation techniques that are widely used in applications as varied as dimension reduction and clustering, matrix completion [1] (e.g. for recommender systems), dictionary learning [2] and time series analysis [3]. In a surprising turn of events, (deep) matrix factorisation also plays a role in the implicit regularisation that enables acceptable generalisation in deep learning [4]. In their abstract version, SVD and PCA amount to two diÔ¨Äerent but related types of matrix factorisation. More precisely, given a general (data) matrix A, the aim is to approximate it as a product of simpler (i.e. lower-rank) matrices. SpeciÔ¨Åcally: ‚Ä¢ PCA-type decomposition: A ‚âàPQT where the columns of Q are orthonormal, i.e. QT Q = I; ‚Ä¢ SVD-type decomposition: A ‚âàPBQT where B is diagonal, while PT P = I, QT Q = I. The approximation in the above equations is measured in terms of the Frobenius (matrix) norm which for an arbitrary matrix X ‚ààRn√óm is deÔ¨Åned as: |X|2 F = n X i=",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_1"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " = I. The approximation in the above equations is measured in terms of the Frobenius (matrix) norm which for an arbitrary matrix X ‚ààRn√óm is deÔ¨Åned as: |X|2 F = n X i=1 m X j=1 x2 i j = Tr(XXT) = Tr(XT X) = |XT|2 F. (1) (In the remainder of the paper, we will drop the subscript F). Although these factorisation techniques are both conceptually simple and eÔ¨Äective, it is well-known that they are sensitive to noise and outliers in the input data. As a consequence, some modiÔ¨Åcations of the original algorithms have been proposed to alleviate the eÔ¨Äect of these disturbances [5, 6]. Candes et al. [7] introduce ‚àóCorresponding author: a.khoshrou@cwi.nl 1Abdolrahman Khoshrou is a (guest) PhD student at TU Delft. He is also with the Intelligent and Autonomous Systems Group at National Dutch Mathematics and Informatics Center (CWI). 2Eric Pauwels is a senior researcher and the leader of the Intelligent and Autonomous Systems Group at CWI. Preprint submitted to Ambient Intelligence and Humanized Computing June 25, 2021 arXiv:2106.12955v1 [cs.CV] 24 Jun 2021 Robust PCA (RPCA) which aims to separate signal from outliers by decomposing any given matrix into the sum of a low-rank approximation and a sparse matrix of outliers. An extension of this work for inexact recovery of the data is presented in [8]. Another example of sparse PCA using low rank approximation is proposed in [9]. Adding a regularisation term is another versatile way to tackle the problem of noisy input. For instance, Dumitrescu et al. [10] show how a regularized version of K-SVD algorithm can be adapted to the Dictionary Learning (DL) problem. However, the presence of noise in the input is not the only reason to invoke regularisation. Recent research [11] shows that in many real data sets, it is not only the observed data that lie on a (non-)linear low dimensional manifold, but this also applies to the features. He et al. [12] point out that if the columns of the matrix A are interpreted as data",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_2"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " sets, it is not only the observed data that lie on a (non-)linear low dimensional manifold, but this also applies to the features. He et al. [12] point out that if the columns of the matrix A are interpreted as data points, then the rows are features. The neighbourhood structure of both the data points and the features give rise to distinct graphs (the so-called data and the feature graph) and hence, to corresponding graph Laplacians (Ld and Lf respectively). The resulting regularised PCA is referred to as the graph-dual Laplacian PCA (gDLPCA) and for a given data matrix A, is obtained by minimising the functional: J(V, Y) = |A ‚àíVY|2 + Œ± Tr(VT LdV) + Œ≤ Tr(YL f YT) subject to VTV = I (2) The ability of the graph dual regularization technique to incorporate both data and feature structure has deservedly attracted considerable attention in dimensionality reduction applications [13, 14, 12]. In the present paper, we take the functional. (2) as a starting point and investigate the two factorisation approaches mentioned above (invoking eq. (1) to recast the trace as a norm): ‚Ä¢ PCA-type decomposition (A ‚âàPQT) by minimising the regularisation functional: |A ‚àíPQT|2 + Œª |DP|2 + ¬µ |GQ|2 (3) ‚Ä¢ SVD-type decomposition (A ‚âàPBQT) by minimising the regularisation functional: |A ‚àíPBQT|2 + Œª |DP|2 + ¬µ |GQ|2 (4) The minimisation of the functional (3) was discussed in [12], but the proposed solution contains an error which we correct in this paper. In addition, we also provide an algorithm to solve functional (4), which somewhat surprisingly is quite diÔ¨Äerent from the one for (3). The remainder of this paper is organised as follows: We Ô¨Ånalise this section by recapitulating some important facts facts about SVD. In section 2 and 3 we derive an algorithm for minimisation of the regularised version of PCA-type and SVD-type factorisation, respectively. In section 4 how gradient descent can be implemented by drawing on some elementary facts from Lie-group theory. Finally, we conclude by giving some pointers to potential extensions. 1.2.",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_3"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " of PCA-type and SVD-type factorisation, respectively. In section 4 how gradient descent can be implemented by drawing on some elementary facts from Lie-group theory. Finally, we conclude by giving some pointers to potential extensions. 1.2. Brief recap of Singular Value Decomposition (SVD) For the sake of completeness, we Ô¨Årst recall the well-known SVD result; for more details we refer to standard textbooks such as [15][16]. Theorem 1 (Singular Value Decomposition, SVD). Any real-valued n √ó m matrix A can be factorized into the product of three matrices: A = US VT where U ‚ààO(n) and V ‚ààO(m) are orthonormal, (5) and S is an n √ó m diagonal matrix where the elements on the main ‚Äúdiagonal‚Äù (so-called singular values ) are non-negative (i.e. œÉi := S ii ‚â•0 for 1 ‚â§i ‚â§min(n, m)). Assuming that the rank rk(A) = r ‚â§min(n, m), we can sort the singular values such that œÉ1 ‚â•œÉ2 ‚â•. . . ‚â•œÉr > 0 = œÉr+1 = . . . = œÉmin(n,m) 2 and recast eq. (5) as A = rX i=1 œÉiUiVT i where Ui, Vi are the i-th columns of U and V, respectively. (6) For the singular values sorted as above, we introduce the short-hand notation U(1:k) and V(1:k) to denote the matrix comprising the Ô¨Årst k columns of U and V, respectively: U(1:k) := [U1, U2, . . . , Uk] and V(1:k) := [V1, V2, . . . , Vk]. In this notation, eq. (6) can be expressed concisely as: A = U(1:r) diag(œÉ1, . . . , œÉr) VT (1:r). (7) ‚ñ† To appreciate the signiÔ¨Åcance of Theorem 1, it is helpful to highlight its geometric interpretation. Recall that any n √ó m matrix A gives rise to a corresponding linear transformation A : Rm ‚àí‚ÜíRn that maps the standard basis in Rm into the columns of A: Aek = Ak where ek = (0, 0, . .",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_4"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " any n √ó m matrix A gives rise to a corresponding linear transformation A : Rm ‚àí‚ÜíRn that maps the standard basis in Rm into the columns of A: Aek = Ak where ek = (0, 0, . . . , 0, 1, 0, . . . , 0)T. Roughly speaking, the SVD theorem therefore tells us that it is always possible to select an orthonormal basis in Rm (columns of V) that is mapped (up to non-negative scaling factors, i.e. the singular values) into an orthonormal basis in Rn (columns of U). This is immediately obvious from eq. (6): AV‚Ñì= rX k=1 œÉkUkVT k V‚Ñì= rX k=1 œÉkUkŒ¥k‚Ñì= œÉ‚ÑìU‚Ñì. where Œ¥k‚Ñìis a Kronecker delta function. It is worth noting that insisting on the orthogonality of V (VTV = I) is not restrictive. Indeed, a linear transformation is completely and uniquely determined by specifying its eÔ¨Äect on any basis, and there is no loss of generality by insisting on the orthonormality of this basis. However, the non-trivial message of this theorem is this orthonormal basis (V) can be chosen in such a way that its image U under A is also orthonormal (again, up to non-negative scalings). Furthermore, in a generic case (where all singular values are diÔ¨Äerent) the singular value decomposition is unique, up to an arbitrary relabeling of the basis-vectors and a simultaneous sign-Ô¨Çip of corresponding columns in U and V, i.e. (U‚Ñì, V‚Ñì) ‚Üí(‚àíU‚Ñì, ‚àíV‚Ñì) for any number of columns. The importance of the SVD result, and the starting point for this paper, is the following well-known minimi- sation result (more details can be found in [17, 18]). Theorem 2 (Eckart-Young-Mirsky Theorem: Optimal low rank approximation). Let us consider an n √ó m matrix A with rank rk(A) = r ‚â§min(n, m). For k < r, Ô¨Ånding the rank-k matrix Ak that is closest to A in (F",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_5"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " Optimal low rank approximation). Let us consider an n √ó m matrix A with rank rk(A) = r ‚â§min(n, m). For k < r, Ô¨Ånding the rank-k matrix Ak that is closest to A in (Frobenius) norm gives rise to the following constrained minimisation problem: min Ak |A ‚àíAk|2 subject to rk(Ak) ‚â§k. The solution to this problem is obtained by truncating the SVD expansion eq. (6) after the k-th largest singular value: Ak = k X i=1 œÉiUiVT i = U(1:k) diag(œÉ1, . . . , œÉk) VT (1:k). (8) ‚ñ† 3 Recall that a rank-k matrix of size n √ó m can always be written as a product Ak = PQT where P ‚ààRn√ók and Q ‚ààRm√ók are matrices of full rank k. Again, in this factorisation, there is no loss of generality in requiring QT Q = Ik. In fact, it is necessary to remove indeterminacy due to arbitrary but trivial rescalings such as P 7‚àí‚ÜírP while Q 7‚àí‚Üí(1/r)Q (with r , 0), and the like. Hence, one can reformulate Theorem 2 as the factorisation result in Theorem 3. Theorem 3 (PCA-type factorisation). Assume that the n √ó m matrix A has rank rk(A) = r ‚â§min(n, m). We now deÔ¨Åne the functional G(P, Q) as follow: G(P, Q) = |A ‚àíPQT|2 (9) and the corresponding constrained optimisation problem: min P,Q G(P, Q) subject to rk(P) = rk(Q) = k and QT Q = Ik (10) where k < r. A solution to the above constrained minimisation problem (in P ‚ààRn√ók and Q ‚ààRm√ók) is given by (using the SVD notation given above): Q = V(1:k) and P = U(1:k) diag(œÉ1, . . . , œÉk) (11) hence: PQT = k X i=1 œÉiUiVT i . (12) From (11) this it also follows that PT P is diagonal, but not necessarily equal to the identity. ‚ñ† Note that If",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_6"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "k) (11) hence: PQT = k X i=1 œÉiUiVT i . (12) From (11) this it also follows that PT P is diagonal, but not necessarily equal to the identity. ‚ñ† Note that If we drop the insistence on the diagonal form for PT P (i.e. P need no longer be an orthogonal frame), then the solution is no longer unique. Indeed, by taking any k √ó k orthogonal matrix R with RTR = Ik = RRT, it is clear that P‚Ä≤ = PR and Q‚Ä≤ = QR are also solutions. In this case: Q‚Ä≤T Q‚Ä≤ = RT QT QR = Ik but P‚Ä≤T P‚Ä≤ = RT PT PR = RT(S S T)R is in general a positive deÔ¨Ånite symmetric matrix. 2. Regularisation for PCA-type factorisation 2.1. Regularised PCA The following theorem outlines an obvious generalisation to the regularised version of the minimisation prob- lem. Theorem 4 (Regularised PCA). Let A be an n √ó m matrix of rank r ‚â§min(n, m). For k ‚â§r, let P ‚ààRn√ók and Q ‚ààRm√ók full rank matrices (i.e. of rank k). Furthermore, for arbitrary (non-zero) integers d and g we introduce regularisation matrices D ‚ààRd√ón and G ‚ààRg√óm, as well as weights Œª, ¬µ ‚â•0. We now deÔ¨Åne the following functional F in the variables P and Q: F(P, Q) = |A ‚àíPQT|2 + Œª |DP|2 + ¬µ |GQ|2 (13) and pose the corresponding constrained optimisation problem: min P,Q F(P, Q) subject to QT Q = Ik. (14) Introducing short-hand notation L := DT D ‚ààRn√ón and M := GTG ‚ààRm√óm (both symmetric and positive semi- deÔ¨Ånite), the solution of the constrained optimisation problem (14) is constructed as follows: ‚Ä¢ The k columns of the m √ó k matrix Q are the eigenvectors of the m √ó m matrix: K := AT(In + ŒªL)‚àí1A ‚àí¬µ M corresponding to the k largest eigenvalues; 4 ‚Ä¢ Furthermore: P = (In + ŒªL)‚àí1AQ For the sake of completeness, we reiterate that the condition QT Q =",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_7"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "(In + ŒªL)‚àí1A ‚àí¬µ M corresponding to the k largest eigenvalues; 4 ‚Ä¢ Furthermore: P = (In + ŒªL)‚àí1AQ For the sake of completeness, we reiterate that the condition QT Q = Ik is not restrictive but necessary to eliminate arbitrary rescalings. In passing, we point out that result above corrects an error in [12] where it is incorrectly stated that P = AQ. Proof. Since the variable P in the functional (13) in unconstrained, we can identify the optimum in P (for Ô¨Åxed Q) by computing the gradient: 1 2‚àáPF = (PQT ‚àíA)Q + ŒªDT DP (15) and solving for P: ‚àáPF = 0 ‚áí P QT Q |{z} Ik ‚àíAQ + ŒªLP = 0 ‚áí (Ik + ŒªL)P = AQ. (16) This condition needs to hold at the solution point. By Ô¨Årst re-writing F(P, Q) formula as the trace of matrices and then plugging in (16), we have: F(P, Q) = Tr h (A ‚àíPQT)(AT ‚àíQPT) i + Œª Tr(PT LP) + ¬µ Tr(QT MQ) = Tr h AAT ‚àíAQPT ‚àíPQT AT + PQT QPTi + Œª Tr(PT LP) + ¬µ Tr(QT MQ) Considering the fact that the trace operator is invariant under transposition as well as cyclic permutation, and plugging in eq. (16) we arrive at: F(P, Q) = Tr h AAT ‚àí2(In + ŒªL)PPT + PPTi + Œª Tr(PT LP) + ¬µ Tr(QT MQ) = Tr \u0010 AAT ‚àíPPT ‚àí2ŒªLPPT\u0011 + Œª Tr(PT LP) + ¬µ Tr(QT MQ) = Tr(AAT) ‚àíTr(PPT) ‚àí2Œª Tr(LPPT) + Œª Tr(PT LP) + ¬µ Tr(QT MQ) = Tr(AAT) ‚àíTr(PT P) ‚àíŒª Tr(PT LP) + ¬µ Tr(QT MQ) = Tr(AAT) ‚àíTr Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞PT (In + ŒªL)P | {z } AQ ÔøΩ",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_8"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": ") ‚àíTr Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞PT (In + ŒªL)P | {z } AQ Ô£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª+ ¬µ Tr(QT MQ). (17) Extracting P and its transpose from eq. (16): P = (In + ŒªL)‚àí1AQ ‚áí PT = QT AT(In + ŒªL)‚àí1 as L is symmetric (18) we arrive at: F(P, Q) = Tr(AAT) ‚àíTr h QT \u0010 AT(In + ŒªL)‚àí1A ‚àí¬µM \u0011 Q i . (19) Therefore, in order to minimize F, one must maximize the right-most term as Tr(AAT) is a constant. This is achieved by selecting for Q, eigenvectors corresponding to the k largest eigenvalues of (AT(In + ŒªL)‚àí1A ‚àí¬µM). Once Q is determined, P is obtained via eq. (18). As a concluding remark, we point out that the matrix In + ŒªL is always invertible. Indeed, since L = DT D is positive semi-deÔ¨Ånite and symmetric, it has a complete set of eigenvectors with corresponding non-negative eigenvalues, i.e., L = WŒõWT, where W is orthogonal (i.e. WTW = WWT = In) and Œõ ‚â•0. Hence, the matrix (In + ŒªL) has strictly positive diagonal elements, and is indeed invertible. ‚ñ† Some illustrative numerical experiments can be found [19]. 5 2.2. Some special cases ‚Ä¢ Œª = 0 and ¬µ = 0 : In that case, Q comprises the Ô¨Årst k eigenvectors of K = AT A and P = AQ, which means that we end up with the standard SVD, as expected. Some numerical experiments can be found [20]. ‚Ä¢ D = In and ¬µ = 0 : The following section provides an overview of the results in [10] where a regularized K-SVD problem is addressed. In the aforementioned paper, the authors consider a special case, where ¬µ = 0 and D = In. Since this implies that L = DT D = In and",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_9"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " the results in [10] where a regularized K-SVD problem is addressed. In the aforementioned paper, the authors consider a special case, where ¬µ = 0 and D = In. Since this implies that L = DT D = In and ¬µM = 0, the matrix K simpliÔ¨Åes to K = 1 1 + Œª AT A The eigenvectors of K are therefore the right singular vectors of A (i.e. the eigenvectors of AT A). Hence Q = V(1:k), and as a result: P = 1 1 + ŒªAQ and AQ = U(1:k) diag(œÉ1, . . . , œÉk). In particular, for k = 1 (the rank-1 reconstruction), we obtain: Q = v1 and P = œÉ1 1 + Œª u1 which is the result that can be found in [10]. The experiments are available in [21]. 3. Regularisation for SVD-type factorisation We now turn our attention to the SVD-type factorisation which looks for an approximation of the form: A ‚âàPBQT subject to: QT Q = Ik, |Pi| = 1 ‚àÄi ‚àà{1, 2, . . . , k}, and B diagonal. Loosely speaking, since the columns of P and Q are of unit length, they only pins down the structure of A, whereas the diagonal matrix B = diag(Œ≤1, Œ≤2, . . . , Œ≤k) captures the amplitude of the corresponding structures. Similar to before, the columns of Q are orthonormal, i.e., we again insist on QT Q = Ik. However, unlike before, the columns of P are now only required to have unit length. In light of the aforementioned SVD-type matrix factorisation technique, Theorems 5 and 6 provide an alter- native solution to the lower-rank matrix approximation problem. For notational convenience, Theorem 5 Ô¨Årst addresses the simpliÔ¨Åed case for ¬µ = 0. Finally, in Theorem 6 we return to the general case. Theorem 5 (Regularised SVD). Let A be an n √ó m matrix of rank r ‚â§min(n, m). For k ‚â§r, let P ‚ààRn√ók and Q ‚ààRm√ók of rank k, while B ‚ààRk√ók diagonal (i",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_10"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " Let A be an n √ó m matrix of rank r ‚â§min(n, m). For k ‚â§r, let P ‚ààRn√ók and Q ‚ààRm√ók of rank k, while B ‚ààRk√ók diagonal (i.e. B = diag(Œ≤1, Œ≤2, . . . , Œ≤k)). Furthermore, for arbitrary non-zero integer d we introduce regularisation matrix D ‚ààRd√ón, as well as weight Œª ‚â•0. Finally, we introduce the short-hand notation L := DT D ‚ààRn√ón (symmetric and positive-deÔ¨Ånite). We are now in a position to deÔ¨Åne the following functional F in the variables P, Q and B: F(P, Q, B) = |A ‚àíPBQT|2 + Œª |DP|2, (20) and the corresponding constrained optimisation problem: min P,Q,B F(P, Q, B) subject to: QT Q = Ik, |Pi| = 1 ‚àÄi ‚àà{1, 2, . . . , k}, and B diagonal. (21) 6 This problem is solved by the solution Algorithm 1 speciÔ¨Åed below. Algorithm 1: Proposed RSVD method (¬µ = 0) Input: A, k, Œª, D Output: P, B, Q Initialization while no convergence do 1. Determine the m √ó k matrix Q = [q1, q2, . . . , qk] (with orthonormal columns: QT Q = Ik) such that the sum of the smallest eigenvalue of each of the k symmetric matrices S (qi) is minimal, i.e.: min Q œà(Q) = min Q k X i=1 Œª1(qi) such that QT Q = Ik where Œª1(qi) = min(eig(S (qi)). To this end we use gradient descent (see Section 4). 2. For each qi as determined above, take pi to be the eigenvector W1(qi) corresponding to the smallest eigenvector Œª1(qi). Construct the n √ó k matrix P = [p1, p2, . . . , pk]. 3. Finally, set B = diag(Œ≤1, . . . , Œ≤n) where Œ≤i = (PT AQ)ii. end Proof. Since B is unconstrained, we can determine its optimal value by computing",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_11"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " , pk]. 3. Finally, set B = diag(Œ≤1, . . . , Œ≤n) where Œ≤i = (PT AQ)ii. end Proof. Since B is unconstrained, we can determine its optimal value by computing the derivative with respect to B and equating it to zero: ‚àáBF(P, Q, B) = ‚àáB|A ‚àíPBQT|2. (22) Expanding the norm in terms of a trace (cf. eq. (1)), and using the invariance of a trace under transposition, we arrive at (recall QT Q = Ik ): |A ‚àíPBQT|2 = Tr h (A ‚àíPBQT)(AT ‚àíQBPT) i = Tr(AAT) ‚àí2Tr(AQBPT) + Tr(PB2PT) = |A|2 ‚àí2 Tr(PT AQB) + Tr(B2PT P) = |A|2 ‚àí2 k X i=1 (PT AQ)ii Œ≤i + k X i=1 (PT P)ii Œ≤2 i (B is diagonal) (23) = |A|2 ‚àí2 k X i=1 (PT AQ)ii Œ≤i + k X i=1 Œ≤2 i (|Pi| = 1 ‚áí(PT P)ii = 1). (24) We therefore calculate the gradient of the functional F with respect to B as follow: ‚àÇ ‚àÇŒ≤i |A ‚àíPBQT|2 = 2 (Œ≤i ‚àí(PT AQ)ii). For given P and Q, we Ô¨Ånd the optimal B by insisting that the resulting gradient vanishes, which yields: Œ≤i = (PT AQ)ii ‚àÄi ‚àà{1, 2, . . . , k}. (25) Plugging this optimal choice back into eq. (24) the functional (20) simpliÔ¨Åes to |A ‚àíPBQT|2 = |A|2 ‚àí k X i=1 Œ≤2 i (26) To recast eq. (26) in terms of P and Q (in order to eliminate B), we observe that for an arbitrary matrix H we have Hij = eT i Hej, where ei = (0, 0, . . . , 1, . . . , 0)T are the standard basis vectors. Hence, using the fact that the 7 diagonal of a matrix is",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_12"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " eT i Hej, where ei = (0, 0, . . . , 1, . . . , 0)T are the standard basis vectors. Hence, using the fact that the 7 diagonal of a matrix is unchanged under transposition, we conclude that Œ≤i = Ô£±Ô£¥Ô£¥Ô£¥Ô£≤Ô£¥Ô£¥Ô£¥Ô£≥ (PT AQ)ii = eT i PT AQ ei = pT i Aqi (QT AT P)ii = eT i QT AT P ei = qT i ATpi where pi, qi are the i-th columns of P and Q, respectively. i.e. P = [p1, p2, . . . , pk] and Q = [q1, q2, . . . , qk]. As a consequence, k X i=1 Œ≤2 i = k X i=1 pT i Aqi qT i ATpi. (27) As a Ô¨Ånal step, we introduce the notation L = DT D to recast the regularisation term as: |DP|2 = Tr(PT LP) = k X i=1 eT i PT LP ei = k X i=1 pT i L pi. (28) Plugging eqs. (27) and (28) into eq. (20), we obtain the following simpliÔ¨Åed form for the functional F (assuming that we eliminate B by using its optimal value): F(P, Q) = |A|2 + F1(P, Q), where F1(P, Q) = k X i=1 pT i (ŒªL ‚àíAqiqT i AT)pi. (29) Introducing the notation S (q) := ŒªL ‚àíAqqT AT, we conclude that F1(P, Q) = k X i=1 pT i S (qi)pi. Since each S (q) is a symmetric matrix, it can be diagonalised with respect to an orthonormal basis, i.e. there is an orthogonal n √ó n matrix W (with WTW = WWT = In) and a diagonal matrix Œõ = diag(Œª1, . . . , Œªn) (ordered Œª1 ‚â§Œª2 ‚â§. . . ‚â§Œªn), both depending on q such that S (q) = W(q)ÔøΩ",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_13"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": ") and a diagonal matrix Œõ = diag(Œª1, . . . , Œªn) (ordered Œª1 ‚â§Œª2 ‚â§. . . ‚â§Œªn), both depending on q such that S (q) = W(q)Œõ(q)W(q)T, i.e. the columns of W are the eigenvectors of S (q), with the corresponding eigenvalues on the diagonal of Œõ. By introducing the notation Œª1(S (q)) to denote the smallest eigenvalue of Œõ(q), we obtain the minimal value pT i S (qi)pi = Œª1(qi) when choosing pi to be the (unit) eigenvector (W1(qi)) corresponding to the smallest eigenvalue. As a consequence, the solution strategy boils down to steps in Algorithm 1. This choice of P, Q and B solves the constrained minimisation problem (21). Notice that due to the fact that P and B matrices are determined after Ô¨Ånding Q, this optimisation problem can essentially be translated into a search in the space of Q matrices. Some illustrative numerical experiments are available at [22]. ‚ñ† We conclude this section by giving a slightly more general version (¬µ , 0) of the previous theorem, thus re-establishing the symmetry between P and Q. Theorem 6 (Regularised SVD, symmetric version). Let A be an n √ó m matrix of rank r ‚â§min(n, m). For k ‚â§r, let P ‚ààRn√ók and Q ‚ààRm√ók of rank k, while B ‚ààRk√ók diagonal (i.e. B = diag(Œ≤1, Œ≤2, . . . , Œ≤k)). Furthermore, for arbitrary non-zero integers d and g we introduce regularisation matrices D ‚ààRd√ón, and G ‚ààRg√óm, as well as weights Œª, ¬µ ‚â•0. Finally, we introduce the short-hand notation L := DT D ‚ààRn√ón and M := GTG ‚ààRm√óm symmetric and positive-deÔ¨Ånite). We are now in a position to deÔ¨Åne the following functional F in the variables P, Q and B: F(P, Q, B) = |A ‚àíPBQT|2 + Œª |DP|2 + ¬µ |GQ|2 (30) and the corresponding constrained optimisation problem: min P,Q,B F(P, Q, B) subject",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_14"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "(P, Q, B) = |A ‚àíPBQT|2 + Œª |DP|2 + ¬µ |GQ|2 (30) and the corresponding constrained optimisation problem: min P,Q,B F(P, Q, B) subject to: QT Q = Ik, |Pi| = 1, ‚àÄi ‚àà{1, 2, . . . , k} and B diagonal. (31) This problem is solved by the solution speciÔ¨Åed in Algorithm 2. 8 Proof. Using the notation introduced above and in Theorem 5, we see that |GQ|2 = Tr(QT MQ) = k X i=1 qT i Mqi. Hence, the functional (30) can be recast as: F(P, Q) = |A|2 + F2(P, Q), where F2(P, Q) = k X i=1 pT i (ŒªL ‚àíAqiqT i AT)pi + ¬µ k X i=1 qT i Mqi. (32) The minimum of each term in the Ô¨Årst summation in F2 is equal to the smallest eigenvalue Œª1(S (qi)). Finding the minimum for the constrained optimisation problem (31) therefore amounts to Ô¨Ånding the minimum of the functional: œà(Q) := k X i=1 \u0010 Œª1(S (qi)) + ¬µ qT i Mqi) \u0011 (33) subject to the constraint QT Q = Ik. Therefore, the minimisation problem again calls for a minimisation in Q space, as the optimal choice for P (corresponding eigen-vectors) follows automatically. We therefore arrive at the following Algorithm 2. Some illustrative numerical examples are available in [22]. ‚ñ† Algorithm 2: Proposed RSVD method (¬µ , 0) Input: A, k, ¬µ, Œª, D, G Output: P, B, Q Initialization while no convergence do 1. Recall that for any unit vector q ‚ààRm we deÔ¨Åne S (q) = ŒªL ‚àíAqqT AT. Since this is a symmetric n √ó n matrix, it has a complete set of eigenvectors and corresponding eigenvalues. Denote the smallest eigenvalue of each S (qi) as Œª1(S (qi)). 2. For a given m √ó k matrix Q = [q1, q2, .",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_15"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " complete set of eigenvectors and corresponding eigenvalues. Denote the smallest eigenvalue of each S (qi) as Œª1(S (qi)). 2. For a given m √ó k matrix Q = [q1, q2, . . . , qk] (with orthonormal columns: QT Q = Ik) compute the functional: œà(Q) := k X i=1 \u0010 Œª1(S (qi)) + ¬µ qT i Mqi) \u0011 and use gradient descent (on the compact torus domain, see section 4) to Ô¨Ånd the minimum. 3. For each qi as determined above, take pi to be the eigenvector W1(qi) corresponding to the smallest eigenvector Œª1(S (qi)). Construct the n √ó k matrix P = [p1, p2, . . . , pk]. 4. Finally, set B = diag(Œ≤1, . . . , Œ≤n) where Œ≤i = (PT AQ)ii. end 4. Computational Aspects 4.1. Gradient Descent on the Unitary Domain From Algorithm 2 it becomes clear that the full regularisation problem can be reduced to the simpler con- strained minimisation problem detailed in eq. (33). Since the œà-functional is smooth on a compact domain, this minimum is guaranteed to exist and one can use gradient descent to locate it. However, gradient descent needs to respect the constraint QT Q = Ik. This can be achieved by applying orthogonal transformations to the current Q matrix, as this will preserve orthonormality. SpeciÔ¨Åcally, recall all orthogonal m √ó m matrices with determinant equal to 1 (rather than ‚àí1), constitute a multiplicative group denoted as SO(m) and formally deÔ¨Åned as: 9 SO(m) = n R ‚ààRm√óm | RRT = Im = RTR, and det(R) = 1 o It is then straightforward to check that for any R ‚ààSO(m), it holds that if ¬ØQ = RQ, the condition QT Q = Ik implies that ¬ØQT ¬ØQ = Ik. It therefore follows that we can generate the ‚ÄúinÔ¨Ånitesimal variations‚Äù needed to compute the gradient ‚àáQ œà(Q) by applying ‚ÄúsuÔ¨Éciently small‚Äù orthogonal matrices to the current value of Q. More precisely, we draw on",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_16"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " can generate the ‚ÄúinÔ¨Ånitesimal variations‚Äù needed to compute the gradient ‚àáQ œà(Q) by applying ‚ÄúsuÔ¨Éciently small‚Äù orthogonal matrices to the current value of Q. More precisely, we draw on the fact that SO(m) is actually a Lie-group [23] and that therefore each R ‚ààSO(m) can be generated by exponentiating an element from its Lie-algebra so(m) = n K ‚ààRm√óm | KT = ‚àíK o (the skew-symmetric matrices): R = exp(tK) ‚â°Im + tK + 1 2!t2K2 + . . . + 1 n!tnKn + . . . (with KT = ‚àíK) By choosing t suÔ¨Éciently small, one obtains an orthogonal transformation that is close to the identity Im. Further- more, it suÔ¨Éces to restrict the variations to orthogonal transformations that result from exponentiating a basis for the space of skew-symmetric matrices. Such a basis is provided by the m(m ‚àí1)/2 skew-symmetric matrices Kij (where 1 ‚â§i < j ‚â§m) for which the matrix element k, ‚Ñìis given by: Kij(k, ‚Ñì) = Ô£±Ô£¥Ô£¥Ô£¥Ô£≤Ô£¥Ô£¥Ô£¥Ô£≥ 1 if k = i, ‚Ñì= j ‚àí1 if k = j, ‚Ñì= i 0 otherwise Given the current value Q0, we construct nearby values for Q by looping over K12, K13, K23, . . . etc and construct- ing the corresponding orthogonal matrices R12(t) = exp(tK12), . . . , etc. Denoting these ‚ÄúinÔ¨Ånitesimal‚Äù rotation matrices as RŒ± (where Œ± = 1, . . . , m(m ‚àí1)/2), we see that the partial derivatives with respect to these rotations can be estimated as: ‚àÇœà(Q) ‚àÇRŒ± ‚âàœà(RŒ±(t)Q0) ‚àíœà(Q0) t (for t suÔ¨Éciently small). From these results we can select the inÔ¨Ånitesimal rotation that results in the steepest descent. Since computing œà is computationally expensive (it requires determining eigenvalues) a viable alternative to computing the",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_17"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "ÔøΩÔøΩciently small). From these results we can select the inÔ¨Ånitesimal rotation that results in the steepest descent. Since computing œà is computationally expensive (it requires determining eigenvalues) a viable alternative to computing the gradient, is random descent: generate random rotations (by exponentiating random skew matrices) and check whether they result in a lower œà-value. As soon as one is found, proceed in that direction, and repeat the process. 4.2. Illustrative example: Smoothing a noisy matrix As common in the literature e.g., [11, 12, 24], we start from the assumption that the n √ó m data matrix A has a relatively smooth underlying structure that is corrupted by noise: A = uvT + œÑZ, where the n √ó m matrix Z has independent standard normal entries, and œÑ controls the size of the noise. To recover the underlying ‚Äùsignals‚Äù u and v, we minimise the SVD-type regularisation functional (30) where the smoothness of the result is enforced by using regularisation matrices D and F that extract the second derivative, i.e. D = F = Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞ ‚àí1 1 0 ¬∑ ¬∑ ¬∑ 0 1 ‚àí2 1 0 ¬∑ ¬∑ ¬∑ 0 0 1 ‚àí2 1 0 ¬∑ ¬∑ ¬∑ 0 0 0 1 ‚àí2 1 ¬∑ ¬∑ ¬∑ 0 0 ... ... ... ... 0 ... ¬∑ ¬∑ ¬∑ 0 1 ‚àí2 1 0 ¬∑ ¬∑ ¬∑ 0 1 ‚àí1 Ô£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫",
    "token_count": 499,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_18"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "ÔøΩÔøΩÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª A typical result for a rank-1 (k = 1) approximation is depicted in Figure 1, and compared to the standard SVD solution. This illustrative example is available in [25]. 10 Figure 1: Reconstruction of noisy matrix based on RSVD. Top left: noise-less rank-1 matrix uvT , (image) , top right: noisy input image uvT + œÑZ (high noise level), Middle left: standard rank-1 SVD reconstruction, middle right: RSVD reconstruction (D and F are 2nd deriv matrices. weight parameters Œª = ¬µ = 1.5). Bottom: comparison of standard SVD U(:, 1) (red) versus P (blue), and V(:, 1) (red) (left) versus Q (blue) (right). The actual u and v for the noiseless input signal are drawn in green. 11 5. Conclusions and Future Research Singular Value Decomposition (SVD) and Principal Component Analysis (PCA) are important matrix fac- torisation techniques that underpin numerous applications. However, it is well-known that disturbances in the input (noise, outliers or missing values) have a signiÔ¨Åcant eÔ¨Äect on the outcome. For that reason we investigate regularisation in two diÔ¨Äerent but related versions of the factorisation, and detail the solution algorithms. An important topic for further research would be to Ô¨Ånd ways in which the gradient descent procedure in Algorithms 1 and 2 can be accelerated by taking advantage of the fact that the functional is very smooth and locally approximately quadratic. It would also be useful to derive some estimates for appropriate values for the weights Œª and ¬µ in terms of noise characteristics corrupting the underlying signal. Finally, although the P matrix in algorithm 2 has unit-length columns, we were not able to prove that these columns are also orthogonal (PT P = I) as is the case in standard SVD. In fact, numerical experiments seem to indicate that such a",
    "token_count": 499,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_19"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " the P matrix in algorithm 2 has unit-length columns, we were not able to prove that these columns are also orthogonal (PT P = I) as is the case in standard SVD. In fact, numerical experiments seem to indicate that such a constraint is not compatible with minimisation of the functional. This requires further theoretical elucidation. Acknowledgment The authors gratefully acknowledge partial support by the Dutch NWO ESI-Bida project NEAT (647.003.002). References [1] M. A. Davenport, J. Romberg, An overview of low-rank matrix recovery from incomplete observations, IEEE Journal of Selected Topics in Signal Processing 10 (4) (2016) 608‚Äì622. doi:10.1109/jstsp.2016.2539100. URL http://dx.doi.org/10.1109/JSTSP.2016.2539100 [2] I. ToÀási¬¥c, P. Frossard, Dictionary learning, IEEE Signal Processing Magazine 28 (2) (2011) 27‚Äì38. [3] A. Khoshrou, E. J. Pauwels, Data-driven pattern identiÔ¨Åcation and outlier detection in time series, in: Science and Information Conference, Springer, 2018, pp. 471‚Äì484. [4] S. Gunasekar, B. Woodworth, S. Bhojanapalli, B. Neyshabur, N. Srebro, Implicit regularization in matrix factorization (2017). arXiv:1705.09280. [5] J. P. Brooks, J. H. Dul¬¥a, E. L. Boone, A pure l1-norm principal component analysis, Computational statistics & data analysis 61 (2013) 83‚Äì98. [6] N. Kwak, Principal component analysis by l {p}-norm maximization, IEEE Transactions on Cybernetics 44 (5) (2013) 594‚Äì609. [7] E. J. Cand`es, X. Li, Y. Ma, J. Wright, Robust principal component analysis?, Journal of the ACM (JACM) 58 (3) (2011) 1‚Äì37. [8] Z. Zhou, X. Li, J. Wright, E. Candes, Y. Ma, Stable principal",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_20"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "?, Journal of the ACM (JACM) 58 (3) (2011) 1‚Äì37. [8] Z. Zhou, X. Li, J. Wright, E. Candes, Y. Ma, Stable principal component pursuit, in: 2010 IEEE international symposium on information theory, IEEE, 2010, pp. 1518‚Äì1522. [9] H. Shen, J. Z. Huang, Sparse principal component analysis via regularized low rank matrix approximation, Journal of multivariate analysis 99 (6) (2008) 1015‚Äì1034. [10] B. Dumitrescu, P. Irofti, Regularized k-svd, IEEE Signal Processing Letters 24 (3) (2017) 309‚Äì313. [11] T. Jin, J. Yu, J. You, K. Zeng, C. Li, Z. Yu, Low-rank matrix factorization with multiple hypergraph regularizer, Pattern Recognition 48 (3) (2015) 1011‚Äì1022. [12] J. He, Y. Bi, B. Liu, Z. Zeng, Graph-dual laplacian principal component analysis, Journal of Ambient Intelligence and Humanized Computing 10 (8) (2019) 3249‚Äì3262. [13] M. Yin, J. Gao, Z. Lin, Q. Shi, Y. Guo, Dual graph regularized latent low-rank representation for subspace clustering, IEEE Transactions on Image Processing 24 (12) (2015) 4918‚Äì4933. [14] N. Shahid, N. Perraudin, V. Kalofolias, G. Puy, P. Vandergheynst, Fast robust pca on graphs, IEEE Journal of Selected Topics in Signal Processing 10 (4) (2016) 740‚Äì756. [15] G. Strang, Introduction to linear algebra, Vol. 3, Wellesley-Cambridge Press Wellesley, MA, 1993. [16] R. Horn, C. Johnson, Matrix Analysis, Cambridge University Press, 1985. [17] G. H. Golub, C. F. Van Loan, Matrix computations, Vol. 3, JHU press, 2013. [18] C. Eckart",
    "token_count": 500,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_21"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": " Analysis, Cambridge University Press, 1985. [17] G. H. Golub, C. F. Van Loan, Matrix computations, Vol. 3, JHU press, 2013. [18] C. Eckart, G. Young, The approximation of one matrix by another of lower rank, Psychometrika 1 (3) (1936) 211‚Äì218. [19] code for theorem 4, https://www.dropbox.com/s/fjtz7fh1hyf9cdm/theorem_4.m?dl=0, created: 2021, June. [20] code for special case:¬µ = 0 and Œª = 0, https://www.dropbox.com/s/ngjksurfepn8dml/special_case_mu_0_lambda_0.m?dl= 0, created: 2021, June. [21] code for special case: ¬µ = 0 and d = in, https://www.dropbox.com/s/ab1rfiquiyuzuvz/special_case_mu_0_D_In.m?dl=0, created: 2021, June. [22] code for factorisation svd-type theorems, https://www.dropbox.com/sh/f257tzsuttbp1ro/AABaJc1IVXZFQFVQKnpIGjr7a?dl= 0, created: 2021, June. [23] A. Iserles, H. Z. Munthe-Kaas, S. P. N√∏rsett, A. Zanna, Lie-group methods, Acta numerica 9 (2000) 215‚Äì365. [24] M. Gavish, D. L. Donoho, The optimal hard threshold for singular values is 4/ ‚àö 3, IEEE Transactions on Information Theory 60 (8) (2014) 5040‚Äì5053. [25] code for the numerical experiments section, https://www.dropbox.com/sh/tcl7lag80cimibw/AAD3QNx8FST0X-c3-wtAh-UFa? dl=0, created: 2021, June. 12",
    "token_count": 466,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_22"
  },
  {
    "id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c",
    "created_at": "2025-07-26T15:28:58.670615+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/2106.12955v1.pdf",
    "title": "2106.12955v1",
    "text": "a? dl=0, created: 2021, June. 12",
    "token_count": 16,
    "chunk_id": "894f3a4f-fa28-4ac1-8103-187d34d28f6c_23"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/263505800 Unsupervised Learning of Gaussian Mixture Models in the Presence of Dynamic Environments Conference Paper in Lecture Notes in Electrical Engineering ¬∑ July 2014 DOI: 10.1007/978-3-319-10380-8_37 CITATIONS 3 READS 361 2 authors: Abdolrahman Khoshrou Centrum Wiskunde & Informatica 27 PUBLICATIONS 112 CITATIONS SEE PROFILE A. Pedro Aguiar University of Porto 392 PUBLICATIONS 8,135 CITATIONS SEE PROFILE All content following this page was uploaded by Abdolrahman Khoshrou on 23 June 2016. The user has requested enhancement of the downloaded file. Unsupervised Learning of Gaussian Mixture Models in the Presence of Dynamic Environments A multiple-model adaptive algorithm ‚ãÜ Abdolrahman Khoshrou and A. Pedro Aguiar Faculty of Engineering, University of Porto, Portugal {a.khoshrou,pedro.aguiar}@fe.up.pt Abstract. This paper tackles the on-line unsupervised learning prob- lem of Gaussian mixture models in the presence of uncertain dynamic environments. In particular, we assume that the number of Gaussian components (clusters) is unknown and can change over time. We pro- pose a multi-hypothesis adaptive algorithm that continuously updates the number of components and estimates the model parameters as the measurements (sample data) are being acquired. This is done by incre- mentally maximizing the likelihood probability associated to the esti- mated parameters and keeping/creating/removing in parallel a number of hypothesis models that are ranked according to the minimum de- scription length (MDL), a well-known concept in information theory. The proposed algorithm has the additional feature that it relaxes ‚Äúthe suÔ¨Éciently large data set‚Äù restriction by not requiring in fact any ini- tial batch of data. Simulation results illustrate the performance of the proposed algorithm. Keywords: On-line learning, Adaptation and learning, Gaussian mix- ture models 1 Introduction Over the years, research on identifying and classifying unknown number of com- ponents in a dynamic environment has been an important topic in computer vision and pattern recognition communities. In particular, for data clustering, mixture models, where each component density of the mixture represents a given set of individuals/samples",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_1"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "ifying unknown number of com- ponents in a dynamic environment has been an important topic in computer vision and pattern recognition communities. In particular, for data clustering, mixture models, where each component density of the mixture represents a given set of individuals/samples in the total population, has been applied in a widespread of applications. Mixture models are able to represent arbitrar- ily complex probability density functions (pdfs). This makes them an excellent choice for representing complex class-conditional pdfs (e.g. likelihood functions) in Bayesian supervised learning scenarios or prior probabilities for Bayesian pa- rameter estimation [1]. For oÔ¨Ä-line clustering, and more precisely to compute ‚ãÜThis work was partially supported by project CONAV/FCT-PT [PTDC/EEACRO/113820/2009]. 2 the parameters that deÔ¨Åne the mixture model given a Ô¨Ånite data set, a widely used procedure is to apply the expectation-maximization (EM) algorithm that incrementally converges to a maximum likelihood estimate of the mixture model. Notice however that the basic EM algorithm is not able to deal with on-line data since it is an iterative algorithm that requires all the batch of data in each itera- tion. Another important restriction is the number of components of the mixture which is to be Ô¨Åxed (does not change) and has to be known a-priori. To solve some of the above problems, several approaches have been developed. In [2], starting from a Ô¨Åxed number of clusters in a batch of data, a split-and- merge approach together a dissimilarity index concept is presented that adap- tively updates the number of mixture models. Z. Zivkovic et al. [3] inspired by [4] proposed an on-line (recursive) algorithm that estimates the parameters of the mixture and simultaneously selects the number of components by starting with a high number of components in a small batch and searching for the maximum a posteriori (MAP) solution, and discarding the irrelevant components. A. De- clercq and J. H. Piater et al. [5] presents a method to incrementally learning Gaussian mixture models (GMMs) based on a new Ô¨Ådelity criterion for splitting and merging mixture components. In this paper we address the on-line unsupervised learning problem of GMMs in the presence of uncertain dynamic environments, i.e., we assume that the number",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_2"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": ") based on a new Ô¨Ådelity criterion for splitting and merging mixture components. In this paper we address the on-line unsupervised learning problem of GMMs in the presence of uncertain dynamic environments, i.e., we assume that the number of Gaussian components (clusters) is not only unknown but it also can change over time. Inspired by the work in [4], namely the use of the minimum description length (MDL) concept, we propose a multi-hypothesis adaptive al- gorithm that continuously updates the number of components and estimates the model parameters as the measurements (sample data) are being acquired. The proposed algorithm has the additional feature that it relaxes ‚Äúthe suÔ¨Éciently large data set‚Äù restriction by not requiring in fact any initial batch of data. Simulation results illustrate the performance of the proposed algorithm where it shows that indeed it is able to continuously adapt to the dynamic changes of the number of clusters and estimate the parameters of the mixture model. 2 Problem Statement Let {Yn, n = 0, 1, 2, . . .} be a discrete-time random process where for each particular time n, Yn follows a K-component mixture of d-dimensional Gaussian with probability density function (pdf) given by p(y|Œ∏, w) := K X k=1 w[k] p[k](y|Œ∏[k]), (1) where y represents one particular outcome of Yn and w := {w[1], . . . , w[K]} is the mixing weight set that satisÔ¨Åes K X k=1 w[k] = 1, w[k] > 0, (2) 3 K denotes the number of components of the mixture, Œ∏[k] := {¬µ[k], Œ£[k]} is the mean and covariance matrix of the kth component, with Œ∏ := {Œ∏[1], . . . , Œ∏[K]}, and p[k](y|Œ∏[k]) := 1 (2œÄ)d/2|Œ£[k]|1/2 exp \u0010 ‚àí1 2(y ‚àí¬µ[k])T (Œ£[k])‚àí1(y ‚àí¬µ[k]) \u0011 . (3) Note that for simplicity of notation we have omitted in the parameters K, w, Œ∏ their explicit dependence on the time n. We can now formulate the problem addressed in the paper: Given a sequence of observations Y0, Y1, .",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_3"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": ") Note that for simplicity of notation we have omitted in the parameters K, w, Œ∏ their explicit dependence on the time n. We can now formulate the problem addressed in the paper: Given a sequence of observations Y0, Y1, . . ., Ô¨Ånd on-line, as the samples are arriving, a sequence of estimates for the parameters K, w, Œ∏ that is most likely to be in some sense close to the correct characterization of the random process {Yn, n = 0, 1, 2, . . .}. 3 Preliminaries and basic results This section presents several background results, starting with the EM algo- rithm, that are needed to understand the proposed on-line unsupervised learning algorithm. 3.1 The Basic Expectation-Maximization (OÔ¨Ä-line) Algorithm For Ô¨Ånite mixture models, given a set of n independent and identically dis- tributed samples Y = {Y1, . . . , Yn}, the log-likelihood corresponding to a K- component mixture where all the components are d-dimensional Gaussian is [1] ‚Ñì:= log p(Y |Œ∏, w) = log n Y i=1 p(Yi|Œ∏, w) = n X i=1 log K X k=1 w[k]p(Yi|Œ∏[k]) (4) It is well-known that the maximum likelihood (ML) or maximum a posteriori (MAP) estimates can not be found analytically [1, Ch. 9]. An elegant and pow- erful method for Ô¨Ånding ML or MAP solutions for models with latent variables is called the expectation-maximization or EM algorithm [6], [1, Ch. 9]. The EM is an easily implementable algorithm that iteratively increases the posterior den- sity or likelihood function. In order to describe the EM, we need to introduce for each observation Yi, a discrete unobserved indicator vector Zi = [Z[1] i , . . . , Z[K] i ]. This vector speciÔ¨Åes from which component the observation Yi was drawn, i.e., if Z[k] i = 1 and Z[p] i = 0 for k Ã∏= p, then this means that the sample Yi was pro- duced by the kth component. Hence, the complete log-likelihood function (i.e. the one from which we",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_4"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": " Z[p] i = 0 for k Ã∏= p, then this means that the sample Yi was pro- duced by the kth component. Hence, the complete log-likelihood function (i.e. the one from which we could estimate Œ∏, w if the complete data X = {Y, Z} was observed [7]) can be written as a product log p(Y, Z|Œ∏, w) := n X i=1 K X k=1 Z[k] i log h w[k]p(Yi|Œ∏[k]) i (5) The EM algorithm runs over the whole data set Y and until some convergence cri- terion is met, iteratively produces a sequence of estimates ÀÜŒ∏m, ÀÜwm, m = 0, 1, 2, . . . by alternatively applying two steps: 4 E-Step: Given Y and the current estimates ÀÜŒ∏m, ÀÜwm and by considering the fact that log p(Y, Z|Œ∏, w) is linear with respect to the missing Z, the so-called Q-function computes the conditional expectation of the complete log-likelihood function as Q(Œ∏, ÀÜŒ∏m):=E h log p(Y, Z|Œ∏, w) Y, ÀÜŒ∏m, ÀÜ wm i = log p(Y, Œì|Œ∏, w), (6) where Œì ‚â°E[Z|Y, ÀÜŒ∏m, ÀÜwm] is the a conditional expectation that each obser- vation is generated by which component. Since the elements of Z are binary, as mentioned in [4], their conditional expectations are given by Œì [k] i := E h Z[k] i |Y, ÀÜŒ∏m, ÀÜwm i = Pr [Z[k] i = 1|Yi, ÀÜŒ∏m, ÀÜwm] = ÀÜw[k] m p(Yi|ÀÜŒ∏[k] m ) K P k=1 ÀÜw[k] m p(Yi|ÀÜŒ∏[k] m ) , (7) where ÀÜw[k] m corresponds to the a priori probability that Z[k] i = 1 in the m-th iteration of the basic EM algorithm over Y , while Œì [k] i is the a posteriori probability that Z[k] i",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_5"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "ÔøΩw[k] m corresponds to the a priori probability that Z[k] i = 1 in the m-th iteration of the basic EM algorithm over Y , while Œì [k] i is the a posteriori probability that Z[k] i = 1, after observing Yi. M-Step: Maximizing Q by constructing a Lagrangian function to update the parameter estimation ÀÜŒ∏m+1 = arg max Œ∏ Q(Œ∏, ÀÜŒ∏m), (8) for the ML estimation. In the case of MAP criterion, instead of Q(Œ∏, ÀÜŒ∏m), we need to maximize {Q(Œ∏, ÀÜŒ∏m) + log p(Œ∏)}. Since in many real world applications, the number of components is unknown and may change over time, and we may also have memory and time constraints, the above EM algorithm, for that type of applications, has to be modiÔ¨Åed to accommodate those issues and also to be applicable in an on-line context. Before we introduce the proposed algorithm, in the next section, Ô¨Årst we brieÔ¨Çy describe the criterion that is used in [4] in order to Ô¨Ånd the number of components in a batch of data. later, we explain how to use this criterion in real time applications. 3.2 The Minimum Description Length (MDL) Principle The MDL principle is rooted in the fact that any regularity in a given set of data can be used to compress it. Thus, the more regularities there are, the more the data can be compressed. This principle can be also used for inductive inference to the model selection problem [8, 9]. Given a set of hypotheses H = {H1, H2, . . .} and a data set Y , the goal is to Ô¨Ånd the hypothesis or combination of hypotheses in H that most compress Y . 5 For the particular case of a data set Y = {Y1, . . . , Yn}, that has been gener- ated according to Eq.(1)-Eq.(3), which has to be encoded and transmitted, the description length can be obtained as follow [4, 10]: L(Œ∏, w, Y ) = N 2 K X k=1 log(nw[k] 12 ) + K 2 log n 12 + K(N + 1) 2 ‚àí‚Ñì",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_6"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "4, 10]: L(Œ∏, w, Y ) = N 2 K X k=1 log(nw[k] 12 ) + K 2 log n 12 + K(N + 1) 2 ‚àí‚Ñì (9) where N is a constant that grows quadratically with the dimension d of the data, K is the number of components, n is the total number of samples, w[k] is the mixing weight of the kth component, and ‚àí‚Ñìcan be viewed as the code-length of the data, given by Eq.(4). 3.3 Titterington‚Äôs On-line Algorithm for a Multivariate Normal Mixture As mentioned earlier, the original EM algorithm works in a batch manner. In contrast to the traditional version of the EM, on-line EM variants can Ô¨Çexi- bly update the parameters of Yn as soon as a new sample is observed. In [11], the application of an on-line EM algorithm proposed by Titterington [12] for estimating the multivariate normal mixture in computer vision tasks is investi- gated. In the proposed on-line algorithm the Titterington-type on-line parameter recursion for multivariate normal mixtures are given by ¬µ[k] n+1 = ¬µ[k] n + 1 n Œì [k] n+1 w[k] n (Yn+1 ‚àí¬µ[k] n ) (10) Œ£[k] n+1 = Œ£[k] n + 1 n Œì [k] n+1 w[k] n h (Yn+1 ‚àí¬µ[k] n )(Yn+1 ‚àí¬µ[k] n ) T ‚àíŒ£[k] n i (11) w[k] n+1 = w[k] n + 1 n(Œì [k] n+1 ‚àíw[k] n ) (12) where Yn+1 is the new observation, Œì [k] n+1 is the a posteriori probability in Eq.(7), n is the time, w[k] n+1 is the mixing weight of kth component at time n + 1, ¬µ[k] n+1 is the updated mean of kth component and Œ£[k] n+1 is the updated covariance of kth component. For more details and the derivation of the formulas see [11]. 3.4 Gaussian Mixture Reduction In this work, we chose a pairwise merging of",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_7"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "th component and Œ£[k] n+1 is the updated covariance of kth component. For more details and the derivation of the formulas see [11]. 3.4 Gaussian Mixture Reduction In this work, we chose a pairwise merging of components method that measures the dissimilarity between the post-merge mixture with respect to the pre-merge mixture based on an easily-computed upper bound of the Kullback-Leibler (KL) discrimination measure presented in [13]. Given a mixture of two Gaussian components m, p with the parameters Œ∏ and w, where Œ∏[i] ‚â°{¬µ[i], Œ£[i]}, i ‚àà{m, p} and w[m] + w[p] = 1, we can obtain the parameters of merging of these two as follow ¬µ[mp] = w[m]¬µ[m] + w[p]¬µ[p] (13) 6 Œ£[mp] = w[m]Œ£[m] + w[p]Œ£[p] + w[m]w[p](¬µ[m] ‚àí¬µ[p])(¬µ[m] ‚àí¬µ[p])T The KL dissimilarity measure B, between two components m and p can be obtained according to (see [13] for details): 2B \u0010 (¬µ[m], Œ£[m], w[m]), (¬µ[p], Œ£[p], w[p]) \u0011 = tr(Œ£[mp]‚àí1 ÀòŒ£[mp]) +(w[m] + w[p]) log det(Œ£[mp]) ‚àíw[m] log det (Œ£[m]) ‚àíw[p] log det (Œ£[p]) (14) where ÀòŒ£[mp] = w[m]Œ£[m]+w[p]Œ£[p]‚àí(w[m]+w[p])Œ£[mp]+ w[m]w[p] w[m] + w[p] (¬µ[m]‚àí¬µ[p])(¬µ[m]‚àí¬µ[p])T Algorithm 1 On-line EM-based Clustering Input: Sample data: Y0, Y1, . . ., Mean and covariance of the initial component Œ∏[0]:(¬µ[0], Œ£[0]), Maximum number of hypotheses: ‚Ñµmax, Dissimilarity measure threshold: Bmax Output: Number of the components: K, Mean and covariance of the components: {Œ∏[1], . . . , Œ∏[K",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_8"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": " Œ£[0]), Maximum number of hypotheses: ‚Ñµmax, Dissimilarity measure threshold: Bmax Output: Number of the components: K, Mean and covariance of the components: {Œ∏[1], . . . , Œ∏[K]}, Mixing weights: {w[1], . . . , w[K]} 1.Update the current components in each hypothesis H1, . . . , H‚Ñµ: Find the a posteriori probabilities Œìn+1 as Eq.(7) Update the current components by Eq.(10)-Eq.(12) Update the log-likelihood ‚Ñìas in Eq.(16) Update the description length L as in Eq.(9) 2.Add a new hypothesis: H‚Ñµ+1 Create a new component according to Eq.(15) DeÔ¨Åne the log-likelihood of this new hypothesis: ‚Ñì‚Ñµ+1 = ‚Ñì1 Obtain the description length of this new hypothesis: L‚Ñµ+1 in Eq.(9) 3.Check if we can add another hypothesis: H‚Ñµ+2 Find B for every pair of components in H1 according to Eq.(14) if min(B) < Bmax then Merge two components according to Eq.(13) Set the log-likelihood of H1 as the log-likelihood of new hypothesis: ‚Ñì‚Ñµ+2 = ‚Ñì1 Obtain the description length for this new hypothesis L‚Ñµ+2 in Eq.(9) end if 4. Refresh the model Re-order incrementally the hypotheses according to their description length L Keep the Ô¨Årst ‚Ñµmax hypotheses Acquire the next sample and go to 1 4 The Proposed On-line Unsupervised Learning Algorithm In this section we describe the proposed on-line unsupervised learning algorithm, which is composed of several models as it will become clear later. Algorithm 1 describes the pseudo-code for one model and its rational is as follows: - Start with one single observation and build the Ô¨Årst hypothesis H1 described by a single Gaussian distribution with mean ¬µ[0] at the point itself, and some predeÔ¨Åned covariance Œ£[0]. Then, calculate the log-likelihood of this hypothesis ‚Ñì1 = ‚àílog p (2œÄ)d|Œ£| and Ô¨Ånd the corresponding description length L1 according to Eq.(9). 7 - The second acquired sample, updates the Ô¨Årst hypothesis H1 according to Eq.(10)-Eq.(",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_9"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "log p (2œÄ)d|Œ£| and Ô¨Ånd the corresponding description length L1 according to Eq.(9). 7 - The second acquired sample, updates the Ô¨Årst hypothesis H1 according to Eq.(10)-Eq.(12), and builds the second hypothesis H2 which contains two components: the Ô¨Årst updated component and a second component with mean ¬µ[K+1] at the point itself, with some predeÔ¨Åned covariance Œ£[K+1] ¬µ [K+1] = Yn+1 , w [K+1] = 1 n + 1 (15) where K is the number of components at the time (being K = 1 for the case of the second sample). - The third point will update the two current hypotheses and build another one by adding a new component to H1 and so on and so forth. For the sake of computational speed and memory, the number of hypotheses has to be bounded. Thus, after reaching the limit of maximum hypotheses ‚Ñµmax, we rank the hypotheses in an increasing order according to their description length and keep only the Ô¨Årst ‚Ñµmax hypotheses and discard the rest. - As explained above, in each iteration we add a new hypothesis by assuming that the new arriving point is a new component, according to Eq.(15), be- side the current Gaussian mixture in H1. Thus, it is likely that we face the very common problem of over Ô¨Åtting. To avoid that, in each iteration after updating the current components in all hypotheses, we check the possibility of adding another hypothesis by merging two most similar components in H1 (the hypothesis with minimum description length), according to the dis- similarity measure Bmax. For example at time n, if there were 5 components in H1, by receiving a new point Yn+1, Ô¨Årst we would update the compo- nents in H1 as we do in all other hypotheses; then if there were two similar components according to a threshold in H1, we would merge them and add another hypothesis H‚Ñµ+2 (see Algorithm 1) composed by the post-merge mixture. For this new hypothesis the log-likelihood is set to be the same as the log-likelihood of the pre-merge mixture in H1, since it is assumed that the two components were very similar to each other. - The dissimilarity measure threshold Bmax is an important",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_10"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "-likelihood is set to be the same as the log-likelihood of the pre-merge mixture in H1, since it is assumed that the two components were very similar to each other. - The dissimilarity measure threshold Bmax is an important quantity since a very small value would not be helpful in tackling the over-Ô¨Åtting problem and setting a very high threshold can cause under-Ô¨Åtting of the components. To address this problem, we propose to run diÔ¨Äerent set of models in parallel, that is, several processes using Algorithm 1 but with diÔ¨Äerent values of Bmax. For each time n the model with MDL is selected as output. Another point that needs to be taken into consideration is the fact that the computation of the log-likelihood has to be done in a recursive on-line format. Thus, after updating Œ∏n and wn, the log-likelihood ‚Ñìfrom Eq.(4) is updated as ‚Ñìn+1 = ‚Ñìn + log p(Yn+1|Œ∏n, wn) (16) where Œ∏n = {Œ∏[1] n , ..., Œ∏[K] n } and wn = {w[1] n , ..., w[K] n }. For some practical reasons, in Eqs. (10), (11), (12), we changed the learning rate 1 n to a faster decaying envelope, i.e. we added a suÔ¨Éciently large enough constant to n in order to reduce the problem of instability as proposed in [3]. 8 (a) n=3 (b) n=1100 (c) n=4000 (d) n=10300 (e) n=12000 (f) n=15000 Fig. 1: An example of the execution behaviour of the proposed algorithm. (a) Description Length (DL) (b) Number of Components (K) Fig. 2: Time evolution of the description length (DL) and K. 5 Simulation Results This section illustrates the behaviour of the proposed algorithm for two types of experiments: a synthetic Gaussian mixture data set and the Iris data set. 5.1 A Gaussian Mixture Data Set Fig.1 shows an example of 3 models running in parallel in order to Ô¨Ånd a mixture of well separated synthetic Gaussian components in real time starting with one 9 (a) Histogram results (100",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_11"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": ".1 A Gaussian Mixture Data Set Fig.1 shows an example of 3 models running in parallel in order to Ô¨Ånd a mixture of well separated synthetic Gaussian components in real time starting with one 9 (a) Histogram results (100 trials) (b) Projected data in 2-D Fig. 3: Iris Data Set Results single observation. The maximum number of hypotheses was set to Nmax = 10 and the merging threshold Bmax to 0.008, 0.08, and 0.8, respectively. This exper- iment can be split in two steps. For n < 10000, the observed data were randomly extracted, according to Eq.(1) with 4 components (K=4) and the mixing weights of the components from left to right are w = [0.35, 0.25, 0.15, 0.25]. It can be seen, after some transient situation, that the algorithm merged the two most similar components and were able to correctly determine the 4 components. Then, for n ‚â•10000, we started to extract data from another component beside those previous ones. The algorithm was able to converge to the solution rapidly. Fig.2 shows the output of 3 diÔ¨Äerent models running in parallel. Intuitively we can say that setting a higher threshold in models 2 and 3, led to early merging in the components and in turn smaller estimation for K. This problem which is known as under-Ô¨Åtting, can cause reduction in the log-likelihood and increase the description length in turn. 5.2 The Iris Data Set We used the well-known 3-component 4-dimensional ‚ÄúIris‚Äù data set [14]. This data set has only 150 samples, and therefore we had to randomize and repeat them 60 times. We set the maximum number of hypotheses Nmax = 50 in 10 diÔ¨Äerent models with the merging threshold starting from Bmax = 0.002. Fig.3(a) shows that in 64 out of 100 trials the 3 components were correctly identiÔ¨Åed. By visual inspection we could observe that the linearly separated component (iris setosa) could almost perfectly be identiÔ¨Åed. On the other hand, the properly identiÔ¨Åcation of the other two non-linear separable components (iris versicolor and iris",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_12"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": " could observe that the linearly separated component (iris setosa) could almost perfectly be identiÔ¨Åed. On the other hand, the properly identiÔ¨Åcation of the other two non-linear separable components (iris versicolor and iris virginca) was more challenging since the order in which the data is presented can inÔ¨Çuence the recursive solution. The typical solution is shown in Fig.3(b) by projecting the 4-dimensional data to the Ô¨Årst two principal components. 10 6 Conclusion This paper proposed an on-line unsupervised learning of GMMs algorithm in the presence of uncertain dynamic environments. The algorithm relies on a multi- hypothesis adaptive scheme that continuously updates the number of compo- nents and estimates the model parameters as the measurements (sample data) are being acquired. The hypothesis models are ranked according to the MDL. In general, we could conclude that the algorithm has a good performance spe- cially when the components are well separated. However, it is worth to mention that a critical issue is the initial selection of the covariance when a new com- ponent is created. This has to be done carefully because choosing a very small covariance can be experimentally problematic since in the process of calculating the a posteriori probability in Eq.(7), the result in Eq.(3) could be zero due to Ô¨Ånite precision. On the other hand, choosing an extremely large covariance can lead to the ‚Äúunder-Ô¨Åtting‚Äù problem. This is something that deserves further investigation. References 1. Bishop, C.M.: Pattern recognition and machine learning, Springer (2006) 2. Greggio, N., Bernardino, A., Victor, J.S.: A practical method for self adapting gaussian expectation maximization. In: ICINCO. (2010) 36‚Äì44 3. Zivkovic, Z., van der Heijden, F.: Recursive unsupervised learning of Ô¨Ånite mixture models. (2004) 4. Figueiredo, M.A.T., Jain, A.K.: Unsupervised learning of Ô¨Ånite mixture models. Volume 24. (2000) 381‚Äì396 5. Declercq, A., Piater, J.H.: Online learning of gaussian mixture models ‚àía two level approach. (2008) 605‚Äì611 6. P., D.A., M., L.N., B., R",
    "token_count": 500,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_13"
  },
  {
    "id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10",
    "created_at": "2025-07-26T15:28:58.736290+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/gmm.pdf",
    "title": "gmm",
    "text": "5. Declercq, A., Piater, J.H.: Online learning of gaussian mixture models ‚àía two level approach. (2008) 605‚Äì611 6. P., D.A., M., L.N., B., R.D.: Maximum likelihood from incomplete data via the EM algorithm. Volume 39. (1977) 1‚Äì38 7. McLachlan, G., Krishnan, T.: The EM Algorithm and Extensions. John Wiley & Sons, New York (1997) 8. Lanterman, A.D.: Schwarz wallace and rissanen: Intertwining themes in theories of model selection. (2000) 9. Gr¬®unwald, P.D.: The minimum description length principle. The MIT Press (2007) 10. Raudys, S.J., Jain, A.K.: Small sample size eÔ¨Äects in statistical pattern recognition: Recommendations for practitioners. IEEE Transactions on Pattern Analysis and Machine Intelligence 13(3) (1991) 252‚Äì264 cited By (since 1996)462. 11. Li, D., Xu, L., Goodman, E.: On-line EM variants for multivariate normal mixture model in background learning and moving foreground detection. (2012) 12. Titterington, D.M.: Recursive parameter estimation using incomplete data. Vol- ume 46. (1984) 257‚Äì267 13. Runnalls, A.R.: A kullback-leibler approach to gaussian mixture reduction. Vol- ume 43. (2007) 989‚Äì999 14. Iris data set. http://archive.ics.uci.edu/ml/datasets/Iris View publication stats",
    "token_count": 356,
    "chunk_id": "ca3d39f3-949f-425a-a62d-e5e4b84b5e10_14"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": "SVD-based Visualisation and Approximation for Time Series Data in Smart Energy Systems Abdolrahman Khoshrou Centrum Wiskunde & Informatica Science Park 123, 1098 XG Amsterdam, The Netherlands Email: a.khoshrou@cwi.nl Andr¬¥e B. Dorsman Vrije Universiteit Amsterdam, De Boelelaan 1105, 1081 HV Amsterdam, The Netherlands Email: a.b.dorsman@vu.nl Eric J. Pauwels Centrum Wiskunde & Informatica Science Park 123, 1098 XG Amsterdam, The Netherlands Email: eric.pauwels@cwi.nl Abstract‚ÄîMany time series in smart energy systems exhibit two different timescales. On the one hand there are patterns linked to daily human activities. On the other hand, there are relatively slow trends linked to seasonal variations. In this paper we interpret these time series as matrices, to be visualized as images. This approach has two advantages: First of all, interpreting such time series as images enables one to visually integrate across the image and makes it therefore easier to spot subtle or faint features. Second, the matrix interpretation also grants elucidation of the underlying structure using well- established matrix decomposition methods. We will illustrate both these aspects for data obtained from the German day-ahead market. Index Terms‚ÄîData analysis, Data preprocessing, Renewable energy sources, Smart grids, Time series analysis. I. INTRODUCTION In smart energy systems, time series often show two distinct time scales. On the one hand, the data exhibit strong diurnal patterns reÔ¨Çecting the daily (or weekly) rhythms of human activity. On the other hand, these relatively fast diurnal patterns are superimposed on slower seasonal variations that have a signiÔ¨Åcant impact on the overall evolution of the data. To improve the visualization and make it easier to spot correlations between variables, we propose to analyze these time series as matrices (to be visualized as images) where rows represent hour slots, whereas columns correspond to days. This approach has two advantages. First, visualizing such time series as images allows one to visually integrate across the image and makes it therefore easier to spot subtle or faint features. Second, one can draw on well-established matrix decomposition methods to elucidate underlying structure. In this paper we will discuss both these aspects in the context of data from the day-ahead market. II. DATA The day-ahead market is an exchange for",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_1"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " features. Second, one can draw on well-established matrix decomposition methods to elucidate underlying structure. In this paper we will discuss both these aspects in the context of data from the day-ahead market. II. DATA The day-ahead market is an exchange for short-term elec- tricity contracts where the tradings are driven by its partici- pants [1]. Fig. 1 illustrates various collected sets of data for the German day-ahead market in 2016. Day-ahead price and the traded quantity data were collected from [2]. We obtained the day-ahead solar and wind feed-in energy data from [3]. ENTSO-E, the European Network of Transmission System Operators [4], was the platform for downloading the day-ahead load forecast. Using the above-mentioned data, we will explore the in- Ô¨Çuence of the daily Ô¨Çuctuations of the predicted supply of renewable energy sources (RES), viz. wind and solar feed-in, on the realized electricity price dynamics. III. BACKGROUND AND LITERATURE REVIEW Recently, the impact of variable generation on the electric- ity market has attracted a lot of attention. Denny et al. [5] explore how increased interconnection between Great Britain and Ireland would facilitate the integration of the wind farms into the power system. Simulation results in this work imply that large increases in the interconnection capacities bring about a decrease in average price and its volatility in Ireland. Furthermore, the growing contribution of intermittent energy sources enforces the transmission grid extensions and ex- panding the cross-border interconnections capacities to ensure the grid stability. K. Schaber, F. Steinke, and T. Hamacher in [6] examine the viability of this approach and its effects, based on the projected wind and solar data until 2020. They conclude that grid expansion is, indeed, helpful in coping with externalities which come with the deployment of renewable energies. The positive outcomes of the substantial deployment of photovoltaic (PV) installations in Germany and Italy, and in particular, their role in daytime peak price drop have been discussed by K. Barnham, K. Knorr, and M. Mazzer in [7]. This work also reports the beneÔ¨Åts of the complementary nature of wind and PV resources in the UK. Continuing further with studying the inÔ¨Çuence of renewable energy sources (RES) in Germany, a preliminary study on the German day-ahead market has been carried out in [8",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_2"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " of the complementary nature of wind and PV resources in the UK. Continuing further with studying the inÔ¨Çuence of renewable energy sources (RES) in Germany, a preliminary study on the German day-ahead market has been carried out in [8]. In the reported work, N. Adaduldah, A. Dorsman, GJ. Franx, and P. Pottuijt have taken into account the priority that the German policies assign to renewables over fossil fuels in case of adequate supply. The authors reported the existence of convincing evidence for the impact of RES on the recent emergence of negative prices on the German day-ahead market. Inspired by the work in [9], the goal of the present work is to determine the inÔ¨Çuence of the variability of the wind and solar feed-in on the price variability in the day-ahead market. To this end we focus on the intra-day dynamics of price as characterized by its second derivative, as this peaks for sharp trend reversals. arXiv:1807.10120v1 [physics.soc-ph] 11 Jul 2018 Fig. 1. An overview of the German day-ahead market in 2016; each data point represents one hour slot. From top to bottom, the price, solar, wind, load, and the traded quantity. IV. METHODS: ANALYSING TIME SERIES AS IMAGES A. Motivation An alternative way of visualizing time series with diurnal patterns is as matrices [10]. Fig. 2 shows one year‚Äôs worth of data represented as a 24 √ó 366 matrix/image (recall that 2016 is a leap year). An important distinction of this new way of representation is that it allows us to visually integrate patterns across longer time spans, which results in higher discriminatory power. For instance, even a cursory glance at the data image for the traded quantity (Fig. 2, bottom) highlights the fact that there is a signiÔ¨Åcant correlation with solar (the eye-like horizontal shape seen in the 2nd panel from the top) as well as wind (the vertical stripes in the 3rd panel Fig. 2. A more informative representation of the German day-ahead market by reformatting the timeseries in Fig. 1 into matrices of size 24 √ó 366. Each image (or matrix) column represents a single day of 24 hour-values. From top to bottom, the price, solar,",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_3"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " market by reformatting the timeseries in Fig. 1 into matrices of size 24 √ó 366. Each image (or matrix) column represents a single day of 24 hour-values. From top to bottom, the price, solar, wind, load, and the traded quantity. from the top). B. Finding peaks and valleys As mentioned before, the main scope of this work is to explore how the inherent variability of the supply by RES can affect the intra-day variability of the market. To address this problem, we have applied an additional transformation on the daily proÔ¨Åles of the quantities of interest (viz. price, load, traded quantity, solar and wind feed-in). More precisely, any of the above quantities (generically denoted by f) can be considered as a function of two variables: ‚Ä¢ time of day, hour slots 1 ‚â§h ‚â§24 ‚Ä¢ day of year, 1 ‚â§d ‚â§366 (2016 is a leap year!) Hence for such a function f(h, d), we can investigate the corresponding 2nd derivative with respect to the hour (intra- day); fhh ‚â°‚àÇ2f ‚àÇh2 ‚âàf(h + 1) ‚àí2f(h) + f(h ‚àí1) h2 (1) Extreme values of this 2nd derivative capture peaks (i.e. local maxima for which fhh < 0 and extreme) or valleys (i.e. local minima for which fhh > 0 and extreme). An example is illustrated in Fig. 3 which shows the wind feed-in proÔ¨Åle (top) and its corresponding intra-day 2nd derivative proÔ¨Åle (bottom) on Nov. 18, 2016. We contend that comparing the evolution of the 2nd derivative proÔ¨Åles (intra-day wise) can highlight the impact of the wind and solar energy feed-in on the price and also the traded quantity in 2016. Applying this intra-day 2nd derivative operator to all Ô¨Åve quantities of interest and re-visualising the resulting time series as images highlights some interesting features of the data. As an illustration, Fig. 4 shows the 2nd derivative for both solar (top) and wind feed-in (bottom). In the top panel the gradual shift of sunrise and sunset over the seasons is clearly visible. Moreover, close inspection of this Ô¨Ågure also reveals the dates",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_4"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " the 2nd derivative for both solar (top) and wind feed-in (bottom). In the top panel the gradual shift of sunrise and sunset over the seasons is clearly visible. Moreover, close inspection of this Ô¨Ågure also reveals the dates of the switch to daylight saving summer time (days 87 and 304). The image for the wind feed-in is also interesting. As expected, wind values are more erratic and less seasonally determined. That being said, there is an undeniable ‚Äúeye-like‚Äù shape that faintly mirrors the intra-day wind activities (see, e.g., [11]). Fig. 3. Wind proÔ¨Åle and its corresponding intra-day 2nd derivative on Nov. 18, 2016. Every sag in the lower proÔ¨Åle corresponds to a swell in upper and vice versa. C. Using SVD to highlight structure Another advantage of representing the time series as ma- trices is the possibility of using the matrix decomposition techniques to analyze the structure of the data. In this paper we will focus on the well-known singular value decomposition (SVD) method which states that an arbitrary h √ó d matrix A of rank r ‚â§min(h, d) can be factored as: A = USV T = r X k=1 œÉkUkV T k (2) where U ‚ààO(h) and V ‚ààO(d) are orthonormal matrices, (with Uk and Vk denoting the kth column of U and V , respectively) and S is an h √ó d matrix for which the only Fig. 4. The evolution of appropriately transformed hourly values (2nd derivatives, see text for more details) for solar (top) and wind (bottom) feed-in. Top: Solar feed-in (intra-day 2nd derivative). The colour coding (in yellow) clearly highlights the change in sunrise and sunset times, creating an overall ‚Äúeye-like‚Äù structure. Bottom: Wind feed-in (intra-day 2nd derivative). As expected, wind feed-in is much more erratic. Interestingly enough, this Ô¨Ågure shows a vague but undeniable outline of an eye-like contour which mirrors the intra-day wind activities. strictly positive elements œÉk (so-called singular values) are placed on the main diagonal (see [12]). The importance of this decomposition lies in the fact that truncating the expansion in the right hand side of (2) after the pth term yields the best",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_5"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " œÉk (so-called singular values) are placed on the main diagonal (see [12]). The importance of this decomposition lies in the fact that truncating the expansion in the right hand side of (2) after the pth term yields the best approximation of the original matrix A by a matrix of (lower) rank p (see [13]). Ap = arg min rank(R)=p ||A ‚àíR|| (3) where the norm || ¬∑ || can be either the Frobenius or spectral L2 norm. Translating these results back to the original time series, we see that the columns of U ‚ààO(24) represent daily proÔ¨Åles, whereas the columns of V ‚ààO(366) furnish the corresponding amplitudes (one for each day). Fig. 5 shows a concrete illustration for the price data: the Ô¨Årst column U1 is depicted in the top panel and provides an overall daily proÔ¨Åle (obtained as a weighted average). The expected price peaks in the morning and early evening are clearly discernible. The corresponding amplitudes (one for each day) are given by the column V1 and shown in the 3rd panel. Some days with exceptionally low or high prices are clearly visible. A rank-1 approximation of the original time series would therefore be obtained by taking the averaged daily proÔ¨Åle U1 in the top panel and scaling it up or down using the 366 values in V1 (depicted in the third panel). Notice that in this Ô¨Årst approximation, each day has the same proÔ¨Åle, only the amplitudes change from one day to another. The values of U2 (depicted in panel 2) specify a Ô¨Årst correction to U1, with the corresponding amplitudes for this correction speciÔ¨Åed in V2 (displayed in panel 4). This correction means that for any day for which the corresponding V2 coefÔ¨Åcient is positive (almost every summer day) will have a lower price value between 11h and 18h than would have expected based on the (weighted) annual average U1. Adding additional terms in the SVD expansion improves the approximation. This is illustrated in Fig. 6 where the actual data for one typical day (18 Jan. Fig. 5. From top to bottom: The Ô¨Årst two panels are the Ô¨Årst (U1) and second (",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_6"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " approximation. This is illustrated in Fig. 6 where the actual data for one typical day (18 Jan. Fig. 5. From top to bottom: The Ô¨Årst two panels are the Ô¨Årst (U1) and second (U2) dominant proÔ¨Åles of the price proÔ¨Åles in 2016; the third and the last one are their corresponding amplitudes (V1 and V2) throughout the year. Fig. 6. Low rank approximation of actual data (one particular day, Jan. 18, blue). Including up to 7 SVD components yields the rank-7 approximation (bold red). Lower rank approximations are also shown. 2016) are shown in conjunction with low-rank approximation up to rank 7. D. Structure-preserving smoothing As mentioned earlier, recasting the time series as images allows us to visually integrate subtle patterns in the data. Now, we indicate how the SVD factorization suggests a straightforward method to smooth the time-series in such a way that the overall structure is preserved. Recall that the V Fig. 7. An example of a smoothed V1 (corresponding to the most dominant singular value) used in reconstruction of the 2nd derivative of the price data. columns determine the amplitudes of every daily-proÔ¨Åle. By smoothing these proÔ¨Åles we eliminate most of the inter-day variation without affecting the overall structure. For the data at hand, the smoothing was based on robust local regression (RLOESS) but alternative approaches would be equally valid. The local regression smoothing method was used to alleviate the effect of outliers, while preserving the general trend in data. Fig. 7 shows an example of the smoothed V1 applied in the calculation of Ap. Using the smoothed version of the V vectors in the low rank reconstruction of data, yields the images depicted in Fig. 8. The panels in the left hand column show the original 2nd derivative proÔ¨Åles for the various quantities of interest (price, solar and wind feed-in, load and traded quantity). The two adjacent columns show the same data, but this time using two different smoothed, low-rank approximations: a rough rank-1 approximation (middle) and a much more accurate rank-7 approximation, which will be used in the regression analysis (Section V). In addition to appearing visually unbiased the choice for rank-7 is also based on the structural similarity",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_7"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " a rough rank-1 approximation (middle) and a much more accurate rank-7 approximation, which will be used in the regression analysis (Section V). In addition to appearing visually unbiased the choice for rank-7 is also based on the structural similarity index (SSIM), typically used for measur- ing image quality. SSIM assesses the deviation of Ap from the original matrix A by comparing their corresponding local means, standard deviations, and cross-covariance matrices. For detailed description, readers are referred to [14]. As can be seen in Fig. 9, in terms of SSIM, the approximations keep improving up till p = 7 after which it levels off. As a conse- quence, we select rank-7 as the appropriate approximation. It is worth noting that this Ô¨Ågure is in line with our expectation regarding volatility of the various quantities: wind results in the lowest similarity, while solar feed-in agrees best with the approximation. V. RESULTS AND CONCLUSIONS After the lengthy methodology section we are now in a position to state some results. In order to shed light on how the price volatility could be linked to the volatility of other data of interest, we perform two pre-processing steps (discussed in detail in the previous section): 1) We compute the intra-day 2nd derivative which high- lights peaks and valleys (concavity/convexity as a notion of intra-day variability). 2) Next, we approximate these images using an SVD expansion up to rank 7. We call the resulting data Cp, Cl, Cq, Cs and Cw where each subscript refers to the corresponding quantity. Finally, we regress the price data Cp on the other data: Cp = Œ±0 + Œ±l Cl + Œ±q Cq + Œ±s Cs + Œ±w Cw (4) (a) Intra-day 2nd derivative of price proÔ¨Åles (b) 1st rank reconstruction of Fig. 8(a) (c) 7th rank reconstruction of Fig. 8(a) (d) Intra-day 2nd derivative of solar feed-in (e) 1st rank reconstruction of Fig. 8(d) (f) 7th rank reconstruction of Fig. 8(d) (g) Intra-day 2nd derivative of wind feed-in (h) 1st rank reconstruction of Fig. 8(g) (i) 7th rank",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_8"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": "f) 7th rank reconstruction of Fig. 8(d) (g) Intra-day 2nd derivative of wind feed-in (h) 1st rank reconstruction of Fig. 8(g) (i) 7th rank reconstruction of Fig. 8(g) (j) Intra-day 2nd derivative of load proÔ¨Åles (k) 1st rank reconstruction of Fig. 8(j) (l) 7th rank reconstruction of Fig. 8(j) (m) Intra-day 2nd derivative of the traded quantity (n) 1st rank reconstruction of Fig. 8(m) (o) 7th rank reconstruction of Fig. 8(m) Fig. 8. Left: The intra-day 2nd derivative (concavity) of the German day-ahead market data in 2016, for (top to bottom) price, solar and wind feed-in, load and traded quantity. The underlying trends have been magniÔ¨Åed using rank-1 (middle) and rank-7 (right) reconstruction. Clearly, the rank-7 reconstruction yields an acceptable approximation of the original images on the left. The regression was performed for three scenarios on untreated (original) and enhanced (smoothed) 2nd derivative data; using all data, using only day-time data, or using only night-time data. Table I contains the results for the case where the original data, A, were used. An improvement of the results was achieved by using the rank-7 reconstructed data, Ap, as is seen Fig. 9. The evolution of SSIM of the reconstructed matrix, Ap (for p = 1, ..., 24) from the original 2nd derivative matrix A. Thus rank-7 was considered an appropriate choice in our experiments. TABLE I. POOR RESULTS OF THE INITIAL REGRESSION MODEL ON THE INTRA-DAY 2ND DERIVATIVE DATA (BEFORE USING SVD-BASED TECHNIQUE) TimeSlot R2 Œ±l Œ±q Œ±s Œ±w 24h 47.28 1.26 0.44 -2.98 -1.98 day time 53.07 1.34 0.44 -2.97 -1.83 night time 15.60 0.91 0.24 N/A -2.05 TABLE II. REGRESSION MODEL APPLIED ON RANK-7",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_9"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": "07 1.34 0.44 -2.97 -1.83 night time 15.60 0.91 0.24 N/A -2.05 TABLE II. REGRESSION MODEL APPLIED ON RANK-7 RECONSTRUCTION OF THE INTRA-DAY 2ND DERIVATIVE OF DATA TimeSlot R2 Œ±l Œ±q Œ±s Œ±w 24h 81.84 1.12 0.59 -2.83 -3.60 day time 86.27 1.26 0.29 -2.36 -1.27 night time 56.40 0.85 0.09 N/A -17.59 in Table II. Fig. 10 highlights the signiÔ¨Åcance of the obtained results of the later case in comparison with the randomized data (permutation test where, Ô¨Årst, the days of the year are shufÔ¨Çed, then the regression models were applied). High values of R2 for 24h and day time scenarios is an indicator of good performance of the model and emphasizes the fact that the concavity of the prices can indeed be modeled as a function of the concavity of other attributes, such as, load, traded quantity, solar and wind feed-in. These Ô¨Åndings lead to a number of conclusions. The intra- day dynamics (concavity) of the price is least affected by the traded quantity on the day-ahead market. Moreover, RES have higher impact on the price dynamics than the load. During the day time, solar is the dominant attribute affecting the price dynamics, almost twice as much as the wind and the load. In a similar way during night hours, wind can affect the price dynamics more than 20 times greater than the load. In latter case, however, the lower value of R2 points out to the fact that other measures are involved in the pricing mechanism at nights. Therefore, other attributes need to be determined to model the night time price dynamics in a more satisfactory fashion. VI. SUMMARY In this paper we have focused on time series in which a strong diurnal pattern is superimposed on slower seasonal variations. We have shown that it makes sense to visualize such time series as images/matrices, which can be approximated using low-rank SVD-based approximations. Furthermore, this decomposition suggests a natural structure-preserving smooth- ing of the data. We applied this decomposition to conc",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_10"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " makes sense to visualize such time series as images/matrices, which can be approximated using low-rank SVD-based approximations. Furthermore, this decomposition suggests a natural structure-preserving smooth- ing of the data. We applied this decomposition to concavity Fig. 10. Permutation test to indicate the signiÔ¨Åcance of R2 values in all three scenarios which can be found in Table II. Each histogram is the result of randomization tests, repeated 1000 times (no. of bins = 20), where the days are shufÔ¨Çed before applying the regression models. data for price, load, traded quantity, solar and wind feed-in on the German day-ahead market (for 2016). This process of visualization suggested a linear regression model to unveil the impact of renewables on price. REFERENCES [1] ‚ÄúEpexspot, european power exchange,‚Äù http://www.epexspot.com/en/ market-coupling. [2] ‚ÄúEpexspot, day-ahead auction,‚Äù https://www.epexspot.com/en/ product-info/auction/germany-austria. [3] ‚ÄúTaking power further,‚Äù https://www.tennettso.de/site/en/Transparency/ publications/overview. [4] ‚ÄúEntso-e, the european network of transmission system operators,‚Äù https: //www.entsoe.eu/Pages/default.aspx. [5] E. Denny, A. Tuohy, P. Meibom, A. Keane, D. Flynn, A. Mullane, and M. Omalley, ‚ÄúThe impact of increased interconnection on electricity systems with large penetrations of wind generation: A case study of ireland and great britain,‚Äù Energy Policy, vol. 38, no. 11, pp. 6946‚Äì6954, 2010. [6] K. Schaber, F. Steinke, and T. Hamacher, ‚ÄúTransmission grid extensions for the integration of variable renewable energies in europe: Who beneÔ¨Åts where?‚Äù Energy Policy, vol. 43, pp. 123‚Äì135, 2012. [7] K. Barnham, K. Knorr, and M. Mazzer, ‚ÄúBeneÔ¨Åts of photovoltaic power in supplying national electricity demand,‚Äù Energy Policy, vol. 54, pp. 385‚Äì390, 2013. [8] N. Adaduldah",
    "token_count": 500,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_11"
  },
  {
    "id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda",
    "created_at": "2025-07-26T15:28:58.764240+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1807.10120v1.pdf",
    "title": "1807.10120v1",
    "text": " M. Mazzer, ‚ÄúBeneÔ¨Åts of photovoltaic power in supplying national electricity demand,‚Äù Energy Policy, vol. 54, pp. 385‚Äì390, 2013. [8] N. Adaduldah, A. Dorsman, G. J. Franx, and P. Pottuijt, ‚ÄúThe inÔ¨Çuence of renewables on the german day ahead electricity prices,‚Äù in Perspectives on Energy Risk. Springer, 2014, pp. 165‚Äì182. [9] L. Hirth, ‚ÄúThe market value of variable renewables: The effect of solar wind power variability on their relative price,‚Äù Energy economics, vol. 38, pp. 218‚Äì236, 2013. [10] P. P. Kanjilal and S. Palit, ‚ÄúThe singular value decompositionapplied in the modelling and prediction of quasiperiodic processes,‚Äù Signal processing, vol. 35, no. 3, pp. 257‚Äì267, 1994. [11] ‚ÄúThe royal netherlands meteorological institute,‚Äù http://www.knmi.nl/ nederland-nu/weer/verwachtingen. [12] K. Baker, ‚ÄúSingular value decomposition tutorial,‚Äù The Ohio State University, vol. 24, 2005. [13] G. H. Golub and C. Reinsch, ‚ÄúSingular value decomposition and least squares solutions,‚Äù Numerische mathematik, vol. 14, no. 5, pp. 403‚Äì420, 1970. [14] ‚ÄúStructural similarity index,‚Äù http://nl.mathworks.com/help/images/ref/ ssim.html.",
    "token_count": 353,
    "chunk_id": "ad76aa65-b7ab-46b6-98dd-eced0b897bda_12"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": "A novel VOC mixtures classification methods based on GBLinear and TabNet and informative feature selection from gas sensors (E-Nose) data Hamed Karami a,* , Abdolrahman Khoshrou b a Department of Petroleum Engineering, Knowledge University, Erbil, 44001, Iraq b System Operations department, Alliander, Arnhem, The Netherlands A R T I C L E I N F O Keywords: Advanced algorithms Classification methodology Feature selection Gas mixture analysis Electronic nose A B S T R A C T The GBLinear and TabNet algorithms have been incorporated with essential feature selection techniques to create a new method of classifying essential oils using e-nose systems. Essential oils, known for their complex chemical compositions and a wide variety of applications in industries such as food, cosmetics, and pharma¬≠ ceuticals, pose some challenges for e-nose systems due to the high variability and subtle differences in volatile compounds (VOCs). This novel approach, used for the first time for the analysis of electronic nose data, integrates efficient machine-learning models with advanced feature selection techniques and aims to increase the accuracy and interpretability of essential oil classification. This study highlights the potential of integrating interpretable machine learning models with deep learning-based architectures to address challenges in the analysis of complex gas mixtures. Not only was the classification accuracy increased by these methods, but these methods could be used in the future as promising models for analyzing complex mixtures. 1. Introduction The electronic nose, commonly known as e-nose, is a new and developing technology that can potentially impact the world of analyzing and identifying multi-mixed volatile compounds eg; VOCs [1]. These systems embed chemical gas sensors, signal processing, and ma¬≠ chine learning techniques and are used in different sectors such as medicine [2,3], environment [4,5], food safety and quality [6‚Äì8]. These devices use chemical sensors that capture odor profiles and translate them into measurable signals trying to replicate the biological olfactory system [9]. E-noses are now very helpful due to their nature of being able to analyze complex odors accurately in a short amount of time and not needing to be intrusive, especially when traditional means of anal¬≠ ysis are long, costly, and troublesome [4,10]. However, the recognition of odor using e-noses is challenging largely due to the methods used to process the signals from the sensors, therefore finding suitable pro¬≠ cessing methods is a key area in",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_1"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " long, costly, and troublesome [4,10]. However, the recognition of odor using e-noses is challenging largely due to the methods used to process the signals from the sensors, therefore finding suitable pro¬≠ cessing methods is a key area in research [11]. The primary step in electronic nose gas recognition is data analysis, which typically involves three stages: data preprocessing, feature extraction and selection, and pattern recognition [12]. Data pre¬≠ processing removes noise and sensor drift using filters like wavelet, Gaussian [13], Savitzky‚ÄìGolay [14] or, Kalman [15], ensuring standardized data. Gas sensing signals, often high-dimensional, are reduced using techniques such as Principal Component Analysis [16] or other feature extraction methods [17]. Feature selection follows to minimize computational complexity. Finally, machine learning algo¬≠ rithms such as genetic algorithms, K-nearest neighbor, support vector machines, and decision trees, are employed for gas classification, with studies comparing their performance across various tasks [18]. Researchers are always on the lookout for new and improved ways to classify e-nose systems, as they are becoming increasingly advanced [19, 20]. However, that presents the problem of accurately processing and understanding the vast amount of noisy data produced by the sensors [21]. This has triggered the growing need for more advanced algorithms that can better model the characteristics of e-nose data [22]. Despite the effectiveness of these methods in so many areas, they are often limited when the sensor data are high dimensional, non-linear, or have complicated interactions among features [11]. Moreover, the inherent noise and variability present in e-nose datasets further complicate these tasks and highlight the importance of exploring more advanced classi¬≠ fication frameworks that can withstand noise while being able to pre¬≠ serve more intricate patterns within the data [21]. In this regard, the introduction of new machine learning structures is one of the solutions that can be effective for analyzing electronic nose * Corresponding author. Department of Petroleum Engineering, Knowledge University, Erbil, 44001, Iraq. E-mail address: hamed.karami@knu.edu.iq (H. Karami). Contents lists available at ScienceDirect Talanta journal homepage: www.elsevier.com/locate/talanta https://doi.org/10.1016/j.talanta.2025.128554 Received 15 February 2025; Received in revised form 30 April 2025; Accepted ",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_2"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " www.elsevier.com/locate/talanta https://doi.org/10.1016/j.talanta.2025.128554 Received 15 February 2025; Received in revised form 30 April 2025; Accepted 4 July 2025 Talanta 297 (2026) 128554 Available online 8 July 2025 0039-9140/¬© 2025 Elsevier B.V. All rights are reserved, including those for text and data mining, AI training, and similar technologies. datasets. GBLinear and TabNet are two advanced models that seek to address the shortcomings of classical models in data analysis. GBLinear, for example, works extremely well in high dimensional datasets for applications that require linear interactions due to its ability to capture linear relationships. This approach is well suited to the balance of enhancing a model‚Äôs complexity while ensuring usability, thus making it a viable option for scenarios in which reasoning behind the decision is of value. Instead, GBLinear can still take complex relationships using linear models‚Äô simplicity and efficacy by sequentially applying linear regres¬≠ sion to the residuals of the last fitted models [23‚Äì25]. This feature is of great importance, especially for e-nose systems because the relationship between the sensor responses and the corresponding odor classes may be far from linear. However, in terms of completeness, I must mention TabNet, which is a latest deep neural network model tailored for tabular data. The combination of its capacity for modeling complex nonlinear relationships and other features such as attention and interpretability make it an appropriate candidate for increasing the performance of e-nose. Developed by Google researchers, TabNet applies attention and feature selection for automatically searching for the features that are most informative for each prediction. Understanding which parts of the data provide the most relevant information allows for more accurate predictions and better training of the model. Also, TabNet‚Äôs interpret¬≠ ability features can help scientists understand which particular re¬≠ sponses of the sensors are most helpful for discriminating some specific compounds, thus aiding the design of the sensor array in a more efficient manner [26‚Äì28]. The investigational method proposed here takes advantage of the simplicity and efficiency of GBLinear, but does not neglect the impor¬≠ tance of the deep learning aspects offered by TabNet, such as its multiple interactions between non-linear features. Together, these methods pre¬≠ sent a comprehensive framework that reconciles the often conflicting requirements of explainability and accuracy. The results of this",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_3"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": "¬≠ tance of the deep learning aspects offered by TabNet, such as its multiple interactions between non-linear features. Together, these methods pre¬≠ sent a comprehensive framework that reconciles the often conflicting requirements of explainability and accuracy. The results of this study have major ramifications for the development of the next generation e- nose systems. All the aforementioned factors make the GBLinear-TabNet fusion a step towards greater accuracy in e-nose classification. 2. Material and methods 2.1. Sample preparation Seven edible essential oils were prepared from various sources. These included three medicinal plant oils; mint, tarragon, and thyme, and four fruit-based oils; mango, lemon, orange, and strawberry. For each sam¬≠ ple, both pure and industrial-grade essential oils were prepared. A total of 14 groups of essential oils were considered for the experiments. 2.2. Electronic nose instrument A custom-built electronic nose system, developed by Karami [29], utilized a 9-sensor tin metal oxide semiconductor (MOS) array (Table 1) to analyze the aroma signature patterns of VOCs emitted by purified essential oils in this study. The system comprised five key components: an activated carbon filter, a sample headspace chamber, three one-way valves, a diaphragm pump, and a sensor array linked in series via 4.0 mm PTFE tubing. Sensor data were captured using a wireless data recorder, which transmitted the information to a personal computer (PC) for collation and statistical analysis. The data acquisition process from the e-nose system was divided into three phases: baseline establishment, sample odor injection, and puri¬≠ fication. In the baseline phase, clean air from the filter was introduced into the sensor chamber through a pump and one-way valves at a flow rate of 0.8 L per minute for 60 s to stabilize the sensor response. During the sample odor injection phase, the sample head was injected into the sensor chamber, maintaining the same flow rate for 150 s, until a stable voltage response was achieved. In the purification phase, clean air was reinjected into the sensor chamber by opening the solenoid valve for 60 s, allowing the sensors to return to their baseline values. To minimize instrument baseline drift, the analysis of sample headspace volatiles from purified essential oils was conducted daily during data acquisition. At least 15 replicates per sample were measured for each essential oil type, and",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_4"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " to return to their baseline values. To minimize instrument baseline drift, the analysis of sample headspace volatiles from purified essential oils was conducted daily during data acquisition. At least 15 replicates per sample were measured for each essential oil type, and all data recorded by a data card were transmitted wirelessly to a computer for further analysis. 2.3. Data analyze Data from the individual sensors of the e-nose sensor array were extracted for preprocessing and subsequent analysis. The purpose of signal preprocessing was to isolate relevant information from the sensor responses and prepare the data for multivariate pattern analysis. To achieve this, sensor responses were normalized against their baseline for thrust compensation, contrast enhancement, and scaling, using the fraction method outlined by Karami, Rasekh and Mirzaee-Ghaleh [30], as shown in equation (1): Ys(t) = Xs(t) ‚àíXs(0) Xs(0) (1) Where Ys(t), Xs(0), and Xs(t) represent the normalized sensor response, the baseline, and the raw unprocessed sensor response, respectively. 2.3.1. GBLinear model (gradient boosted linear) GBLinear is a variant of the gradient boosting algorithm [31] spe¬≠ cifically designed for linear models. Unlike its tree-based counterparts, GBLinear uses linear functions as weak learners, making it particularly effective for datasets where relationships among features are linear or nearly linear. By combining the power of gradient boosting with linear regression or logistic regression, GBLinear provides both simplicity and interpretability. Its straightforward implementation in frameworks like XGBoost makes it a practical choice for various domains that prioritize interpretable results. For multi-class classification with k classes, the model uses the softmax function to compute class probabilities and a cross-entropy loss function as follows: L (Œò) = ‚àí ‚àë n i=1 ‚àë k j=1 yi,j log ( ÃÇyi,j ) + Œ©(Œò) (2) Where: yi,j ‚àà{0, 1} is a one-hot encoding of the true label for sample i. y ‚å¢ i,j = exp(WT j xi+bj) ‚àëk l=1 exp(WT l xi+bl) is the predicted probability for class j, obtained using the softmax function. Œò = {W,b}, where W is the matrix of weights and b is the vector of biases for all",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_5"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": "ÔøΩk l=1 exp(WT l xi+bl) is the predicted probability for class j, obtained using the softmax function. Œò = {W,b}, where W is the matrix of weights and b is the vector of biases for all classes. Œ©(Œò) = 1 2 Œª‚ÄñW‚Äñ2 + Œ±‚ÄñW‚Äñ1 includes the regularization terms. 2.3.2. TabNet model (tabular neural networks) TabNet is a deep learning architecture that uniquely combines Table 1 The types of sensors, gas detection limits, and established chemical sensitivities of tin oxide MOS sensors incorporated within the electronic nose array. Sensor name Detection ranges (ppm) Main applications (gas detection) MQ9 10-1000 and 100-10000 CO, combustible gases MQ4 300‚Äì100 Urban gases and methane MQ135 10‚Äì10000 Steam ammonia, benzene, sulfides MQ8 100‚Äì1000 Hydrogen (H2) TGS2620 50‚Äì5000 Alcohols, steam organic solvents MQ136 1‚Äì200 Sulfur dioxide (SO2) TGS813 500‚Äì10000 CH4, C3H8, C4H10 (hydrocarbons) TGS822 50‚Äì5000 Steam organic solvents MQ3 10‚Äì300 Alcohols H. Karami and A. Khoshrou Talanta 297 (2026) 128554 2 feature selection and decision-making processes within a unified framework, leveraging sequential attention mechanisms. Unlike tradi¬≠ tional gradient-boosted models or neural networks, TabNet dynamically selects features at each decision step, allowing the model to focus on the most relevant features for classification. This feature selection is ach¬≠ ieved using sparse attention masks, promoting interpretability and ef¬≠ ficiency in high-dimensional datasets. TabNet‚Äôs ability to learn directly from raw tabular data without requiring extensive preprocessing makes it particularly suited for complex, heterogeneous data structures. In this study, TabNet was particularly valuable for capturing non-linear in¬≠ teractions and subtle patterns in the volatile organic compounds (VOCs) emitted by essential oils. L CE = ‚àí1 n ‚àë n i=1 ‚àë k j=1 yi,j log ( ÃÇyi,j ) (3) Where: similar to the previous case yi,j is a one-hot encoding of the true labels",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_6"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": ". L CE = ‚àí1 n ‚àë n i=1 ‚àë k j=1 yi,j log ( ÃÇyi,j ) (3) Where: similar to the previous case yi,j is a one-hot encoding of the true labels for sample i. y ‚å¢ i,j = exp(zi,j) ‚àëk c=1 exp(zi,c) is the predicted probability for class j for sample i. zi,j is the raw logit (output before applying softmax) for class j for sample i. For more details, see Ref. [26]. Fig. 1. Two-dimensional LDA plot. Fig. 2. Confusion matrix resulting from LDA model analysis. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 3 2.4. Evaluation criteria To evaluate the system‚Äôs performance, standard criteria such as Specificity, Recall, Precision, Accuracy, Area Under the Curve (AUC), and F-score were utilized. A confusion matrix, which incorporates true positive (TP), false positive (FP), true negative (TN), and false negative (FN) values, was used to calculate these metrics. The diagnostic criteria considered were outlined by Refs. [32,33]: Specificity = TN TN + FP (4) Precision = TP TP + FP (5) Recall = TP TP + FN (6) Accuracy = TP + TN TP + TN + FN + FP (7) AUC = Sensitivity + Precision 2 (8) F = 2 √ó PR P + R (9) In this study, 70 % of the data was used for training and 30 % for validation, and all analyses were performed using Python (version 3.9.12). 3. Result 3.1. LDA In this study, LDA was used to visually evaluate the grouping and overlap of different classes within the dataset, providing insights into the distinctiveness of each class based on their features. Additionally, LDA served as a benchmark classification method, offering a comparative baseline for evaluating the performance of more complex machine learning models used in subsequent analyses. As shown in Fig. 1, the natural essential oil samples from medicinal plants are clearly distin¬≠ guishable from their synthetic counterparts. However, for fruit-based samples, there is noticeable overlap between the natural and synthetic types. The confusion matrix for classifying different essential oil groups is shown",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_7"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " natural essential oil samples from medicinal plants are clearly distin¬≠ guishable from their synthetic counterparts. However, for fruit-based samples, there is noticeable overlap between the natural and synthetic types. The confusion matrix for classifying different essential oil groups is shown in Fig. 2. For each class, the main diagonal values represent true positives (TP), while the sum of the remaining diagonal values corre¬≠ sponds to true negatives (TN). Additionally, the sum of the values in the respective column indicates false positives (FP), and the sum of the values in the respective row represents false negatives (FN). According to the figure, within the natural fruit essential oil group, 17 out of 24 samples were correctly classified, while 7 samples were misclassified. In the second group, representing synthetic essential oils, 22 samples were accurately identified, and 2 samples were misclassified. Finally, for the third and fourth groups, comprising pure medicinal essential oils and synthetic medicinal essential oils, all 8 samples in each group were correctly classified. Based on equations (2)‚Äì(7), the performance parameters of the LDA method for classifying essential oils are summarized in Table 2. The confusion matrix was employed to compute the performance parameters of the detection models. As shown in Table 2, the LDA method achieved an impressive 100 % accuracy in classifying the data, highlighting its effectiveness in distinguishing between different essential oil groups. As shown in Table 2, the average precision of the LDA method achieved 90.6 % in data classification, and the values of accuracy, recall, AUC, Table 2 Performance parameters obtained from the LDA model. Group Accuracy Precision Recall Specificity AUC F Fruit Natural 0.893 0.708 0.895 0.892 0.800 0.791 Fruit Synthetic 0.893 0.917 0.759 0.964 0.940 0.830 Medicine Natural 1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average per class 0.946 0.906 0.913 0.964 0.935 0.905 Fig. 3. Confusion matrix resulting from GBLinear model analysis. H. Karami and A",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_8"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": "000 Average per class 0.946 0.906 0.913 0.964 0.935 0.905 Fig. 3. Confusion matrix resulting from GBLinear model analysis. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 4 and F-score were equal to 94.6, 91.3, 96.4, 93.5, and 90.5 %, respectively. 3.2. GBLinear The results of the LDA method revealed its limitations in accurately classifying fruit-based essential oils, emphasizing the importance of achieving reliable differentiation within these groups. To address this challenge, GBLinear was utilized as a more robust approach for classi¬≠ fying and analyzing the dataset. This method provided valuable insights into the predictive capabilities of the features and served as a benchmark for comparing its performance with other models. As illustrated in Fig. 3, GBLinear demonstrated exceptional accuracy in distinguishing between natural and synthetic essential oils derived from medicinal plants. For fruit-based samples, while some overlap was observed, only 3 sample were misclassified, showcasing a significant improvement over tradi¬≠ tional methods commonly applied to electronic nose data. Also, ac¬≠ cording to Table 3, the values of precision, recall, and F-score were 96.9 % for the performance parameters. 3.3. TabNet TabNet was employed to further analyze the dataset and classify essential oil groups, leveraging its advanced deep learning architecture designed for tabular data. This method combines attention mechanisms with feature selection, enabling it to capture complex patterns and re¬≠ lationships within the data. As shown in Fig. 4, TabNet achieved excellent results in distinguishing between natural and synthetic essential oils from both medicinal plants and fruits. Unlike other models, TabNet effectively minimized misclassification, correctly classifying all medicinal plant samples and achieving near-perfect accuracy for fruit- based samples, with only 2 minor overlaps observed. As presented in Table 4, TabNet demonstrated exceptional performance across various classification metrics. The model achieved an average precision of 97.9 %, reflecting its strong ability to correctly identify relevant samples. In terms of other performance metrics, accuracy reached 98.8 %, recall was 97.9 %, AUC scored 98.5 %, and the F-score was 97.9 %. These results highlight TabNet‚Äôs superior capability in",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_9"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " terms of other performance metrics, accuracy reached 98.8 %, recall was 97.9 %, AUC scored 98.5 %, and the F-score was 97.9 %. These results highlight TabNet‚Äôs superior capability in effectively handling complex datasets and ensuring high reliability in the classification of essential oil samples. According to the results obtained, the models classified 100 % of the medicinal essential oil samples and only failed to classify fruit essential oils completely. Therefore, it is very important to focus on the sensors that are important for this sector in this section. Some sensors in the analysis may exhibit high sensitivity toward specific target analytes, making them crucial for the detection of trace compounds in food samples. Fig. 5a and b illustrate how each sensor contributes positively or negatively to the overall sensor system performance. According to Fig. 5a, the positive effect of the sensors on the classes is observed. As it is clear, the MQ136 sensor is the only sensor that has a 100 % role on the Table 3 Performance parameters obtained from the GBLinear model. Group Accuracy Precision Recall Specificity AUC F Fruit Natural 0.964 0.917 0.957 0.967 0.942 0.936 Fruit Synthetic 0.964 0.958 0.920 0.983 0.971 0.939 Medicine Natural 1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average per class 0.982 0.969 0.969 0.988 0.978 0.969 Fig. 4. Confusion matrix resulting from TabNet model analysis. Table 4 Performance parameters obtained from the TabNet model. Group Accuracy Precision Recall Specificity AUC F Fruit Natural 0.976 0.958 0.958 0.983 0.971 0.958 Fruit Synthetic 0.976 0.958 0.958 0.983 0.971 0.958 Medicine Natural 1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_10"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": "1.000 1.000 1.000 1.000 1.000 1.000 Medicine Synthetic 1.000 1.000 1.000 1.000 1.000 1.000 Average per class 0.988 0.979 0.979 0.992 0.985 0.979 H. Karami and A. Khoshrou Talanta 297 (2026) 128554 5 chemical fruit essential oil group. The MQ3 sensor also played the most role in the natural fruit essential oil. Therefore, these two sensors are key sensors for increasing the classification accuracy in these groups. The two sensors MQ135 and TGS813 also have a positive role in detecting natural fruit essential oil. On the other hand, the two sensors MQ9 and MQ4 also played the most role in classifying the essential oil of aromatic plants. Also, according to Fig. 5b, it can be seen that the TGS822 sensor has the most negative effect on the natural fruit essential oil group and the MQ8 sensor has the most positive effect on the chemical fruit essential oil group. Perhaps by removing these two sensors, better ac¬≠ curacy can be achieved in these groups. And similarly, the TGS 2620 sensor has a large negative impact on the natural medicinal essential oil group. These three sensors in Fig. 5a are sensors that have had an effect on at least three groups of essential oils. Perhaps by removing these sensors, higher accuracy can be achieved, especially in the fruit group. This study‚Äôs results reveal that the GBLinear and TabNet approach has outperformed the traditional classification methods like LDA. While employing an electronic nose for essential oil analysis, it is important to make use of models that can capture complicated non-linear relation¬≠ ships between the sensor responses and the volatile organic compounds (VOCs). Our research clearly illustrates how the use of these algorithms, especially in the classification of fruit-based essential oils, has had significantly better results than before.To this point, the work done on e- nose classification techniques has primarily focused on the use of the traditional machine learning methods like Principal Component Anal¬≠ ysis (PCA), Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and Random Forest (RF). For example, Rasekh and Karami [34] tried to detection of juices fraud and achieved a success rate of nearly ",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_11"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": "PCA), Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and Random Forest (RF). For example, Rasekh and Karami [34] tried to detection of juices fraud and achieved a success rate of nearly 94 %, an outcome that was bettered with our method. Others, like. This study shows that the GBLinear model alone is superior to this method by achieving 96.9 % accuracy. Furthermore, TabNet further enhances classification performance, achieving an overall accuracy of 98.8 %. The complexity and variations of e-nose sensor response is one of the main challenges that data analyzers must deal with. Linear approaches are implemented mainly using LDA, however, fruits-based essential oils suffer from classification errors during LDA. The reason for this is the overlap between VOC profiles. As was shown in our analysis, several fruit-based samples were assigned LDA class marks in error due to composition of volatile organic compounds. That is, LDA assumptions were satisfied only to an accuracy level of 94.6 %. On the other hand, GBLinear showed improvement but only through attaining the most essential linear relationships present in the data set. While GBLinear also showed improvements counting 96,9 % in recall, the real improvement was in TabNet with 97.9 % accuracy and 99.2 % specificance. This model uses attention-based feature selection techniques deep learning classification models to overcome classification blockades. With TabNet setting, the model was able to successfully tell apart natural and syn¬≠ thetic fruit essential oils. In this case the model also greatly improved recall and specificity. Another important factor is the contribution of a specific sensor element within a classification category. During the conducted analysis of sensor importance, it was found that specific sensors like, MQ136 and MQ3, are much more critical than MQ9 and Fig. 5. a) positive and b) negative effect. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 6 MQ4 for classifying fruit essential oils and medicinal plant essential oils. Research has shown that gas sensors can often respond to multiple volatile organic compounds (VOCs), making them prone to misidenti¬≠ fication, especially when analyzing complex mixtures [35]. This insight aligns with findings from previous research, such as Di Natale, Capuano, Quercia, Catini, Biasioli, Khomen",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_12"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " misidenti¬≠ fication, especially when analyzing complex mixtures [35]. This insight aligns with findings from previous research, such as Di Natale, Capuano, Quercia, Catini, Biasioli, Khomenko and Paolesse [35], which empha¬≠ sized the need for selective sensor optimization to improve e-nose classification accuracy. Moreover, our results indicate that certain sen¬≠ sors, including TGS822 and MQ8, contributed negatively to classifica¬≠ tion performance in specific groups, suggesting that their exclusion or recalibration could further enhance model accuracy. 4. Conclusion The combination of GBLinear and TabNet algorithms along with the selection of informative features has improved the classification of oils with the use of e-nose. TabNet with an accuracy of 98.8 %, was able to classify samples of essential oils more accurately. The accuracy of Tab¬≠ Net was considerably higher than that of LDA and GBLinear which was 94.6 % and 96.9 %. While all models worked well for the classification of the essential oils from the medicinal plants, it was found that TabNet algorithm did the best with incorporating essential oils derived from fruits. These results also emphasize the superiority of combining elec¬≠ tronic noses with advanced machine learning algorithms by demon¬≠ strating their ability to fathom complex odors. The combination of GBLinear and TabNet improves accuracy and interpretability, then this method can enhance e-nose technology in the food, cosmetics, and pharmaceutical industries. As a result, this methodology contributes to algorithms combination for enhance model robustness, complete. Future research could explore the application of this methodology to a broader range of volatile compounds and investigate its potential in real-time analysis scenarios. CRediT authorship contribution statement Hamed Karami: Supervision, Visualization, Data curation, Re¬≠ sources, Writing ‚Äì original draft, Validation, Software, Methodology, Conceptualization, Investigation, Formal analysis. Abdolrahman Kho¬≠ shrou: Writing ‚Äì original draft, Data curation, Software, Formal analysis. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability Data will be made available on request. References [1] J.A. Covington, S. Marco, K.C. Persaud, S.S. Schiffman, H.T. Nagle, Artificial",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_13"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " the work reported in this paper. Data availability Data will be made available on request. References [1] J.A. Covington, S. Marco, K.C. Persaud, S.S. Schiffman, H.T. Nagle, Artificial olfaction in the 21 st century, IEEE Sens. J. 21 (11) (2021) 12969‚Äì12990. [2] D. Karakaya, O. Ulucan, M. Turkan, Electronic nose and its applications: a survey, Int. J. Autom. Comput. 17 (2) (2020) 179‚Äì209. [3] A.D. Wilson, M. Baietto, Advances in electronic-nose technologies developed for biomedical applications, Sensors 11 (1) (2011) 1105‚Äì1176. [4] A. Khorramifar, H. Karami, L. Lvova, A. Kolouri, E. ≈Åazuka, M. Pi≈Çat-RoÀôzek, G. ≈Åag¬¥od, J. Ramos, J. Lozano, M. Kaveh, Y. Darvishi, Environmental engineering applications of electronic nose systems based on MOX gas sensors, Sensors 23 (12) (2023) 5716. [5] J.P. S¬¥a, M.C.M. Alvim-Ferraz, F.G. Martins, S.I.V. Sousa, Application of the low-cost sensing technology for indoor air quality monitoring: a review, Environ. Technol. Innovat. 28 (2022) 102551. [6] J.B.B. Rayappan, A.J. Kulandaisamy, M. Ezhilan, P. Srinivasan, G.K. Mani, Developments in electronic noses for quality and safety control, Advances in Food Diagnostics2017, pp. 63-96. [7] H. Karami, M. Kamruzzaman, J.A. Covington, M.¬¥e. Hassouna, Y. Darvishi, M. Ueland, S. Fuentes, M. Gancarz, Advanced evaluation techniques: gas sensor networks, machine learning, and chemometrics for fraud detection in plant and animal products, Sensor Actuator Phys. 370 (2024) 115192. [8] P",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_14"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": ", M. Gancarz, Advanced evaluation techniques: gas sensor networks, machine learning, and chemometrics for fraud detection in plant and animal products, Sensor Actuator Phys. 370 (2024) 115192. [8] P. Darvishi, E. Mirzaee-Ghaleh, Z. Ramedani, H. Karami, A.D. Wilson, Detecting whey adulteration of powdered milk by analysis of volatile emissions using a MOS electronic nose, Int. Dairy J. 157 (2024) 106012. [9] A.D. Wilson, M. Baietto, Applications and advances in electronic-nose technologies, Sensors 9 (7) (2009) 5099‚Äì5148. [10] S. Zorpeykar, E. Mirzaee-Ghaleh, H. Karami, Z. Ramedani, A.D. Wilson, Electronic nose analysis and statistical methods for investigating volatile organic compounds and yield of mint essential oils obtained by hydrodistillation, Chemosensors 10 (11) (2022) 486. [11] F. Wu, R. Ma, Y. Li, F. Li, S. Duan, X. Peng, A novel electronic nose classification prediction method based on TETCN, Sensor. Actuator. B Chem. 405 (2024) 135272. [12] J.A. Covington, S. Marco, K.C. Persaud, S.S. Schiffman, H.T. Nagle, Artificial olfaction in the 21st century, IEEE Sens. J. 21 (11) (2021) 12969‚Äì12990. [13] H.H. Afshari, S.A. Gadsden, S. Habibi, Gaussian filters for parameter and state estimation: a general review of theory and recent trends, Signal Process. 135 (2017) 218‚Äì238. [14] X. Wang, C. Qian, Z. Zhao, J. Li, M. Jiao, A novel gas recognition algorithm for gas sensor array combining savitzky‚Äìgolay smooth and image conversion route, Chemosensors 11 (2) (2023) 96. [15] F. Auger, M. Hilairet, J.M. Guerrero, E. Monmasson, T. Orl",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_15"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": " and image conversion route, Chemosensors 11 (2) (2023) 96. [15] F. Auger, M. Hilairet, J.M. Guerrero, E. Monmasson, T. Orlowska-Kowalska, S. Katsura, Industrial applications of the Kalman filter: a review, IEEE Trans. Ind. Electron. 60 (12) (2013) 5458‚Äì5471. [16] H. Karami, B. Thurn, N.K. de Boer, J. Ramos, J.A. Covington, J. Lozano, T. Liu, W. Zhang, S. Su, M. Ueland, Application of gas sensor technology to locate victims in mass disasters ‚Äì a review, Nat. Hazards (2024). [17] N.S. Aghili, M. Rasekh, H. Karami, O. Edriss, A.D. Wilson, J. Ramos, Aromatic fingerprints: VOC analysis with E-Nose and GC-MS for rapid detection of adulteration in sesame oil, Sensors 23 (14) (2023) 6294. [18] X. Wang, Y. Zhou, Z. Zhao, X. Feng, Z. Wang, M. Jiao, Advanced algorithms for low dimensional metal oxides-based electronic nose application: a review, Crystals 13 (4) (2023) 615. [19] M. Rasekh, H. Karami, S. Fuentes, M. Kaveh, R. Rusinek, M. Gancarz, Preliminary study non-destructive sorting techniques for pepper (Capsicum annuum L.) using odor parameter, LWT 164 (2022) 113667. [20] N. Mohammadian, A.M. Ziaiifar, E. Mirzaee-Ghaleh, M. Kashaninejad, H. Karami, Gas sensor technology and AI: forecasting lemon juice quality dynamics during the storage period, J. Stored Prod. Res. 109 (2024) 102449. [21] T. Liu, L. Guo, M. Wang, C. Su, D. Wang, H. Dong, J. Chen, W. Wu, Review on algorithm design in electronic noses: challenges, status, and",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_16"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": ". [21] T. Liu, L. Guo, M. Wang, C. Su, D. Wang, H. Dong, J. Chen, W. Wu, Review on algorithm design in electronic noses: challenges, status, and trends, Intelligent Computing 2 (2023) 12. [22] H.-J. He, d.S.F.M. Vinicius, W. Qianyi, K. Hamed, M. Kamruzzaman, Portable and miniature sensors in supply chain for food authentication: a review, Crit. Rev. Food Sci. Nutr. 1-21. [23] C. Wade, K. Glynn, Hands-On Gradient Boosting with Xgboost and scikit-learn: Perform Accessible Machine Learning and Extreme Gradient Boosting with Python, Packt Publishing Ltd2020. [24] S. Karimi, M. Asghari, R. Rabie, M. Emami Niri, Machine learning-based white-box prediction and correlation analysis of air pollutants in proximity to industrial zones, Process Saf. Environ. Prot. 178 (2023) 1009‚Äì1025. [25] S. Dhiman, A. Thukral, P. Bedi, Impact of clinical features on disease diagnosis using knowledge graph embedding and machine learning: a detailed analysis, in: A. Verma, P. Verma, K.K. Pattanaik, S.K. Dhurandher, I. Woungang (Eds.), Advanced Network Technologies and Intelligent Computing, Springer Nature Switzerland, Cham, 2024, pp. 340‚Äì352. [26] S.¬®O. Arik, T. Pfister, Tabnet: attentive interpretable tabular learning, Proc. AAAI Conf. Artif. Intell. (2021) 6679‚Äì6687. [27] C. Shah, Q. Du, Y. Xu, Enhanced TabNet: attentive interpretable tabular learning for hyperspectral image classification, Remote Sens. 14 (3) (2022) 716. [28] K. McDonnell, F. Murphy, B. Sheehan, L. Masello, G. Castignani, Deep learning in insurance: accuracy and model interpretability using TabNet, Expert Syst. Appl. 217 (2023) 119543. [29] M. Rase",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_17"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": "an, L. Masello, G. Castignani, Deep learning in insurance: accuracy and model interpretability using TabNet, Expert Syst. Appl. 217 (2023) 119543. [29] M. Rasekh, H. Karami, A.D. Wilson, M. Gancarz, Performance analysis of MAU-9 electronic-nose MOS sensor array components and ANN classification methods for discrimination of herb and fruit essential oils, Chemosensors 9 (9) (2021) 243. [30] H. Karami, M. Rasekh, E. Mirzaee-Ghaleh, Application of the E-nose machine system to detect adulterations in mixed edible oils using chemometrics methods, J. Food Process. Preserv. 44 (9) (2020) e14696. [31] T. Chen, C. Guestrin, Xgboost: a scalable tree boosting system, Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining (2016) 785‚Äì794. [32] H. Karami, M. Rasekh, E. Mirzaee ‚Äì Ghaleh, Comparison of chemometrics and AOCS official methods for predicting the shelf life of edible oil, Chemometr. Intell. Lab. Syst. 206 (2020) 104165. [33] H. Karami, S. Karami Chemeh, V. Azizi, H. Sharifnasab, J. Ramos, M. Kamruzzaman, Gas sensor-based machine learning approaches for characterizing tarragon aroma and essential oil under various drying conditions, Sensor Actuator Phys. 365 (2024) 114827. [34] M. Rasekh, H. Karami, Application of electronic nose with chemometrics methods to the detection of juices fraud, J. Food Process. Preserv. 45 (5) (2021) e15432. [35] C. Di Natale, R. Capuano, L. Quercia, A. Catini, F. Biasioli, I. Khomenko, R. Paolesse, AR1. 3-Real time proton transfer reaction and electronic nose H. Karami and A. Khoshrou Talanta 297 (",
    "token_count": 500,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_18"
  },
  {
    "id": "ea75633e-f7b1-4859-b020-a5a9f256fd87",
    "created_at": "2025-07-26T15:28:58.786605+00:00",
    "source_type": "local",
    "source_path": "static/pdfs/1-s2.0-S0039914025010446-main.pdf",
    "title": "1-s2.0-S0039914025010446-main",
    "text": ", F. Biasioli, I. Khomenko, R. Paolesse, AR1. 3-Real time proton transfer reaction and electronic nose H. Karami and A. Khoshrou Talanta 297 (2026) 128554 7 simultaneous measurements on same samples, Proceedings IMCS 2018 (2018) 229‚Äì230. H. Karami and A. Khoshrou Talanta 297 (2026) 128554 8",
    "token_count": 103,
    "chunk_id": "ea75633e-f7b1-4859-b020-a5a9f256fd87_19"
  },
  {
    "id": "2eaf356b-ee56-453c-9427-afdd516697c1",
    "created_at": "2025-07-26T15:28:58.822503+00:00",
    "source_type": "external",
    "source_path": "https://github.com/OpenSTEF/openstef",
    "title": "GitHub - OpenSTEF/openstef: Automated Machine Learning pipelines. Builds the Open Short Term Energy Forecasting package.",
    "text": "GitHub - OpenSTEF/openstef: Automated Machine Learning pipelines. Builds the Open Short Term Energy Forecasting package. Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert OpenSTEF / openstef Public Notifications You must be signed in to change notification settings Fork 35 Star 107 Automated Machine Learning pipelines. Builds the Open Short Term Energy Forecasting package. openstef.github.io/openstef License MPL-2.0 license 107 stars 35 forks Branches Tags Activity Star Notifications You must be signed in to change notification settings OpenSTEF/openstef mainBranchesTagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commit History2,835 Commits.github.github .reuse.reuse LICENSESLICENSES docsdocs imgimg openstefopenstef testtest .gitignore.gitignore .pre-commit-config.yaml.pre-commit-config.yaml CITATION.cffCITATION.cff COMMITTERS.mdCOMMITTERS.md LICENSELICENSE README.mdREADME.md RELEASE.mdRELEASE.md pyproject.tomlpyproject.toml requirements.txtrequirements.txt setup.cfgsetup.cfg setup.pysetup.py sonar-project.propertiessonar-project.properties test-requirements.txttest-requirements.txt View all filesRepository files navigation OpenSTEF OpenSTEF is a Python package designed for generating short-term forecasts in the energy sector. The repository includes all the essential components required for machine learning pipelines that facilitate the forecasting process. To utilize the package, users are required to furnish their own data storage and retrieval interface. Table of contents OpenSTEF Table of contents External information sources Installation Usage Example notebooks Reference Implementation Database connector for OpenSTEF License Contributing Contact External information sources Documentation website; Python package; Linux Foundation project page; Documentation on dashboard; Video about OpenSTEF; Installation Install the openstef package pip install openstef Remark regarding installation within a conda environment on Windows A version of the pywin32 package will be installed as a secondary dependency along with the installation of the openstef package. Since conda relies on an old version of pywin32, the new installation can break conda's functionality. The following command can solve this issue: pip install pywin32==300 For more information on this issue see the readme of pywin32",
    "token_count": 500,
    "chunk_id": "2eaf356b-ee56-453c-9427-afdd516697c1_1"
  },
  {
    "id": "2eaf356b-ee56-453c-9427-afdd516697c1",
    "created_at": "2025-07-26T15:28:58.822503+00:00",
    "source_type": "external",
    "source_path": "https://github.com/OpenSTEF/openstef",
    "title": "GitHub - OpenSTEF/openstef: Automated Machine Learning pipelines. Builds the Open Short Term Energy Forecasting package.",
    "text": " conda relies on an old version of pywin32, the new installation can break conda's functionality. The following command can solve this issue: pip install pywin32==300 For more information on this issue see the readme of pywin32 or this Github issue. Remark regarding installation on Apple Silicon If you want to install the openstef package on Apple Silicon (Mac with M1-chip or newer), you can encounter issues with the dependencies, such as xgboost. Solution: Run brew install libomp (if you haven‚Äôt installed Homebrew: follow instructions here) If your interpreter can not find the libomp installation in /usr/local/bin, it is probably in /opt/brew/Cellar. Run: mkdir -p /usr/local/opt/libomp/ ln -s /opt/brew/Cellar/libomp/{your_version}/lib /usr/local/opt/libomp/lib Uninstall xgboost with pip (pip uninstall xgboost) and install with conda-forge (conda install -c conda-forge xgboost) If you encounter similar issues with lightgbm: uninstall lightgbm with pip (pip uninstall lightgbm) and install later version with conda-forge (conda install -c conda-forge 'lightgbm>=4.2.0') Remark regarding installation with minimal XGBoost dependency It is possible to install openSTEF with a minimal XGBoost (CPU-only) package. This only works on x86_64 (amd64) Linux and Windows platforms. Advantage is that significantly smaller dependencies are installed. In that case run: pip install openstef[cpu] Usage Example notebooks To help you get started, a set of fundamental example notebooks has been created. You can access these offline examples here. Reference Implementation A complete implementation including databases, user interface, example data, etc. is available at: https://github.com/OpenSTEF/openstef-reference Screenshot of the operational dashboard showing the key functionality of OpenSTEF. Dashboard documentation can be found here. To run a task use: python -m openstef task <task_name> Database connector for openstef This repository provides an interface to OpenSTEF (reference) databases. The repository can be found here. License This project is licensed under the Mozilla Public License, version 2.0 - see LICENSE for details. Licenses third-party libraries This project includes third-party libraries, which are licensed under their own",
    "token_count": 500,
    "chunk_id": "2eaf356b-ee56-453c-9427-afdd516697c1_2"
  },
  {
    "id": "2eaf356b-ee56-453c-9427-afdd516697c1",
    "created_at": "2025-07-26T15:28:58.822503+00:00",
    "source_type": "external",
    "source_path": "https://github.com/OpenSTEF/openstef",
    "title": "GitHub - OpenSTEF/openstef: Automated Machine Learning pipelines. Builds the Open Short Term Energy Forecasting package.",
    "text": ") databases. The repository can be found here. License This project is licensed under the Mozilla Public License, version 2.0 - see LICENSE for details. Licenses third-party libraries This project includes third-party libraries, which are licensed under their own respective Open-Source licenses. SPDX-License-Identifier headers are used to show which license is applicable. The concerning license files can be found in the LICENSES directory. Contributing Please read CODE_OF_CONDUCT.md, CONTRIBUTING.md and PROJECT_GOVERNANCE.md for details on the process for submitting pull requests to us. Contact Please read SUPPORT.md for how to connect and get into contact with the OpenSTEF project About Automated Machine Learning pipelines. Builds the Open Short Term Energy Forecasting package. openstef.github.io/openstef Topics python data-science machine-learning energy time-series forecasting energy-forecasting Resources Readme License MPL-2.0 license Code of conduct Code of conduct Uh oh! There was an error while loading. Please reload this page. Activity Custom properties Stars 107 stars Watchers 6 watching Forks 35 forks Report repository Releases 270 v3.4.79 Latest May 27, 2025 + 269 releases Uh oh! There was an error while loading. Please reload this page. Contributors 41 Uh oh! There was an error while loading. Please reload this page. + 27 contributors Languages HTML 97.3% Python 2.7% You can‚Äôt perform that action at this time.",
    "token_count": 302,
    "chunk_id": "2eaf356b-ee56-453c-9427-afdd516697c1_3"
  },
  {
    "id": "97c23484-7a16-4066-b4f3-0c510ab510db",
    "created_at": "2025-07-26T15:29:15.018918+00:00",
    "source_type": "external",
    "source_path": "https://github.com/majidkhoshrou",
    "title": "majidkhoshrou (Majid Khoshrou) ¬∑ GitHub",
    "text": "majidkhoshrou (Majid Khoshrou) ¬∑ GitHub Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert majidkhoshrou Follow More Overview Repositories Projects Packages Stars majidkhoshrou Follow üè† Learning Majid Khoshrou majidkhoshrou üè† Learning Follow 3 followers ¬∑ 22 following @Alliander Amsterdam, The Netherlands https://www.linkedin.com/in/abdolrahman-majid-khoshrou-a2728349/ AchievementsAchievements Block or Report Block or report majidkhoshrou Block user Prevent this user from interacting with your repositories and sending you notifications. Learn more about blocking users. You must be logged in to block users. Add an optional note: Please don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you. Block user Report abuse Contact GitHub support about this user‚Äôs behavior. Learn more about reporting abuse. Report abuse More Overview Repositories Projects Packages Stars Popular repositories Loading AUV_Path_Planning_GMM AUV_Path_Planning_GMM Public C 1 Flask-endpoints Flask-endpoints Public Python probabilistic_forecasting probabilistic_forecasting Public MATLAB credit_card_application credit_card_application Public Jupyter Notebook Basic_Pytorch Basic_Pytorch Public Jupyter Notebook majidkhoshrou.github.io majidkhoshrou.github.io Public Project Website HTML Something went wrong, please refresh the page to try again. If the problem persists, check the GitHub status page or contact support. Uh oh! There was an error while loading. Please reload this page. You can‚Äôt perform that action at this time.",
    "token_count": 382,
    "chunk_id": "97c23484-7a16-4066-b4f3-0c510ab510db_1"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "Qaem Shahr - Wikipedia Jump to content Coordinates: 36¬∞27‚Ä≤49‚Ä≥N 52¬∞51‚Ä≤29‚Ä≥EÔªø / Ôªø36.46361¬∞N 52.85806¬∞EÔªø / 36.46361; 52.85806 From Wikipedia, the free encyclopedia (Redirected from Ghaemshahr) City in Mazandaran province, Iran For the administrative division of Mazandaran province, see Qaem Shahr County. City in Mazandaran, IranQaem Shahr Persian: ŸÇÿßÿ¶ŸÖ‚Äåÿ¥Ÿáÿ±CityQaem ShahrCoordinates: 36¬∞27‚Ä≤49‚Ä≥N 52¬∞51‚Ä≤29‚Ä≥EÔªø / Ôªø36.46361¬∞N 52.85806¬∞EÔªø / 36.46361; 52.85806[1]CountryIranProvinceMazandaranCountyQaem ShahrDistrictCentralArea ‚Ä¢ City27 km2 (10 sq mi)Population (2016)[3] ‚Ä¢ City204,953 ‚Ä¢ Density7,600/km2 (20,000/sq mi) ‚Ä¢ Urban247,953[2]Time zoneUTC+3:30 (IRST)Websitewww.ghaemshahr.ir Qaem Shahr (Persian: ŸÇÿßÿ¶ŸÖ‚Äåÿ¥Ÿáÿ±; pronunciation‚ìò)[a] is a city in the Central District of Qaem Shahr County, Mazandaran province, Iran, serving as capital of both the county and the district.[5] Originally known as ≈ú√¢hi was used until the Iranian Revolution in 1979 when the city acquired its current name.[6] In terms of natural topography, Qaem Shahr is divided into two regions: the plain and the foothills of the Alborz. It is situated at an elevation of 51 meters above sea level. Qaem Shahr has a Humid subtropical climate. In most years, winter contributes to half of the city‚Äôs annual rainfall, while summer is the least rainy season in Qaem Shahr. The average annual precipitation in Qaem Shahr is approximately 850 millimeters.[7] Based on the latest accurate geographic data, Qaem Shahr is considered one of the largest cities in Northern Iran.[8] The people of Qaem Shahr belong to the Tabari ethnic group.[9] They speak the Maz",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_1"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "7] Based on the latest accurate geographic data, Qaem Shahr is considered one of the largest cities in Northern Iran.[8] The people of Qaem Shahr belong to the Tabari ethnic group.[9] They speak the Mazandarani language.[10] Specifically, they communicate in the Qaem Shahr dialect, one of the dialects of the Mazandarani language.[11] Most residents of Qaem Shahr are officially Muslim and adhere to the Twelver Shia Islam.[12] The history of human settlement in Qaem Shahr, which also includes the ancient cities of Chamno and Tooji, dates back to the Iron Age. Archaeological excavations in Qaem Shahr have uncovered 5,000-year-old pottery and stone tools.[13] During the Safavid period, the city garnered greater attention. Its initial foundation as Aliabad took place during the Qajar dynasty. However, the era of significant growth and development for Qaem Shahr traces back to the Pahlavi dynasty. During this period, construction of the Trans-Iranian Railway began in Qaem Shahr, and various factories and facilities were established in the city.[14] In September 1935, by a decree of the Council of Ministers, the city's name was changed to Shahi.[15] Following the end of World War II, Qaem Shahr's development continued, making it a hub for population settlement. During the 1979 Iranian Revolution, the name Shahi was changed to Qaem Shahr. Qaem Shahr holds significant strategic geographic importance as it connects Tehran to the northern and northeastern regions of Iran via two different routes: Firuzkuh Road and Haraz Road. It is reported that five million travelers annually commute through Firuzkuh Road to Qaem Shahr, which is linked to a maritime border through the port of Babolsar.[16][17] This city is recognized as one of Iran's tourism centers, offering a variety of tourist attractions. The clock tower in Talaqani Square serves as the symbol of Qaem Shahr. Until 1945, Qaem Shahr was part of Sari County. With the establishment of Shahi County that year, the city became its administrative center. Historically, regions like Shahmirzad District, Firuzkuh County, Savadkuh County, Juybar County,",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_2"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " of Sari County. With the establishment of Shahi County that year, the city became its administrative center. Historically, regions like Shahmirzad District, Firuzkuh County, Savadkuh County, Juybar County, and Simorgh County were originally sections of Qaem Shahr before being designated as independent counties. As of the 2016 census, Qaem Shahr's population was approximately 204,953, making it the most densely populated city in Mazandaran Province and northern Iran.[18] etymology[edit] Chamno: Also known as Jemanan, it consists of two parts: \"Chamn\" (grass) and \"o\" (water in the Tabari language). It referred to an area characterized by lush grasslands and water. Historical records of Tabaristan mention that during the 6th century AH, a river flowed through Chamno. Its bridge was repaired at the personal expense of Shah Ghazi Rustam (460 to 536 AH), the ruler of Tabaristan, to prevent its water from going to waste. Ibn Isfandiyar also frequently mentioned Chamno in the History of Tabaristan. Today, there is a neighborhood called Jemanan in Qaem Shahr. Toji: The origin of the name for the city Toji or Triji remains unclear but may derive from the Toji River located south of Qaem Shahr Shahi: In the early 1300s (solar calendar), the newly established city of Shahi was founded by order of Reza Shah, his birthplace, and Aliabad was renamed Shahi.[19] Qaem Shahr: Following the 1979 Revolution, the city was renamed to Qaem Shahr.[20] Demographics[edit] Population[edit] In 1951, Qaem Shahr's population was around 18,000, growing to 123,684 in 1991.[citation needed] At the time of the 2006 National Census, the city's population was 174,246 in 48,055 households.[21] The following census in 2011 counted 196,050 people in 60,347 households.[22] The 2016 census measured the population of the city as 204,953 people in 68,407 households.[3] History[edit] According to existing evidence, including religious sites such as Imamz",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_3"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " 60,347 households.[22] The 2016 census measured the population of the city as 204,953 people in 68,407 households.[3] History[edit] According to existing evidence, including religious sites such as Imamzadeh Yousef Reza and the tomb of the scholar and jurist Sheikh Tabarsi, Qaem Shahr reflects a long-standing history of civilization and culture dating back to before the 6th century AH. In the city of Shahi, a weekly bazaar was held every Wednesday. On these days, locals from nearby districts, as well as merchants from surrounding villages and even other cities, brought their goods and products to this market for sale. Over time, this bazaar gained significance and established a certain level of prominence and centrality in the region. During the era of the Umayyad dynasty, the Arab rulers, aiming to control and dominate the southern regions of the Caspian Sea, established 44 military outposts stretching from present-day Astara to Esterabad (modern-day Gorgan). One of the most prominent of these posts was the Arta military fortress. These 44 outposts were commonly known as ‚ÄúDine Sar,‚Äù which essentially means ‚Äúprotector of religion.‚Äù At the Arta military fortress, a commander named Bani Abbas, accompanied by 330 soldiers, governed the areas of present-day Qaem Shahr, Arateh, and Sari. Before Christ[edit] Based on the presence of ancient hills, Qaem Shahr boasts a deep and long-standing history: Gardkooh Jemanoon Hill: The antiquity of Gardkooh Hill dates back to the Iron Age. Taleghani Hill: Archaeological findings, historical relics, and human remains from the first millennium have been unearthed here. Dineh Kafashgarkola Hill in Arateh: This hill, located in the village of Kafashgarkola Arateh in Qaem Shahr County, dates back to the first millennium BC, further proving the region's ancient history. Ancient Era[edit] Location of the Tapur tribe in the 2nd century BC, from East Sepidrud to Aserm Hyrcania Before Islam, Mazandaran Province was known as Tapurstan (in Pahlavi: ), derived from the name of the Tapur tribe (in Greek: Œ§Œ¨œÄœÖœÅŒøŒπ). After",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_4"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " to Aserm Hyrcania Before Islam, Mazandaran Province was known as Tapurstan (in Pahlavi: ), derived from the name of the Tapur tribe (in Greek: Œ§Œ¨œÄœÖœÅŒøŒπ). After Islam, the Tabari tribe inherited the name, and their homeland became known as Tabarestan.[23][24][25] According to Vasily Bartold, the Tapurs lived in the southeastern regions of the province and were subjects of the Achaemenid Empire. The Amardians were defeated by Alexander the Great, and later subdued by the Parthians, who resettled them near Rey in the 2nd century BC. The Tapurs then occupied the former lands of the Amardians. In his description of the Deylam region (eastern Gilan on the shores of the Caspian Sea), Ptolemy mentions only the Tapurs.[26] According to Mojtaba Minovi, the Amardian and Tapur tribes inhabited the land of Mazandaran. The Tapurs resided in the mountainous areas, while the Amardians lived in the plains of Mazandaran. In 176 BC, Phraates I relocated the Amardian tribe to the Khvar region, allowing the Tapurs to occupy the entire Mazandaran area, which then became known as Tapurstan.[27] The cities of Amol, Chalous, Klar, Saeedabad, and Royan were part of the Tapur tribe's territory.[28] William Smith, in the Dictionary of Greek and Roman Geography, writes that the Tapur tribe was a people whose settlement throughout different historical periods seems to have extended across a vast area from Armenia eastward to the Oxus River (Amu Darya). Strabo places them near the Caspian Gates and Rey, in Parthia, between the Derbices and Aserm Hyrcania, alongside the Amardians and other groups along the southern shores of the Caspian Sea. This last perspective, which locates the Tapurs along the southern coasts of the Caspian Sea, aligns with the views of Quintus Curtius Rufus, Dionysius, and Pliny the Elder. Ptolemy at times considers the Tapurs as part of the peoples of Media, while elsewhere he associates them with Margiana. There is no doubt that the region currently known as Tabarestan",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_5"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " Dionysius, and Pliny the Elder. Ptolemy at times considers the Tapurs as part of the peoples of Media, while elsewhere he associates them with Margiana. There is no doubt that the region currently known as Tabarestan derives its name from the Tapurs mentioned by Pliny and Quintus Curtius. Aelian provides a peculiar description of the Tapurs who lived in Media.[29] Background[edit] Throughout its history, Qaem Shahr has been known by various names such as Chamno, Tooji, Aliabad, and Shahi. The earliest recorded name of the city, mentioned in Islamic-era sources from the 7th to 9th centuries AH, is Chamno or Jamno. Chamno was the site of a battle in the 3rd century between Soleiman bin Abdollah, a Taherian ruler of Tabarestan, and Hasan bin Zayd, the leader of the Alavids of Tabarestan. Other historical and geographical sources also refer to the city as Tooji, Triji, or Taranjeh. This fortified city, which also had a castle, has been mentioned under different names. Some sources consider Taranjeh and Tooji to be the same location, while others treat them as two distinct places. Zahir al-Din Marashi refers to Tooji and Chamno as villages in the western parts of the Sari province. Based on Zahir al-Din Marashi's accounts, the city of Tooji should be located near present-day Qaem Shahr. In Istakhri's Masalik al-Mamalik, the location of Tooji is described as being near Sari and separate from Mamtabar. A significant historical event at the fortress of Tooji was the battle between the forces of Seyyed Kamal al-Din Marashi and Kiyavastasp Jalali.[30] In sources from the 9th century AH, this city is referred to as the region of Aliabad. In the travelogues of Safavid-era explorers, such as Pietro della Valle, who visited Mazandaran and present-day Qaem Shahr, as well as in Tarikh-e Giti Gosha related to the Zand dynasty period, the city is mentioned under the name Aliabad. In late February 1931, by order of Reza Shah, Aliabad was renamed Shahi.[31] The Position",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_6"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " Tarikh-e Giti Gosha related to the Zand dynasty period, the city is mentioned under the name Aliabad. In late February 1931, by order of Reza Shah, Aliabad was renamed Shahi.[31] The Position of Tujƒ´ in Tabarestan[edit] Tujƒ´ (also referred to as Trƒ´jƒ´, Trƒ´jeh, Tarnjeh, and Barjƒ´) is mentioned as one of the cities of Tabarestan. Ibn Rusta,[32] a historian from the 3rd century, describes Tabarestan as bounded by Gorgan and Qumis in the east, Deylam in the west, the sea in the north, and certain regions of Qumis and Rey in the south. According to Ibn Rusta, Tabarestan consisted of fourteen districts, with Khore of Amol as the capital and central city of the region, and its cities included: Sari, Vasram, Mamteer, Tarnjeh, Roubast, Mileh, Merarkadieh (Kadah), Mehrovan, Tamis, Tamar, Natel, Shalus, Royan, and Kalar (Kalardasht).[33] Estakhri writes that the cities of Amol, Natel, Salus (Chalous), Kalar (Kalardasht), Royan, Mileh, Barjƒ´, Cheshmeh Al-Ham, Mamteer, Sari, Asram, Mehrovan, Lamresk, and Tamisha are part of Tabarestan.[34] Ibn Hawqal, in describing Tabarestan, mentions that Amol is the largest city of Tabarestan and was the seat of government at his time. He describes the distances between cities: from Plur to Amol is one stage; Amol to Mileh is two farsakhs; Mileh to Trƒ´jƒ´ is two farsakhs; Trƒ´jƒ´ to Sari is one stage; Sari to Esterabad is four stages; Esterabad to Gorgan is two stages; Amol to Natel is one stage; Natel to Chalous is one stage; and towards the sea, Ayn Al-Ham is one stage. Ibn Hawqal lists the cities of Amol, Shalus (Chalous), Kalar (Kalardasht), Royan, Mile",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_7"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " to Chalous is one stage; and towards the sea, Ayn Al-Ham is one stage. Ibn Hawqal lists the cities of Amol, Shalus (Chalous), Kalar (Kalardasht), Royan, Mileh, Trƒ´jƒ´, Ayn Al-Ham, Mamteer, Asram, Sariyeh, and Tamisha as belonging to the province of Tabarestan.[35] Maqdisi identifies \"Jurjan, Tabarestan, Deylam, and Jilan\" as belonging to the fifth climatic region of the world in Ahsan al-Taqasim fi Ma'rifat al-Aqalim.[36] Maqdisi also describes Tabarestan as having many mountains and abundant rain, noting Amol as the capital of Tabarestan and cities like Chalous, Mamteer, Tarnjeh, Asram, Sariyeh, Tamisha, and others as part of Tabarestan.[37][38] According to Hudud al-'Alam, Tamisha, Lamresk, Sari, Asram, Mamteer, Trƒ´jƒ´, Mileh, Amol, Al-Ham, Natel, Roudan, Chalous, and Kalar (Kalardasht) are among the cities of Tabarestan. The author of Hudud al-'Alam notes that Natel, Roudan, Chalous, and Kalar (Kalardasht) were small towns located in the mountains and valleys, forming part of Tabarestan but under a different kingdom governed by a ruler called \"Istandar.\"[39][40] Abul Qasim ibn Ahmad Jihani in his book Ashkal al-'Alam mentions the cities of Tabarestan, including: Amol, Natel, Salus (Chalous), Kalaroudan (Kalardasht), Ayn Al-Ham, Mamteer, the ancient city of Asram, Sari, Tamisha, Esterabad, Jurjan, Abaskoon, and Dehestan. He notes the routes from Amol to Deylam, Amol to Natel, from Natel to Salus, from Salus to Kalar, and from Kalar to Deylam.[41] Rabino notes that the extent of Deylam did not exceed more than one stage west of the Kalar",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_8"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " Natel, from Natel to Salus, from Salus to Kalar, and from Kalar to Deylam.[41] Rabino notes that the extent of Deylam did not exceed more than one stage west of the Kalar region of Tabarestan.[42] Hamzeh Esfahani, a historian from the 3rd century, writes in his book History of the Kings and Prophets that Tabarestan had many districts, one of which was the region of Deylam, and Iranians referred to the people of Deylam as the \"Kurds of Tabarestan,\" just as Arabs called the people of Iraq the \"Kurds of SorestƒÅn.\"[43] Ibn Esfandiyar describes Tabarestan as spanning east to west, bounded by Dinargar to Malat, roughly equivalent to the present-day Kordkuy and Rudsar.[44] In his book History of Tabarestan, Ibn Esfandiyar lists cities in Tabarestan that had mosques and congregational prayer spaces: Amol, Asram, Sari, Mamteer, Roudbast, Trijeh, Mileh, Mehrovan, Ahlam, Pay Dasht, Natel, Kanu, Shalus (Chalous), Bikhuri, Lamresk, Tamish in the plains; and in the mountains, Kalar (Kalardasht), Royan, Namar, Kajuyeh, Vimeh, Shelanbeh, Vafad, Al-Jomha, Sharmam, Larjan, Omidvar Kuh, Prim, and Hazarger.[45] Zahir al-Din Mar'ashi in his book History of Tabarestan, Royan, and Mazandaran describes the boundaries of Tabarestan: in the east, Dinargar, and Geography[edit] Geographical Location[edit] According to historical records, the initial foundation of this city was established during the Qajar era under the name Aliabad. It originally consisted of a village with commercial and residential units near today's Taleghani Square, along with neighborhoods surrounding it and large villages such as Chamno (present-day Jemnan, which is now a part of the city itself), Qadikola-ye Bozorg, and Kuchaksara on its outskirts. After the fall of the Qajar dynasty and the beginning of Reza Shah's reign",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_9"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " Jemnan, which is now a part of the city itself), Qadikola-ye Bozorg, and Kuchaksara on its outskirts. After the fall of the Qajar dynasty and the beginning of Reza Shah's reign, due to its strategic regional position (serving as a transit route for trade and pilgrimage caravans from neighboring provinces such as Tehran, Gilan, and Khorasan), the area gained increased importance. Today, it is recognized as a geographically strategic city, linking Tehran to the north and northeast through two different routes: Firuzkuh Road and Haraz road. It is reported that annually, five million travelers pass through the Firuzkuh Road to Qaem Shahr, which also connects to the maritime border via the port of Babolsar.[46][47] From a climatic and geographical perspective, the area experiences a Mediterranean and moderate Caspian climate, characterized by humid summers, while the southern regions have relatively cold and rainy winters. The city is located 20 kilometers from the provincial center and 180 kilometers north of Tehran, situated between the Caspian Sea and the Alborz Mountains. Qaem Shahr is where the North Iranian railway quits the fertile plains of Mazandaran to cross the highest mountain range of the Middle East, the Alborz. Reza Shah, Qaemshahr railway Sheykh Tabarsi's tomb in Qaem Shahr Climate[edit] Climate data for Qara Kheyl(normals 1991-2020, extremes 1984-2023) elevation: 14.7 Month Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Year Record high ¬∞C (¬∞F) 30.4(86.7) 34.6(94.3) 36.2(97.2) 39.0(102.2) 40.6(105.1) 39.6(103.3) 38.4(101.1) 40.6(105.1) 40.2(104.4) 38.6(101.5) 32.2(90.0) 28.4(83.1) 40.6(105.1) Mean daily maximum ¬∞C (¬∞F) 12.6(54.7) 12.7(54.9) 15.",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_10"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "0) 28.4(83.1) 40.6(105.1) Mean daily maximum ¬∞C (¬∞F) 12.6(54.7) 12.7(54.9) 15.5(59.9) 20.1(68.2) 25.3(77.5) 29.1(84.4) 30.9(87.6) 31.8(89.2) 28.7(83.7) 24.3(75.7) 18.2(64.8) 14.1(57.4) 21.9(71.5) Daily mean ¬∞C (¬∞F) 7.3(45.1) 7.7(45.9) 10.6(51.1) 14.9(58.8) 20.3(68.5) 24.2(75.6) 26.1(79.0) 26.5(79.7) 23.5(74.3) 18.7(65.7) 12.8(55.0) 8.8(47.8) 16.8(62.2) Mean daily minimum ¬∞C (¬∞F) 3.1(37.6) 3.7(38.7) 6.7(44.1) 10.8(51.4) 16.0(60.8) 20.0(68.0) 22.2(72.0) 22.4(72.3) 19.6(67.3) 14.4(57.9) 8.7(47.7) 4.6(40.3) 12.7(54.8) Record low ¬∞C (¬∞F) ‚àí6.0(21.2) ‚àí5.2(22.6) ‚àí1.8(28.8) 0.2(32.4) 5.4(41.7) 13.0(55.4) 16.6(61.9) 14.2(57.6) 11.6(52.9) 4.2(39.6) ‚àí3.8(",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_11"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " 13.0(55.4) 16.6(61.9) 14.2(57.6) 11.6(52.9) 4.2(39.6) ‚àí3.8(25.2) ‚àí3.6(25.5) ‚àí6.0(21.2) Average precipitation mm (inches) 70.7(2.78) 66.1(2.60) 67.6(2.66) 43.8(1.72) 27.3(1.07) 30.1(1.19) 30.0(1.18) 33.4(1.31) 77.1(3.04) 91.9(3.62) 110.2(4.34) 74.5(2.93) 722.7(28.44) Average precipitation days (‚â• 1.0 mm) 7.2 7.8 7.7 6.3 4.8 3.9 4.5 4.7 6.9 6.3 7.6 7.2 74.9 Average rainy days 9.5 10.7 13 11.2 7.8 5 5.7 6.5 8 8.1 9.4 9.5 104.4 Average snowy days 0.9 0.85 0.1 0 0 0 0 0 0 0 0.25 0 2.1 Average relative humidity (%) 84 84 83 82 78 77 79 78 81 82 84 85 81 Average dew point ¬∞C (¬∞F) 4.5(40.1) 4.9(40.8) 7.5(45.5) 11.5(52.7) 16.1(61.0) 19.7(67.5) 21.8(71.2) 22.1(71.8) 19.8(67.6) 15.3(59.5) 10.0(50.0) 6.1(43.0) 13.3(",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_12"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " 22.1(71.8) 19.8(67.6) 15.3(59.5) 10.0(50.0) 6.1(43.0) 13.3(55.9) Mean monthly sunshine hours 139 119 131 153 204 222 212 206 166 173 146 137 2,008 Source 1: NOAA[48] Source 2: IRIMO (extremes[49]), meteomanz(snow days 2004-2023, extremes since 2021)[50] Notable people[edit] Behdad Salimi (born 1989) ‚Äì weightlifter Farhad Majidi ‚Äì football player Nader Dastneshan (1960‚Äì2021) ‚Äì football coach Mehrdad Oladi (1985‚Äì2016) ‚Äì football player Mehrdad Kafshgari (born 1987) ‚Äì football player Fereydoon Fazli (born 1971) ‚Äì football player Babak Nourzad (born 1978) ‚Äì wrestler Mojtaba Tarshiz (born 1978) ‚Äì football player Farshid Talebi (born 1981) ‚Äì football player Maysam Baou (born 1983) ‚Äì football player Mehdi Jafarpour (born 1984) ‚Äì football player Mohammad Abbaszadeh (born 1990) ‚Äì football player Ali Alipour (born 1995) ‚Äì football player Behnam Tayyebi (born 1975) ‚Äì wrestler Ahmad Mohammadi (born 1989) ‚Äì wrestler Mansour Hedayati ‚Äì (residence) ‚Äì poet Notable places[edit] Gerdkooh Hills Old Municipality Building Islamic Azad University Qaemshahr Branch Telar Jungle Park Tomb of Sheykh Tabarsi Qadi Kola Forest Paein Lamok Park Siah Dasht Cave Imamzadeh Seyed Mohammad Zarin Nava Kerchang Lagoon Zamzam Dam Talar River Kutna Village Golpol Lake Tomb of Seyyed Abu Saleh Reykandeh Village Agriculture and Animal Husbandry[edit] The fertile lands of this county have significant potential for cultivating various crops, especially wheat, barley, rice, vegetables, soybeans, and more. Additionally, Qaem Shahr is known as the hub of",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_13"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " Agriculture and Animal Husbandry[edit] The fertile lands of this county have significant potential for cultivating various crops, especially wheat, barley, rice, vegetables, soybeans, and more. Additionally, Qaem Shahr is known as the hub of citrus production in Iran;[51] the highly productive citrus orchards in this city, particularly along the Military Road, are well-regarded.[52] Other products, such as sugarcane,[53] honey, silk,[54] hemp, and sesame, are found in forested and mountainous villages like Seyyed Abusaleh, Golafshan, and Rikandeh. Cattle, sheep, and goat rearing are also common practices in various plain and mountainous areas, utilizing the resources available in each village. Sugarcane Cultivation[edit] The cultivation and traditional production of red sugar from sugarcane are mostly observed in the villages of Seyf Kati, Rikandeh, and Seyyed Abusaleh in Qaem Shahr. Sugarcane is processed in traditional workshops, producing not only sugar but also molasses. The resulting sugar, which is brown or locally called \"black sugar,\" has numerous health benefits. These include alleviating chronic fatigue, cleansing liver toxins, soothing mouth and tongue heat, and reducing gum inflammation. It is also highly beneficial in treating favism, anemia, internal jaundice, and nervous disorders. Following a period of decline, sugarcane cultivation continued in a very basic form and on a small scale in Mazandaran and favorable areas near the Caspian Sea. During the reign of Naser al-Din Shah and with the efforts of Amir Kabir, steps were taken to revive this industry. Sugarcane from Mazandaran was brought for cultivation in Khuzestan. This effort in Mazandaran and Khuzestan involved importing new cuttings from India. However, sugar production from sugarcane did not thrive in either Mazandaran or Khuzestan.[55][56][57] Sports[edit] Qaem Shahr is one of the sports hubs in Iran[51] and has consistently excelled in various sports disciplines such as football, wushu,[58] kabaddi,[59] weightlifting,[60][61] roller skating,[62] swimming,[63][64][65] basketball,[66] wrestling, gymnastics,[67] boxing,[68] chess",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_14"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " football, wushu,[58] kabaddi,[59] weightlifting,[60][61] roller skating,[62] swimming,[63][64][65] basketball,[66] wrestling, gymnastics,[67] boxing,[68] chess,[69] and martial arts.[70] It has produced international and world-renowned athletes in these disciplines. In 2010, athletes from this city earned 189 medals at the world, Asian, international, and national levels within just seven months, making Qaem Shahr the most honored county in this regard in the country.[71] History of Football in Qaem Shahr[edit] Football has a long history in Qaem Shahr. The Vatani Stadium (formerly Shahna) was built in the 1940s in Qaem Shahr. In the distant past, teams such as Taj Shahi before the 1950s, Bank Mellat, Azmayesh, and F.C. Nassaji Mazandaran (founded in 1959)‚Äîone of the oldest teams in Iran and a symbol of football in northern Iran‚Äîwere prominent. Another notable team was Naft Qaem Shahr, which was later dissolved.[72] In the 1980s, football in Qaem Shahr was divided between two main teams: Nassaji and Sanat Naft Qaem Shahr, which competed in Iran's first league, Azadegan League (before the Persian Gulf Pro League was established). These two teams were tough competitors, even defeating Esteghlal or Persepolis in Qaem Shahr or holding them to draws in Tehran. Nassaji Mazandaran (2) Persepolis Tehran (0) Goals: Abbas Kavand (70) and Ghadir Ghaffari (93)[dead link] During the 1980s, Hossein Mesgar Saravi was the captain of the Iran national football team, and football in Qaem Shahr was associated with the brilliance of players like Nader Dastneshan. (Nader Dastneshan scored 9 goals for Nassaji in 8 games during the Iranian league in 1993, a record that remains unbroken to date.)[73] However, the decline of football in Qaem Shahr began abruptly, with Naft being dissolved and Nassaji relegated to the first division. In 2018, after twenty-four years",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_15"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " a record that remains unbroken to date.)[73] However, the decline of football in Qaem Shahr began abruptly, with Naft being dissolved and Nassaji relegated to the first division. In 2018, after twenty-four years of waiting, Nassaji returned to Iran's Persian Gulf Pro League.[74] Although Qaem Shahr has introduced many players to the Premier League and national team in recent years, it was unable to fill Nassaji's absence in the Pro League.[75] Nassaji Mazandaran is the champion of the 2021‚Äì2022 Iran Football Hazfi Cup.[76][77][78][79] See also[edit] Iran portal Notes[edit] ^ Also romanized as QƒÅ‚Äôem Shahr; formerly known as ShƒÅhi (ÿ¥ÿßŸá€å)[4] References[edit] ^ OpenStreetMap contributors (15 January 2025). \"Qaem Shahr, Qaem Shahr County\" (Map). OpenStreetMap (in Persian). Retrieved 15 January 2025. ^ \"Statistical Center of Iran > Home\". ^ a b Census of the Islamic Republic of Iran, 1395 (2016): Mazandaran Province. amar.org.ir (Report) (in Persian). The Statistical Center of Iran. Archived from the original (Excel) on 7 October 2021. Retrieved 19 December 2022. ^ Qaem Shahr can be found at GEOnet Names Server, at this link, by opening the Advanced Search box, entering \"-3078746\" in the \"Unique Feature Id\" form, and clicking on \"Search Database\". ^ Habibi, Hassan (c. 2024) [Approved 21 June 1369]. Approval of the organization and chain of citizenship of the elements and units of the divisions of Mazandaran province, centered in Sari city. lamtakam.com (Report) (in Persian). Ministry of the Interior, Defense Political Commission of the Government Council. Subject Letter 3233.1.5.53; Notification 83346/T144K. Archived from the original on 14 January 2024. Retrieved 14 January 2024 ‚Äì via Lam ta Kam. ^ \"ŸÖÿßÿ≤ŸÜÿØÿ±ÿßŸÜ- ÿßÿØÿßÿ±Ÿá ÿ´ÿ®ÿ™ ÿßÿ≠ŸàÿßŸÑ ŸÇÿßÿ¶ŸÖÿ¥Ÿáÿ± - ÿ™ÿßÿ±€åÿÆ⁄ÜŸá\". www.sab",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_16"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " 2024 ‚Äì via Lam ta Kam. ^ \"ŸÖÿßÿ≤ŸÜÿØÿ±ÿßŸÜ- ÿßÿØÿßÿ±Ÿá ÿ´ÿ®ÿ™ ÿßÿ≠ŸàÿßŸÑ ŸÇÿßÿ¶ŸÖÿ¥Ÿáÿ± - ÿ™ÿßÿ±€åÿÆ⁄ÜŸá\". www.sabteahval.ir (in Persian). Archived from the original on 6 March 2021. Retrieved 17 February 2022. ^ \"Image Viewer and Downloader | Free and Permanent File Upload\". imgurl.ir. Retrieved 9 October 2024. ^ Geographic International System Data Center ^ Naseri Ashrafi, Jahangir (2020). Jafar Shoja Kivani (ed.). Encyclopedia of Tabarestan and Mazandaran, Volume 3. Nashreni. p. 201. ^ Naseri Ashrafi, Jahangir (1998). The Great Tabari Dictionary. Vol. 1. Tehran: Andisheh Pardaz and Khane Sabz. p. 31. ISBN 964-91131-5-0. ^ Habib Borjian (2005), Verb Markers in Eastern Mazandarani: Qaem Shahr Dialect, p. 16 ^ Population and Households Statistics Based on the 2016 National Census of Mazandaran Province ^ https://www.irna.ir/news/82005978/ŸÇÿßÿ¶ŸÖ‚Äåÿ¥Ÿáÿ±-⁄©ŸáŸÜ-ÿ¥Ÿáÿ±-ŸÖÿßÿ≤ŸÜÿØÿ±ÿßŸÜ-ÿ™ÿ±ÿß-ŸÅÿ±ÿß-ŸÖ€å‚ÄåÿÆŸàÿßŸÜÿØ ^ \"Archived Version\". Archived from the original on 29 June 2021. Retrieved 28 October 2021. ^ Moein, Mohammad (1985) [1966]. Persian Dictionary. Vol. 5. Tehran: Amir Kabir Publishing Institute. p. 883. ^ \"History of the City\". Archived from the original on 24 January 2012. Retrieved 27 January 2012. ^ Hassanzadeh Ahmadi, Mousa (1979). Summary of Tabarestan. Shelfine. ^ Maps, Weather, Videos, and Airports for Qa'emshahr, Iran ^ http://www.shomalnews.com/view/75497/%ŸÖÿπÿ±ŸÅ€å20ÿ¥Ÿáÿ±Ÿáÿß%20Ÿà%20ÿ¨ÿßÿ∞ÿ®Ÿá%20Ÿáÿß€å%20ÿßÿ≥ÿ™ÿßŸÜ%20ŸÖÿßÿ≤ŸÜÿØ",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_17"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " ^ http://www.shomalnews.com/view/75497/%ŸÖÿπÿ±ŸÅ€å20ÿ¥Ÿáÿ±Ÿáÿß%20Ÿà%20ÿ¨ÿßÿ∞ÿ®Ÿá%20Ÿáÿß€å%20ÿßÿ≥ÿ™ÿßŸÜ%20ŸÖÿßÿ≤ŸÜÿØÿ±ÿßŸÜ/ ^ http://hamshahrionline.ir/details/44782 ^ Census of the Islamic Republic of Iran, 1385 (2006): Mazandaran Province. amar.org.ir (Report) (in Persian). The Statistical Center of Iran. Archived from the original (Excel) on 20 September 2011. Retrieved 25 September 2022. ^ Census of the Islamic Republic of Iran, 1390 (2011): Mazandaran Province. irandataportal.syr.edu (Report) (in Persian). The Statistical Center of Iran. Archived from the original (Excel) on 19 January 2023. Retrieved 19 December 2022 ‚Äì via Iran Data Portal, Syracuse University. ^ Emadi, Asadollah (1993). Revisiting the History of Mazandaran. Mazandaran Culture House Publications. p. 72. ^ Marquart, Josef (1994). Eranshahr Based on the Geography of Moses of Chorene. Translated by Maryam Mir Ahmadi. Tehran Information Publications. p. 245. ^ Borjian, Habib (2004). \"Mazandaran: Language and People (The State of Research)\". Yerevan State University: 289. doi:10.1163/1573384043076045. ^ Bartold, Vasily (1930). Historical Geography of Iran. Tehran Union. p. 283. ^ Minovi, Mojtaba (1963). Maziyar. Amir Kabir Publishing Institute. p. 9. ^ Mohammadpour, Safarali (2007). Chalous in the Mirror of History. Masoud Kalam Publications. p. 370. ^ \"Dictionary of Greek and Roman Geography, illustrated by numerous engravings on wood. William Smith, LLD. London. Walton and Maberly, Upper Gower Street and Ivy Lane, Paternoster Row; John Murray, Albemarle Street. 1854. ,TAPU¬¥RI\". www.perseus.tufts.edu. Retrieved 4 February 2021. ^ Nasri Ashrafi, Jahangir (2020). J",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_18"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": ", Albemarle Street. 1854. ,TAPU¬¥RI\". www.perseus.tufts.edu. Retrieved 4 February 2021. ^ Nasri Ashrafi, Jahangir (2020). Jafar Shoja Keyvani (ed.). Encyclopedia of Tabarestan and Mazandaran, Vol. 3. Nashr Ney. p. 200. ^ Nasri Ashrafi, Jahangir (2020). Jafar Shoja Keyvani (ed.). Encyclopedia of Tabarestan and Mazandaran, Vol. 3. Nashr Ney. p. 200. ^ Ibn Rusta, Ahmad ibn Umar (1986). Al-Alaq al-Nafisa. Translated by Hossein Ghareh Chaanloo. Amir Kabir Publishing Institute. p. 176. ^ Aghajani, Hashem (2013). \"The Origins of Tapurians Until the Formation of Tabarestan City\" (PDF). 8 (31): 5‚Äì9. {{cite journal}}: Cite journal requires |journal= (help) ^ Sajadi, Mohammad Taghi (1999). History and Historical Geography of Ramsar. Moein Publications. p. 67. ^ Zabihi, Ali (2012). Amol. Rasanesh Novin. p. 18. ^ Cite error: The named reference Fath was invoked but never defined (see the help page). ^ Hossein Hosseinian Moghadam, Mansour Dadashnejad, Hossein Moradinassab, and Mohammadreza Hedayatpanah, under the supervision of Dr. Seyyed Ahmadreza Khezri. History of Shiism 2: Governments, Dynasties, and Scientific and Cultural Works. Tehran: Research Institute for Seminary and University, 2014. 145. ISBN 978-964-7788-37-3 ^ Maqdisi, Shams al-Din (1982). Ahsan al-Taqasim fi Ma'rifat al-Aqalim, Volume II. Authors and Translators Association of Iran. p. 519. ^ Sotoudeh, Manouchehr (1983). Hudud al-'Alam. Language and Culture Iran Publications. p. 146. ^ Hoseynnia Amirkelayi",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_19"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": " Association of Iran. p. 519. ^ Sotoudeh, Manouchehr (1983). Hudud al-'Alam. Language and Culture Iran Publications. p. 146. ^ Hoseynnia Amirkelayi, Hanieh; Mousavi Hajji, Seyyed Rasoul (2020). \"Study of Islamic Era Ceramics of the Historical City of Natel\". Archaeological Studies of Parse. 4 (14): 88. ^ Eghbal, Mehdi (2010). History of Chalous. Shamloo Publications. p. 23. ^ Sajadi, Mohammad Taghi (1999). History and Historical Geography of Ramsar. Moein Publications. p. 57. ^ Esfahani, Hamzeh (1983). History of Prophets and Kings (History of the Kings and Prophets). Iranian Cultural Foundation Publications. p. 214. ^ Cite error: The named reference Nabi was invoked but never defined (see the help page). ^ Eghbal, Mehdi (2010). History of Chalous. Shamloo Publications. p. 23. ^ \"History of the City\". Archived from the original on 24 January 2012. Retrieved 27 January 2012. ^ Hasanzadeh Ahmadi, Mousa (1979). A Summary of Tabarestan. Shelfine. ^ \"World Meteorological Organization Climate Normals for 1991-2020: Gharakhil\" (CSV). ncei.noaa.gov. NOAA. Retrieved 28 January 2024. ^ \"Form 6: Temperature Records Lowest in C. Station: Gharaghil Ghaemshahr (40737)\". Chaharmahalmet. IRIMO. Archived from the original on 14 June 2016. Retrieved 19 January 2024. \"Form 7: Temperature Records Highest in C. Station Gharakhil Ghaemshahr (40737)\". Chaharmahalmet. IRIMO. Archived from the original on 14 June 2016. Retrieved 19 January 2024. ^ \"GHARAKHIL - Weather data by months\". meteomanz. Retrieved 4 July 2024. ^ a b Qaemshahr is the hub of citrus and sports in the country ^ http://www.yjc.ir/fa/news",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_20"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "ARAKHIL - Weather data by months\". meteomanz. Retrieved 4 July 2024. ^ a b Qaemshahr is the hub of citrus and sports in the country ^ http://www.yjc.ir/fa/news/4256324/ÿµÿßÿØÿ±ÿßÿ™-345-ÿ™ŸÜ€å-ÿßŸÜŸàÿßÿπ-ŸÖÿ≠ÿµŸàŸÑÿßÿ™-⁄©ÿ¥ÿßŸàÿ±ÿ≤€å-ÿßÿ≤-ŸÇÿßÿ¶ŸÖÿ¥Ÿáÿ± ^ \"Archived Version\". Archived from the original on 29 March 2013. Retrieved 24 April 2013. ^ \"Archived Version\". Archived from the original on 28 August 2012. Retrieved 24 April 2013. ^ http://www.magiran.com/npview.asp?ID=2588838 ^ \"Archived Version\". Archived from the original on 5 October 2018. Retrieved 24 April 2013. ^ http://www.yjc.ir/fa/news/4248082/ÿ®ÿ±ÿØÿßÿ¥ÿ™-140ÿ™ŸÜ-ŸÜ€åÿ¥⁄©ÿ±-ÿßÿ≤-ÿßÿ±ÿßÿ∂€å-⁄©ÿ¥ÿßŸàÿ±ÿ≤€å-ŸÇÿßÿ¶ŸÖÿ¥Ÿáÿ± ^ \"Qaemshahr, as the hub of wushu in the country, requires a specialized hall\". Archived from the original on 12 January 2013. Retrieved 10 October 2012. ^ \"Qaem Shahr Kabaddi reaches the semi-final stage of the national kabaddi league\". Archived from the original on 12 January 2013. Retrieved 10 October 2012. ^ http://sari.irna.ir/News/80304910/ŸÇÿßÿ¶ŸÖÿ¥Ÿáÿ±-ŸÇŸáÿ±ŸÖÿßŸÜ-ÿ±ŸÇÿßÿ®ÿ™‚ÄåŸáÿß€å-Ÿàÿ≤ŸÜŸá‚Äåÿ®ÿ±ÿØÿßÿ±€å-ÿ¨ŸàÿßŸÜÿßŸÜ-ŸÖÿßÿ≤ŸÜÿØÿ±ÿßŸÜ-ÿ¥ÿØ/Ÿàÿ±ÿ≤ÿ¥€å/[dead link] ^ \"Archived Version\". Archived from the original on 24 May 2013. Retrieved 10 October 2012. ^ http://www.mehrnews.com/fa/newsdetail.aspx?NewsID=1696191[dead link] ^ http://www.mazaniha.com/fa/news.php?id=172&page_id=&dir_id=5[dead link] ^ http://vazeh.com/n-1450912.html ^ http://www.farsnews.ir/newstext.php?",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_21"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "://www.mazaniha.com/fa/news.php?id=172&page_id=&dir_id=5[dead link] ^ http://vazeh.com/n-1450912.html ^ http://www.farsnews.ir/newstext.php?nn=13910430000038 ^ \"Archived Version\". Archived from the original on 9 April 2014. Retrieved 10 October 2012. ^ \"Archived Version\". Archived from the original on 26 December 2012. Retrieved 10 October 2012. ^ http://www.mehrnews.com/fa/NewsDetail.aspx?NewsID=419753[dead link] ^ \"Archived Version\". Archived from the original on 5 March 2016. Retrieved 10 October 2012. ^ http://www.farsnews.ir/newstext.php?nn=9004190721 ^ \"189 medals won by Qaem Shahr athletes this year\". Archived from the original on 4 March 2016. Retrieved 22 February 2012. ^ \"Archived Version\". Archived from the original on 10 September 2012. Retrieved 3 April 2013. ^ \"Archived Version\". Archived from the original on 8 August 2014. Retrieved 6 August 2014. ^ \"Nassaji promoted to the Premier League with six goals; Tigers create history at Takhti Stadium\". Archived from the original on 8 May 2018. Retrieved 11 May 2018. ^ \"Archived Version\". Archived from the original on 19 August 2012. Retrieved 3 April 2013. ^ \"Nassaji Mazandaran crowned Hazfi Cup champions\". Al Arabiya Farsi (in Persian). 27 April 2022. Retrieved 28 April 2022. ^ \"Nassaji Mazandaran crowned Hazfi Cup champions; the trophy goes to the men of the \"Tired City\"\". Mehr News Agency (in Persian). 27 April 2022. Retrieved 28 April 2022. ^ \"Nassaji crowned Hazfi Cup football champions\". ISNA (in Persian). 27 April 2022. Retrieved 28 April 2022. ^ \"Video; Nassaji's celebration as Hazfi Cup champions\". IRNA (in Persian). 28 April 2022. Retrieved 28 April 2022. Columbia Encyclopedia Authority control databases: Geographic MusicBrainz area vte",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_22"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "2. ^ \"Video; Nassaji's celebration as Hazfi Cup champions\". IRNA (in Persian). 28 April 2022. Retrieved 28 April 2022. Columbia Encyclopedia Authority control databases: Geographic MusicBrainz area vteMazandaran province, IranCapital Sari Counties and citiesAbbasabad County Abbasabad Kelarabad Salman Shahr Amol County Amol Babakan Dabudasht Emamzadeh Abdollah Gazanak Rineh Babol County Babol Amirkola Galugah Gatab Khush Rudpey Marzikola Zargar(Zargarmahalleh) Babolsar County Babolsar Bahnemir Hadishahr(Kalleh Bast) Behshahr County Behshahr Khalil Shahr Rostamkola Chalus County Chalus Hachirud Marzanabad Fereydunkenar County Fereydunkenar Astaneh-ye Sara Galugah County Galugah Juybar County Juybar Kuhi Kheyl Kelardasht County Kelardasht Mahmudabad County Mahmudabad Sorkhrud Miandorud County Surak Tabaqdeh Neka County Neka North Savadkuh County Shirgah Nowshahr County Nowshahr Kojur Pul Nur County Nur Baladeh Chamestan Izadshahr Royan Qaem Shahr County Qaem Shahr Arateh Ramsar County Ramsar Dalkhani Ketalem and Sadat Shahr Sari County Sari Akand Farim Kiasar Pain Hular Savadkuh County Zirab Alasht Pol-e Sefid Simorgh County Kiakola Tonekabon County Tonekabon Khorramabad Nashtarud Shirud Sights Mount Damavand Abbas Abad Historical Complex Lar National Park Badab-e Surt Mausoleum of Mir Bozorg Davazdah Cheshmeh Dasht-e Naz National Park Gohar Tepe Larijan Hot Spring Imamzadeh Abbas of Sari Resket Tower Shahandasht Waterfall Tomb of Haydar Amuli Miankaleh peninsula Farahabad Complex Watchtower of Babol Mollana Mosque Dohezar Forest Lajim Tower Kangelo Castle Sisangan Forest Park Challdareh National Park Veresk Bridge Mohammad Hassan Khan Bridge Chaikhoran Palace Namakabro",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_23"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "abad Complex Watchtower of Babol Mollana Mosque Dohezar Forest Lajim Tower Kangelo Castle Sisangan Forest Park Challdareh National Park Veresk Bridge Mohammad Hassan Khan Bridge Chaikhoran Palace Namakabrood Aerial tramway Javaher Deh Nima Yooshij House Sefid Chah Cemetery Ab Pari Waterfall Kolbadi House Lake of Ghosts Mijran Lake Safi Abad Palace Gharmerez spa Avidar Lake Alendan lake Lar Dam Azad Kuh Alasht Kolakchal Deryuok Sari Clock Square Tamishan Palace Gerdkooh Hills Filband Alam-Kuh Jameh Mosque of Amol Jameh Mosque of Babol Jameh Mosque of Sari Palaeolithic Hotu and Kamarband Caves Markuh Castle Galehgardan Vaziri Bath of Sari Ramsar Palace Dalkhani Jungle Paein Lamouk Park Babol Museum Khoshedaran Museum of natural history Kandolus Sari's clock square Palace of Behshahr Churat Lake Gol-e Zard Cave Tirkan Waterfall Danial Cave Babolsar Boating Pier Elimalat Lake Gabri Tonekabon Espahbod Khorshid Cave Mirza Kuchak Khan Forest Park Alimastan Village Imamzadeh Kati Hill Moalagh Bridge Ramsar Hotel Nassereddin Shah relief Kashpel Forest Park Shur Mast Lake Baliran Jungle Kheshtpol Bridge Valasht lake of Kelardasht Tomb of Sultan Mohammad Taher Takor Tekyeh Sorkh Roud Wetland Dokhaharan lake Qaleh Gardan Malek Bahman Castle Chehel dar Castle Gazou Waterfall Cheshmeh Kileh Bridge Sangeno Waterfall DD Center Amir Abad Ecobiology Garden Nowshahr Saghanefar populated places List of cities, towns and villages in Mazandaran Province vte Qaem Shahr CountyCapital Qaem Shahr DistrictsCentralCities Qaem Shahr Arateh Rural Districts and villagesAliabad Abmal Ahangar Kola Chaleh Zamin Chepi Denj Kola Eskandar Kola Fulad Kola Gol Afshan Macheh Bon Malek Kola Matan Kola Qadi Kola-ye Bozorg Shahrak-e Yasrab Shahrud Kola Talar Pos",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_24"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "j Kola Eskandar Kola Fulad Kola Gol Afshan Macheh Bon Malek Kola Matan Kola Qadi Kola-ye Bozorg Shahrak-e Yasrab Shahrud Kola Talar Posht-e Olya Talar Posht-e Sofla Vaskas Vosta Kola Balatajan Afra Afra Koti Asiab Sar Bagh Dasht Bala Joneyd-e Lakpol Bala Rostam Hajji Barf Kola Bi Kola Bibi Kola Chaft-e Kola Chamrandeh Dizabad Estarabad Mahalleh Fenderi Fenderi-ye Nam Avar Kola Gavan Ahangar Gazneh Kola Hajji Kola Hajji Kola-ye Arazlu Hajji Kola-ye Sanam Kamangar Kola Kardgar Khatir Kashka Khatir Kola Khorma Kola Kolar Darreh Malek Kheyl Meydan Sar Mi Kola Musa Kheyl Now Kola Nowgiri Owji Talar Pain Rostam Pasha Kola Qalzam Kola Qara Kheyl Rangriz Kola Sanam Sang Koti Seraj Kola Shah Kola-ye Said Kashi Shami Kola Sheykh Koli Sukhteh Kola Tarsi Kola Til Khani Torkaman Kheyl Vaki Kola Valvand Bisheh Sar Abu Kheyl-e Arateh Afra Takht Arateh Dasht Bala Afrakoti Bur Kheyl-e Arateh Juja Deh-e Arateh Kafshgar Kola-ye Arateh Laharem Taluk Mehdiabad Pain Afrakoti Pain Lamuk Pasha Kola-ye Afrakoti Qadi Kola-ye Arateh Qasem Kheyl-e Arateh Sheykh Rajeh Kuhsaran Kar Chang Kutna Mian Rud Par Chinak Reykandeh Saru Kola Seyf Koti Seyyed Abu Saleh Nowkand Kola Abjar Afrapol Ahangar Kola-ye Now Kandeh Alamshir Bala Lamuk Chamaz Koti Choft Sar Dashtian Div Kola-ye Olya Div Kola-ye Sofla Duk Furija Gileh Kola Hajjiabad Hardow Rud Kasegar Kola",
    "token_count": 500,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_25"
  },
  {
    "id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea",
    "created_at": "2025-07-26T15:29:20.446437+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Ghaemshahr",
    "title": "Qaem Shahr - Wikipedia",
    "text": "shir Bala Lamuk Chamaz Koti Choft Sar Dashtian Div Kola-ye Olya Div Kola-ye Sofla Duk Furija Gileh Kola Hajjiabad Hardow Rud Kasegar Kola Kelagar Mahalleh Kerva Khomir Kandeh Khonar Darvish Lehmal Mavarem Kola Now Deh Owjabandan Pain Jadeh Parchi Kola Qadi Kola Rekabdar Kola Rostam Kola Zahed Kola Zilet Retrieved from \"https://en.wikipedia.org/w/index.php?title=Qaem_Shahr&oldid=1299176004\" Categories: Populated places in Qaem Shahr CountyCities in Mazandaran provinceHidden categories: Pages using gadget WikiMiniAtlasPages using the Phonos extensionPages with reference errorsCS1 Persian-language sources (fa)CS1 errors: missing periodicalPages with broken reference namesCS1: unfit URLAll articles with dead external linksArticles with dead external links from October 2019Articles with dead external links from April 2025Articles with dead external links from June 2020Articles with short descriptionShort description matches WikidataUse dmy dates from May 2023Short description is different from WikidataArticles containing Persian-language textCoordinates on WikidataPages including recorded pronunciationsAll articles with unsourced statementsArticles with unsourced statements from June 2024Articles with dead external links from February 2020 Search Search Qaem Shahr 69 languages Add topic",
    "token_count": 315,
    "chunk_id": "43b29bcf-27a0-45eb-bb0f-1330e265cfea_26"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "'s-Hertogenbosch - Wikipedia Jump to content Coordinates: 51¬∞41‚Ä≤N 5¬∞18‚Ä≤EÔªø / Ôªø51.683¬∞N 5.300¬∞EÔªø / 51.683; 5.300 From Wikipedia, the free encyclopedia City in North Brabant, Netherlands \"Den Bosch\" redirects here. For the association football team, see FC Den Bosch. For the basketball team, see Heroes Den Bosch. For the field hockey club, see HC 's-Hertogenbosch. For all uses of Bosch, see Bosch (disambiguation). This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: \"'s-Hertogenbosch\" ‚Äì news ¬∑ newspapers ¬∑ books ¬∑ scholar ¬∑ JSTOR (December 2021) (Learn how and when to remove this message) City and municipality in North Brabant, Netherlands's-Hertogenbosch Den BoschCity and municipalityView over the city centreThe city seen from the Bossche BrookBinnendieze canalsDragon FountainHieronymus BoschNorth Brabant MuseumSt. John's CathedralCity hall of 's-Hertogenbosch FlagCoat of armsBrandmarkLocation in North Brabant's-HertogenboschLocation within the NetherlandsShow map of Netherlands's-HertogenboschLocation within EuropeShow map of EuropeCoordinates: 51¬∞41‚Ä≤N 5¬∞18‚Ä≤EÔªø / Ôªø51.683¬∞N 5.300¬∞EÔªø / 51.683; 5.300CountryNetherlandsProvinceNorth BrabantGovernment[1] ‚Ä¢ BodyMunicipal council ‚Ä¢ MayorJack Mikkers (VVD)Area[2] ‚Ä¢ Municipality117.81 km2 (45.49 sq mi) ‚Ä¢ Land109.99 km2 (42.47 sq mi) ‚Ä¢ Water7.82 km2 (3.02 sq mi)Elevation[3]6 m (20 ft)Population (Municipality, May 2022; Urban and Metro, May 2014)[4][5][6][a] ‚Ä¢ Municipality160,783 ‚Ä¢ Density1,414/km2 (3,660/sq mi) ‚Ä¢ Urban169,714 ‚Ä¢ Metro198,000 ‚Ä¢ Metro region355,230 ‚Ä¢ Brabant CMSA1,932,055DemonymBosschenaarTime zoneUTC",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_1"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " Density1,414/km2 (3,660/sq mi) ‚Ä¢ Urban169,714 ‚Ä¢ Metro198,000 ‚Ä¢ Metro region355,230 ‚Ä¢ Brabant CMSA1,932,055DemonymBosschenaarTime zoneUTC+1 (CET) ‚Ä¢ Summer (DST)UTC+2 (CEST)Postcode5200‚Äì5249Area code073Websites-hertogenbosch.nlClick on the map for a fullscreen view 's-Hertogenbosch (Dutch: [Àås…õrtoÀê…£…ô(m)Ààb…îs] ‚ìò),[b] colloquially known as Den Bosch (pronounced [d…õm Ààb…îs] ‚ìò), is a city and municipality in the Netherlands with a population of 160,783. It is the capital of the province of North Brabant and its fourth largest city by population. The city is south of the Maas river and near the Waal. History[edit] For a chronological guide, see Timeline of 's-Hertogenbosch. The city's official name is a contraction of the (archaic) Dutch des Hertogen bosch ‚Äî 'the forest of the duke'. The duke in question was Henry I, Duke of Brabant, whose family had owned a large estate at nearby Orthen for at least four centuries. He founded a new town located on some forested dunes in the middle of a marsh. At age 26, he granted 's-Hertogenbosch city rights and the corresponding trade privileges in 1185. This is the traditional date given by later chroniclers; the first mention in contemporaneous sources is 1196. The original charter has been lost. His reason for founding the city was to protect his own interests against encroachment from Gelre and Holland; from its first days, he conceived of the city as a fortress. It was destroyed in 1203 in a joint expedition of Gelre and Holland, but was soon rebuilt. Some remnants of the original city walls remain. 's-Hertogenbosch in the 16th century In the late 14th century, a much larger wall was erected to protect the greatly expanded settled area. Artificial waterways were dug to serve as a city moat, through which the rivers Dommel and Aa were diverted. 's-Hertogenbosch became the",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_2"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": ", a much larger wall was erected to protect the greatly expanded settled area. Artificial waterways were dug to serve as a city moat, through which the rivers Dommel and Aa were diverted. 's-Hertogenbosch became the birthplace and home of northern Renaissance painter Hieronymus Bosch. Until 1520, the city flourished, becoming the second largest population centre in the territory of the present Netherlands, after Utrecht. The city was also a center of music, and composers, such as Jheronimus Clibano, received their training at its churches. Others held positions there: Matthaeus Pipelare was musical director at the Confraternity of Our Lady; and renowned Habsburg copyist and composer Pierre Alamire did much of his work at 's-Hertogenbosch. Eighty Years' War[edit] The wars of the Reformation changed the course of the city's history. It became an independent bishopric. During the Eighty Years' War, the city took the side of the Habsburg (Catholic) authorities and thwarted a Calvinist coup. It was besieged several times by Prince Maurice of Orange, stadtholder of most of the Dutch Republic, who wanted to bring 's-Hertogenbosch under the rule of the rebel United Provinces. The city was successfully defended against Prince Maurice in 1601 and again in 1603,[7] but it eventually fell in the 1629 siege led by his brother Frederick Henry.[8] Thirty Years' War[edit] Historical populationYearPop.¬±% p.a.137414,526‚Äî 143812,973‚àí0.18%146410,507‚àí0.81%147310,579+0.08%148013,185+3.20%149615,552+1.04%152618,571+0.59%156017,500‚àí0.17%160018,000+0.07%16659,000‚àí1.06%174712,574+0.41%179512,841+0.04%Source: Lourens & Lucassen 1997, pp. 45‚Äì46 In the years of Truce, before the renewed fighting after 1618, the fortifications were greatly expanded. The surrounding marshes made a siege of the conventional type impossible, and the fortress, deemed impregnable, was nicknamed mo",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_3"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "‚Äì46 In the years of Truce, before the renewed fighting after 1618, the fortifications were greatly expanded. The surrounding marshes made a siege of the conventional type impossible, and the fortress, deemed impregnable, was nicknamed moerasdraak, or the Swamp Dragon.[9] The town was nevertheless finally conquered by Frederik Hendrik of Orange in 1629 in a typically Dutch stratagem: he diverted the rivers Dommel and Aa, created a polder by constructing a forty-kilometre (25 mile) dyke and then pumped out the water by mills. After a siege of three months, the city had to surrender‚Äîan enormous blow to Habsburg geo-political strategy during the Thirty Years' War. This surrender cut the town off from the rest of the duchy and the area was treated by the Republic as an occupation zone without political liberties (see also Generality Lands). Louis XIV to Bonaparte[edit] After the Peace of Westphalia, the fortifications were again expanded. In 1672, the Dutch rampjaar, the city held against the army of Louis XIV of France. In 1794 French revolutionary troops under the command of Charles Pichegru attacked the city. It was only weakly defended, and fell after a short siege. Pichegru then crossed the rivers and put an end to the Dutch Republic. Under the new Batavian Republic, established in 1795, both Catholics and Brabanders at last gained equal rights. From 1806, the city became part of the Kingdom of Holland and from 1810, it was incorporated into the First French Empire. It was captured by the Prussians in 1814. Kingdom of the Netherlands[edit] The next year, 1815, when the United Kingdom of the Netherlands was established, it became the capital of North Brabant. Many newer and more modern fortresses were created in the vicinity of the city. A new canal was built, the 'Zuid-Willemsvaart', which gave the city an economic impulse. Trade, manufacturing and industry grew. Until 1878, it was forbidden to build outside the ramparts. That led to overcrowding and the highest infant mortality in the kingdom. At the end of the 19th century, the very conservative city government prevented industrial investment to avoid an increase in the number of workers and the establishment of educational institutions: students were",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_4"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " That led to overcrowding and the highest infant mortality in the kingdom. At the end of the 19th century, the very conservative city government prevented industrial investment to avoid an increase in the number of workers and the establishment of educational institutions: students were regarded as disorderly. As a result, the relative importance of the city diminished. World War II and after[edit] De Moriaan [nl] One of the few official Nazi concentration camp complexes in Western Europe outside Germany and Austria was named after 's-Hertogenbosch. It operated from January 1943, to September 1944 and was known to the Germans as Herzogenbusch (see List of subcamps of Herzogenbusch). About 30,000 inmates were interned in the complex during this time, of whom about 12,000 were Jews. In the Netherlands, this camp is known as 'Kamp Vught', because the concentration camp was actually located at a heath near Vught, a village a few kilometres south of 's-Hertogenbosch. The city was occupied by German forces during World War II from 1940 to 1944. The railway station was bombed by planes of the Royal Air Force on 16 September 1944. The city was liberated between 24 and 27 October 1944 during Operation Pheasant by British soldiers of Major-General Robert Knox Ross's 53rd (Welsh) Infantry Division following the victory of the 1st Battalion, East Lancashire Regiment, of 158th Infantry Brigade over the enemy on 23‚Äì24 October.[10] After the war, 's-Hertogenbosch was modernized, like many other cities in the Netherlands. It was possible that it was only the geography that shielded the old town from rigorous reconstruction in those early years. Just in time, the pendulum swung back to protecting the history of the city. In 1956, the council wanted to demolish the Moriaan, the oldest brick building in the Netherlands, to give traffic better access to the market square. The permit was refused by the government and instead the building was restored, starting in 1963. Later, city councils became much more aware of the value of historic buildings and from about the turn of the millennium, the historic fortifications are also given much attention by the authorities. Geography[edit] Dutch Topographic map of 's-Hertogenbosch, as of",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_5"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " much more aware of the value of historic buildings and from about the turn of the millennium, the historic fortifications are also given much attention by the authorities. Geography[edit] Dutch Topographic map of 's-Hertogenbosch, as of March 2014 Population centres[edit] The population centres in the municipality are: Bokhoven, Crevecoeur, Deuteren (former village), Dieskant, Empel, Engelen, Gewande, 's-Hertogenbosch, Hintham, Kruisstraat, Maliskamp, Meerwijk, Orthen (former village), Oud-Empel, and Rosmalen. Climate[edit] Climate in this area has mild differences between highs and lows, and there is adequate rainfall year-round. The K√∂ppen Climate Classification subtype for this climate is \"Cfb\" (Marine West Coast Climate/Oceanic climate).[11] Climate data for Gemert-Bakel Month Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Year Mean daily maximum ¬∞C (¬∞F) 4(39) 4(39) 9(49) 13(56) 18(64) 21(69) 22(72) 22(71) 19(66) 14(57) 8(47) 6(43) 13(56) Mean daily minimum ¬∞C (¬∞F) ‚àí1(31) ‚àí2(29) 2(35) 4(39) 7(45) 10(50) 13(55) 12(54) 10(50) 7(44) 3(38) 2(36) 6(42) Average precipitation mm (inches) 69(2.7) 51(2) 79(3.1) 30(1.2) 48(1.9) 58(2.3) 89(3.5) 81(3.2) 71(2.8) 51(2) 48(1.9) 61(2.4) 730(28.9) Average precipitation days 8.8 6.3 5.8 4 6 6.7 7.8 8.7 8.2 7 5.4 8.",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_6"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "730(28.9) Average precipitation days 8.8 6.3 5.8 4 6 6.7 7.8 8.7 8.2 7 5.4 8.8 83.5 Source: Weatherbase[12] Economy[edit] The city of 's-Hertogenbosch has become a center of industry, education, administration and culture. It is currently the fourth city of North Brabant. It is home to many national and international businesses such as Heineken, Epic, Tyco International, SAP and many others. The Jeroen Bosch Hospital is the biggest employer in the area, with over 4,000 employees.[13] Culture[edit] Typical street in 's-Hertogenbosch 's-Hertogenbosch is home to a variety of events such as the theatre festival Boulevard, Jazz in Duketown, and hip hop in duketown, the start of the Tour de France (1996), Tour Feminin (1997), the International Vocal Competition, November Music (a contemporary music festival) and the UNICEF Open (formerly the Ordina Open) grass court tennis tournament (in the nearby town of Rosmalen). There are also over 350 restaurants, pubs and caf√©s to be found in the city.[citation needed] 's-Hertogenbosch is also home to the European Ceramic Work Centre. This is a juried international ceramic residency where they invite artists, designers and architects from around to the world to explore the medium of Ceramics. This program was initially started in 1991 and continues to this day. The city has its own food speciality, the Bossche Bol ‚Äî effectively a giant profiterole, somewhat larger than a tennis ball, which is filled with whipped cream and coated with chocolate. The spoken language is Maaslands [nl] (the variant spoken in 's-Hertogenbosch is called Bosch which is placed among the Central North Brabantian dialects, although other classification systems also describe it as East Brabantian), which is very similar to colloquial Dutch.[14] De Toonzaal is a music venue for chamber music, improvised music, and experimental music. For popular music there is the venue W2 (or Willem II). Museums[edit] Noordbrabants Museum The Noordbrabants Museum is a provincial museum",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_7"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " music venue for chamber music, improvised music, and experimental music. For popular music there is the venue W2 (or Willem II). Museums[edit] Noordbrabants Museum The Noordbrabants Museum is a provincial museum with an overview of works that Vincent van Gogh made in Brabant. The Design Museum Den Bosch is a modern art museum. The Jheronimus Bosch Art Center, is dedicated to the work of Hieronymus Bosch. Other museums include the Swan Brothers' House and Museum Slager. Also the National (Dutch) Carnavalsmuseum Oeteldonks gemintemuzejum is located in the city. In the near future a new museum will be opened about the fortresses of the town and in general in Europe.[citation needed] The house where the famous painter Hieronymus produced his paintings can be visited on the market square. Carnival celebrations[edit] Mayor Ton Rombouts, the Mayor of Oeteldonk, and the prince at City Hall in 2007 's-Hertogenbosch has a strong carnival tradition. In its current form the story and symbolism dates from 1881 to 1883. In these years some citizens created the legend of \"Oeteldonk\", whereby the city was renamed to Oeteldonk for the three day carnival. \"Donk\" is a reference to a dry place in the marsh. The frog is widely used as a symbol during the 's-Hertogenbosch Carnival. It is also a symbol of the Oeteldonk marsh.[15] It was also a remark aimed at Bishop Godschalk from Den Dungen, where 'Van den Oetelaar' was a common family name. He had wanted to forbid the traditional festivities of Shrove Tuesday that often led to excesses. Oeteldonk is a village and therefore every inhabitant is a farmer or a 'durske' (a girl or young woman), eliminating class differences.[16] The village is headed by the Mayor \"Peer vaan den Muggenheuvel tot den Bobberd\". Each year the mayor of 's-Hertogenbosch hands over his authority to the Mayor of Oeteldonk. On Sunday at 11:11 AM the Mayor of Oeteldonk then receives Prince Carnaval \"Prince Amadeiro XXVI\" at Oeteldonk central station. From there a parade of all carnival clubs",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_8"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " of Oeteldonk. On Sunday at 11:11 AM the Mayor of Oeteldonk then receives Prince Carnaval \"Prince Amadeiro XXVI\" at Oeteldonk central station. From there a parade of all carnival clubs escorts the company to the town hall. The citizens of 's-Hertogenbosch wear traditional outfits throughout these days. A so-called boerenkiel is worn and every year patches are designed according to that years theme which can then be stitched onto the outfit. The boerenkiel is often combined with a traditional farmers bandana and a long scarf in the colors of Oeteldonk. The tradition of the Boerenkiel and / or Bandana is very different from the carnival traditions in the rest of the Netherlands. Other aspects like the parade, the temporary name and the temporary flag (for Oeteldonk red, white and yellow) are very similar. Attractions[edit] Saint John's Cathedral 's-Hertogenbosch was founded as a fortified city and that heritage can still be seen today. After World War II, plans were made to modernise the old city, by filling in the canals, removing or modifying some ramparts and redeveloping historic neighbourhoods. Before these plans could come to effect, the central government declared the city a protected townscape. Most historic elements have been preserved. In contrast to cities like Rotterdam, 's-Hertogenbosch also survived the Second World War relatively unscathed. Much of its historic heritage remains intact, and today there are always renovations going on in the city to preserve the many old buildings, fortifications, churches and statues for later generations.[citation needed] City center[edit] City Hall of 's-Hertogenbosch Market square The city center has a cosy atmosphere because of the almost continuous ramparts that still surround it. It has been molded by the multiple rivers that convene on 's-Hertogenbosch, giving the center its strange street plan so different from the usual grid plan where streets meet at right angles. The center is dominated by Saint John's Cathedral (Sint-Janskathedraal in Dutch), which dates from c. 1220 and is best known for its Brabantine Gothic design and the many sculptures of craftsmen that are sitting on almost every arc and rim along the outside of the cathedral. In 2010 an extensive restoration was completed, undoing the damage of many years",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_9"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " is best known for its Brabantine Gothic design and the many sculptures of craftsmen that are sitting on almost every arc and rim along the outside of the cathedral. In 2010 an extensive restoration was completed, undoing the damage of many years of wear-and-tear and acid rain. On the central square is the oldest remaining brick house of the Netherlands, 'de Moriaan',[17] which was built at the beginning of the 13th century. In the 1960s, de Moriaan was renovated to its former glory based on a famous 16th-century Dutch painting called 'De Lakenmarkt van 's-Hertogenbosch' ('The fabric market of 's-Hertogenbosch').[18] The town hall is an original 14th-century Gothic building. After the town was conquered by the Dutch Republic in 1629, it received a new facade in the style of Dutch Baroque architecture. It showcased the authority of the new masters, just like the new town hall in Maastricht would. Hidden below the old city is a canal network called the Binnendieze, which once spanned 22 km (14 mi). It started out as a regular river, the Dommel, running through the city in medieval times. Due to a lack of space in the city, people started building their houses and roads over the river. Later, the Binnendieze functioned as a sewer and fell into disrepair. In recent decades, the remaining sixth part of the old waterway system has been renovated, and it is possible to take several guided subterranean boat trips through it. Fortifications[edit] City rampart Citadel of 's-Hertogenbosch Boze Griet, a forged cannon from 1510 in the Bastionder 's-Hertogenbosch has an extensive and almost complete fifteenth-to-seventeenth-century city fortification. It was made to profit from the city's strong defensive position, lying on a sandy hill in the center of a large swamp fed by many rivers. This also caused the main ramparts to be preserved, because they were crucial in keeping out the water. In 2004 the city was awarded the title European Fortress City of the year. In the years that followed it restored many of the city defenses to much of their old glory. Apart from small sections of medieval walls, the main structure of the fortification is a",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_10"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "4 the city was awarded the title European Fortress City of the year. In the years that followed it restored many of the city defenses to much of their old glory. Apart from small sections of medieval walls, the main structure of the fortification is a late-medieval (fifteenth-century) wall. The upper sections were removed when cannon became more powerful, and polygonal bastions were added, some after the conquest by the republic. Most of these have not been restored to their original height, but do maintain their brick walls. The citadel in the north west of the city does retain its original height. Around the city itself many other fortresses can still be seen. In the north east of the old city, the hexagonal gunpowder magazine, called Kruithuis[19] is located close to the citadel. It is one of only a handful that still exist in the Netherlands, and was built when the city was still part of the Spanish Netherlands. It is planned to become the museum of fortress 's-Hertogenbosch. One of the bastions of the fortress now houses the mini museum Bastionder. It has been dug out in a bastion of the south side. On the inside it shows a unique wrought iron cannon, and an older bastion that was walled in by the current one. Nature[edit] View on the St. Jan from Bossche Broek On the south side of the city, the city center and walls still border the Bossche Broek, an old polder that could never be made dry. In 1995 the dyke of the Dommel broke and an enormous amount of water entered the polder. It also flooded and blocked the main Dutch highway A2. In order to prevent this in the future, the area was rearranged to store excess water in case of emergencies. In 2006 the area had been furnished with higher dikes and locks that allowed a controlled flooding of the polder and some adjacent areas in case of emergency. The Bossche Broek is now a 22-hectare (54-acre) nature reserve, that stretches all the way to Vught. It is connected to the Moerputten and Vlijmens Ven, with which it forms a Natura 2000 area. Rare species in the area are the scarce large blue and the European weather loach. The Moerputten sports the Moerputten Bridge, a 600-m",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_11"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "lijmens Ven, with which it forms a Natura 2000 area. Rare species in the area are the scarce large blue and the European weather loach. The Moerputten sports the Moerputten Bridge, a 600-metre (650 yard) long nineteenth century railway bridge and engineering feat. What is unique about the area is its close proximity to the city center. Miscellaneous[edit] The city is also the location of the Bolwoningen complex, an array of fifty experimental spherical houses designed by Dries Kreijkamp.[20] The Lutheran Church, 's-Hertogenbosch is no longer used as a church. Sport[edit] The city has one professional football club, FC Den Bosch. It is the 1967 successor of the professional branches of BVV (Bossche Voetbal Vereniging) and Wilhelmina. Both of them still exist as amateur football clubs. As a successor of BVV FC Den Bosch can claim the national championship of 1948. This championship led to the construction of stadium De Vliert, which at one time had a capacity of 30,000. Due to the less successful years that followed, the capacity is now only 8,500 visitors. FC Den Bosch was the first club of Dutch international player Ruud van Nistelrooy. 's-Hertogenbosch is more successful in field hockey. It is home to top club HC Den Bosch. The women's team in particular is a dominant force in the Dutch field hockey competition. The professional basketball club New Heroes Den Bosch is also very successful. The city's rugby club is called The Dukes and dates from 1974. It is located at a very scenic location at the foot of the city walls. Because of the limited space, the club plays on artificial turf and part of the accommodation is subterranean. The Dukes has the most junior members. It became the national rugby champion in 2008.[21] As regards events the city is host to the Rosmalen Grass Court Championships, a combined ATP Tour and WTA Tour grass court tennis event played two weeks before the Wimbledon Championships. The World Archery Championships and World Para Archery Championship were held here in June 2019. During these combined World Championships two separate venues were used: the Parade and the rugby fields of The Dukes. All finals took place in the arena at the Parade. The Parade is a historic square surrounded",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_12"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " Championship were held here in June 2019. During these combined World Championships two separate venues were used: the Parade and the rugby fields of The Dukes. All finals took place in the arena at the Parade. The Parade is a historic square surrounded by high trees, situated at the foot of the nearly seven-hundred-year-old Saint John's Cathedral in the attractive center of 's-Hertogenbosch. Transport[edit] This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.Find sources: \"'s-Hertogenbosch\" ‚Äì news ¬∑ newspapers ¬∑ books ¬∑ scholar ¬∑ JSTOR (August 2020) (Learn how and when to remove this message) 's-Hertogenbosch railway station The Zuid-Willemsvaart runs from the Meuse just north of the city towards Maastricht via Helmond and Weert. In 's-Hertogenbosch it runs through the city proper, south east from where a bastion has been cut off from the citadel. Because of this route it was impossible to widen it further than for ships of CEMT class II. Therefore, the M√°xima Canal of 8 km (5 miles) was dug just east of the city, creating a shortcut from the canal to the Meuse suitable for ships of CEMT class IV. On the remaining part of the Zuid-Willemsvaart west of the city is the industrial harbor of 's-Hertogenbosch. A marina is located in the center. 's-Hertogenbosch is situated on the busy A2 motorway, the most important north‚Äìsouth connection of the Netherlands. This connection was established with the opening of the Dieze Bridge in 1942. From 1961 the Utrecht-'s-Hertogenbosch section was 2 times 2 lanes. In 1970 the A2 was rerouted to the east of the city. In 1989 it finally became a controlled-access highway. In 1996 the section between 's-Hertogenbosch and Eindhoven became a controlled-access highway. The situation in Maastricht was only solved in 2016, when the Koning Willem-Alexandertunnel was opened. On the east‚Äìwest axis 's-Hertogenbosch is on the A59 motorway.",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_13"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " The situation in Maastricht was only solved in 2016, when the Koning Willem-Alexandertunnel was opened. On the east‚Äìwest axis 's-Hertogenbosch is on the A59 motorway. The A65 motorway between 's-Hertogenbosch and Tilburg is a regional highway, but is not completely access-controlled. 's-Hertogenbosch railway station is on the Utrecht‚ÄìBoxtel part of the railway stretch between Amsterdam and the Dutch industrial/tech center near Eindhoven. As a consequence north‚Äìsouth trains depart every ten minutes. On the Tilburg‚ÄìNijmegen railway trains run on a more modest schedule. 's-Hertogenbosch railway station is also a major station for Arriva buslines that serve the city and most of its suburbs. Other stations within the limits of the municipality are 's-Hertogenbosch Oost railway station and Rosmalen railway station. Vught railway station is actually closer to the city center than that in Rosmalen. 's-Hertogenbosch has attempted to adapt to the growing popularity of the bicycle in Dutch cities. A reasonable amount of bike paths has so far been constructed in the town. In 2011, the city was chosen as Fietsstad 2011‚Äîthe top bike city of the Netherlands for 2011. The details of the report were less jubilant and showed that it was really a prize meant to stimulate 's-Hertogenbosch to take further action; Hugo van der Steenhoven of the Fietsersbond: \"In the past years Den Bosch has spent much energy, ambition, creativity and money to give cycling an enormous boost. This is a big achievement for a city where bicycle use is lower than in the rest of the Netherlands\" (cyclist union).[22] Education[edit] 's-Hertogenbosch has multiple vocational universities called Hogeschool in Dutch. The HAS Hogeschool of about 3,500 students is focused on agricultural and food technology. Avans Hogeschool is located in 's-Hertogenbosch and two nearby cities. The AKV St. Joost is an art academy that is now part of Avans and dates back to 1812.[23] Fontys Hogeschool also offers some education in the city. The Jheronimus Academy of Data Science (JADS), located at the Mari",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_14"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " an art academy that is now part of Avans and dates back to 1812.[23] Fontys Hogeschool also offers some education in the city. The Jheronimus Academy of Data Science (JADS), located at the Mari√´nburg Campus in the center of 's-Hertogenbosch, and provides a number of data science programs at graduate (MSc) and post-graduate level (PhD).[24] It is a department of the Eindhoven University of Technology and Tilburg University. In secondary education the City Gymnasium is a gymnasium (school) that originated from the Latin school of the city. It is comparable to a grammar school and can trace its origin back 1274. The same type of education and all other types of secondary education are offered by a number of large institutes. Religion[edit] Religions in 's-Hertogenbosch (2013)[25] No affiliation (44.8%) Roman Catholic (43.3%) Protestant (4.1%) Other Christian denominations (2.1%) Islam (5%) Hinduism (0.3%) Buddhism (0.4%) Roman Catholicism is the dominant religion in 's-Hertogenbosch, with somewhat more than 40% of the population counting themselves as belonging to it. Even so, attendance at mass is significantly lower than 40%. Three churches in the city center are still in use by the Catholic church: Saint John's Cathedral, Saint Catherine and the Monastery Church of the Franciscans nearby the railway station. Smaller churches in use by the Roman Catholic church are: Saint Anne's Church in Hintham, Saint Landoline Church in Empel, Saint Willibrord Church in Maaspoort, Saint Lambert Church (Rosmalen), etc. The Protestant religion has seen its share of believers in the city fall from 20% to about 4%. It is based in the Great Church. The Eastern Orthodox Church is a new church in town. It is based at Saint Catherine's Church where Catholic worship services have been held again since 2021. The Arrahma Mosque has been built by the Moroccan community. The Turkish community has the Orhan Gazi Mosque. Notable residents[edit] Public thinking and public service[edit] Macropedius, 1572 Jan de Quay, 1962 Erasmus (1484‚Äì1497), priest and humanist scholar",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_15"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " Orhan Gazi Mosque. Notable residents[edit] Public thinking and public service[edit] Macropedius, 1572 Jan de Quay, 1962 Erasmus (1484‚Äì1497), priest and humanist scholar Macropedius (1487‚Äì1558), a Dutch humanist, schoolmaster and Latin playwright John Slotanus (died 1560), a Dutch Roman Catholic polemical writer.[26] Johannes Chrysostomus vander Sterre (1591‚Äì1652), an ecclesiastical writer and abbot Johan Bax van Herenthals (1637‚Äì1678), the governor of the Dutch Cape Colony 1676/1678 Laurens Storm van 's Gravesande (1704‚Äì1775), governor of Essequibo and Demerara[27] Petrus Josephus Johannus Sophia Marie van der Does de Willebois (1843‚Äì1937), a Dutch jonkheer, politician and Mayor of 's-Hertogenbosch Joseph Sweens (1858‚Äì1950), an RC missionary bishop in South Nyanza in German East Africa Christiaan Cornelissen (1864‚Äì1942), a Dutch syndicalist writer, economist and trade unionist Henk Sneevliet (1883‚Äì1942), a Dutch Communist, active in both the Netherlands and the Dutch East Indies Frans Teulings (1891‚Äì1966), a Dutch politician and economist Pieter Godfried Maria van Meeuwen (1899‚Äì1982), a Dutch judge and a politician Jan de Quay (1901‚Äì1985), a politician and psychologist; Prime Minister of the Netherlands 1959/1963 Bert R√∂ling (1906‚Äì1985), a Dutch jurist and founding father of polemology, the study of war Louis van de Laar (1921‚Äì2004), a Dutch politician and historian Bram Stemerdink (born 1936), a retired Dutch politician and army officer Don Burgers (1932‚Äì2006), a Dutch politician, mayor of 's-Hertogenbosch from 1989 to 1996 Marco Kroon (born 1970), soldier with the Korps Commandotroepen Matthijs van Miltenburg (born 1972), a politician, municipal councillor 2010/2014 and MEP 2014/2019 Science and business[",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_16"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " 1970), soldier with the Korps Commandotroepen Matthijs van Miltenburg (born 1972), a politician, municipal councillor 2010/2014 and MEP 2014/2019 Science and business[edit] Mercator, engraving from 1739 Gerardus Mercator (ca.1520‚Äì1530), a geographer, cosmographer and cartographer Wilhelm de Raet (ca.1537-1583), a Dutch hydraulic engineer and master builder, worked in Lucca Willem 's Gravesande (1688‚Äì1742), a Dutch academic, mathematician and natural philosopher, developed the laws of classical mechanics Gerard Troost (1776‚Äì1850), a Dutch-American medical doctor, naturalist and mineralogist Jacob Moleschott (1822‚Äì1893), physiologist and writer on dietetics and scientific materialism Diederik Korteweg (1848‚Äì1941), a mathematician, co-wrote the Korteweg‚Äìde Vries equation Jacob R. H. Neervoort van de Poll (1862‚Äì1924), an entomologist specialising in Coleoptera Peter Reijnders (1900‚Äì1974), a photographer and film director; co-founded the theme park Efteling Frans de Waal (1948‚Äì2024), primatologist, ethologist and academic Art[edit] Jheronimus Bosch, posthumous portrait from ca.1550 Hieronymus Bosch (ca.1450‚Äì1516), painter of the Early Netherlandish painting school. Hubert Gerhard (ca.1540‚Äì1620), a Dutch sculptor Abraham van Diepenbeeck (1596‚Äì1675), a Dutch painter of the Flemish School.[28][29] Theodoor van Thulden (1606‚Äì1669), a painter and engraver of altarpieces and portraits. Quirinus van Amelsfoort (1760‚Äì1820), a Dutch painter of allegories, history and portraits Karel Sluijterman (1863‚Äì1931), a Dutch architect, furniture designer, interior designer, illustrator, ceramist, book binding designer and professor Anton Sistermans (1865‚Äì1926), a Dutch baritone, singer of lieder and oratorios Sophie van der Does de Willebois (1891‚Äì1961),",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_17"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " illustrator, ceramist, book binding designer and professor Anton Sistermans (1865‚Äì1926), a Dutch baritone, singer of lieder and oratorios Sophie van der Does de Willebois (1891‚Äì1961), a Dutch ceramist Charles Bolsius (1907‚Äì1983), painter and woodworker Willem van den Hout (1915‚Äì1985), a Dutch writer of the Bob Evers series of children's books Jos van Veldhoven (born 1952), a Dutch choral conductor Leon de Winter (born 1954), writer and columnist[30] Oscar van Dillen (born 1958), a Dutch composer, conductor and instrumentalist Sport[edit] Gijs van Heumen, 1986 Mijntje Donners, 2004 Henri Smulders (1863‚Äì1933), a sailor and team silver medallist at the 1900 Summer Olympics Sjef van Run (1904‚Äì1973), a Dutch footballer, appeared 359 times for PSV Eindhoven Wim van Heumen (1928‚Äì1992), a field hockey coach and municipal councillor 1970/1992 Gijs van Heumen (born 1952), a retired field hockey coach, son of Wim Cees Schapendonk (born 1955), a former football striker with over 510 club caps Sophie von Weiler (born 1958), a retired Dutch field hockey forward, team gold and bronze medallist at the 1984 and 1988 Summer Olympics Arnold Scholten (born 1962), a retired football midfielder with over 440 club caps Marcel Brands (born 1962), a former professional footballer, former Director of Football at Everton F.C. Fred van der Hoorn (born 1963), a Dutch former footballer with over 500 club caps Manon Bollegraf (born 1964), a former professional female tennis player Annemarie Verstappen (born 1965), a female former freestyle swimmer, team silver and double bronze medallist at the 1984 Summer Olympics Mijntje Donners (born 1974), field hockey player, with 234 caps for the Dutch National Women's Team, and team silver and bronze medallist at three Summer Olympics Anthony Lurling (born 1977), a Dutch former footballer with 587 club",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_18"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "1974), field hockey player, with 234 caps for the Dutch National Women's Team, and team silver and bronze medallist at three Summer Olympics Anthony Lurling (born 1977), a Dutch former footballer with 587 club caps brothers Geert-Jan Derikx (born 1980) & Rob Derikx (born 1982), field hockey players, team silver medallists at the 2004 Summer Olympics Henri van Opstal (born 1989), a Dutch kickboxer Robin van Roosmalen (born 1989), a Dutch kickboxer and mixed martial artist Maikel Scheffers (born 1982), wheelchair tennis player, bronze medallist at the 2008 Summer Paralympics Andy Souwer (born 1982), a Dutch welterweight shoot boxer and mixed martial artist Maartje Goderie (born 1984), a Dutch field hockey player, twice team gold medallist at the 2008 and 2012 Summer Olympics Carlien Dirkse van den Heuvel (born 1987), a Dutch field hockey player, team gold and silver medallist at the 2012 and 2016 Summer Olympics Marianne Vos (born 1987), a Dutch cyclo-cross, road, track and mountain bicycle racer Kenny van Gaalen (born 1988), a Dutch sidecarcross rider Toon Greebe (born 1988), a Dutch darts player Patrick van Aanholt (born 1990), a Dutch professional footballer with over 280 club caps Michiel van der Heijden (born 1992), a Dutch mountain biker and Cyclo-Cross Rider. Notes[edit] ^ 'Metropolitan region Waalboss' Stedelijke regio streekplan Waalboss143,733 ‚Äì 's-Hertogenbosch84,954 ‚Äì Oss46,498 ‚Äì Waalwijk43,165 ‚Äì Heusden25,638 ‚Äì Vught11,242 ‚Äì Maasdonk+ 355,230 ^ French: Bois-le-Duc [bw…ë l(…ô) dyk]; German: Herzogenbusch [Àåh…õ ÅtsoÀê…°nÃ©Ààb ä É] ‚ìò. References[edit] ^ \"Samenstelling van het college\" [Members of the board] (in",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_19"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "ch [Àåh…õ ÅtsoÀê…°nÃ©Ààb ä É] ‚ìò. References[edit] ^ \"Samenstelling van het college\" [Members of the board] (in Dutch). Gemeente 's-Hertogenbosch. Archived from the original on 25 December 2018. Retrieved 12 April 2014. ^ \"Kerncijfers wijken en buurten 2020\" [Key figures for neighbourhoods 2020]. StatLine (in Dutch). CBS. 24 July 2020. Retrieved 19 September 2020. ^ \"Postcodetool for 5211HH\". Actueel Hoogtebestand Nederland (in Dutch). Het Waterschapshuis. Archived from the original on 21 September 2013. Retrieved 15 April 2014. ^ \"Bevolkingsontwikkeling; regio per maand\". StatLine. Statistics Netherlands. Retrieved 14 July 2022. ^ \"Bevolkingsontwikkeling; Regionale kerncijfers Nederland\" [Regional core figures Netherlands]. CBS Statline (in Dutch). CBS. 1 January 2020. Retrieved 8 March 2021. ^ \"De grenzeloze regio\". Sdu uitgevers. 2007. ISBN 9789012124577. Het BBP van BrabantStad ligt op 14.7% van het nationale BBP. In de regio liggen Philips, de Technische Universiteit Eindhoven, de Universiteit Tilburg en de HAS Den Bosch. De regio heeft 1.4 miljoen inwoners. Er is veel R&D, ICT, automotive, logistiek en agribusiness. ^ Coetzee, Daniel; Eysturlid, Lee W. (2013). Philosophers of War: The Evolution of History's Greatest Military Thinkers. ABC-CLIO. p. 118. ISBN 978-0-313-07033-4. ^ Knight, Charles Raleigh: Historical records of The Buffs, East Kent Regiment (3rd Foot) formerly designated the Holland Regiment and Prince George of Denmark's Regiment. Vol I. London, Gale & Polden, 1905, pp. 69-70 ^ \"The Siege of the Swamp Dragon\". bada.org. British",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_20"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " Foot) formerly designated the Holland Regiment and Prince George of Denmark's Regiment. Vol I. London, Gale & Polden, 1905, pp. 69-70 ^ \"The Siege of the Swamp Dragon\". bada.org. British Antique Dealers' Association. Retrieved 25 April 2023. ^ \"Rory Bremner salutes his East Lancashire war hero dad\". Lancashire Telegraph. 6 November 2009. Archived from the original on 2015-04-04. Retrieved 2015-04-02. ^ Climate Summary for Gemert-Bakel (closest city on record) ^ \"Weatherbase.com\". Weatherbase. 2013. Retrieved on June 3, 2013. ^ \"Over Ons\". Jeroen Bosch Ziekenhuis. 2020. Retrieved 26 September 2020. ^ Swanenberg, Jos; Swanenberg, Cor (2002). Oost-Brabants. Taal in stad en land, 7. (in Dutch). Den Haag: Sdu Uitgevers. ISBN 9789012090100. OCLC 783055844. ^ \"Oeteldonk ‚Äì Oetelpedia\" (in Dutch). Oetelpedia.nl. 2010-11-17. Retrieved 2013-03-25. ^ \"De stichting van Oeteldonk en de decennia daarna (1882-1945)\" [The foundation of Oeteldonk and the subsequent decades] (in Dutch). Oeteldonksche Club van 1882. 2020-06-28. Retrieved 2020-06-28. ^ Teletijd.nl: 'De Moriaan' before and after renovation ^ Painting: De Lakenmarkt van 's-Hertogenbosch ^ Teletijd.nl: Kruithuis inner court ^ \"The Worlds Ugliest Buildings ‚Äì AOL Real Estate\". Realestate.aol.com. Retrieved 2013-03-25. ^ \"Geschiedenis van The Dukes\". Retrieved 2021-12-09. ^ \"Den Bosch fietsstad van 2011\" ['s-Hertogenbosch bicycle city 2011] (in Dutch). NOS. 2011-11-17. ^ AKV|St.Joost Archived 2013-09-21 at the Way",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_21"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "2011\" ['s-Hertogenbosch bicycle city 2011] (in Dutch). NOS. 2011-11-17. ^ AKV|St.Joost Archived 2013-09-21 at the Wayback Machine. Retrieved 7 October 2016. ^ JADS Archived 2017-03-13 at the Wayback Machine. Retrieved 12 March 2017. ^ \"Kerkelijkheid en kerkbezoek, 2010/2013\". Centraal Bureau voor de Statistiek. 2 October 2014. ^ Callan, Charles J. (1912). \"John Slotanus\" . Catholic Encyclopedia. Vol. 14. ^ David A. Granger. \"Laurens Storm van 's Gravesande: Guyana's greatest governor?\". Stabroek News. Retrieved 14 August 2020. ^ Van Cleef, Augustus (1908). \"Abraham van Diepenbeeck\" . Catholic Encyclopedia. Vol. 4. ^ \"Diepenbeeck, Abraham van\" . Encyclopedia Americana. Vol. IX. 1920. ^ IMDb Database retrieved 10 February 2020 Literature[edit] See also: Bibliography of the history of 's-Hertogenbosch Lourens, Piet; Lucassen, Jan (1997). Inwonertallen van Nederlandse steden ca. 1300‚Äì1800. Amsterdam: NEHA. ISBN 9057420082. External links[edit] Wikimedia Commons has media related to: 's-Hertogenbosch (category) Official website 's-Hertogenbosch travel guide from Wikivoyage Places adjacent to 's-Hertogenbosch Maasdriel (GE)Meuse Oss Heusden 's-Hertogenbosch Bernheze Vught Sint-Michielsgestel vteMunicipalities of North Brabant Alphen-Chaam Altena Asten Baarle-Nassau Bergeijk Bergen op Zoom Bernheze Best Bladel Boekel Boxtel Breda Cranendonck Deurne Dongen Drimmelen Eersel Eindhoven Etten-Leur Geertruidenberg Geldrop-Mierlo Gemert-Bakel Gilze en Rijen Goirle Halderberge Heeze-Leende Helmond 's-Hertogenbos",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_22"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": " Eersel Eindhoven Etten-Leur Geertruidenberg Geldrop-Mierlo Gemert-Bakel Gilze en Rijen Goirle Halderberge Heeze-Leende Helmond 's-Hertogenbosch Heusden Hilvarenbeek Laarbeek Land van Cuijk Loon op Zand Maashorst Meierijstad Moerdijk Nuenen, Gerwen en Nederwetten Oirschot Oisterwijk Oosterhout Oss Reusel-De Mierden Roosendaal Rucphen Sint-Michielsgestel Someren Son en Breugel Steenbergen Tilburg Valkenswaard Veldhoven Vught Waalre Waalwijk Woensdrecht Zundert See also Netherlands Provinces Municipalities vteCapital cities of the Kingdom of the NetherlandsNational capital: AmsterdamSeat of government: The HagueConstituent countriesProvincesPublic bodies Oranjestad, Aruba Willemstad, Cura√ßao Amsterdam, Netherlands Philipsburg, Sint Maarten Assen, Drenthe Lelystad, Flevoland Leeuwarden, Friesland Arnhem, Gelderland Groningen, Groningen Maastricht, Limburg 's-Hertogenbosch, North Brabant Haarlem, North Holland Zwolle, Overijssel The Hague, South Holland Utrecht, Utrecht Middelburg, Zeeland Kralendijk, Bonaire The Bottom, Saba Oranjestad, Sint Eustatius See also: List of cities in the Netherlands by province Authority control databases InternationalVIAFFASTWorldCatNationalGermanyUnited StatesFranceBnF dataCzech RepublicSpainVaticanIsraelGeographicMusicBrainz areaOtherIdRefYale LUX Retrieved from \"https://en.wikipedia.org/w/index.php?title=%27s-Hertogenbosch&oldid=1300147884\" Categories: 's-Hertogenbosch1185 establishments in EuropeCities in the NetherlandsMunicipalities of North BrabantPopulated places in North BrabantProvincial capitals of the NetherlandsHolocaust locations in the NetherlandsHidden categories: Pages using gadget WikiMiniAtlasPages using the Phonos extensionArticles containing French-language textPages with French IPAArticles containing German-language textPages with German IPAPages including recorded pronunciationsCS1",
    "token_count": 500,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_23"
  },
  {
    "id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe",
    "created_at": "2025-07-26T15:29:20.689968+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/%27s-Hertogenbosch",
    "title": "'s-Hertogenbosch - Wikipedia",
    "text": "Holocaust locations in the NetherlandsHidden categories: Pages using gadget WikiMiniAtlasPages using the Phonos extensionArticles containing French-language textPages with French IPAArticles containing German-language textPages with German IPAPages including recorded pronunciationsCS1 Dutch-language sources (nl)Webarchive template wayback linksArticles incorporating a citation from the 1913 Catholic Encyclopedia with Wikisource referenceWikipedia articles incorporating a citation from the Encyclopedia Americana with a Wikisource referenceArticles with short descriptionShort description is different from WikidataArticles needing additional references from December 2021All articles needing additional referencesPages using multiple image with auto scaled imagesCoordinates on WikidataPages with Dutch IPAArticles containing Dutch-language textAll articles with unsourced statementsArticles with unsourced statements from October 2022Articles needing additional references from August 2020Pages using the Kartographer extension Search Search 's-Hertogenbosch 92 languages Add topic",
    "token_count": 188,
    "chunk_id": "0b4a6c4d-6e80-437d-90cc-f73ef5d1a6fe_24"
  },
  {
    "id": "4cfee214-8f01-4eda-ab07-5496a79a869e",
    "created_at": "2025-07-26T15:29:20.984877+00:00",
    "source_type": "external",
    "source_path": "https://www.alliander.com/en/",
    "title": "Welcome - Alliander",
    "text": "Welcome - Alliander Quick search Our activities More about Alliander Investors Latest news Alliander N.V. announces early redemption of ‚Ç¨ 500 million Perpetual Subordinated Securities (Reset Perpetual Capital Securities) Alliander N.V. announces early redemption of ‚Ç¨ 500 million Perpetual Subordinated Securities (Reset Perpetual Capital‚Ä¶ Read story Alliander launches a ‚Ç¨ 1 billion dual-tranche Green Bond On April 28, 2025, Alliander successfully launched a dual tranche Green Bond transaction for a‚Ä¶ Read story Joris de Groot appointed CTO of Alliander On 1 May 2025 Joris de Groot (1980) will take up the post of Chief‚Ä¶ Read story Interested in our results? Read our year results 2024 Close Search NL EN 308 Working at Alliander Privacy statement Disclaimer CVD Cookies Change cookie preferences",
    "token_count": 184,
    "chunk_id": "4cfee214-8f01-4eda-ab07-5496a79a869e_1"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": "Arnhem - Wikipedia Jump to content Coordinates: 51¬∞59‚Ä≤N 5¬∞55‚Ä≤EÔªø / Ôªø51.983¬∞N 5.917¬∞EÔªø / 51.983; 5.917 From Wikipedia, the free encyclopedia City and municipality in Gelderland, Netherlands This article is about the Dutch city and municipality. For other uses, see Arnhem (disambiguation). Not to be confused with Arnheim. City and municipality in Gelderland, NetherlandsArnhem √àrnem (Ernems)City and municipalityMusis SacrumArnhem Centraal railway stationBuilding by Willem DiehlJohn Frost BridgeVilla Sonsbeek FlagCoat of armsBrandmarkNickname(s): Ernem, Arnheim, Arra, Nultweezes, Nulzesentwintig, 026Location in GelderlandArnhemLocation within the NetherlandsShow map of NetherlandsArnhemLocation within EuropeShow map of EuropeCoordinates: 51¬∞59‚Ä≤N 5¬∞55‚Ä≤EÔªø / Ôªø51.983¬∞N 5.917¬∞EÔªø / 51.983; 5.917CountryNetherlandsProvinceGelderlandGovernment[1] ‚Ä¢ BodyMunicipal council ‚Ä¢ MayorAhmed Marcouch (PvdA)Area[2] ‚Ä¢ Municipality101.54 km2 (39.20 sq mi) ‚Ä¢ Land97.82 km2 (37.77 sq mi) ‚Ä¢ Water3.72 km2 (1.44 sq mi)Elevation[3]13 m (43 ft)Population (Municipality, January 2021; Urban and Metro, May 2014)[4][5] ‚Ä¢ Municipality162,424 ‚Ä¢ Density1,660/km2 (4,300/sq mi) ‚Ä¢ Urban152,850 ‚Ä¢ Metro361,048DemonymErnemmerTime zoneUTC+1 (CET) ‚Ä¢ Summer (DST)UTC+2 (CEST)Postcode6800‚Äì6846Area code026Websitewww.arnhem.nlClick on the map for a fullscreen view Arnhem (Dutch: [Àà…ërn…õm] ‚ìò or [Àà…ër(…ô)n…¶…õm] ‚ìò; German: Arnheim [Ààa Ånha…™m] ‚ìò; Ernems: √àrn",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_1"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": "ÔøΩrn…õm] ‚ìò or [Àà…ër(…ô)n…¶…õm] ‚ìò; German: Arnheim [Ààa Ånha…™m] ‚ìò; Ernems: √àrnem) is a city and municipality situated in the eastern part of the Netherlands, near the German border. It is the capital of the province of Gelderland, located on both banks of the rivers Nederrijn and Sint-Jansbeek, which was the source of the city's development. Arnhem is home to the Hogeschool van Arnhem en Nijmegen, ArtEZ Institute of the Arts, Netherlands Open Air Museum, Airborne Museum 'Hartenstein', Royal Burgers' Zoo, NOC*NSF and National Sports Centre Papendal. The north corner of the municipality is part of the Hoge Veluwe National Park. It is approximately 55 square kilometres (21 sq mi) in area, consisting of heathlands, sand dunes, and woodlands.[citation needed] History[edit] Early history[edit] Old city hall The oldest archeological findings of human activity around Arnhem are two firestones of about 70,000 years ago. These come from the Stone Age, when the Neanderthals lived in this part of Europe. In Schuytgraaf, remnants of a hunters camp from around 5000 BC have been discovered. In Schaarsbergen, twelve grave mounds were found from 2400 BC, which brought the so-called Neolithic Revolution to the area of Arnhem, which meant the rise of the farmers. The earliest settlement in Arnhem dates from 1500 BC, of which traces have been found on the Hoogkamp, where the Van Goyenstraat is currently located. In the inner city, around the Sint-Jansbeek, traces of settlement have been found from around 700 BC, while the first traces south of the Rhine have been found dating to around 500 BC, in the Schuytgraaf. Though the early tracks of settlements did show that the early residents of Arnhem descended from the forests on the hills, Arnhem was not built on the banks of the river Rhine, but a little higher along the Sint-Jansbeek. Arnhem arose on the location where the road between Nijm",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_2"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " descended from the forests on the hills, Arnhem was not built on the banks of the river Rhine, but a little higher along the Sint-Jansbeek. Arnhem arose on the location where the road between Nijmegen and Utrecht and Zutphen split. Seven streams provided the city with water, and only when the flow of the Rhine was changed in 1530, was the city located on the river. Middle Ages[edit] Arnhem was first mentioned as such in 893 as Arneym or Arentheym. In 1233, Count Otto II of Guelders from Zutphen, conferred city rights on the town, which had belonged to the abbey of Pr√ºm, settled in, and fortified it. Arnhem entered the Hanseatic League in 1443.[6] In 1473, it was captured by Charles the Bold of Burgundy. 16th and 17th century[edit] In 1514, Charles of Egmond, duke of Guelders, took it from the dukes of Burgundy; in 1543, it fell to the emperor Charles V. As capital of the so-called \"Kwartier van Veluwe\" it joined the Union of Utrecht during the Eighty Years' War in 1579. After its capture from the Spanish forces by Dutch and English troops in 1585 the city became part of the Republic of the Seven United Provinces of the Netherlands.[6] The French occupied the town from 1672 to 1674. 18th and 19th century[edit] Huis Zypendaal From 1795 to 1813, it was reoccupied by the French, by both revolutionary and imperial forces. In the early 19th century, the former fortifications were almost completely dismantled, to give space for town expansion. The Sabelspoort (Sabresgate) is the only remaining part of the medieval walls. In the 19th century, Arnhem was a genteel resort town famous for its picturesque beauty. It was known as \"het Haagje van het oosten\" (The Little Hague of the East), mainly because a number of rich former sugar barons or planters from the Indies settled there, as they did in The Hague. Even now the city is famous for its parks and greenery. The urbanization in the north on",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_3"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " of the East), mainly because a number of rich former sugar barons or planters from the Indies settled there, as they did in The Hague. Even now the city is famous for its parks and greenery. The urbanization in the north on hilly terrain is also quite unusual for the Netherlands. 20th century[edit] World War II[edit] See also: Battle of Arnhem and Liberation of Arnhem During the German occupation (World War II), the occupiers operated a subcamp of the Herzogenbusch concentration camp in the city.[7] Battle of Arnhem During Operation Market Garden (September 1944), the British 1st Airborne Division, under the command of Major-General Roy Urquhart, and the Polish 1st Independent Parachute Brigade were given the task of securing the bridge at Arnhem. Glider infantry and paratrooper units were landed into the area on 17 September and later. The bulk of the force was dropped rather far from the bridge and never met their objective. A small element of the British 1st Airborne, the 2nd Parachute Battalion under Lieutenant Colonel John D. Frost, managed to make its way as far as the bridge but was unable to secure both sides. The British troops encountered stiff resistance from the German 9th and 10th SS Panzer Divisions, which had been stationed in and around the city. The John Frost Bridge, seen from the Airborne memorial The British force at the bridge eventually ran out of ammunition and was captured on 21 September, and a full withdrawal of the remaining forces was made on 26 September. These events were dramatized in the 1977 movie A Bridge Too Far. (The bridge scenes in the movie were shot in Deventer, where a similar bridge over the IJssel was available, as the area around Arnhem bridge had changed too much to represent WWII-era Arnhem). As a tribute, the rebuilt bridge was renamed 'John Frost Bridge' after the commander of the paratroopers. The official commemoration is 17 September. The current bridge is the third almost-identical bridge built at the same spot. The Dutch Army destroyed the first bridge when the German Army invaded the Netherlands in 1940. The second bridge was destroyed by the United States Army Air Forces shortly after the 1944 battle. A second battle of Arnhem took place in April",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_4"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " The Dutch Army destroyed the first bridge when the German Army invaded the Netherlands in 1940. The second bridge was destroyed by the United States Army Air Forces shortly after the 1944 battle. A second battle of Arnhem took place in April 1945 when the city was liberated by the British 49th (West Riding) Infantry Division fighting as part of the First Canadian Army. The inhabitants of the city, who had been forcibly evacuated by the Germans during and after the battle, returned in the summer of 1945. The reconstruction of Arnhem took until 1969 to finally be completed. Just outside Arnhem, in the town of Oosterbeek the Commonwealth War Graves Commission built the Arnhem Oosterbeek War Cemetery which contains the graves of most of those killed during the September landings, and many of those killed in later fighting in the area. 1945‚Äì1999[edit] Arnhem hosted the 1980 Summer Paralympics.[8] 21st century[edit] On 6 March 2025, a major city fire broke out in Arnhem. The fire destroyed a block of shops and upstairs apartments in the historic city center. Geography[edit] Topographic map of Arnhem. Neighbourhoods[edit] The municipality of Arnhem consists of the city of Arnhem and the following surrounding suburbs and former villages: Elden, Netherlands (former village, now totally surrounded by other Arnhem neighbourhoods) Schaarsbergen Arnhem consists of three districts (stadsdelen) and 24 neighbourhoods (wijken). Each neighbourhood has a number which corresponds to its postal code. Arnhem Centrum (Binnenstad) Arnhem-North (Spijkerkwartier, Arnhemse Broek, Presikhaaf-West, Presikhaaf-East, St. Marten/Sonsbeek-Zuid, Klarendal, Velperweg, Alteveer en Cranevelt, Geitenkamp, Monnikenhuizen, Burgemeesterswijk/Hoogkamp, Heijenoord/Lombok, Klingelbeek) Arnhem-South (Malburgen-West, Malburgen-East (North), Malburgen-East (South), De Laar East/West, Vredenburg/Kronenburg, Elderveld, Rijkerswoerd, Sch",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_5"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " Arnhem-South (Malburgen-West, Malburgen-East (North), Malburgen-East (South), De Laar East/West, Vredenburg/Kronenburg, Elderveld, Rijkerswoerd, Schuytgraaf) Neighbouring villages[edit] The outlying areas of the following villages are bordering the municipality of Arnhem directly, which means among others that in many a case a considerable number of their inhabitants originate from Arnhem. Velp Oosterbeek Driel Elst Huissen Wolfheze Rozendaal Westervoort Proximity of border with Germany[edit] The city lies approximately 15 kilometers from the border with Germany, and to some extent the westernmost villages in the municipality of Elten, Germany, function as dormitories for people who work in the Dutch city of Arnhem in part due to the immigration of Dutch people from the region that were attracted by the lower house pricing just across the border. Climate[edit] Arnhem features the same climate (Cfb, oceanic climate) as all of the Netherlands; however, its location on the foothills of the Veluwe, the largest forest in the Netherlands, contributes to some higher precipitation values. Climate data for Deelen, Arnhem (1991‚àí2020 normals, extremes 1953‚àípresent) Month Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Year Record high ¬∞C (¬∞F) 14.5(58.1) 19.5(67.1) 24.6(76.3) 29.4(84.9) 31.9(89.4) 34.2(93.6) 39.2(102.6) 37.2(99.0) 32.7(90.9) 26.4(79.5) 19.5(67.1) 15.2(59.4) 39.2(102.6) Mean daily maximum ¬∞C (¬∞F) 5.4(41.7) 6.5(43.7) 10.3(50.5) 14.9(58.8) 18.6(65.5) 21.3(70.3) 23.4(74.1) 23.0(73.4)",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_6"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": "(50.5) 14.9(58.8) 18.6(65.5) 21.3(70.3) 23.4(74.1) 23.0(73.4) 19.4(66.9) 14.5(58.1) 9.3(48.7) 6.0(42.8) 14.4(57.9) Daily mean ¬∞C (¬∞F) 2.9(37.2) 3.2(37.8) 5.9(42.6) 9.6(49.3) 13.3(55.9) 16.1(61.0) 18.1(64.6) 17.7(63.9) 14.5(58.1) 10.5(50.9) 6.4(43.5) 3.5(38.3) 10.1(50.2) Mean daily minimum ¬∞C (¬∞F) 0.0(32.0) -0.0(32.0) 1.6(34.9) 3.8(38.8) 7.5(45.5) 10.4(50.7) 12.6(54.7) 12.3(54.1) 9.8(49.6) 6.6(43.9) 3.3(37.9) 0.9(33.6) 5.7(42.3) Record low ¬∞C (¬∞F) ‚àí24.2(‚àí11.6) ‚àí23.2(‚àí9.8) ‚àí17.0(1.4) ‚àí9.4(15.1) ‚àí4.5(23.9) ‚àí0.9(30.4) 2.0(35.6) 2.4(36.3) ‚àí0.9(30.4) ‚àí6.5(20.3) ‚àí9.9(14.2) ‚àí18.4(‚àí1.1) ‚àí24.2(‚àí11.6) Average precipitation mm (inches) 79.5(3.13) 63.7(2.51)",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_7"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": "(14.2) ‚àí18.4(‚àí1.1) ‚àí24.2(‚àí11.6) Average precipitation mm (inches) 79.5(3.13) 63.7(2.51) 60.7(2.39) 43.8(1.72) 62.9(2.48) 69.1(2.72) 86.5(3.41) 83.9(3.30) 73.8(2.91) 73.3(2.89) 79.5(3.13) 91.3(3.59) 868.0(34.17) Average relative humidity (%) 88.8 85.5 80.0 72.8 72.5 74.5 75.7 77.5 82.5 86.6 90.9 90.8 81.5 Mean monthly sunshine hours 62.7 86.7 135.8 181.6 205.1 196.2 203.2 188.3 148.7 115.9 66.7 53.5 1,644.4 Percentage possible sunshine 24.2 30.8 36.8 43.6 42.2 39.3 40.4 41.4 39.0 35.0 25.0 22.0 35.0 Source: Royal Netherlands Meteorological Institute[9][10] Demographics[edit] Inhabitants by nationality[edit] Arnhem residents by ethnic background (1 January 2023)[11] Country 2023 Netherlands 64.2% European Union 8.9% Turkey 5.2% Indonesia 3.4% Morocco 2.4% Suriname 2.1% Dutch Caribbean 2.1% Other non-western 11.7% Places of interest[edit] City centre The Grote Kerk (St. Eusebius' Church), built 1452‚Äì1560, lost most of its tower during World War II, of which a part has been reconstructed to a modern design and opened in 1964. Officially the tower is not part of the church and is owned by the municipality. The house of Maarten van Ros",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_8"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " of its tower during World War II, of which a part has been reconstructed to a modern design and opened in 1964. Officially the tower is not part of the church and is owned by the municipality. The house of Maarten van Rossum, a general serving Duke Charles van Gelre, has been the town hall since 1830: The satyrs in its Renaissance ornamentation earned it the name Duivelshuis (devil's house). The Netherlands Open Air Museum is located outside the city. It includes antique houses, farms, factories, and windmills from different parts of the Netherlands. Two other windmills stand in Arnhem itself, De Hoop and De Kroon. The Royal Burgers' Zoo in Arnhem is one of the biggest and most-visited zoos in the Netherlands, featuring an underwater walkthrough, desert, mangrove, and rainforest. The GelreDome, the home of Vitesse Arnhem, the city's Eredivisie team in football, is a unique facility that features a retractable roof and a slide-out grass pitch. The concept has been fully duplicated since then by the Veltins-Arena in Gelsenkirchen, Germany, and State Farm Stadium in Glendale, Arizona, U.S., and partially by the Sapporo Dome in Japan (which has a sliding pitch but a fixed roof). The KEMA Toren (formerly known as SEP Control Tower) is the highest structure of the town. It is a 140-m-high TV tower. Parks[edit] Sonsbeek Park (Urban park) Zypendaal Park Veluwezoom National Park Hoge Veluwe National Park Museums in and around Arnhem[edit] Netherlands Open Air Museum Airborne Museum 'Hartenstein' Gemeentemuseum Museum Bronbeek Buildings and locations[edit] Musis Sacrum Arnhem Centrum Central Station Burgers Zoo Events[edit] Airborne Commemoration (1994) Airborne Commemoration (17‚Äì26 September) World Statues Festival (The World Championship of Living Statues) Sonsbeek Theater Avenue Free Your Mind Festival Dancetour 8Bahn De Rabo Bridge to Bridge (Marathon) UITboulevard (Cultural Festival) Sprookjesfestival (Fairy tale Festival) King's Day Sinterklaas Hoogte80 ASM Festival Sport[edit] National Sports",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_9"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " Rabo Bridge to Bridge (Marathon) UITboulevard (Cultural Festival) Sprookjesfestival (Fairy tale Festival) King's Day Sinterklaas Hoogte80 ASM Festival Sport[edit] National Sports Centre Papendal GelreDome Stadium The National Sports Centre Papendal is the national sports development centre of the Netherlands, located in Arnhem. The first event held at Papendal was the 1980 Summer Paralympics, from 21 June to 5 July. However the site was formally adopted and developed from 1993, after the merger of the Dutch National Olympic Committee (NOC) and the Nederlandse Sport Federatie (NSF). NOC*NSF have 90 affiliated national sports organizations, representing about 2700 individual sports clubs.[12] Papendal is also the training location of football club Vitesse Arnhem, and the club's youth development system. Supporting facilities include a conference centre and hotel. In preparation for the 2012 Summer Olympics, in 2011 the facility built a replica of the proposed BMX racing track at the London Velopark venue.[13] The track will host the second event on the 2011 UCI BMX World Championships, on 27 and 28 May 2011. Since January 2013 Sports Centre Papendal officially split from NOC * NSF and thus as organization demerges. This split offers Sports Centre Papendal many commercial benefits. There are facilities for various sports, including athletics, cycling and more. Sport in the city is principally focussed on its association football club Vitesse Arnhem and its stadium the GelreDome built for the UEFA Euro 2000. The club has enjoyed some success in the Eredivisie and has featured in the UEFA Cup competition. Their best result in the Eredivisie was third place in 1997‚Äì98. The club won the KNVB Cup in 2016‚Äì17. Introdans is a dance company based in the city of Arnhem. In 2009 the Ministry of Education, Culture and Science designated Introdans part of the basic national infrastructure. In 2016 was the Giro d'Italia in Arnhem. Transport[edit] Trolleybus in Arnhem Due to its central location in Eastern Netherlands, Arnhem is a hub for water, road, and rail traffic",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_10"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " In 2016 was the Giro d'Italia in Arnhem. Transport[edit] Trolleybus in Arnhem Due to its central location in Eastern Netherlands, Arnhem is a hub for water, road, and rail traffic. Arnhem is bikeable. The RijnWaalpad is a 17 km long bicycle highway and connects Arnhem with Nijmegen. It is the region's first fast-paced cycling route. In 2018 the second fast bike route was opened and Arnhem connects with Wageningen. Arnhem has had a main central railway station since 1845 ‚Äì Arnhem Centraal railway station, which is serviced by several intercity lines and the Intercity-Express to D√ºsseldorf and further on to Frankfurt. Until 2016, there were also NS International trains to other destinations abroad, with some coaches going as far as Moscow. The intercity lines provide direct connections to Utrecht, Nijmegen and Zutphen. It is also the terminus for several local railway services. Arnhem has three other stations, namely Arnhem Velperpoort (since 1953), Arnhem Presikhaaf (since 1969) and Arnhem Zuid (since 2005). KLM operates a bus from the train station to Schiphol Airport for its customers until April 2025.[14][15] Arnhem is unique in the Netherlands with its trolleybus system. Notable people[edit] Karel Aalbers (1949), Business man and club president Truus van Aalten (1910‚Äì1999), actress Afro Brothers (2016), electronic/urban DJ duo Blaudzun (1974), singer-songwriter Marion Bloem (1952), writer and film maker Hetty Blok (1920‚Äì2012), cabaret artist, singer, and actress Edmond Classen (1938‚Äì2014), actor Ien Dales (1931‚Äì1994), politician of the Labour Party (PvdA) Esm√©e Denters (1988), singer and YouTube celebrity Eva Duldig (born 1938), Austrian-born Australian and Dutch tennis player, author Henk Guth (1921-2002), artist Jan van Hooff (1936), biologist Aarnoud van Heemstra (1871‚Äì1957), politician and maternal grandfather of Audrey",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_11"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": "), Austrian-born Australian and Dutch tennis player, author Henk Guth (1921-2002), artist Jan van Hooff (1936), biologist Aarnoud van Heemstra (1871‚Äì1957), politician and maternal grandfather of Audrey Hepburn Kenny van Hummel (1982), bicycle racer Rudolf Jansen (1940‚Äì2024), pianist Tania de Jong, Dutch-born Australian soprano and entrepreneur; daughter of Eva Duldig Ferdi Kadƒ±oƒülu, (1999), Dutch-born Turkish player Antonie Kamerling (1966‚Äì2010), actor and musician Herman Koch (1953), writer and actor Hendrik Lorentz (1853‚Äì1928), physicist and Nobel Prize laureate Mark van der Maarel (1989), former Dutch football player Goos Meeuwsen (1982), circus artist Leo Peelen (1968‚Äì2017), track cyclist Estavana Polman (1992), handballer Eveline Saalberg (1998), Track and Field Runner, 4x400m Relay European Indoor Champion (2023), 4x400m Relay European Outdoor Champion (2022, 2024), 4x400m Relay World Outdoor Champion (2023), 4x400m Relay World Indoor Champion (2024), 4x400m Relay Silver Medalist at the 2024 Summer Olympics Joran van der Sloot (1987), convicted murderer Mart Smeets (1947), radio and television host, and writer Saar de Swart (1861‚Äì1951), sculptor Rik Toonen (1954), water polo player, bronze medalist at the 1976 Summer Olympics Linda Wagenmakers (1975), singer and voice actress William H. Machen (1832-1911), Dutch-born American artist Facts and figures[edit] Arnhem is the name of a march composed by A.E. Kelly. Arnhem Land in Australia is named after the VOC-ship Arnhem. Theirs is the Glory (a.k.a. Men of Arnhem), is a 1946 British war film about the British 1st Airborne Division's involvement in the Battle of Arnhem (17 to 25 September 1944) during Operation Market Garden in the Second World War. Another film, A Bridge Too Far, tells the story of the failure of Operation Market Garden in Arnh",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_12"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": "'s involvement in the Battle of Arnhem (17 to 25 September 1944) during Operation Market Garden in the Second World War. Another film, A Bridge Too Far, tells the story of the failure of Operation Market Garden in Arnhem. Twin towns ‚Äì sister cities[edit] See also: List of twin towns and sister cities in the Netherlands Arnhem is twinned with:[16] Coventry, England, United Kingdom Croydon, England, United Kingdom Gera, Germany Hradec Kr√°lov√©, Czech Republic Kimberley, South Africa Villa El Salvador, Peru Airdrie, Scotland, United Kingdom See also[edit] Arnhem Metal Meeting References[edit] ^ \"Ahmed Marcouch (burgemeester)\" [Ahmed Marcouch (mayor)] (in Dutch). Gemeente Arnhem. Archived from the original on 22 April 2016. Retrieved 10 June 2014. ^ \"Kerncijfers wijken en buurten 2020\" [Key figures for neighbourhoods 2020]. StatLine (in Dutch). CBS. 24 July 2020. Retrieved 19 September 2020. ^ \"Postcodetool for 6811DG\". Actueel Hoogtebestand Nederland (in Dutch). Het Waterschapshuis. Archived from the original on 21 September 2013. Retrieved 10 June 2014. ^ \"Bevolkingsontwikkeling; regio per maand\" [Population growth; regions per month]. CBS Statline (in Dutch). CBS. 1 January 2021. Retrieved 2 January 2022. ^ \"Bevolkingsontwikkeling; Regionale kerncijfers Nederland\" [Regional core figures Netherlands]. CBS Statline (in Dutch). CBS. 1 January 2020. Retrieved 8 March 2021. ^ a b \"Arnhem | Netherlands | Britannica\". May 2023. ^ Megargee, Geoffrey P. (2009). The United States Holocaust Memorial Museum Encyclopedia of Camps and Ghettos 1933‚Äì1945. Volume I. Indiana University Press, United States Holocaust Memorial Museum. p. 820. ISBN 978-0-253-35328-3. ^ \"Arnhem 1980\". ^ \"Weerstatistieken Deelen\". Royal Netherlands Meteorological Institute",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_13"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": ", United States Holocaust Memorial Museum. p. 820. ISBN 978-0-253-35328-3. ^ \"Arnhem 1980\". ^ \"Weerstatistieken Deelen\". Royal Netherlands Meteorological Institute. Retrieved 25 June 2022. ^ \"Klimaatviewer 1991-2020\". Royal Netherlands Meteorological Institute. Retrieved 25 June 2022. ^ \"Mosaic3\". arnhem.incijfers.nl. Retrieved 25 April 2023. ^ \"Over ons (About us)\" (in Dutch). NOC*NSF. Retrieved 4 December 2010. ^ Ollie Williams (25 March 2011). \"Building a London 2012 venue - in a Dutch forest\". BBC Sport. Retrieved 25 March 2011. ^ \"Travel by bus or rail with a KLM ticket Archived 29 October 2016 at the Wayback Machine.\" KLM. Retrieved 29 October 2016. ^ Marks, Jitka (28 January 2025). \"Geen gratis bus naar Schiphol meer vanuit Nijmegen en Arnhem\". www.gld.nl. ^ \"Arnhem\" (PDF). amazing-holland.nl (in Dutch). Amazing Holland. p. 11. Retrieved 21 July 2021. External links[edit] Wikimedia Commons has media related to Arnhem. Wikivoyage has a travel guide for Arnhem. Municipality Official website (English version) VVV Arnhem Archived 12 April 2018 at the Wayback Machine Tourist Office (English version) Commonwealth War Graves Commission The CWGC Page for the cemetery. Places adjacent to Arnhem Ede Apeldoorn Rozendaal Renkum Arnhem Rheden Overbetuwe Lingewaard IJssel / Westervoort vteMunicipalities of Gelderland Aalten Apeldoorn Arnhem Barneveld Berg en Dal Berkelland Beuningen Bronckhorst Brummen Buren Culemborg Doesburg Doetinchem Druten Duiven Ede Elburg Epe Ermelo Harderwijk Hattem Heerde Heumen Lingewaard Lochem Maasdriel Montferland Neder-Betuwe Nijkerk Nijmegen Nunspeet Oldebroek Oost Gelre Oude IJ",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_14"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": "erwijk Hattem Heerde Heumen Lingewaard Lochem Maasdriel Montferland Neder-Betuwe Nijkerk Nijmegen Nunspeet Oldebroek Oost Gelre Oude IJsselstreek Overbetuwe Putten Renkum Rheden Rozendaal Scherpenzeel Tiel Voorst Wageningen West Betuwe West Maas en Waal Westervoort Wijchen Winterswijk Zaltbommel Zevenaar Zutphen See also Netherlands Provinces Municipalities vteCapital cities of the Kingdom of the NetherlandsNational capital: AmsterdamSeat of government: The HagueConstituent countriesProvincesPublic bodies Oranjestad, Aruba Willemstad, Cura√ßao Amsterdam, Netherlands Philipsburg, Sint Maarten Assen, Drenthe Lelystad, Flevoland Leeuwarden, Friesland Arnhem, Gelderland Groningen, Groningen Maastricht, Limburg 's-Hertogenbosch, North Brabant Haarlem, North Holland Zwolle, Overijssel The Hague, South Holland Utrecht, Utrecht Middelburg, Zeeland Kralendijk, Bonaire The Bottom, Saba Oranjestad, Sint Eustatius See also: List of cities in the Netherlands by province vte Summer Paralympic Games host cities 1960: Rome 1964: Tokyo 1968: Tel Aviv 1972: Heidelberg 1976: Toronto 1980: Arnhem 1984: New York City / Stoke Mandeville 1988: Seoul 1992: Barcelona / Madrid 1996: Atlanta 2000: Sydney 2004: Athens 2008: Beijing 2012: London 2016: Rio de Janeiro 2020: Tokyo 2024: Paris 2028: Los Angeles 2032: Brisbane Authority control databases InternationalISNIVIAFFASTWorldCatNationalGermanyUnited StatesFranceBnF dataCzech RepublicSpainVaticanIsraelCataloniaGeographicMusicBrainz areaOtherIdRefYale LUX Retrieved from \"https://en.wikipedia.org/w/index.php?title=Arnhem&oldid=1301388786\" Categories: ArnhemCities in the NetherlandsMunicipalities of GelderlandPopulated places in GelderlandPopulated",
    "token_count": 500,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_15"
  },
  {
    "id": "ee52d466-c065-4b1c-a23c-4942b7a71988",
    "created_at": "2025-07-26T15:29:21.491825+00:00",
    "source_type": "external",
    "source_path": "https://en.wikipedia.org/wiki/Arnhem",
    "title": "Arnhem - Wikipedia",
    "text": " Retrieved from \"https://en.wikipedia.org/w/index.php?title=Arnhem&oldid=1301388786\" Categories: ArnhemCities in the NetherlandsMunicipalities of GelderlandPopulated places in GelderlandPopulated places on the RhineProvincial capitals of the NetherlandsMembers of the Hanseatic LeagueHidden categories: Pages using gadget WikiMiniAtlasPages using the Phonos extensionCS1 Dutch-language sources (nl)Webarchive template wayback linksArticles with short descriptionShort description is different from WikidataUse dmy dates from November 2023Pages using multiple image with auto scaled imagesPages using infobox settlement with possible nickname listCoordinates on WikidataPages with Dutch IPAPages including recorded pronunciationsArticles containing German-language textPages with German IPAAll articles with unsourced statementsArticles with unsourced statements from August 2018Commons link from WikidataPages using the Kartographer extension Search Search Arnhem 103 languages Add topic",
    "token_count": 196,
    "chunk_id": "ee52d466-c065-4b1c-a23c-4942b7a71988_16"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "Delft University of Technology Short-term scenario-based probabilistic load forecasting A data-driven approach Khoshrou, Abdolrahman; Pauwels, Eric J. DOI 10.1016/j.apenergy.2019.01.155 Publication date 2019 Document Version Accepted author manuscript Citation (APA) Khoshrou, A., & Pauwels, E. J. (2019). Short-term scenario-based probabilistic load forecasting: A data- driven approach. Applied Energy, 238, 1258-1268. https://doi.org/10.1016/j.apenergy.2019.01.155 Important note To cite this publication, please use the final published version (if applicable). Please check the document version above. Copyright Other than for strictly personal use, it is not permitted to download, forward or distribute the text or part of it, without the consent of the author(s) and/or copyright holder(s), unless the work is under an open content license such as Creative Commons. Takedown policy Please contact us and provide details if you believe this document breaches copyrights. We will remove access to the work immediately and investigate your claim. This work is downloaded from Delft University of Technology. For technical reasons the number of authors shown on this cover page is limited to a maximum of 10. Short-Term Scenario-Based Probabilistic Load Forecasting: A Data-Driven Approach Abdolrahman Khoshroua,b,1,‚àó, Eric J. Pauwelsa,2 aCentrum Wiskunde & Informatica, Science Park 123, 1098 XG, Amsterdam, The Netherlands bDepartment of Mathematics and Computer Science, Delft University of Technology, The Netherlands Abstract Scenario-based probabilistic forecasting models have been explored extensively in the literature in recent years. The performance of such models evidently depends to a large extent on how diÔ¨Äerent input (temperature) scenarios are being generated. This paper proposes a generic framework for probabilistic load forecasting using an ensemble of regression trees. A major distinction of the current work is in using matrices as an alternative representation for quasi-periodic time series data. The singular value decomposition (SVD) technique is then used herein to generate temperature scenarios in a robust and timely manner. The strength of our proposed method lies in its simplicity and robustness, in terms of the training window size, with no need for subsetting or thresholding to generate",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_1"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": ") technique is then used herein to generate temperature scenarios in a robust and timely manner. The strength of our proposed method lies in its simplicity and robustness, in terms of the training window size, with no need for subsetting or thresholding to generate temperature scenarios. Furthermore, to systematically account for the non-linear interactions between diÔ¨Äerent variables, a new set of features is deÔ¨Åned: the Ô¨Årst and second derivatives of the predictors. The empirical case studies performed on the data from the load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014-L) show that the proposed method outperforms the top two scenario-based models with a similar set-up. Keywords: Time-series analysis, Energy forecasting, Probabilistic forecasting, Time-varying eÔ¨Äects, Singular value decomposition 1. Introduction In the energy transition era (transition from conventional to non-conventional energy sources), the balancing of the power grid has become more challenging. It is mostly due to the inherently intermittent nature of renewable energy sources (RES), on the one hand, and shortcomings in bulk energy storage systems, on the other. The studies on probabilistic energy production and demand forecast have hence gained momentum, as they are highly valuable from both a technical and an economic point of view [18]. Generally speaking, load forecasting problems can be contemplated from two main perspectives: 1) time hori- zon; and 2) type of forecasting (point vs. probabilistic forecasting). The time-interval of interest, which can vary from the next few seconds or minutes to a couple of months or even years, categorizes the load forecasting problems into four groups [18]. The future of a grid and its expansion in long run is studied in the context of long term load forecasting (LTLF). Moreover, balance sheet calculations, risk management, purchasing energy and price planning purposes are most relevant from a few weeks up to a few months in advance; that is where medium term load fore- casting (MTLF) techniques come into play. Short term load forecasting (STLF), as a dominant factor in electricity dispatching, scheduling and unit commitment, is mostly concerned with the load estimations for a few hours up to a few days ahead. Finally, very short term load forecasting (VSTLF) approaches are aimed to mitigate the possible mismatches between supply and demand, by generating highly accurate load prognoses for the coming half an",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_2"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "ations for a few hours up to a few days ahead. Finally, very short term load forecasting (VSTLF) approaches are aimed to mitigate the possible mismatches between supply and demand, by generating highly accurate load prognoses for the coming half an hour or less. Although point (single-value) load forecasting methodologies have been implemented since the early days of ‚àóCorresponding author: a.khoshrou@cwi.nl 1Abdolrahman Khoshrou is with the Intelligent and Autonomous Systems Group at CWI; he is also a guest PhD student at TU Delft. 2Eric Pauwels is a senior researcher and the leader of the Intelligent and Autonomous Systems Group at CWI. Postprint: Applied Energy Journal November 2018 ¬© 2019 Manuscript version made available under CC-BY-NC-ND 4.0 license https:// creativecommons.org/licenses/by-nc-nd/4.0/ modern grids, probabilistic load forecasting (PLF) studies have gained prominence in recent years [18]. Moreover, with the growing integration of weather-dependent and intermittent RES, diÔ¨Äerent lines of research on the energy systems data have emerged. These include issues such as data-driven outlier detection, pre-processing, incorporating the dependency between diÔ¨Äerent attributes, and so on demand further exploration. Load forecasting methodologies can typically be classiÔ¨Åed into two groups: statistical and machine learning (ML) based techniques. The major argument in favor of the statistical approaches is the interpretability of their results; noteworthy is that some expert knowledge is usually needed to (partially) guide the learning process. On the other hand, ML based approaches are more independent in the sense that the user interventions are mostly limited to hyper- parameter tuning. Such models are generally more robust, easy to reconÔ¨Ågure, user-friendly and successful in ad- dressing the non-linearity in the data. The major drawback of ML based methods, however, is that being a black box, it is often not clear how diÔ¨Äerent attributes have contributed to the Ô¨Ånal results. A number of single-value and probabilistic load forecasting models using two diÔ¨Äerent statistical and ML based approaches are summarized below. Statistical approaches: Multiple linear regression (MLR) models are among the most fundamental and widely used models for both STLF and LTLF problems. Broadly speaking, such models are",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_3"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "ÔøΩÔøΩerent statistical and ML based approaches are summarized below. Statistical approaches: Multiple linear regression (MLR) models are among the most fundamental and widely used models for both STLF and LTLF problems. Broadly speaking, such models are mostly aimed to learn a relationship between several explanatory variables and a dependent (target) variable. Typically, a goodness-of-Ô¨Åt function is used to estimate the target variable (load) based on other explanatory attributes (such as historical load and temperature data, calendar information or some interaction of them). The performance of such models, consequently, are only satisfactory if the dependent variables are well formulated based on explanatory variables. However, the most striking feature of such models is their need for some expert-knowledge to formulate the interaction between diÔ¨Äerent variables - namely the recency eÔ¨Äect, as it seems unworkable to incorporate the eÔ¨Äects between diÔ¨Äerent variables without some domain expertise. Usually, a large number of lagged temperature data are being used to account for the recency eÔ¨Äect (which leads to an increase of the parameter-space). A solid ground for applying MLR analysis to STLF is provided in [34]. To include in part the interactions between the variables, 24 separate family regression models (one model for every hour of the day) have repeatedly been deployed in the literature to generate the day-ahead load prognoses (see e.g., [35]). Nonetheless, an interesting Ô¨Ånding in [39] is that using 24 separate models (one for every hour of the day) might not necessarily ensure outperformance of such models over one interaction model for all 24 hours. Another category of regression based models are semi-parametric additive models, which generally are designed to address the nonlinear relationships and serially correlated errors. Auto regressive integrated moving average (ARIMA) models, as a class of ARMA models, are well-suited to capture diÔ¨Äerent standard temporal structures in time series data. A family of such statistical models have been used numerously in the literature for time series forecasting problems, as they oÔ¨Äer a baseline regression-based approach to account for the recency eÔ¨Äect in the data. A comprehensive discussion on diÔ¨Äerent types of autoregressive models, such as ARMA, ARIMA and ARMAX models is presented in [32]. Exponential",
    "token_count": 499,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_4"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " account for the recency eÔ¨Äect in the data. A comprehensive discussion on diÔ¨Äerent types of autoregressive models, such as ARMA, ARIMA and ARMAX models is presented in [32]. Exponential smoothing is another capable and eÔ¨Äective approach to systematically assimilate the recency eÔ¨Äect in the data, by assigning weights to the previous data points inside a certain window [22]. However, the major drawback of most statistical models lies in their need for a lot of hyper-parameter tuning; speciÔ¨Åc factors such as threshold sets, the choice of lag sets, and also capturing the time-varying structures of the coeÔ¨Écients are crucial in the overall performance of the model. Furthermore, setting up a good Ô¨Åt enlarges the parameter space, which brings about longer computation time and raises the concern of over-Ô¨Åtting. To better accommodate the various non-linearity in the data, a least absolute shrinkage and selection operator (LASSO) estimation algorithm is introduced in [44]. Machine learning approaches : Machine learning (ML) based approaches are in fact a number of more advanced sta- tistical methods for handling more complex regression and classiÔ¨Åcation problems. Support vector machines (SVM), artiÔ¨Åcial neural networks (ANN), fuzzy regression models, classiÔ¨Åcation and regression trees (CART), and k‚àínearest neighbours are among the most well-recognized ML based techniques. SVM is a powerful method for handling vari- ous regression and classiÔ¨Åcation problems by recognizing patterns and constructing nonlinear decision boundaries. A generic model for STLF problem using SVM is developed in [8]; the strength of this work lies in its novel automatic feature selection algorithms and also the use of a particle swarm global optimization based technique to tweak the hyper-parameters. To enhance the performance of such models, diÔ¨Äerent clustering approaches (e.g., based on hour of the day) have been proposed in the literature to group the data Ô¨Årst, and apply an SVM model on each subset of data. In [14], an unsupervised self organizing map (SOM) is used for clustering the load proÔ¨Åles, Ô¨Årst; an SVM regression model, for each group, is then applied to estimate the daily load proÔ¨Åles. As mentioned before, failing to 2 incorporate the rec",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_5"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "OM) is used for clustering the load proÔ¨Åles, Ô¨Årst; an SVM regression model, for each group, is then applied to estimate the daily load proÔ¨Åles. As mentioned before, failing to 2 incorporate the recency eÔ¨Äects in forecasting methodologies can lead to under performance. An SVM type hourly load forecasting model in [10] accounts for the recency eÔ¨Äects by including a couple of previous ambient temperature values (several hours) as input variables. Nevertheless, the performance of such models relies on a suitable kernel function and hyper-parameter settings. A new approach for choosing an optimal kernel function for an SVM based model is proposed in [9]. Furthermore, fuzzy logic models have been developed to address some limitations of the linear models such as vague relation between diÔ¨Äerent independent and dependent attributes, shortage in the number of observations, and error distribution veriÔ¨Åcation [11], [23]. Such models provides a means to better incorporate the recency and cross eÔ¨Äects in the data, and hence can outperform their corresponding MLR based counterpart mod- els [20]. Over the last few years, artiÔ¨Åcial neural networks (ANN) have seen an explosion of interest in various types of prediction, classiÔ¨Åcation and control applications across diÔ¨Äerent Ô¨Åelds. Typically, ANN do not perform based on modelling the underlying relation between predictors and the target variable; a mapping mechanism is instead in place to assign inputs to a target variable. DiÔ¨Äerent variations of (hybrid) NN-based models for the STLF problems have been proposed [36], [41]. It is a common sense that no individual forecasting model is the best for all data sets. Therefore, it is highly appreciated to combine diÔ¨Äerent forecasts to reduce the overall risk of making poor decisions. In [31], forecast combinations or ensemble models are classiÔ¨Åed into homogeneous and heterogeneous ensemble methods. In the former method, diÔ¨Äerent forecast series are obtained by varying the hyper-parameters, input data, input features, or output targets for the same algorithm. The latter method, however, combines a number of forecasts with the hope that diversity help improving the results. Some examples of the application of diÔ¨Äerent types of ensemble learning methods in energy forecasting tasks are presented in [4], [12],",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_6"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " latter method, however, combines a number of forecasts with the hope that diversity help improving the results. Some examples of the application of diÔ¨Äerent types of ensemble learning methods in energy forecasting tasks are presented in [4], [12], [27]. S. B. Taieb and R. J. Hyndman propose a robust component-wise gradient boosting model for STLF in [38]. The reported work incorporates diÔ¨Äerent non-parametric eÔ¨Äects such as calendar, temperature, lagged demand using an additive framework; it is done by considering a separate model for each hour of the day (24 diÔ¨Äerent models for a day). Furthermore, univariate penalized regression spline functions is used to account for the recency eÔ¨Äect in the data. However, caution should be exercised in the application of most exponential smoothing models, as the performance heavily relies on the window-size and hyper-parameter tuning [38]. Scenario-based probabilistic load forecasting models, as a subcategory of homogeneous models, have been exercised extensively, in recent years. Among the various methods, feeding simulated temperature scenarios to a single-value load forecasting model is being commonly accepted by the industry for its simplicity and interpretability. There are mainly three practical and popular methods for generating temperature scenarios, namely Ô¨Åxed-date, shifted- date, and bootstrap approaches. Nevertheless, these methods have mostly been used on an ad-hoc basis without being formally compared or quantitatively evaluated [43]. The performance of such models evidently depends to a great deal on how diÔ¨Äerent temperature scenarios are being generated. Addressing the issues such as outliers, or gradual drifts in the data is essential in developing an accurate model. Another challenge in load forecasting problems (especially, short term) is the incorporation of recency eÔ¨Äects of the data using time-varying models. The recency eÔ¨Äect refers to the continuous nature of electricity consumption - at any moment it depends on the weather conditions and accordingly load, prior to that [28]. In other words, it mostly reÔ¨Çects the lagging eÔ¨Äect associated with the thermal inertia of the buildings and facilities. In the literature, some heuristic, data-oriented lagging window of a couple hours, or subsetting of the data are typical approaches to incorporate the recency eÔ¨Äect [28], [39]. The",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_7"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " inertia of the buildings and facilities. In the literature, some heuristic, data-oriented lagging window of a couple hours, or subsetting of the data are typical approaches to incorporate the recency eÔ¨Äect [28], [39]. The major concern regarding such methods is the generalizability of the results, as, e.g., the window size or the threshold in the subsetting step can aÔ¨Äect the performance of the models drastically [44]. We herein propose two scenario-based probabilistic load forecasting models using an ensemble of regression trees. The contribution of this paper is as follow. ‚Ä¢ An important distinction of the current work is the use of matrices as an alternative representation of the data. The singular value decomposition (SVD) technique is then used to generate temperature scenarios, in a robust and data-driven manner. ‚Ä¢ In the second model, we extend the Ô¨Årst one by adding the Ô¨Årst and the second derivatives of the non-deterministic attributes (temperature and historical load data). This was done to partially account for the recency eÔ¨Äects and interactions among the data. Unlike some family of time-varying models, our proposed approach is systematic, with no need for subsetting or thresholding the data. ‚Ä¢ The experiment results show that special enhancements can consequently be obtained using this new set of 3 features (Section 4). The rest of this paper is organized as follow. Section 2 provides a brief introduction to the data from the load fore- casting track of the Global Energy Forecasting Competition (GEFCom2014-L). Section 3 is devoted to our methodol- ogy in this paper. A brief recapitulation of the Gradient Boosting method is presented, Ô¨Årst, followed by out proposed models for point forecasting. After an introduction to the singular value decomposition (SVD), we explain how our proposed scenario based load forecasting models works. The proposed method in this paper is, in fact, a marriage between an SVD-based temperature scenario generator and an ensemble of trees (gradient boosting algorithm). The experimental results along with a comparison with the results of a number of benchmark models are presented in Section 4. We conclude this work in Section 5. 2. Data To make the results of the proposed models replicable and accordingly comparable with the benchmark models, a case study was constructed based on the data from the load forecasting track of the Global Energy Forecasting Compe- tition ",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_8"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "5. 2. Data To make the results of the proposed models replicable and accordingly comparable with the benchmark models, a case study was constructed based on the data from the load forecasting track of the Global Energy Forecasting Compe- tition 2014 (GEFCom2014-L). The participants had been asked to develop a short term probabilistic load forecasting model, with the forecasting horizon of one month. The publicly available data set consists of the hourly temperature values from 25 anonymous weather stations and the aggregated hourly load proÔ¨Åles; for detailed description of data and the competition instructions see [19]. The electricity consumption patterns are subject to a variety of factors, such as meteorological conditions, calendar information, season, working schedules, energy cost and economic activ- ities [30]. In the current work, however, consistent with the requirements in the GEFCom2014-L, only the temperature and the calendar information are considered as the available predictors (besides historic load proÔ¨Åles). Temperature is believed to be a major driving force behind the electricity demand; the non-linear eÔ¨Äect of the temperature to the electricity demand is hence at the center of our attention. The left panel of Figure 1 provides an overview of the typical electricity consumption proÔ¨Åles on daily basis. This Ô¨Ågure aÔ¨Érms that the consumption patterns diÔ¨Äer notably during the weekends from the weekdays. Interestingly enough, on Friday afternoons, the demand proÔ¨Åle gets close to the weekends, whereas, during the working hours, it is akin to other working days. Furthermore, the right panel in Figure 1, illustrates the evolution of daily load proÔ¨Åles in the year 2010; this Ô¨Ågure was obtained by recasting the time series into a 24 √ó 365 matrix, where every column contains 24 hourly values for each daily proÔ¨Åle [24]. As expected, in spring and fall, where the temperature is moderate, electricity demand tends to be lower than any other time of the year (winter and summer times). It underscores the fact that electricity demand is driven by climate conditions (e.g., air conditioning usage), and also the lifestyle changes followed by that. This Ô¨Ågure also highlights the non-linear relation between load and temperature throughout the year. In the literature, temperature is arguably the most dominant predictor of the load; however, in and of itself, it is",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_9"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " the lifestyle changes followed by that. This Ô¨Ågure also highlights the non-linear relation between load and temperature throughout the year. In the literature, temperature is arguably the most dominant predictor of the load; however, in and of itself, it is not suÔ¨Écient, for two main reasons: ‚Ä¢ Diurnal human activities: As it is seen in the left panel of Figure 1, the typical electricity demand behaviour changes throughout the week. These diurnal human activities are plainly not reÔ¨Çected in the temperature data. Figure 1: Left: Comparison of typical daily consumption patterns during the week. Right: An overall representation of the evolution of the load proÔ¨Åles throughout a year. 4 Figure 2: An overview of the evolution of the Ô¨Årst derivative of the temperature (Left) and load (Right) proÔ¨Åles. ‚Ä¢ Recency and cross eÔ¨Äects: Even for similar days (weekends or weekdays), the trend of daily load proÔ¨Åles, corresponding to similar temperature data, might not be necessarily alike; the recency and cross eÔ¨Äects can play a vital role. For instance, the rise of temperature in early spring might not necessarily lead to high electricity consumption, in comparison with summer times, as people might appreciate the rise in outside temperature after a cold winter. This, of course, can deviate across diÔ¨Äerent seasons. Figure 2 illustrates an overview of the trend (Ô¨Årst derivative) changes of daily temperature and load proÔ¨Åles in 2010. These Ô¨Ågures were obtained by taking the Ô¨Årst derivatives of daily temperature and load matrices. It is seen that, e.g., in early spring and summer time, with the rise of temperature, afternoon peak proÔ¨Åles start to disappear. Although, the overall relationship between load and temperature is clear; it is, however, non-trivial how to robustly address the non-linear eÔ¨Äect between temperature and load proÔ¨Åles. Experiment results in Section 4 aÔ¨Érm that including the 1st and 2nd derivatives of the daily proÔ¨Åles can indeed enhance the performance of the forecasting model. The following section provides a brief to the ensemble of regression trees, followed by our proposed methodology for probabilistic STLF problem. 3. Methodology In the present work, we opt to use an ensemble of regression",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_10"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " the performance of the forecasting model. The following section provides a brief to the ensemble of regression trees, followed by our proposed methodology for probabilistic STLF problem. 3. Methodology In the present work, we opt to use an ensemble of regression trees (Gradient Boosting method) to predict day-ahead load prognoses, with forecasting horizon of one month, given hourly temperature proÔ¨Åles, historical (or estimated) load proÔ¨Åles, and calendar information. A brief recapitulation of an ensemble of regression trees is Ô¨Årst provided in below. 3.1. Ensemble of regression trees The use of ‚Äúensemble learning‚Äù methods in various classiÔ¨Åcation and regression problems has taken oÔ¨Äover the last few years. Ensembles generally rely on ‚Äúresampling‚Äù techniques to obtain diÔ¨Äerent training sets for each individual regression or classiÔ¨Åcation model. Two popular methods for creating accurate ensembles are bootstrap aggregating (Bagging) and Boosting. In Bagging method, the training data for each individual model is drawn randomly, i.e., n instances with replacement- where n is the number of observations in the training set. In other words, successive members (e.g., trees or neural networks) in this method are independent of each other; since each member of the ensemble is trained individually using a bootstrap sample of the data set [5]. In other words, Bagging methods control the generalization error through perturbation and averaging of sub-models. Worth noting that in this approach, to ensure that every training sample is predicted at least a few times, the number of trees needs to be large enough. Since the trees are independent of each other, the distribution function and the quantiles of each hourly forecast can be easily computed based on the output of all the trees [40]. In Gradient Boosting method, however, the training set for each member of the ensemble depends on the per- formance of the previous model(s). More precisely, in order to alleviate the error in earlier models, extra weights are assigned to samples with higher prediction error rates; those are hence more likely to take part in the training of 5 the next model [16, 15]. A comprehensive evaluation of both these techniques on 23 data sets, using two popular classiÔ¨Åers, i.e., decision trees and neural networks is presented in [33]. The applicability of Gradient Boosting method in quantile regression load",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_11"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "]. A comprehensive evaluation of both these techniques on 23 data sets, using two popular classiÔ¨Åers, i.e., decision trees and neural networks is presented in [33]. The applicability of Gradient Boosting method in quantile regression load forecasting application have been put into practice in [38, 40]. A brief recapitulation of the Gradient Boosting method, as the main methodology used herein to predict the hourly load values, is provided in below. The goal in every typical prediction problem is to determine an estimate or approximation ÀÜF(x), of the true map- ping function F‚àó(x) which assigns a y ‚ààR to any given set of covariates x ‚ààRp. This process is optimized by minimizing the expected value of some speciÔ¨Åed loss function L(y, F(x)) over the set of the joint distribution of all {y, x} pairs. In mathematical parlance, we have: F‚àó(x) = arg min F(x) Ey,xL(y, F(x)) = arg min F(x) Ex[Ey(L(y, F(x)))|x] (1) where E(.) is the expectation operator, and L(y, F(x)) is a loss function, e.g., the popular choice of squared-error {y ‚àíF(x)}2, for regression problems. F(x) is a member of ‚Äúadditive‚Äù class of functions of the form: F(x; {Œªk, ak}K 1 ) = K X k=1 Œªkh(x; ak). (2) where K is the number of members of the ensemble model, Œªk is the coeÔ¨Écient of the additive model, the generic Algorithm 1: The Gradient Boosting Algorithm, with an squared-error loss function, in a nutshell. Initialization: F0(x) = ¬Øy for k=1 to K do Àúyi = yi ‚àíFk‚àí1(xi), i ‚àà[1 : N] (œÅk, ak) = arg min œÅ,a NP i=1 [ Àúyi ‚àíœÅ h(xi; a)]2 Fk(x) = Fk‚àí1(x) + œÅkh(x; ak) end function h(x; a) in (2) is called a weak learner or base learner-it is usually a simple parameterized function of the explanatory variables, speciÔ¨Åed by parameters a = {a1",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_12"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "ÔøΩkh(x; ak) end function h(x; a) in (2) is called a weak learner or base learner-it is usually a simple parameterized function of the explanatory variables, speciÔ¨Åed by parameters a = {a1, a2, . . .}. In the present work, each h(x; ak) is a small regression tree as introduced in [7]. For a regression tree the parameters ak are the splitting variables, split locations and means of the terminal node of the individual trees. An overview of the Gradient Boosting algorithm, with an squared-error loss function is presented in Algorithm 1, where the multiplier œÅk is given by the line search: œÅk = arg min Ey,xL(y, Fk‚àí1(x) ‚àíœÅgk(x)) œÅ , (3) and gk(x) = Ey \"‚àÇL(y, F(x)) ‚àÇF(x) # F(x)=Fk‚àí1(x) . (4) The rationale underpinning the choice of the ensemble of the trees is their ability in better handling the hetero- geneous input data‚Äìwhich comprise both continuous and discrete variables. Additionally, tree models are eÔ¨Äective, adaptive and modular, in that new predictors can be easily added. It is perceived that ensemble models, unlike their other ML based counterparts, are less prone to overÔ¨Åtting; they promise to strike a good trade-oÔ¨Äbetween bias and variance [6]. 3.2. Our proposed forecasting models Generally speaking, a regression tree is an adaptive nearest neighbours like algorithm. However, it usually shows a better performance in comparison with other counterpart nearest neighbour-based methods; it tends to Ô¨Ånd the homogeneous portions of the sampling space locally, on the contrary to the other conventional methods which incline to treat all distances equally [29]. In the present work, we follow a homogeneous forecast combination framework, 6 Attribute Description Model no. mn month of year: 1,2,...,12 I,II wk day of week: 1,2,...,7 I,II hr hour of day: 1,2,...,24 I,II L(d ‚àí1) previous day (estimated) hourly load I,II L(d ‚àí7) previous week (estimated) hourly load I,II T(d) hourly temperature (generated proÔ¨Åles) I,II L‚Ä≤(d ‚àí1) 1",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_13"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": ") previous day (estimated) hourly load I,II L(d ‚àí7) previous week (estimated) hourly load I,II T(d) hourly temperature (generated proÔ¨Åles) I,II L‚Ä≤(d ‚àí1) 1st derivative of L(d ‚àí1) II L‚Ä≤‚Ä≤(d ‚àí1) 2nd derivative of L(d ‚àí1) II L‚Ä≤(d ‚àí7) 1st derivative of L(d ‚àí7) II L‚Ä≤‚Ä≤(d ‚àí7) 2nd derivative of L(d ‚àí7) II T‚Ä≤(d) 1st derivative of T(d) II T‚Ä≤‚Ä≤(d) 2nd derivative of T(d) II L(d) hourly load (forecast target) I,II Table 1: An overview of the attributes used in our proposed models. i.e., we, Ô¨Årst, train a single-value load forecasting model, then, vary the input data (diÔ¨Äerent temperature scenarios) to obtain a series of forecasts, and accordingly, the quantiles. Time series data in smart energy systems often comprise more than one distinct time scales. There are some conspicuous diurnal patterns in the data, reÔ¨Çecting typical patterns for daily or weekly human activities. Furthermore, the overall structure of the data is aÔ¨Äected by a combination of those fast diurnal patterns superimposed on slower seasonal variations [24]. We herein consider two Gradient Boosting based methods to predict the day-ahead load prognoses. In the Ô¨Årst model, only calendar information, temperature data along with the historical load data are the input variables. We proceed further in the second model to incorporate the daily dynamics of the temperature and load proÔ¨Åles. It is done using the Ô¨Årst and second derivatives of the daily proÔ¨Åles. As it was principled in [19] the forecasting horizon is one month, therefore, the estimated values for the Ô¨Årst week of the month are being used to estimate the load proÔ¨Åles in the second week of the month and so on. In all cases, the aim is to predict L(d), 24 hourly load values for the target day d. Power consumption is subject to a wide range of exogenous variables, including calendar eÔ¨Äects, electricity price and so on. In the literature, the previous consumption patterns and calendar information have been extensively used in developing various load forecasting models",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_14"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": ". Power consumption is subject to a wide range of exogenous variables, including calendar eÔ¨Äects, electricity price and so on. In the literature, the previous consumption patterns and calendar information have been extensively used in developing various load forecasting models. However, accounting for the interaction between diÔ¨Äerent variables, namely the recency and cross eÔ¨Äects can be an onerous task; it demands some domain expertise to be done sensibly [28, 39]. A number of common deterministic (categorical) explanatory variables used in our methodologies are as follows: month of the year mn ‚àà{1, 2, . . . , 12}, day of the week wk ‚àà{1, 2, . . . , 7} (starting from Sunday=1), and hour of the day hr ‚àà{1, 2, . . . , 24}. Below we discuss the models in more details, but for ease of reference, Table 1 summarizes all the common and distinctive attributes used in two proposed models. Model I: The Ô¨Årst model provides us with a benchmark to measure the credibility of our proposed method in incor- porating the recency and cross eÔ¨Äects in the data in Model II. Here, we introduce six diÔ¨Äerent attributes to predict the hourly load values on the target day d. The three above mentioned common discrete (categorical) values, namely, mn, wk, hr, along with the (estimated) load value for a given hour on a day or a week before (L(d ‚àí1) and L(d ‚àí7), respectively). The intuition for this choice is the reÔ¨Çection of diurnal and weekly human activities on electricity con- sumption (Figure 1). The last covariate T(d) is the hourly temperature forecast for the target day d. As it it explained in Section 3.3, we generate one hundred independent temperature proÔ¨Åles, using the singular value decomposition, to correspondingly obtain 100 independent load forecasts for each target day; the combination of these forecasts are then used to obtain the load quantiles for each hour. Model II: To reÔ¨Çect the lagging eÔ¨Äect of temperature on load changes, in the second model, we add the daily dynam- ics of the temperature and load proÔ¨Åles (1st and 2nd derivatives)",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_15"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " reÔ¨Çect the lagging eÔ¨Äect of temperature on load changes, in the second model, we add the daily dynam- ics of the temperature and load proÔ¨Åles (1st and 2nd derivatives) [24], [25]. For a given hour slot h the corresponding Ô¨Årst derivative of the variable z ‚àà{L, T} can be obtained by z‚Ä≤(h) = 0.5[z(h + 1) ‚àíz(h ‚àí1)]; with obvious analogues for the 2nd derivative. As previously mentioned (see Figure 2), the thinking here is to include the daily dynamics and 7 An overview of the predictors importance mn wk hr L(d-7) L(d-1) T(d) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 An overview of the predictors importance mn wk hr L(d-7) L(d-1) L‚Äò(d-1) L‚Äò‚Äò(d-1) L‚Äò(d-7) L‚Äò‚Äò(d-7) T(d) T‚Äò(d) T‚Äò‚Äò(d) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Figure 3: An overview of the importance of the predictors used in Model I (top), and Model II (bottom). The horizontal axis represents the predictors used in each model. The vertical axis illustrates their relative importance. 12 diÔ¨Äerent colors represent 12 diÔ¨Äerent models (one for each month, stating from the dark blue on the left for January 2011). Full description is followed in the text. trends of load and temperature proÔ¨Åles as a new predictor. The reasoning for doing so is that oftentimes the actual val- ues are not as important as the general underlying trends captured by the Ô¨Årst or second derivatives of the covariates. In other words, load value at any moment is inÔ¨Çuenced by the variations of the other attributes (namely, temperature proÔ¨Åles) prior to that moment. Including the derivatives is, in fact, a relatively simple and generic means to account for the recency eÔ¨Äect in the data.",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_16"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " the variations of the other attributes (namely, temperature proÔ¨Åles) prior to that moment. Including the derivatives is, in fact, a relatively simple and generic means to account for the recency eÔ¨Äect in the data. In comparison with most time-varying models, where the data is typically divided into subsets (based on thresholds), or a lagging window is optimized, our proposed approach is more straightforward and user-friendly. Figure 3 provides a comparison of the importance of the predictors used to train Model I and II. The importance was determined by summing up all the estimates over all weak learners in the ensemble [3]. Predictor with the highest value is the most important one. The bottom panel of Figure 3 highlights the fact that including the derivatives (especially the second derivatives) can indeed be helpful. As it become clear in Section 4, to predict the load values for every month of the year 2011, we train a new model using all the available data up to the beginning of that month (rolling window mechanism). Each shade of color in Figure 3, hence, corresponds to one experiment (dark blue on the left is for January 2011, and yellow, on the right for December 2011). A major contribution herein is the use of the singular value decomposition (SVD) to generate temperature scenarios T(d) for the target day d; it is done to determine the distribution (99 percentiles) of the load proÔ¨Åle in our proposed probabilistic forecasting models. A brief recapitulation to the singular value decomposition (SVD) technique is provided in below. 8 3.3. Singular value decomposition As mentioned before, time series data in energy systems usually comprises at least two distinct time scales. Recasting such quasi-periodic time series as a matrix such that each column represents the values for a single day, could be helpful in gaining a better understanding of the data. The advantage of this approach is twofold. Primarily, representing a matrix as an image provides a thorough overview of the evolution of data in a certain time span; it hence can lead to better appreciation of indistinct or subtle features. Second, it makes it possible to draw on numerically stable matrix decomposition methods, such as SVD to elucidate the underlying data structure [24]. The SVD technique is used herein to generate new temperature proÔ¨Åles (matrices). To be more precise, we recast",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_17"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " draw on numerically stable matrix decomposition methods, such as SVD to elucidate the underlying data structure [24]. The SVD technique is used herein to generate new temperature proÔ¨Åles (matrices). To be more precise, we recast one year‚Äôs worth of hourly temperature values as a matrix T ‚ààR24√ó365 such that every column corresponds to 24 hourly values of a day. Consequently, the matrix T can conveniently be represented by a low-rank approximation. More speciÔ¨Åcally, given any arbitrary matrix A ‚ààRh√ód, there exist orthogonal matrices U ‚ààRh√óh and V ‚ààRd√ód (both with orthonormal columns) such that: A = USVT = rX k=1 œÉkukvT k (5) where S is a diagonal matrix of the singular values œÉk, such that its non-zero elements œÉ1 ‚â•œÉ2 ‚â•. . . ‚â•œÉr ‚â•0 are positioned uniquely, in a descending order, on the main diagonal (S has the same size as A and r = min{h, d}). Furthermore, uk and vk, called the left and right singular vectors, denote the kth column of U and V, respectively [37]. If there are only a few dominant singular values (as it is the case for the temperature matrices, in Figure 4), the expansion of the matrix in (5) can be suÔ¨Éciently truncated after just the Ô¨Årst few K terms to yield AK, an adequate lower rank approximation of A: AK = K X k=1 œÉkukvT k where K < r. (6) To elaborate more, Figure 5 illustrates the Ô¨Årst three columns of uk (left) and vk (right) for temperature matrix for the year 2009. In geometrical terms, uk columns can be interpreted as the fundamental daily proÔ¨Åle and its successive increments; vk values represent the corresponding scaling factors for each uk proÔ¨Åles for each day. In other words, SVD decomposes the original time series into a linear combination of a number of (data-driven) orthonormal proÔ¨Åles, speciÔ¨Åed by uk columns; each proÔ¨Åle is then scaled up (or down) according to their corresponding weights in vk. For instance, u1 in the top left panel of Figure 5 strikingly resembles the averaged daily temperature proÔ¨Åle.",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_18"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " uk columns; each proÔ¨Åle is then scaled up (or down) according to their corresponding weights in vk. For instance, u1 in the top left panel of Figure 5 strikingly resembles the averaged daily temperature proÔ¨Åle. Moreover, its corresponding v1 proÔ¨Åle (top right panel) outlines the evolution of that proÔ¨Åle throughout the year; it is in agreement with the fact that temperature is higher in summer time (middle part of the graph). Recall that these proÔ¨Åles are weighted based on the magnitude of their corresponding singular values which are sorted in descending order from left to right (Figure 4). The most dominant ‚Äúcorrective‚Äù incremental proÔ¨Åle u2 and its corresponding coeÔ¨Écients v2 are displayed in the middle panel of Figure 5. This correction hence needs to be added to the Ô¨Årst proÔ¨Åle to get a better approximation, i.e., K = 2 in (6). Similar interpretations are valid for the third proÔ¨Åle (bottom panels) and so on. It is worth noting that vk proÔ¨Åles on the right-hand side of Figure 5 imply a distinct impression that temperatures are 5 10 15 20 200 400 600 800 1000 1200 1400 1600 Temperature: singular values 2005 2006 2007 2008 2009 2010 Figure 4: The evolution of the singular values of the temperature matrices over the years; it suggests that a reconstruction of rank-4 approximation would suÔ¨Éce, indicating that temperature is quite regular. 9 5 10 15 20 0.2 0.22 U1 100 200 300 0.02 0.04 0.06 V 1 5 10 15 20 -0.2 0 0.2 U2 100 200 300 -0.1 0 0.1 V 2 5 10 15 20 -0.2 0 0.2 0.4 U3 100 200 300 -0.1 0 0.1 0.2 V 3 Figure 5: SVD-based decomposition of hourly temperature data for 2009. On the left, there are the Ô¨Årst three uk columns; whereas the right",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_19"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "0.1 0 0.1 0.2 V 3 Figure 5: SVD-based decomposition of hourly temperature data for 2009. On the left, there are the Ô¨Årst three uk columns; whereas the right column displays their corresponding vk‚Äôs. less variable during the summer (middle parts of the graph). In the following Section, SVD is practiced to simulate pragmatic temperature scenarios, in a systematic and data-driven manner. The generated proÔ¨Åles are accordingly fed to Models I and II to obtain the probability distribution (99 quantiles) of the load values for every given hour. 3.4. Temperature scenario generation A common approach in probabilistic load forecasting problems is to vary the input (e.g., temperature proÔ¨Åles) to obtain a series of forecasts and combine them. One of the major challenges, however, is how to create realistic temperature proÔ¨Åles, as e.g., simply adding independent Gaussian noise to the hourly values of individual temperature curves results in some preposterously jagged proÔ¨Åles. In the literature, a number of solutions have been proposed to simulate temperature scenarios. In [42], it is proposed to combine diÔ¨Äerent weather station measurements to generate new temperature proÔ¨Åles. Nonetheless, it can be argued that normal weather scenarios cannot precisely be simulated by averaging the temperature proÔ¨Åles, as they tend to underestimate the peaks. Furthermore, such approaches are not resilient toward outliers, as even one instance can change the whole proÔ¨Åle as long as it takes part in generating new temperature scenarios; the performance of the forecasting model can consequently be diminished as a result of that. Worth noting that shifting the temperature data by one, two or even three days was initially used to generate temperature scenarios; it was later abandoned for obvious reasons. Some cumbersome approaches in terms of computational costs, such as Monte Carlo based methods are also popular, especially among utilities, to simulate thousands of temperature proÔ¨Åles - an approach which is used in scenario analysis in LTLF problems [21]. In [44], new temperature scenarios are generated, again, by averaging the temperature of stations 3 and 9 (GEFCom2014-L data was used). The reason for that is mentioned to be due to the existence of a good in-sample Ô¨Åt with a cubic relation between the temperature records of those two stations and the load data. Besides pre-processing there are not a lot of",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_20"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " data was used). The reason for that is mentioned to be due to the existence of a good in-sample Ô¨Åt with a cubic relation between the temperature records of those two stations and the load data. Besides pre-processing there are not a lot of solutions in the literature on how to generate robust and pragmatic input (temperature) scenarios. We herein propose a generic, data-driven and computationally eÔ¨Écient SVD-based approach for simulating tem- perature scenarios. SVD allows us to create hundreds of sensible and realistic temperature proÔ¨Åles for any target day d, in a fairly fast and robust manner. Figure 4 aÔ¨Érms the fact that the singular values œÉk of the temperature matrices over the years have not changed much; similar conclusions can be drawn for the left singular vectors uk. Furthermore, it is plain to see in Figure 5 that the vk coeÔ¨Écients implicate the variability of the temperature proÔ¨Åles throughout the year. Since the forecasting horizon is one month, hereafter temperature matrix is referred to a month worth of 10 -0.4 -0.2 0 0.2 0.4 0.6 0 1 2 3 4 5 6 7 8 9 10 Figure 6: Histogram of the v2 coeÔ¨Écients for June 2011 temperature data (30 values). Note that the distribution is approximately normal with zero mean and std(v2) ‚âà0.18. temperature data for the coming month (test data in Section 4). We, therefore, proceed with the following steps, to create temperature scenarios: 1. In the Ô¨Årst step, we estimate the corresponding standard deviation sk for a number of right singular vectors vk (v2, . . . , v4). Figure 6 illustrates the histogram for v2, which shows that s2 ‚âà0.18. Interestingly enough, similar experiments on all three vk columns (k ‚â•2) yield similar results; however, their contribution to the Ô¨Ånal rank K reconstructed proÔ¨Åle is scaled up or down by the magnitude of their corresponding singular values. 2. Next, for any given day d of the test month, for which a number of temperature scenarios are desired, we take the actual temperature proÔ¨Åle for that day T = T(d), Ô¨Ånd the corresponding vk coe",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_21"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " 2. Next, for any given day d of the test month, for which a number of temperature scenarios are desired, we take the actual temperature proÔ¨Åle for that day T = T(d), Ô¨Ånd the corresponding vk coeÔ¨Écients (v0 2, v0 3, v0 4); then blend them with zero-mean Gaussian noise: vn k = v0 k + N(0, œµ2). These perturbed vk coeÔ¨Écients are then used to generate a new (noisy) temperature scenario (reconstruct the matrix). 3. According to the scheme outlined above, for each actual daily proÔ¨Åle T(d), a hundred temperature scenarios are being generated. This new data set is then fed into the proposed prediction models; in the end, the forecasts are duly compared to the real load values. This enables us to determine the distribution of the hourly load values (99 quantiles) and compute the corresponding pinball error values (Section 4). Figure 7 illustrates an example of one hundred generated temperature proÔ¨Åles (Left), and their corresponding daily load proÔ¨Åles (Right). 4. For the sake of completeness, it should be noted that v1 is left unperturbed as this is a proxy of the average temperature on a particular day, for which the uncertainty is negligible. Similarly, there is not much to be gained from perturbing other right singular vectors (v5 etc), as their impact on the proÔ¨Åle is insigniÔ¨Åcant (their corresponding œÉk are small). In [25], a preliminary study was done to investigate how the eÔ¨Äect of the perturbation variance in temperature proÔ¨Åles T(d) propagates into uncertainty on the target load proÔ¨Åle L(d). 4. Experimental Results Probabilistic forecasts can provide more comprehensive information about future uncertainties that what point forecasts can do [18]. As previously mentioned, the aim of the GEFCom2014-L was to estimate the quantiles of the hourly load values for a utility in the US, on a rolling basis [19]; the forecasting horizon was one month. Furthermore, it was expected from the contestants to investigate the weather scenario generation methods for probabilistic load forecasting. The scenario-based probabilistic forecasting methodology proposed by [21] was used by two top 8 teams (Jingrui Xie, top 3",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_22"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " it was expected from the contestants to investigate the weather scenario generation methods for probabilistic load forecasting. The scenario-based probabilistic forecasting methodology proposed by [21] was used by two top 8 teams (Jingrui Xie, top 3; Bidong Liu, top 8) in GEFCom2014-L. Therefore, we opt to compare our results with similar works. A least absolute shrinkage and selection operator (LASSO) estimation based method is proposed in [44] for probabilistic load forecasting. This work is reported to outperform the methodology used by Bidong Liu to win a top 8 place in GEFCom2014-L. We hence have considered the proposed method in [44] as one of the benchmark models. 11 10-Jan 11-Jan 12-Jan 13-Jan 14-Jan 15-Jan 15 20 25 30 35 40 45 50 55 10-Jan 11-Jan 12-Jan 13-Jan 14-Jan 15-Jan 120 140 160 180 200 220 240 260 280 300 Figure 7: An illustrative example of 100 generated temperature scenarios for each day and their corresponding daily load proÔ¨Åles (obtained by Model II) for January 10-15, 2011. The spotted points are the actual values and the noise level is N(0, 0.09). These 100 diÔ¨Äerent load values for every hour are then used to calculate the 99 quantiles. The reported work uses a bivariate time-varying threshold autoregressive (AR) process for the hourly load YL,t and temperature YT ,t data (D = {L, T }). The time series of interest are accordingly modeled for i ‚ààD as follow: Yi,t = œÜi,0(t) + X j‚ààD X c‚ààCi,j X k‚ààIi,j,c œÜi, j,c,k(t) max{Yj,t‚àík, c} + œµi,t (7) where œÜi,0 are the time-varying intercepts and œÜi, j,c,k are time-varying autoregressive coeÔ¨Écients. Furthermore, Ci, j are the set of all considered thresholds for the load and temperature data (all set manually). Ii,j,c are the index sets of the",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_23"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": ",k are time-varying autoregressive coeÔ¨Écients. Furthermore, Ci, j are the set of all considered thresholds for the load and temperature data (all set manually). Ii,j,c are the index sets of the corresponding lags and œµi,t is the error term. The modelling process is done in three parts: 1) choice of thresholds Ci,j; 2) choice of lag sets Ii,j,c; and 3) time-varying structure of the coeÔ¨Écients. For further details see [44]. Another winning team (top 3) in the GEFCom2014-L was Jingrui Xie, who developed an integrated solution for probabilistic load forecasting [42]. Her proposed methodology consists of three parts: 1) pre-processing, which in- cludes data cleaning and temperature station selection; 2) forecasting (which focuses on the development of point forecasting models), forecast combination, and temperature scenario generation; and 3) post-processing, which em- bodies the residual simulation for probabilistic forecasting purposes. Inspired by the Vanilla model in [28], their core forecasting model is as follow: Lt = Œ≤0 + Œ≤1Trendt + Œ≤2Tt + Œ≤3T 2 t + Œ≤4T 3 t + Œ≤5Montht + Œ≤6Weekdayt + Œ≤7Hourst + Œ≤8HourstWeekdayt+ Œ≤9TtMontht + Œ≤10T 2 t Montht + Œ≤11T 3 t Montht + Œ≤12TtHourt + Œ≤13T 2 t Hourt + Œ≤14T 3 t Hourt (8) It is in fact a multiple linear regression (MLR) model with the following main and cross eÔ¨Äects: ‚Ä¢ Main eÔ¨Äects: a chronological Trendt variable, Ô¨Årst to third order polynomials of the temperature (Tt, T 2 t , T 3 t ), and a number of categorical variables namely, Month, weekday, and Hour. ‚Ä¢ Cross eÔ¨Äects: similar to [28], the cross eÔ¨Äects are incorporated using the multiplications of diÔ¨Äerent attributes such as HourtWeekdayt, TtMontht, T 2 t Montht, T 3 t Montht, TtHourt, T 2 t",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_24"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " are incorporated using the multiplications of diÔ¨Äerent attributes such as HourtWeekdayt, TtMontht, T 2 t Montht, T 3 t Montht, TtHourt, T 2 t Hourt, and T 3 t Hourt. In the next step, the residuals obtained from (8) is modeled using four diÔ¨Äerent techniques, namely unobserved component models (UCM), exponential smoothing models (ESM), three-layer feedforward neural network (NN), and autoregressive integrated moving average models (ARIMA). Four diÔ¨Äerent sets of point forecasts are accordingly generated by adding each set of residuals to the values obtained from the previous stage. The average of each four 12 Mar-20 Mar-21 Mar-22 Mar-23 Mar-24 Mar-25 Mar-26 Mar-27 Mar-28 Mar-29 Mar-30 60 80 100 120 140 160 180 200 220 240 1-th 25-th 50-th 75-th 99-th actual Figure 8: Probabilistic load forecast of 11 days from March 20, 2011 to March 30, 2011; the solid line in black is the actual value and the dash-dot lines are the forecast quantiles. value is the Ô¨Ånal estimation for the load forecast for every given hour. In the end, 10 diÔ¨Äerent temperature scenarios are generated according to [21], to obtain the 99 percentiles from the 10 point forecasts. The regression-based models are arguably vulnerable towards outliers, especially in the scenario based applica- tions. Due to the recency eÔ¨Äects, outliers, e.g., in temperature scenarios, can aÔ¨Äect the load forecasts for a longer time span. Our proposed SVD-based model is more robust and capable of handling this issue. As mentioned before, for every hour of the target day L(d), we obtain 100 diÔ¨Äerent load values (right panel in Figure 7). The results are then being used to determine the distribution of the hourly load values (99 diÔ¨Äerent quantiles) for any given hour by employing linear extrapolations [26]. An illustrative example of the predicted quantiles for 11 days, March 20-30, 2011, is provided",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_25"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " values (99 diÔ¨Äerent quantiles) for any given hour by employing linear extrapolations [26]. An illustrative example of the predicted quantiles for 11 days, March 20-30, 2011, is provided in Figure 8. Pinball loss is a comprehensive index to evaluate the reliability, sharpness, and calibration of the forecasts. It is an extensively used error measure for quantile forecasts in probabilistic forecasting problems. The performance of the forecasting models in GEFCom2014 was evaluated by the overall mean of the pinball loss values. Recall that the Month [44] [42] Model I Model II 1 9.88 11.87 3.43 3.23 2 9.54 10.93 3.24 2.89 3 7.79 8.44 2.69 2.56 4 4.89 4.50 2.53 2.30 5 5.96 7.27 3.33 3.50 6 5.86 6.99 4.98 4.66 7 7.66 9.05 3.63 3.42 8 10.70 11.26 8.71 8.58 9 6.28 5.49 4.46 4.05 10 5.20 3.36 2.97 2.76 11 6.38 5.90 3.50 3.59 12 8.99 9.73 3.57 3.36 Table 2: The left two columns are the reported results in [44], and [42]. The results of our proposed two diÔ¨Äerent models are presented on the right part. The results reported here are the average of 100 iterations (no. of trees is 100, and MaxNumSplits=128). 13 Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec -3 -2 -1 0 1 2 3 4 5 6 Diebold-Mariano Test Figure 9: Comparison of the two models I and II, using Diebold-Mariano test (h = 1 and k = 0). pinball loss function can be written as: Pinball(ÔøΩ",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_26"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " Diebold-Mariano Test Figure 9: Comparison of the two models I and II, using Diebold-Mariano test (h = 1 and k = 0). pinball loss function can be written as: Pinball(ÀÜyt,q, yt, q) = Ô£±Ô£¥Ô£¥Ô£≤Ô£¥Ô£¥Ô£≥ (1 ‚àíq)(ÀÜyt,q ‚àíyt) if ÀÜyt,q > yt q(yt ‚àíÀÜyt,q) if ÀÜyt,q ‚â§yt (9) where yt is the target hourly value of the load proÔ¨Åle from [19], and ÀÜyt,q is the corresponding forecast value at the q‚àíth quantile (q ‚àà{0.01, 0.02, . . . , 0.99}); it is obtained from one of the models speciÔ¨Åed above. To evaluate the full predictive densities, pinball scores obtained from (9) are averaged over the time horizon (99 quantiles for every hour, 24 hours of the day, n days of the month). A better forecast yield a lower pinball score. For more details on the pinball loss function and the evaluation methods used in GEFCom2014, see [19]. Table 2 contains the results of our proposed models along with two benchmark models. It is worth noting that all the data prior to the target month have taken part in the training of each model, i.e., the Ô¨Årst eleven months in 2011 were used for training a model to predict the load proÔ¨Åles in December 2011. Furthermore, the average of 100 diÔ¨Äerent hourly load values (right panel of Figure 7) is used as a proxy for the actual load value anytime needed; it is done because in the later days of the month, the earlier load proÔ¨Åles are needed in the form of L(d ‚àí1) or L(d ‚àí7). The results in Table 2, together with Figure 3 highlights the fact that including the derivatives (especially the 2nd derivatives) is indeed helpful in enhancing the performance of the forecasting model. To investigate further, Figure 9 contains the Diebold-Mariano test [17], [13] to determine whether two models are signiÔ¨Åcantly diÔ¨Äerent. These results were obtained by comparing",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_27"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " the forecasting model. To investigate further, Figure 9 contains the Diebold-Mariano test [17], [13] to determine whether two models are signiÔ¨Åcantly diÔ¨Äerent. These results were obtained by comparing the error between the median (q = 0.5) of the forecasts from two models and the actual values. The results are the average of 100 iterations, calculated according to (10). Suppose that the signiÔ¨Åcance level of the test is Œ± = 0.05. For a two-tailed test, therefore, the upper and lower tails would each be 0.025. Accordingly, the upper and lower z‚àívalues are 1.96 and ‚àí1.96, respectively [1]. The null hypothesis of no diÔ¨Äerence between the two models (forecasts) will be rejected if the computed Diebold- Mariano statistic falls outside the range of [-1.96 , 1.96]. Consistent with the results in Table 2, in February, June and September 2011, Models I and II are most signiÔ¨Åcantly diÔ¨Äerent. On the other hands, in August, where both models have the highest pinball score, the Diebold-Mariano (DM) test is low. Finally, DM tests in May and November 2011, are negative, as Model I outperforms Model II. We use the Diebold-Mariano test to determine whether forecasts are signiÔ¨Åcantly diÔ¨Äerent. Let ei1 and ei2 be the residuals for Model I and II, respectively (i ‚àà[1 : n]). n is the number of 14 data points, and k is the lagging variable [2]. di = |ei1|2 ‚àí|ei2|2 ¬Ød = 1 n n X i=1 di Œ≥k = 1 n n X i=k+1 (di ‚àí¬Ød)(di‚àík ‚àí¬Ød), n > k ‚â•1 DM = ¬Ød s [Œ≥0 + 2 h‚àí1 P k=1 Œ≥k]/n , h ‚â•1 (10) 5. Conclusions This paper proposes two generic scenario-based probabilistic load forecasting models using an ensemble of re- gression trees. An important distinction of the current work is in recasting quasi-periodic time series data as matrices",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_28"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "1 (10) 5. Conclusions This paper proposes two generic scenario-based probabilistic load forecasting models using an ensemble of re- gression trees. An important distinction of the current work is in recasting quasi-periodic time series data as matrices. The singular value decomposition technique is then used to generate temperature scenarios, in a robust and data-driven manner. In the second model, we extend the Ô¨Årst one by adding the Ô¨Årst and second derivatives of the non-deterministic attributes (temperature and historical load data). It was done to partially account for the recency eÔ¨Äects and interac- tions among the data. The empirical case studies performed on the data from the load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014-L) show how the proposed models outperform two benchmark scenario-based models with a similar set-up. Acknowledgment The authors gratefully acknowledge partial support by the Dutch NWO-TTW under project grant Smart Energy Management and Services in Buildings and Grids (SES-BE). The authors also would like to thank the anonymous reviewers for their fruitful comments. References [1] , a. Comparing predictive accuracy of two forecasts: The diebold-mariano test. http://www.phdeconomics.sssup.it/documents/ Lesson19.pdf. [2] , b. Diebold-mariano test statistic. https://nl.mathworks.com/matlabcentral/fileexchange/ 33979-diebold-mariano-test-statistic?focused=7267180&tab=function. [3] , . Estimates of predictor importance. https://nl.mathworks.com/help/stats/compactregressionensemble. predictorimportance.html. [4] Alobaidi, M.H., Chebana, F., Meguid, M.A., 2018. Robust ensemble learning framework for day-ahead forecasting of household based energy consumption. Applied Energy 212, 997‚Äì1012. [5] Breiman, L., 1996. Bagging predictors. Machine learning 24, 123‚Äì140. [6] Breiman, L., 2001. Random forests. Machine learning 45, 5‚Äì32. [7] Breiman, L., Friedman, J., Stone, C., Olshen, R., 1984. ClassiÔ¨Åcation and Regression Trees. The Wadsworth and Brooks-Cole statistics- probability series,",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_29"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "32. [7] Breiman, L., Friedman, J., Stone, C., Olshen, R., 1984. ClassiÔ¨Åcation and Regression Trees. The Wadsworth and Brooks-Cole statistics- probability series, Taylor & Francis. [8] Ceperic, E., Ceperic, V., Baric, A., 2013. A strategy for short-term load forecasting by support vector regression machines. IEEE Transactions on Power Systems 28, 4356‚Äì4364. [9] Che, J., Wang, J., 2014. Short-term load forecasting using a kernel-based support vector regression combination model. Applied energy 132, 602‚Äì609. [10] Chen, Y., Xu, P., Chu, Y., Li, W., Wu, Y., Ni, L., Bao, Y., Wang, K., 2017. Short-term electrical load forecasting using the support vector regression (svr) model to calculate the demand response baseline for oÔ¨Éce buildings. Applied Energy 195, 659‚Äì670. [11] Coelho, V.N., Coelho, I.M., Coelho, B.N., Reis, A.J., Enayatifar, R., Souza, M.J., GuimarÀúaes, F.G., 2016. A self-adaptive evolutionary fuzzy model for load forecasting problems on smart grid environment. Applied Energy 169, 567‚Äì584. [12] Craparo, E., Karatas, M., Singham, D.I., 2017. A robust optimization approach to hybrid microgrid operation using ensemble weather forecasts. Applied energy 201, 135‚Äì147. [13] Diebold, F.X., Lopez, J.A., 1996. 8 forecast evaluation and combination. Handbook of statistics 14, 241‚Äì268. [14] Fan, S., Chen, L., 2006. Short-term load forecasting based on an adaptive hybrid method. IEEE Transactions on Power Systems 21, 392‚Äì401. 15 [15] Freund, Y., Schapire, R., Abe, N., 1999. A short introduction to boosting. Journal-Japanese Society For ArtiÔ¨Åcial Intelligence 14, 1612. [16] Freund, Y., Schapire, R.E., et al., 1996. Experiments with a new boosting",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_30"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " short introduction to boosting. Journal-Japanese Society For ArtiÔ¨Åcial Intelligence 14, 1612. [16] Freund, Y., Schapire, R.E., et al., 1996. Experiments with a new boosting algorithm, in: Icml, Citeseer. pp. 148‚Äì156. [17] Harvey, D., Leybourne, S., Newbold, P., 1997. Testing the equality of prediction mean squared errors. International Journal of forecasting 13, 281‚Äì291. [18] Hong, T., Fan, S., 2016. Probabilistic electric load forecasting: A tutorial review. International Journal of Forecasting 32, 914‚Äì938. [19] Hong, T., Pinson, P., Fan, S., Zareipour, H., Troccoli, A., Hyndman, R.J., 2016. Probabilistic energy forecasting: Global energy forecasting competition 2014 and beyond. [20] Hong, T., Wang, P., 2014. Fuzzy interaction regression for short term load forecasting. Fuzzy optimization and decision making 13, 91‚Äì103. [21] Hong, T., Wilson, J., Xie, J., 2014. Long term probabilistic load forecasting and normalization with hourly information. IEEE Transactions on Smart Grid 5, 456‚Äì462. [22] Hyndman, R., Koehler, A.B., Ord, J.K., Snyder, R.D., 2008. Forecasting with exponential smoothing: the state space approach. Springer Science & Business Media. [23] Keshtkar, A., Arzanpour, S., 2017. An adaptive fuzzy logic system for residential energy management in smart grid environments. Applied Energy 186, 68‚Äì81. [24] Khoshrou, A., Dorsman, A.B., Pauwels, E.J., 2017. Svd-based visualisation and approximation for time series data in smart energy systems, in: Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), 2017 IEEE PES, IEEE. pp. 1‚Äì6. [25] Khoshrou, A., Pauwels, E.J., 2017. Propagating uncertainty in tree-based load forecasts, in: 2017 10th International Conference on Electrical and Electronics Engineering (E",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_31"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": "6. [25] Khoshrou, A., Pauwels, E.J., 2017. Propagating uncertainty in tree-based load forecasts, in: 2017 10th International Conference on Electrical and Electronics Engineering (ELECO), pp. 120‚Äì124. [26] Langford, E., 2006. Quartiles in elementary statistics. Journal of Statistics Education 14. [27] Li, S., Goel, L., Wang, P., 2016. An ensemble approach for short-term load forecasting by extreme learning machine. Applied Energy 170, 22‚Äì29. [28] Liu, B., Nowotarski, J., Hong, T., Weron, R., 2017. Probabilistic load forecasting via quantile regression averaging on sister forecasts. IEEE Transactions on Smart Grid 8, 730‚Äì737. [29] Loh, W.Y., 2011. ClassiÔ¨Åcation and regression trees. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1, 14‚Äì23. [30] Lusis, P., Khalilpour, K.R., Andrew, L., Liebman, A., 2017. Short-term residential load forecasting: Impact of calendar eÔ¨Äects and forecast granularity. Applied Energy 205, 654‚Äì669. [31] Mendes-Moreira, J., Soares, C., Jorge, A.M., Sousa, J.F.D., 2012. Ensemble approaches for regression: A survey. ACM Computing Surveys (CSUR) 45, 10. [32] Misiorek, A., Trueck, S., Weron, R., 2006. Point and interval forecasting of spot electricity prices: Linear vs. non-linear time series models. Studies in Nonlinear Dynamics & Econometrics 10. [33] Opitz, D., Maclin, R., 1999. Popular ensemble methods: An empirical study. Journal of artiÔ¨Åcial intelligence research 11, 169‚Äì198. [34] Papalexopoulos, A.D., Hesterberg, T.C., 1990. A regression-based approach to short-term system load forecasting. IEEE Transactions on Power Systems 5, 1535‚Äì1547. [35] Ramanathan, R., Engle, R., Granger, C.W., Vahid",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_32"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": ". A regression-based approach to short-term system load forecasting. IEEE Transactions on Power Systems 5, 1535‚Äì1547. [35] Ramanathan, R., Engle, R., Granger, C.W., Vahid-Araghi, F., Brace, C., 1997. Short-run forecasts of electricity loads and peaks. International journal of forecasting 13, 161‚Äì174. [36] Singh, P., Dwivedi, P., 2018. Integration of new evolutionary approach with artiÔ¨Åcial neural network for solving short term load forecast problem. Applied Energy 217, 537‚Äì549. [37] Strang, G., 1993. Introduction to linear algebra. volume 3. Wellesley-Cambridge Press Wellesley, MA. [38] Taieb, S.B., Hyndman, R.J., 2014. A gradient boosting approach to the kaggle load forecasting competition. International journal of forecasting 30, 382‚Äì394. [39] Wang, P., Liu, B., Hong, T., 2016. Electric load forecasting with recency eÔ¨Äect: A big data approach. International Journal of Forecasting 32, 585‚Äì597. [40] Wang, Y., Zhang, N., Tan, Y., Hong, T., Kirschen, D.S., Kang, C., 2018. Combining probabilistic load forecasts. IEEE Transactions on Smart Grid . [41] Xiao, L., Shao, W., Yu, M., Ma, J., Jin, C., 2017. Research and application of a hybrid wavelet neural network model with the improved cuckoo search algorithm for electrical power system forecasting. Applied energy 198, 203‚Äì222. [42] Xie, J., Hong, T., 2016. Gefcom2014 probabilistic electric load forecasting: An integrated solution with forecast combination and residual simulation. International Journal of Forecasting 32, 1012‚Äì1016. [43] Xie, J., Hong, T., 2018. Temperature scenario generation for probabilistic load forecasting. IEEE Transactions on Smart Grid 9, 1680‚Äì1687. [44] Ziel, F., Liu, B., 2016. Lasso estimation for gefcom2014 probabilistic electric load forecasting. International Journal of Forecasting 32, ",
    "token_count": 500,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_33"
  },
  {
    "id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea",
    "created_at": "2025-07-26T15:29:21.740909+00:00",
    "source_type": "external",
    "source_path": "https://pure.tudelft.nl/ws/files/56847223/Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "title": "Applied_Energy_LSBoosting_LoadForecast_002_.pdf",
    "text": " Smart Grid 9, 1680‚Äì1687. [44] Ziel, F., Liu, B., 2016. Lasso estimation for gefcom2014 probabilistic electric load forecasting. International Journal of Forecasting 32, 1029‚Äì1037. 16",
    "token_count": 58,
    "chunk_id": "f42cc57c-698b-45f6-970c-ef79ef7d6fea_34"
  }
]